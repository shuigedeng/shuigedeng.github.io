<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>jdk源码分析(7)-BlockingQueue</title>
      <link href="/2019/07/22/jdk-yuan-ma-fen-xi-7-blockingqueue/"/>
      <url>/2019/07/22/jdk-yuan-ma-fen-xi-7-blockingqueue/</url>
      
        <content type="html"><![CDATA[<h1 id="jdk源码分析-7-BlockingQueue"><a href="#jdk源码分析-7-BlockingQueue" class="headerlink" title="jdk源码分析(7)-BlockingQueue"></a>jdk源码分析(7)-BlockingQueue</h1><h2 id="一、BlockingQueue-概述"><a href="#一、BlockingQueue-概述" class="headerlink" title="一、BlockingQueue 概述"></a>一、BlockingQueue 概述</h2><p>说到阻塞队列想到的第一个应用场景可能就是生产者消费者模式了，如图所示；</p><p><img src="/images/20190722/5.png"></p><p>根据上图所示，明显在入队和出队的时候，会发生竞争；所以一种很自然的想法就是使用锁，而在 JDK 中也的确是通过锁来实现的；所以 <code>BlockingQueue</code> 的源码其实可以当成锁的应用示例来查看；同时 JDK 也为我们提供了多种不同功能的队列：</p><ul><li><strong>ArrayBlockingQueue</strong> ：基于数组的有界队列；</li><li><strong>LinkedBlockingQueue</strong> ：基于链表的无界队列（可以设置容量）；</li><li><strong>PriorityBlockingQueue</strong> ：基于二叉堆的无界优先级队列；</li><li><strong>DelayQueue</strong> ：基于 PriorityBlockingQueue 的无界延迟队列；</li><li><strong>SynchronousQueue</strong> ：无容量的阻塞队列（Executors.newCachedThreadPool() 中使用的队列）；</li><li><strong>LinkedTransferQueue</strong> ：基于链表的无界队列；</li></ul><p>接下来我们就对最常用的 <code>ArrayBlockingQueue</code> 和 <code>LinkedBlockingQueue</code> 进行分析；</p><h2 id="二、-ArrayBlockingQueue-源码分析"><a href="#二、-ArrayBlockingQueue-源码分析" class="headerlink" title="二、 ArrayBlockingQueue 源码分析"></a>二、 ArrayBlockingQueue 源码分析</h2><h3 id="1-结构概述"><a href="#1-结构概述" class="headerlink" title="1. 结构概述"></a>1. 结构概述</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ArrayBlockingQueue</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">AbstractQueue</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">BlockingQueue</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">,</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">Serializable</span> <span class="token punctuation">{</span>    <span class="token keyword">final</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span> items<span class="token punctuation">;</span>               <span class="token comment">// 容器数组</span>    <span class="token keyword">int</span> takeIndex<span class="token punctuation">;</span>                      <span class="token comment">// 出队索引</span>    <span class="token keyword">int</span> putIndex<span class="token punctuation">;</span>                       <span class="token comment">// 入队索引</span>    <span class="token keyword">int</span> count<span class="token punctuation">;</span>                          <span class="token comment">// 排队个数</span>    <span class="token keyword">final</span> <span class="token class-name">ReentrantLock</span> lock<span class="token punctuation">;</span>           <span class="token comment">// 全局锁</span>    <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">Condition</span> notEmpty<span class="token punctuation">;</span>   <span class="token comment">// 出队条件队列</span>    <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">Condition</span> notFull<span class="token punctuation">;</span>    <span class="token comment">// 入队条件队列</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span></code></pre><p><code>ArrayBlockingQueue</code> 的结构如图所示:</p><p><img src="/images/20190722/6.png"></p><p>如图所示，</p><ul><li><code>ArrayBlockingQueue</code> 的数组其实是一个逻辑上的环状结构，在添加、取出数据的时候，并没有像 <code>ArrayList</code> 一样发生数组元素的移动（当然除了 <code>removeAt(final int removeIndex)</code>）；</li><li>并且由 <code>takeIndex</code> 和 <code>putIndex</code> 指示读写位置；</li><li>在读写的时候还有两个读写条件队列；</li></ul><p>下面我们就读写操作，对源码简单分析</p><h3 id="2-入队"><a href="#2-入队" class="headerlink" title="2. 入队"></a>2. 入队</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">E</span> e<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>  <span class="token function">checkNotNull</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">final</span> <span class="token class-name">ReentrantLock</span> lock <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>lock<span class="token punctuation">;</span>  lock<span class="token punctuation">.</span><span class="token function">lockInterruptibly</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">try</span> <span class="token punctuation">{</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>count <span class="token operator">==</span> items<span class="token punctuation">.</span>length<span class="token punctuation">)</span>  <span class="token comment">// 当队列已满的时候放入 putCondition 条件队列</span>      notFull<span class="token punctuation">.</span><span class="token function">await</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       <span class="token function">enqueue</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 入队</span>  <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>    lock<span class="token punctuation">.</span><span class="token function">unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">enqueue</span><span class="token punctuation">(</span><span class="token class-name">E</span> x<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// assert lock.getHoldCount() == 1;</span>  <span class="token comment">// assert items[putIndex] == null;</span>  <span class="token keyword">final</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span> items <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>items<span class="token punctuation">;</span>  items<span class="token punctuation">[</span>putIndex<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">;</span>  <span class="token comment">// 插入队列</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">++</span>putIndex <span class="token operator">==</span> items<span class="token punctuation">.</span>length<span class="token punctuation">)</span> putIndex <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>  <span class="token comment">// 指针走一圈的时候复位</span>  count<span class="token operator">++</span><span class="token punctuation">;</span>  notEmpty<span class="token punctuation">.</span><span class="token function">signal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 唤醒 takeCondition 条件队列中等待的线程</span><span class="token punctuation">}</span></code></pre><h3 id="3-出队"><a href="#3-出队" class="headerlink" title="3. 出队"></a>3. 出队</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">E</span> <span class="token function">take</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>  <span class="token keyword">final</span> <span class="token class-name">ReentrantLock</span> lock <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>lock<span class="token punctuation">;</span>  lock<span class="token punctuation">.</span><span class="token function">lockInterruptibly</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">try</span> <span class="token punctuation">{</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>count <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment">// 当队列为空的时候，放入 takeCondition 条件</span>      notEmpty<span class="token punctuation">.</span><span class="token function">await</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">return</span> <span class="token function">dequeue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">// 出队</span>  <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>    lock<span class="token punctuation">.</span><span class="token function">unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">private</span> <span class="token class-name">E</span> <span class="token function">dequeue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// assert lock.getHoldCount() == 1;</span>  <span class="token comment">// assert items[takeIndex] != null;</span>  <span class="token keyword">final</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span> items <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>items<span class="token punctuation">;</span>  <span class="token annotation punctuation">@SuppressWarnings</span><span class="token punctuation">(</span><span class="token string">"unchecked"</span><span class="token punctuation">)</span>  <span class="token class-name">E</span> x <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">E</span><span class="token punctuation">)</span> items<span class="token punctuation">[</span>takeIndex<span class="token punctuation">]</span><span class="token punctuation">;</span>  <span class="token comment">// 取出元素</span>  items<span class="token punctuation">[</span>takeIndex<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">++</span>takeIndex <span class="token operator">==</span> items<span class="token punctuation">.</span>length<span class="token punctuation">)</span>    takeIndex <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>  count<span class="token operator">--</span><span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>itrs <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span>    itrs<span class="token punctuation">.</span><span class="token function">elementDequeued</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  notFull<span class="token punctuation">.</span><span class="token function">signal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 取出元素后，队列空出一位，所以唤醒 putCondition 中的线程</span>  <span class="token keyword">return</span> x<span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><h2 id="三、LinkedBlockingQueue-源码分析"><a href="#三、LinkedBlockingQueue-源码分析" class="headerlink" title="三、LinkedBlockingQueue 源码分析"></a>三、LinkedBlockingQueue 源码分析</h2><h3 id="1-结构概述-1"><a href="#1-结构概述-1" class="headerlink" title="1. 结构概述"></a>1. 结构概述</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LinkedBlockingQueue</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">AbstractQueue</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">BlockingQueue</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">,</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">Serializable</span> <span class="token punctuation">{</span>  <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token keyword">int</span> capacity<span class="token punctuation">;</span> <span class="token comment">// 默认 Integer.MAX_VALUE</span>  <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">AtomicInteger</span> count <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AtomicInteger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 容量</span>  <span class="token keyword">transient</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> head<span class="token punctuation">;</span>          <span class="token comment">// 头结点 head.item == null</span>  <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> last<span class="token punctuation">;</span>  <span class="token comment">// 尾节点 last.next == null</span>  <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">ReentrantLock</span> takeLock <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ReentrantLock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 出队锁</span>  <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">Condition</span> notEmpty <span class="token operator">=</span> takeLock<span class="token punctuation">.</span><span class="token function">newCondition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 出队条件</span>  <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">ReentrantLock</span> putLock <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ReentrantLock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">// 入队锁</span>  <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">Condition</span> notFull <span class="token operator">=</span> putLock<span class="token punctuation">.</span><span class="token function">newCondition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">// 入队条件</span>  <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>    <span class="token class-name">E</span> item<span class="token punctuation">;</span>    <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">;</span>    <span class="token class-name">Node</span><span class="token punctuation">(</span><span class="token class-name">E</span> x<span class="token punctuation">)</span> <span class="token punctuation">{</span> item <span class="token operator">=</span> x<span class="token punctuation">;</span> <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p><code>LinkedBlockingQueue</code> 的结构如图所示：</p><p><img src="/images/20190722/7.png"></p><p>如图所示，</p><ul><li><code>LinkedBlockingQueue</code> 其实就是一个简单的单向链表，其中头部元素的数据为空，尾部元素的 next 为空；</li><li>因为读写都有竞争，所以在头部和尾部分别有一把锁；同时还有对应的两个条件队列；</li></ul><p>下面我们就读写操作，对源码简单分析：</p><h3 id="2-入队-1"><a href="#2-入队-1" class="headerlink" title="2. 入队"></a>2. 入队</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">offer</span><span class="token punctuation">(</span><span class="token class-name">E</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>e <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">NullPointerException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">final</span> <span class="token class-name">AtomicInteger</span> count <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>count<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>count<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> capacity<span class="token punctuation">)</span> <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>  <span class="token comment">// 如果队列已满，直接返回失败</span>  <span class="token keyword">int</span> c <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> node <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>              <span class="token comment">// 将数据封装为节点</span>  <span class="token keyword">final</span> <span class="token class-name">ReentrantLock</span> putLock <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>putLock<span class="token punctuation">;</span>  putLock<span class="token punctuation">.</span><span class="token function">lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">try</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>count<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> capacity<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token function">enqueue</span><span class="token punctuation">(</span>node<span class="token punctuation">)</span><span class="token punctuation">;</span>                          <span class="token comment">// 入队</span>      c <span class="token operator">=</span> count<span class="token punctuation">.</span><span class="token function">getAndIncrement</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>c <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">&lt;</span> capacity<span class="token punctuation">)</span>                   <span class="token comment">// 如果队列未满，则继续唤醒 putCondition 条件队列</span>        notFull<span class="token punctuation">.</span><span class="token function">signal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>    putLock<span class="token punctuation">.</span><span class="token function">unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>c <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>           <span class="token comment">// 如果添加之前的容量为0，说明在出队的时候有竞争，则唤醒 takeCondition</span>    <span class="token function">signalNotEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">// 因为是两把锁，所以在唤醒 takeCondition的时候，还需要获取 takeLock</span>  <span class="token keyword">return</span> c <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">enqueue</span><span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> node<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// assert putLock.isHeldByCurrentThread();</span>  <span class="token comment">// assert last.next == null;</span>  last <span class="token operator">=</span> last<span class="token punctuation">.</span>next <span class="token operator">=</span> node<span class="token punctuation">;</span>  <span class="token comment">// 连接节点，并设置尾节点</span><span class="token punctuation">}</span></code></pre><h3 id="3-出队-1"><a href="#3-出队-1" class="headerlink" title="3. 出队"></a>3. 出队</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">E</span> <span class="token function">take</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>  <span class="token class-name">E</span> x<span class="token punctuation">;</span>  <span class="token keyword">int</span> c <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>  <span class="token keyword">final</span> <span class="token class-name">AtomicInteger</span> count <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>count<span class="token punctuation">;</span>  <span class="token keyword">final</span> <span class="token class-name">ReentrantLock</span> takeLock <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>takeLock<span class="token punctuation">;</span>  takeLock<span class="token punctuation">.</span><span class="token function">lockInterruptibly</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">try</span> <span class="token punctuation">{</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>count<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>   <span class="token comment">// 如果队列为空，则加入 takeCondition 条件队列</span>      notEmpty<span class="token punctuation">.</span><span class="token function">await</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    x <span class="token operator">=</span> <span class="token function">dequeue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token comment">// 出队</span>    c <span class="token operator">=</span> count<span class="token punctuation">.</span><span class="token function">getAndDecrement</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>c <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span>      notEmpty<span class="token punctuation">.</span><span class="token function">signal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment">// 如果队列还有剩余，则继续唤醒 takeCondition 条件队列</span>  <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>    takeLock<span class="token punctuation">.</span><span class="token function">unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>c <span class="token operator">==</span> capacity<span class="token punctuation">)</span>             <span class="token comment">// 如果取之前队列是满的，说明入队的时候有竞争，则唤醒 putCondition</span>    <span class="token function">signalNotFull</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>             <span class="token comment">// 同样注意是两把锁</span>  <span class="token keyword">return</span> x<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">private</span> <span class="token class-name">E</span> <span class="token function">dequeue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// assert takeLock.isHeldByCurrentThread();</span>  <span class="token comment">// assert head.item == null;</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> h <span class="token operator">=</span> head<span class="token punctuation">;</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> first <span class="token operator">=</span> h<span class="token punctuation">.</span>next<span class="token punctuation">;</span>  h<span class="token punctuation">.</span>next <span class="token operator">=</span> h<span class="token punctuation">;</span> <span class="token comment">// help GC   // 将next引用指向自己，则该节点不可达，在下一次GC的时候回收</span>  head <span class="token operator">=</span> first<span class="token punctuation">;</span>  <span class="token class-name">E</span> x <span class="token operator">=</span> first<span class="token punctuation">.</span>item<span class="token punctuation">;</span>  first<span class="token punctuation">.</span>item <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> x<span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><h2 id="四、ABQ、LBQ-对比"><a href="#四、ABQ、LBQ-对比" class="headerlink" title="四、ABQ、LBQ 对比"></a>四、ABQ、LBQ 对比</h2><p>根据以上的讲解，我们可以逐步分析出一些不同，以及在不同场景队列的选择：</p><ol><li>结构不同<ul><li>ABQ：基于数组，有界，一把锁；</li><li>LBQ：基于链表，无界，两把锁；</li></ul></li><li>内存分配<ul><li>ABQ：队列空间预先初始化，受堆空间影响小，稳定性高；</li><li>LBQ：队列空间动态变化，受对空间影响大，稳定性差；</li></ul></li><li>入队、出队效率<ul><li>ABQ：数据直接赋值，移除；队列空间重复使用，效率高；</li><li>LBQ：数据需要包装为节点；需开辟新空间，效率低；</li></ul></li><li>竞争方面<ul><li>ABQ：出入队共用一把锁，相互影响；竞争严重时效率低；</li><li>LBQ：出入队分用两把锁，互不影响；竞争严重时效率影响小；</li></ul></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JDK源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JDK源码分析 </tag>
            
            <tag> BlockingQueue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jdk源码分析(6)-ConcurrentHashMap</title>
      <link href="/2019/07/22/jdk-yuan-ma-fen-xi-6-concurrenthashmap/"/>
      <url>/2019/07/22/jdk-yuan-ma-fen-xi-6-concurrenthashmap/</url>
      
        <content type="html"><![CDATA[<h1 id="jdk源码分析-6-ConcurrentHashMap"><a href="#jdk源码分析-6-ConcurrentHashMap" class="headerlink" title="jdk源码分析(6)-ConcurrentHashMap"></a>jdk源码分析(6)-ConcurrentHashMap</h1><p>本文将主要讲述 <strong>JDK1.8 版本</strong> 的 ConcurrentHashMap，其内部结构和很多的哈希优化算法，都是和 JDK1.8 版本的 HashMap是一样的，所以在阅读本文之前，一定要先了解 HashMap。</p><h2 id="一、ConcurrentHashMap-结构概述"><a href="#一、ConcurrentHashMap-结构概述" class="headerlink" title="一、ConcurrentHashMap 结构概述"></a>一、ConcurrentHashMap 结构概述</h2><p>CHM 的源码有 6k 多行，包含的内容多，精巧，不容易理解；建议在查看源码的时候，可以首先把握整体结构脉络，对于一些精巧的优化，哈希技巧可以先了解目的就可以了，不用深究；对整体把握比较清楚后，在逐步分析，可以比较快速的看懂；</p><p>JDK1.8 版本中的 CHM，和 JDK1.7 版本的差别非常大，在查看资料的时候要注意区分，1.7 中主要是使用 <strong>Segment 分段锁</strong> 来解决并发问题的；而在 1.8 中则完全没有这些稍显臃肿的结构，其结构基本和 HashMap 是一样的，都是 数组 + 链表 + 红黑树，如图所示</p><p><img src="/images/20190722/1.png"></p><p>其主要区别就在 CHM 支持并发：</p><ul><li>使用 Unsafe 方法操作数组内部元素，保证可见性；（U.getObjectVolatile、U.compareAndSwapObject、U.putObjectVolatile）；</li><li>在更新和移动节点的时候，直接锁住对应的哈希桶，锁粒度更小，且动态扩展；</li><li>针对扩容慢操作进行优化，<ul><li>首先扩容过程的中，节点首先移动到过度表 <strong>nextTable</strong> ，所有节点移动完毕时替换散列表 <strong>table</strong>；</li><li>移动时先将散列表定长等分，然后逆序依次领取任务扩容，设置 <strong>sizeCtl</strong> 标记正在扩容；</li><li>移动完成一个哈希桶或者遇到空桶时，将其标记为 <strong>ForwardingNode</strong> 节点，并指向 <strong>nextTable</strong> ；</li><li>后有其他线程在操作哈希表时，遇到 <strong>ForwardingNode</strong> 节点，则先帮助扩容（继续领取分段任务），扩容完成后再继续之前的操作；</li></ul></li><li>优化哈希表计数器，采用 <strong>LongAdder、Striped64</strong> 类似思想；</li><li>以及大量的哈希算法优化和状态变量优化；</li></ul><p>以上讲的这些不太清楚也没有关系，主要是有一个印象，大致清楚 CHM 的实现方向，具体细节后面还会结合源码详细讲解；</p><h3 id="2-类定义和成员变量"><a href="#2-类定义和成员变量" class="headerlink" title="2. 类定义和成员变量"></a>2. 类定义和成员变量</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ConcurrentHashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span>              <span class="token keyword">extends</span> <span class="token class-name">AbstractMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">ConcurrentMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">,</span> <span class="token class-name">Serializable</span> <span class="token punctuation">{</span>  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> MAXIMUM_CAPACITY <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">30</span><span class="token punctuation">;</span>       <span class="token comment">// 最大容量</span>  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> DEFAULT_CAPACITY <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">;</span>            <span class="token comment">// 默认初始化容量</span>  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> DEFAULT_CONCURRENCY_LEVEL <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">;</span>   <span class="token comment">// 并发级别，为兼容1.7，实际未用</span>  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">float</span> LOAD_FACTOR <span class="token operator">=</span> <span class="token number">0.75f</span><span class="token punctuation">;</span>       <span class="token comment">// 固定负载系数，n - (n &gt;&gt;&gt; 2)</span>  <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> TREEIFY_THRESHOLD <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">;</span>               <span class="token comment">// 链表超过8时，转为红黑树</span>  <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> UNTREEIFY_THRESHOLD <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">;</span>             <span class="token comment">// 红黑树低于6时，转为链表</span>  <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> MIN_TREEIFY_CAPACITY <span class="token operator">=</span> <span class="token number">64</span><span class="token punctuation">;</span>           <span class="token comment">// 树化最小容量，容量小于64时，先扩容</span>  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> MIN_TRANSFER_STRIDE <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">;</span>    <span class="token comment">// 扩容时拆分散列表，最小步长</span>  <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">int</span> RESIZE_STAMP_BITS <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">;</span>              <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> MAX_RESIZERS <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span><span class="token number">32</span> <span class="token operator">-</span> RESIZE_STAMP_BITS<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>  <span class="token comment">// 可参与扩容的最大线程</span>  <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> NCPU <span class="token operator">=</span> <span class="token class-name">Runtime</span><span class="token punctuation">.</span><span class="token function">getRuntime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">availableProcessors</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// CPU 数</span>  <span class="token keyword">transient</span> <span class="token keyword">volatile</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> table<span class="token punctuation">;</span>                <span class="token comment">// 散列表</span>  <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token keyword">volatile</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> nextTable<span class="token punctuation">;</span>    <span class="token comment">// 扩容时的过度表</span>  <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token keyword">volatile</span> <span class="token keyword">int</span> sizeCtl<span class="token punctuation">;</span>              <span class="token comment">// 最重要的状态变量，下面详讲</span>  <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token keyword">volatile</span> <span class="token keyword">int</span> transferIndex<span class="token punctuation">;</span>        <span class="token comment">// 扩容进度指示</span>  <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token keyword">volatile</span> <span class="token keyword">long</span> baseCount<span class="token punctuation">;</span>              <span class="token comment">// 计数器，基础基数</span>  <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token keyword">volatile</span> <span class="token keyword">int</span> cellsBusy<span class="token punctuation">;</span>               <span class="token comment">// 计数器，并发标记</span>  <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token keyword">volatile</span> <span class="token class-name">CounterCell</span><span class="token punctuation">[</span><span class="token punctuation">]</span> counterCells<span class="token punctuation">;</span>  <span class="token comment">// 计数器，并发累计</span>  <span class="token keyword">public</span> <span class="token class-name">ConcurrentHashMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token punctuation">}</span>  <span class="token keyword">public</span> <span class="token class-name">ConcurrentHashMap</span><span class="token punctuation">(</span><span class="token keyword">int</span> initialCapacity<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>initialCapacity <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span>      <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IllegalArgumentException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> cap <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>initialCapacity <span class="token operator">&gt;=</span> <span class="token punctuation">(</span>MAXIMUM_CAPACITY <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">?</span>           MAXIMUM_CAPACITY <span class="token operator">:</span>           <span class="token function">tableSizeFor</span><span class="token punctuation">(</span>initialCapacity <span class="token operator">+</span> <span class="token punctuation">(</span>initialCapacity <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 注意这里不是0.75，后面介绍</span>    <span class="token keyword">this</span><span class="token punctuation">.</span>sizeCtl <span class="token operator">=</span> cap<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">public</span> <span class="token class-name">ConcurrentHashMap</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span> <span class="token keyword">extends</span> <span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token operator">?</span> <span class="token keyword">extends</span> <span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> m<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">this</span><span class="token punctuation">.</span>sizeCtl <span class="token operator">=</span> DEFAULT_CAPACITY<span class="token punctuation">;</span>    <span class="token function">putAll</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">ConcurrentHashMap</span><span class="token punctuation">(</span><span class="token keyword">int</span> initialCapacity<span class="token punctuation">,</span> <span class="token keyword">float</span> loadFactor<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">this</span><span class="token punctuation">(</span>initialCapacity<span class="token punctuation">,</span> loadFactor<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">public</span> <span class="token class-name">ConcurrentHashMap</span><span class="token punctuation">(</span><span class="token keyword">int</span> initialCapacity<span class="token punctuation">,</span> <span class="token keyword">float</span> loadFactor<span class="token punctuation">,</span> <span class="token keyword">int</span> concurrencyLevel<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token punctuation">(</span>loadFactor <span class="token operator">&gt;</span> <span class="token number">0.0f</span><span class="token punctuation">)</span> <span class="token operator">||</span> initialCapacity <span class="token operator">&lt;</span> <span class="token number">0</span> <span class="token operator">||</span> concurrencyLevel <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span>       <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IllegalArgumentException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>initialCapacity <span class="token operator">&lt;</span> concurrencyLevel<span class="token punctuation">)</span>   <span class="token comment">// Use at least as many bins</span>      initialCapacity <span class="token operator">=</span> concurrencyLevel<span class="token punctuation">;</span>   <span class="token comment">// as estimated threads</span>    <span class="token keyword">long</span> size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">long</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token keyword">long</span><span class="token punctuation">)</span>initialCapacity <span class="token operator">/</span> loadFactor<span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">// 注意这里的初始化</span>    <span class="token keyword">int</span> cap <span class="token operator">=</span> <span class="token punctuation">(</span>size <span class="token operator">&gt;=</span> <span class="token punctuation">(</span><span class="token keyword">long</span><span class="token punctuation">)</span>MAXIMUM_CAPACITY<span class="token punctuation">)</span> <span class="token operator">?</span> MAXIMUM_CAPACITY <span class="token operator">:</span> <span class="token function">tableSizeFor</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">this</span><span class="token punctuation">.</span>sizeCtl <span class="token operator">=</span> cap<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">}</span></code></pre><p>上面有几个重要的地方这里单独讲：</p><p><strong>LOAD_FACTOR:</strong></p><p>这里的负载系数，同 HashMap 等其他 Map 的系数有明显区别：</p><ul><li><p>通常的系数默认 0.75，可以由构造函数传入，当节点数 size 超过 loadFactor * capacity 时扩容；</p></li><li><p>而 CMH 的系数则固定 0.75（使用 <code>n - (n &gt;&gt;&gt; 2)</code> 表示），构造函数传入的系数只影响初始化容量，见第5个构造函数；</p></li><li><p>上面第二个构造函数中，<code>initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)</code>，这里居然不是使用的默认0.75，可以看作bug，也可视作优化，见</p><p><a href="https://bugs.openjdk.java.net/browse/JDK-8202422">https://bugs.openjdk.java.net/browse/JDK-8202422</a></p><p><a href="https://stackoverflow.com/questions/50083966/bug-parameter-initialcapacity-of-concurrenthashmaps-construct-method">https://stackoverflow.com/questions/50083966/bug-parameter-initialcapacity-of-concurrenthashmaps-construct-method</a></p></li></ul><p><strong>sizeCtl</strong>:</p><p>sizeCtl 是 CHM 中最重要的状态变量，其中包括很多中状态，这里先整体介绍帮助后面源码理解；</p><ul><li>sizeCtl = 0 ：初始值，还未指定初始容量；</li><li>sizeCtl &gt; 0 ：<ul><li>table 未初始化，表示初始化容量；</li><li>table 已初始化，表示扩容阈值（0.75n）；</li></ul></li><li>sizeCtl = -1 ：表示正在初始化；</li><li>sizeCtl &lt; -1 ：表示正在扩容，具体结构如图所示：</li></ul><p><img src="/images/20190722/2.png"></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token comment">/* * n=64 * Integer.numberOfLeadingZeros(n)＝26 * resizeStamp(64) = 0001 1010 | 1000 0000 0000 0000 = 1000 0000 0001 1010 */</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> <span class="token function">resizeStamp</span><span class="token punctuation">(</span><span class="token keyword">int</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">return</span> <span class="token class-name">Integer</span><span class="token punctuation">.</span><span class="token function">numberOfLeadingZeros</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token operator">|</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span>RESIZE_STAMP_BITS <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>所以 <code>resizeStamp(64) &lt;&lt; RESIZE_STAMP_SHIFT) + 2</code> ，表示扩容目标为 64，有一个线程正在扩容；</p><h3 id="3-Node-节点"><a href="#3-Node-节点" class="headerlink" title="3. Node 节点"></a>3. Node 节点</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>  <span class="token comment">// 哈希表普通节点</span>  <span class="token keyword">final</span> <span class="token keyword">int</span> hash<span class="token punctuation">;</span>  <span class="token keyword">final</span> <span class="token class-name">K</span> key<span class="token punctuation">;</span>  <span class="token keyword">volatile</span> <span class="token class-name">V</span> val<span class="token punctuation">;</span>  <span class="token keyword">volatile</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">;</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token function">find</span><span class="token punctuation">(</span><span class="token keyword">int</span> h<span class="token punctuation">,</span> <span class="token class-name">Object</span> k<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>   <span class="token comment">// 主要在扩容时，利用多态查询已转移节点</span><span class="token punctuation">}</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">class</span> <span class="token class-name">ForwardingNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>  <span class="token comment">// 标识扩容节点</span>  <span class="token keyword">final</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> nextTable<span class="token punctuation">;</span>  <span class="token comment">// 指向成员变量 ConcurrentHashMap.nextTable</span>  <span class="token class-name">ForwardingNode</span><span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">super</span><span class="token punctuation">(</span>MOVED<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// hash = -1，快速确定 ForwardingNode 节点</span>    <span class="token keyword">this</span><span class="token punctuation">.</span>nextTable <span class="token operator">=</span> tab<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token function">find</span><span class="token punctuation">(</span><span class="token keyword">int</span> h<span class="token punctuation">,</span> <span class="token class-name">Object</span> k<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">class</span> <span class="token class-name">TreeBin</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span> <span class="token comment">// 红黑树根节点</span>  <span class="token class-name">TreeBin</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> b<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">super</span><span class="token punctuation">(</span>TREEBIN<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// hash = -2，快速确定红黑树，</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span>  <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">class</span> <span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span> <span class="token punctuation">}</span> <span class="token comment">// 红黑树普通节点，其 hash 同 Node 普通节点 &gt; 0；</span></code></pre><h3 id="4-哈希计算"><a href="#4-哈希计算" class="headerlink" title="4. 哈希计算"></a>4. 哈希计算</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> MOVED     <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>          <span class="token comment">// hash for forwarding nodes</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> TREEBIN   <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">;</span>          <span class="token comment">// hash for roots of trees</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> RESERVED  <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">;</span>          <span class="token comment">// hash for transient reservations</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> HASH_BITS <span class="token operator">=</span> <span class="token number">0x7fffffff</span><span class="token punctuation">;</span>  <span class="token comment">// usable bits of normal node hash</span><span class="token comment">// 让高位16位，参与哈希桶定位运算的同时，保证 hash 为正</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> <span class="token function">spread</span><span class="token punctuation">(</span><span class="token keyword">int</span> h<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">return</span> <span class="token punctuation">(</span>h <span class="token operator">^</span> <span class="token punctuation">(</span>h <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> HASH_BITS<span class="token punctuation">;</span><span class="token punctuation">}</span>除此之外还有，tableSizeFor <span class="token operator">:</span> 将容量转为大于n，且最小的<span class="token number">2</span>的幂；除留余数法 ：hash <span class="token operator">%</span> length <span class="token operator">=</span> hash <span class="token operator">&amp;</span> <span class="token punctuation">(</span>length<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> ；扩容后哈希桶定位：<span class="token punctuation">(</span>e<span class="token punctuation">.</span>hash <span class="token operator">&amp;</span> oldCap<span class="token punctuation">)</span>，<span class="token number">0</span> <span class="token operator">-</span> 位置不变，<span class="token number">1</span> <span class="token operator">-</span> 原来的位置 <span class="token operator">+</span> oldCap；</code></pre><h3 id="5-哈希桶可见性"><a href="#5-哈希桶可见性" class="headerlink" title="5. 哈希桶可见性"></a>5. 哈希桶可见性</h3><p>我们都知道一个数组即使声明为 <code>volatile</code>，也只能保证这个数组引用本身的可见性，其内部元素的可见性是无法保证的，如果每次都加锁，则效率必然大大降低，在 CHM 中则使用 <code>Unsafe</code> 方法来保证：</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token function">tabAt</span><span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab<span class="token punctuation">,</span> <span class="token keyword">int</span> i<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">)</span><span class="token class-name">U</span><span class="token punctuation">.</span><span class="token function">getObjectVolatile</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">long</span><span class="token punctuation">)</span>i <span class="token operator">&lt;&lt;</span> ASHIFT<span class="token punctuation">)</span> <span class="token operator">+</span> ABASE<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">boolean</span> <span class="token function">casTabAt</span><span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab<span class="token punctuation">,</span> <span class="token keyword">int</span> i<span class="token punctuation">,</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> c<span class="token punctuation">,</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> v<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">return</span> <span class="token class-name">U</span><span class="token punctuation">.</span><span class="token function">compareAndSwapObject</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">long</span><span class="token punctuation">)</span>i <span class="token operator">&lt;&lt;</span> ASHIFT<span class="token punctuation">)</span> <span class="token operator">+</span> ABASE<span class="token punctuation">,</span> c<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">void</span> <span class="token function">setTabAt</span><span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab<span class="token punctuation">,</span> <span class="token keyword">int</span> i<span class="token punctuation">,</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> v<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">U</span><span class="token punctuation">.</span><span class="token function">putObjectVolatile</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">long</span><span class="token punctuation">)</span>i <span class="token operator">&lt;&lt;</span> ASHIFT<span class="token punctuation">)</span> <span class="token operator">+</span> ABASE<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><h2 id="6-initTable-方法"><a href="#6-initTable-方法" class="headerlink" title="6.initTable 方法"></a>6.initTable 方法</h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">initTable</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab<span class="token punctuation">;</span> <span class="token keyword">int</span> sc<span class="token punctuation">;</span>  <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>tab <span class="token operator">=</span> table<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">||</span> tab<span class="token punctuation">.</span>length <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>sc <span class="token operator">=</span> sizeCtl<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token keyword">yield</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 有其他线程在初始化</span>    <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">U</span><span class="token punctuation">.</span><span class="token function">compareAndSwapInt</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> SIZECTL<span class="token punctuation">,</span> sc<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 设置状态 -1</span>      <span class="token keyword">try</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>tab <span class="token operator">=</span> table<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">||</span> tab<span class="token punctuation">.</span>length <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>          <span class="token keyword">int</span> n <span class="token operator">=</span> <span class="token punctuation">(</span>sc <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">?</span> sc <span class="token operator">:</span> DEFAULT_CAPACITY<span class="token punctuation">;</span>  <span class="token comment">// 注意此时的 sizeCtl 表示初始容量，完毕后表示扩容阈值</span>          <span class="token annotation punctuation">@SuppressWarnings</span><span class="token punctuation">(</span><span class="token string">"unchecked"</span><span class="token punctuation">)</span>          <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> nt <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">new</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span><span class="token operator">?</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>          table <span class="token operator">=</span> tab <span class="token operator">=</span> nt<span class="token punctuation">;</span>          sc <span class="token operator">=</span> n <span class="token operator">-</span> <span class="token punctuation">(</span>n <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 同 0.75n</span>        <span class="token punctuation">}</span>      <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>        sizeCtl <span class="token operator">=</span> sc<span class="token punctuation">;</span>  <span class="token comment">// 注意这里没有 CAS 更新，这就是状态变量的高明了，因为前面设置了 -1，此时这里没有竞争</span>      <span class="token punctuation">}</span>      <span class="token keyword">break</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> tab<span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><h2 id="7-get-方法"><a href="#7-get-方法" class="headerlink" title="7.get 方法"></a>7.get 方法</h2><p>get 方法可能看代码不是很长，但是他却能 <strong>保证无锁状态下的内存一致性</strong> ，他的每一句代码都要仔细理解，多设想一下如果发生竞争会怎样，如此才能有所得；</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">V</span> <span class="token function">get</span><span class="token punctuation">(</span><span class="token class-name">Object</span> key<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab<span class="token punctuation">;</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e<span class="token punctuation">,</span> p<span class="token punctuation">;</span> <span class="token keyword">int</span> n<span class="token punctuation">,</span> eh<span class="token punctuation">;</span> <span class="token class-name">K</span> ek<span class="token punctuation">;</span>  <span class="token keyword">int</span> h <span class="token operator">=</span> <span class="token function">spread</span><span class="token punctuation">(</span>key<span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 计算 hash</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>tab <span class="token operator">=</span> table<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>n <span class="token operator">=</span> tab<span class="token punctuation">.</span>length<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span>  <span class="token comment">// 确保 table 已经初始化</span>    <span class="token comment">// 确保对应的哈希桶不为空，注意这里是 Volatile 语义获取；因为扩容的时候，是完全拷贝，所以只要不为空，则链表必然完整</span>    <span class="token punctuation">(</span>e <span class="token operator">=</span> <span class="token function">tabAt</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> <span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> h<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>eh <span class="token operator">=</span> e<span class="token punctuation">.</span>hash<span class="token punctuation">)</span> <span class="token operator">==</span> h<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>ek <span class="token operator">=</span> e<span class="token punctuation">.</span>key<span class="token punctuation">)</span> <span class="token operator">==</span> key <span class="token operator">||</span> <span class="token punctuation">(</span>ek <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> key<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>ek<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> e<span class="token punctuation">.</span>val<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment">// hash &lt; 0，则必然在扩容，原来位置的节点可能全部移动到 i + oldCap 位置，所以利用多态到 nextTable 中查找</span>    <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>eh <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">return</span> <span class="token punctuation">(</span>p <span class="token operator">=</span> e<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">?</span> p<span class="token punctuation">.</span>val <span class="token operator">:</span> <span class="token keyword">null</span><span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e <span class="token operator">=</span> e<span class="token punctuation">.</span>next<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 遍历链表</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>e<span class="token punctuation">.</span>hash <span class="token operator">==</span> h <span class="token operator">&amp;&amp;</span>        <span class="token punctuation">(</span><span class="token punctuation">(</span>ek <span class="token operator">=</span> e<span class="token punctuation">.</span>key<span class="token punctuation">)</span> <span class="token operator">==</span> key <span class="token operator">||</span> <span class="token punctuation">(</span>ek <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> key<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>ek<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> e<span class="token punctuation">.</span>val<span class="token punctuation">;</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><h2 id="8-putVal-方法"><a href="#8-putVal-方法" class="headerlink" title="8.putVal 方法"></a>8.putVal 方法</h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">final</span> <span class="token class-name">V</span> <span class="token function">putVal</span><span class="token punctuation">(</span><span class="token class-name">K</span> key<span class="token punctuation">,</span> <span class="token class-name">V</span> value<span class="token punctuation">,</span> <span class="token keyword">boolean</span> onlyIfAbsent<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>key <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">||</span> value <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">NullPointerException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">int</span> hash <span class="token operator">=</span> <span class="token function">spread</span><span class="token punctuation">(</span>key<span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// hash 计算</span>  <span class="token keyword">int</span> binCount <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>                   <span class="token comment">// 状态变量，主要表示查找链表节点数，最后判断是否转为红黑树</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab <span class="token operator">=</span> table<span class="token punctuation">;</span><span class="token punctuation">;</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> f<span class="token punctuation">;</span> <span class="token keyword">int</span> n<span class="token punctuation">,</span> i<span class="token punctuation">,</span> fh<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>tab <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">||</span> <span class="token punctuation">(</span>n <span class="token operator">=</span> tab<span class="token punctuation">.</span>length<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> tab <span class="token operator">=</span> <span class="token function">initTable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 初始化</span>    <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>f <span class="token operator">=</span> <span class="token function">tabAt</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> i <span class="token operator">=</span> <span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> hash<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token comment">// cas 获取哈希桶</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">casTabAt</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>hash<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// cas 更新，失败时继续循环更新</span>        <span class="token keyword">break</span><span class="token punctuation">;</span>  <span class="token comment">// no lock when adding to empty bin</span>    <span class="token punctuation">}</span>    <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>fh <span class="token operator">=</span> f<span class="token punctuation">.</span>hash<span class="token punctuation">)</span> <span class="token operator">==</span> MOVED<span class="token punctuation">)</span> tab <span class="token operator">=</span> <span class="token function">helpTransfer</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> f<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 正在扩容的时候，先帮助扩容</span>    <span class="token keyword">else</span> <span class="token punctuation">{</span>      <span class="token class-name">V</span> oldVal <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>      <span class="token keyword">synchronized</span> <span class="token punctuation">(</span>f<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 注意这里只锁定了一个哈希桶，所以比 1.7 中的 Segment 分段锁 粒度更低</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">tabAt</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token operator">==</span> f<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 确认该哈希桶是否已经移动</span>          <span class="token keyword">if</span> <span class="token punctuation">(</span>fh <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>   <span class="token comment">// hash &gt;=0 则必然是普通节点，直接遍历链表即可</span>            binCount <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e <span class="token operator">=</span> f<span class="token punctuation">;</span><span class="token punctuation">;</span> <span class="token operator">++</span>binCount<span class="token punctuation">)</span> <span class="token punctuation">{</span>              <span class="token class-name">K</span> ek<span class="token punctuation">;</span>              <span class="token keyword">if</span><span class="token punctuation">(</span>e<span class="token punctuation">.</span>hash <span class="token operator">==</span> hash <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>ek <span class="token operator">=</span> e<span class="token punctuation">.</span>key<span class="token punctuation">)</span> <span class="token operator">==</span> key <span class="token operator">||</span> <span class="token punctuation">(</span>ek <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> key<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>ek<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 查找成功</span>                oldVal <span class="token operator">=</span> e<span class="token punctuation">.</span>val<span class="token punctuation">;</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>onlyIfAbsent<span class="token punctuation">)</span> e<span class="token punctuation">.</span>val <span class="token operator">=</span> value<span class="token punctuation">;</span>                <span class="token keyword">break</span><span class="token punctuation">;</span>              <span class="token punctuation">}</span>              <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> pred <span class="token operator">=</span> e<span class="token punctuation">;</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e <span class="token operator">=</span> e<span class="token punctuation">.</span>next<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 查找失败时，直接在末尾添加新节点</span>                pred<span class="token punctuation">.</span>next <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>hash<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">break</span><span class="token punctuation">;</span>              <span class="token punctuation">}</span>            <span class="token punctuation">}</span>          <span class="token punctuation">}</span>          <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>f <span class="token keyword">instanceof</span> <span class="token class-name">TreeBin</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 树根节点</span>            <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> p<span class="token punctuation">;</span>            binCount <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">TreeBin</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">)</span>f<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">putTreeVal</span><span class="token punctuation">(</span>hash<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 红黑树查找</span>              oldVal <span class="token operator">=</span> p<span class="token punctuation">.</span>val<span class="token punctuation">;</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>onlyIfAbsent<span class="token punctuation">)</span> p<span class="token punctuation">.</span>val <span class="token operator">=</span> value<span class="token punctuation">;</span>            <span class="token punctuation">}</span>          <span class="token punctuation">}</span>        <span class="token punctuation">}</span>      <span class="token punctuation">}</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>binCount <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>binCount <span class="token operator">&gt;=</span> TREEIFY_THRESHOLD<span class="token punctuation">)</span> <span class="token function">treeifyBin</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 如果链表长度大于8，转为红黑树</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>oldVal <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span>          <span class="token keyword">return</span> oldVal<span class="token punctuation">;</span>        <span class="token keyword">break</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>  <span class="token function">addCount</span><span class="token punctuation">(</span><span class="token number">1L</span><span class="token punctuation">,</span> binCount<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 计数加一，注意这里使用的是计数器，普通的 Atomic 变量仍然可能称为性能瓶颈；</span>  <span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>其具体流程如图所示</p><p><img src="/iamges/20190722/3.png"></p><h2 id="9-扩容"><a href="#9-扩容" class="headerlink" title="9.扩容"></a>9.扩容</h2><p>扩容操作一直都是比较慢的操作，而 CHM 中巧妙的利用任务划分，使得多个线程可能同时参与扩容；另外扩容条件也有两个：</p><ul><li>有链表长度超过 8，但是容量小于 64 的时候，发生扩容；</li><li>节点数超过阈值的时候，发生扩容；</li></ul><p>其扩容的过程可描述为：</p><ul><li>首先扩容过程的中，节点首先移动到过度表 <strong>nextTable</strong> ，所有节点移动完毕时替换散列表 <strong>table</strong>；</li><li>移动时先将散列表定长等分，然后逆序依次领取任务扩容，设置 <strong>sizeCtl</strong> 标记正在扩容；</li><li>移动完成一个哈希桶或者遇到空桶时，将其标记为 <strong>ForwardingNode</strong> 节点，并指向 <strong>nextTable</strong> ；</li><li>后有其他线程在操作哈希表时，遇到 <strong>ForwardingNode</strong> 节点，则先帮助扩容（继续领取分段任务），扩容完成后再继续之前的操作；</li></ul><p>图形化表示如下：</p><p><img src="/iamges/20190722/4.png"></p><p>源码分析如下:</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token keyword">void</span> <span class="token function">transfer</span><span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab<span class="token punctuation">,</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> nextTab<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">int</span> n <span class="token operator">=</span> tab<span class="token punctuation">.</span>length<span class="token punctuation">,</span> stride<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>stride <span class="token operator">=</span> <span class="token punctuation">(</span>NCPU <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token punctuation">(</span>n <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">/</span> NCPU <span class="token operator">:</span> n<span class="token punctuation">)</span> <span class="token operator">&lt;</span> MIN_TRANSFER_STRIDE<span class="token punctuation">)</span>    stride <span class="token operator">=</span> MIN_TRANSFER_STRIDE<span class="token punctuation">;</span> <span class="token comment">// 根据 CPU 数量计算任务步长</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>nextTab <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>          <span class="token comment">// 初始化 nextTab</span>    <span class="token keyword">try</span> <span class="token punctuation">{</span>      <span class="token annotation punctuation">@SuppressWarnings</span><span class="token punctuation">(</span><span class="token string">"unchecked"</span><span class="token punctuation">)</span>      <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> nt <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">new</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span><span class="token operator">?</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span>n <span class="token operator">&lt;&lt;</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>  <span class="token comment">// 扩容一倍</span>      nextTab <span class="token operator">=</span> nt<span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Throwable</span> ex<span class="token punctuation">)</span> <span class="token punctuation">{</span>      sizeCtl <span class="token operator">=</span> <span class="token class-name">Integer</span><span class="token punctuation">.</span>MAX_VALUE<span class="token punctuation">;</span> <span class="token comment">// 发生 OOM 时，不再扩容</span>      <span class="token keyword">return</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    nextTable <span class="token operator">=</span> nextTab<span class="token punctuation">;</span>    transferIndex <span class="token operator">=</span> n<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">int</span> nextn <span class="token operator">=</span> nextTab<span class="token punctuation">.</span>length<span class="token punctuation">;</span>  <span class="token class-name">ForwardingNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> fwd <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ForwardingNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>nextTab<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 标记空桶，或已经转移完毕的桶</span>  <span class="token keyword">boolean</span> advance <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>  <span class="token keyword">boolean</span> finishing <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span> <span class="token comment">// to ensure sweep before committing nextTab</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> bound <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">;</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 逆向遍历扩容</span>    <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> f<span class="token punctuation">;</span> <span class="token keyword">int</span> fh<span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span>advance<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 向前获取哈希桶</span>      <span class="token keyword">int</span> nextIndex<span class="token punctuation">,</span> nextBound<span class="token punctuation">;</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">--</span>i <span class="token operator">&gt;=</span> bound <span class="token operator">||</span> finishing<span class="token punctuation">)</span>               <span class="token comment">// 已经取到哈希桶，或已完成时退出</span>        advance <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>      <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>nextIndex <span class="token operator">=</span> transferIndex<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 遍历到达头节点，已经没有待迁移的桶，线程准备退出</span>        i <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        advance <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>      <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">U</span><span class="token punctuation">.</span>compareAndSwapInt           <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> TRANSFERINDEX<span class="token punctuation">,</span> nextIndex<span class="token punctuation">,</span>            nextBound <span class="token operator">=</span> <span class="token punctuation">(</span>nextIndex <span class="token operator">&gt;</span> stride <span class="token operator">?</span> nextIndex <span class="token operator">-</span> stride <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 当前任务完成，领取下一批哈希桶</span>        bound <span class="token operator">=</span> nextBound<span class="token punctuation">;</span>        i <span class="token operator">=</span> nextIndex <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>  <span class="token comment">// 索引指向下一批哈希桶</span>        advance <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment">// i &lt; 0  ：表示扩容结束，已经没有待移动的哈希桶</span>    <span class="token comment">// i &gt;= n ：扩容结束，再次检查确认</span>    <span class="token comment">// i + n &gt;= nextn ： 在使用 nextTable 替换 table 时，有线程进入扩容就会出现</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> <span class="token number">0</span> <span class="token operator">||</span> i <span class="token operator">&gt;=</span> n <span class="token operator">||</span> i <span class="token operator">+</span> n <span class="token operator">&gt;=</span> nextn<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 完成扩容准备退出</span>      <span class="token keyword">int</span> sc<span class="token punctuation">;</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>finishing<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 两次检查，只有最后一个扩容线程退出时，才更新变量</span>        nextTable <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>        table <span class="token operator">=</span> nextTab<span class="token punctuation">;</span>        sizeCtl <span class="token operator">=</span> <span class="token punctuation">(</span>n <span class="token operator">&lt;&lt;</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token punctuation">(</span>n <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 0.75*2*n</span>        <span class="token keyword">return</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">U</span><span class="token punctuation">.</span><span class="token function">compareAndSwapInt</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> SIZECTL<span class="token punctuation">,</span> sc <span class="token operator">=</span> sizeCtl<span class="token punctuation">,</span> sc <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 扩容线程减一</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>sc <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token function">resizeStamp</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> RESIZE_STAMP_SHIFT<span class="token punctuation">)</span> <span class="token keyword">return</span><span class="token punctuation">;</span>  <span class="token comment">// 不是最后一个线程，直接退出</span>        finishing <span class="token operator">=</span> advance <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>   <span class="token comment">// 最后一个线程，再次检查</span>        i <span class="token operator">=</span> n<span class="token punctuation">;</span>                        <span class="token comment">// recheck before commit</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>f <span class="token operator">=</span> <span class="token function">tabAt</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>  <span class="token comment">// 当前节点为空，直接标记为 ForwardingNode，然后继续获取下一个桶</span>      advance <span class="token operator">=</span> <span class="token function">casTabAt</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">,</span> fwd<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">// 之前的线程已经完成该桶的移动，直接跳过，正常情况下自己的任务区间，不会出现 ForwardingNode 节点，</span>    <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>fh <span class="token operator">=</span> f<span class="token punctuation">.</span>hash<span class="token punctuation">)</span> <span class="token operator">==</span> MOVED<span class="token punctuation">)</span>  <span class="token comment">// 此处为极端条件下的健壮性检查</span>      advance <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">// already processed</span>    <span class="token comment">// 开始处理链表</span>    <span class="token keyword">else</span> <span class="token punctuation">{</span>      <span class="token comment">// 注意在 get 的时候，可以无锁获取，是因为扩容是全拷贝节点，完成后最后在更新哈希桶</span>      <span class="token comment">// 而在 put 的时候，是直接将节点加入尾部，获取修改其中的值，此时如果允许 put 操作，最后就会发生脏读，</span>      <span class="token comment">// 所以 put 和 transfer，需要竞争同一把锁，也就是对应的哈希桶，以保证内存一致性效果</span>      <span class="token keyword">synchronized</span> <span class="token punctuation">(</span>f<span class="token punctuation">)</span> <span class="token punctuation">{</span>         <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">tabAt</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token operator">==</span> f<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 确认锁定的是同一个桶</span>          <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> ln<span class="token punctuation">,</span> hn<span class="token punctuation">;</span>          <span class="token keyword">if</span> <span class="token punctuation">(</span>fh <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 正常节点</span>            <span class="token keyword">int</span> runBit <span class="token operator">=</span> fh <span class="token operator">&amp;</span> n<span class="token punctuation">;</span>  <span class="token comment">// hash &amp; n，判断扩容后的索引</span>            <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> lastRun <span class="token operator">=</span> f<span class="token punctuation">;</span>            <span class="token comment">// 此处找到链表最后扩容后处于同一位置的连续节点，这样最后一节就不用再一次复制了</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> p <span class="token operator">=</span> f<span class="token punctuation">.</span>next<span class="token punctuation">;</span> p <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">;</span> p <span class="token operator">=</span> p<span class="token punctuation">.</span>next<span class="token punctuation">)</span> <span class="token punctuation">{</span>              <span class="token keyword">int</span> b <span class="token operator">=</span> p<span class="token punctuation">.</span>hash <span class="token operator">&amp;</span> n<span class="token punctuation">;</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span>b <span class="token operator">!=</span> runBit<span class="token punctuation">)</span> <span class="token punctuation">{</span>                runBit <span class="token operator">=</span> b<span class="token punctuation">;</span>                lastRun <span class="token operator">=</span> p<span class="token punctuation">;</span>              <span class="token punctuation">}</span>            <span class="token punctuation">}</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>runBit <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>              ln <span class="token operator">=</span> lastRun<span class="token punctuation">;</span>              hn <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">else</span> <span class="token punctuation">{</span>              hn <span class="token operator">=</span> lastRun<span class="token punctuation">;</span>              ln <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token comment">// 依次将链表拆分成，lo、hi 两条链表，即位置不变的链表，和位置 + oldCap 的链表</span>            <span class="token comment">// 注意最后一节链表没有new，而是直接使用原来的节点</span>            <span class="token comment">// 同时链表的顺序也被打乱了，lastRun 到最后为正序，前面一节为逆序</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> p <span class="token operator">=</span> f<span class="token punctuation">;</span> p <span class="token operator">!=</span> lastRun<span class="token punctuation">;</span> p <span class="token operator">=</span> p<span class="token punctuation">.</span>next<span class="token punctuation">)</span> <span class="token punctuation">{</span>              <span class="token keyword">int</span> ph <span class="token operator">=</span> p<span class="token punctuation">.</span>hash<span class="token punctuation">;</span> <span class="token class-name">K</span> pk <span class="token operator">=</span> p<span class="token punctuation">.</span>key<span class="token punctuation">;</span> <span class="token class-name">V</span> pv <span class="token operator">=</span> p<span class="token punctuation">.</span>val<span class="token punctuation">;</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>ph <span class="token operator">&amp;</span> n<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>                ln <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>ph<span class="token punctuation">,</span> pk<span class="token punctuation">,</span> pv<span class="token punctuation">,</span> ln<span class="token punctuation">)</span><span class="token punctuation">;</span>              <span class="token keyword">else</span>                hn <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>ph<span class="token punctuation">,</span> pk<span class="token punctuation">,</span> pv<span class="token punctuation">,</span> hn<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token function">setTabAt</span><span class="token punctuation">(</span>nextTab<span class="token punctuation">,</span> i<span class="token punctuation">,</span> ln<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment">// 插入 lo 链表</span>            <span class="token function">setTabAt</span><span class="token punctuation">(</span>nextTab<span class="token punctuation">,</span> i <span class="token operator">+</span> n<span class="token punctuation">,</span> hn<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 插入 hi 链表</span>            <span class="token function">setTabAt</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> i<span class="token punctuation">,</span> fwd<span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment">// 哈希桶移动完成，标记为 ForwardingNode 节点</span>            advance <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>                <span class="token comment">// 继续获取下一个桶</span>          <span class="token punctuation">}</span>          <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>f <span class="token keyword">instanceof</span> <span class="token class-name">TreeBin</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// 拆分红黑树</span>            <span class="token class-name">TreeBin</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> t <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">TreeBin</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">)</span>f<span class="token punctuation">;</span>            <span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> lo <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">,</span> loTail <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span> <span class="token comment">// 为避免最后在反向遍历，先留头结点的引用，</span>            <span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> hi <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">,</span> hiTail <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span> <span class="token comment">// 因为顺序的链表，可以加速红黑树构造</span>            <span class="token keyword">int</span> lc <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> hc <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>  <span class="token comment">// 同样记录 lo，hi 链表的长度</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e <span class="token operator">=</span> t<span class="token punctuation">.</span>first<span class="token punctuation">;</span> e <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">;</span> e <span class="token operator">=</span> e<span class="token punctuation">.</span>next<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 中序遍历红黑树</span>              <span class="token keyword">int</span> h <span class="token operator">=</span> e<span class="token punctuation">.</span>hash<span class="token punctuation">;</span>              <span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> p <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> e<span class="token punctuation">.</span>key<span class="token punctuation">,</span> e<span class="token punctuation">.</span>val<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 构造红黑树节点</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>h <span class="token operator">&amp;</span> n<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>prev <span class="token operator">=</span> loTail<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>                  lo <span class="token operator">=</span> p<span class="token punctuation">;</span>                <span class="token keyword">else</span>                  loTail<span class="token punctuation">.</span>next <span class="token operator">=</span> p<span class="token punctuation">;</span>                loTail <span class="token operator">=</span> p<span class="token punctuation">;</span>                <span class="token operator">++</span>lc<span class="token punctuation">;</span>              <span class="token punctuation">}</span>              <span class="token keyword">else</span> <span class="token punctuation">{</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>prev <span class="token operator">=</span> hiTail<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>                  hi <span class="token operator">=</span> p<span class="token punctuation">;</span>                <span class="token keyword">else</span>                  hiTail<span class="token punctuation">.</span>next <span class="token operator">=</span> p<span class="token punctuation">;</span>                hiTail <span class="token operator">=</span> p<span class="token punctuation">;</span>                <span class="token operator">++</span>hc<span class="token punctuation">;</span>              <span class="token punctuation">}</span>            <span class="token punctuation">}</span>            <span class="token comment">// 判断是否需要将其转化为红黑树，同时如果只有一条链，那么就可以不用在构造</span>            ln <span class="token operator">=</span> <span class="token punctuation">(</span>lc <span class="token operator">&lt;=</span> UNTREEIFY_THRESHOLD<span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token function">untreeify</span><span class="token punctuation">(</span>lo<span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token punctuation">(</span>hc <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token keyword">new</span> <span class="token class-name">TreeBin</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>lo<span class="token punctuation">)</span> <span class="token operator">:</span> t<span class="token punctuation">;</span>            hn <span class="token operator">=</span> <span class="token punctuation">(</span>hc <span class="token operator">&lt;=</span> UNTREEIFY_THRESHOLD<span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token function">untreeify</span><span class="token punctuation">(</span>hi<span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token punctuation">(</span>lc <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token keyword">new</span> <span class="token class-name">TreeBin</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>hi<span class="token punctuation">)</span> <span class="token operator">:</span> t<span class="token punctuation">;</span>            <span class="token function">setTabAt</span><span class="token punctuation">(</span>nextTab<span class="token punctuation">,</span> i<span class="token punctuation">,</span> ln<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token function">setTabAt</span><span class="token punctuation">(</span>nextTab<span class="token punctuation">,</span> i <span class="token operator">+</span> n<span class="token punctuation">,</span> hn<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token function">setTabAt</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> i<span class="token punctuation">,</span> fwd<span class="token punctuation">)</span><span class="token punctuation">;</span>            advance <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>          <span class="token punctuation">}</span>        <span class="token punctuation">}</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h2 id="10-计数器"><a href="#10-计数器" class="headerlink" title="10.计数器"></a>10.计数器</h2><p>当获取 Map.size 的时候，如果使用 Atomic 变量，很容易导致过度竞争，产生性能瓶颈，所以 CHM 中使用了，计数器的方式：</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">long</span> n <span class="token operator">=</span> <span class="token function">sumCount</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>n <span class="token operator">&lt;</span> <span class="token number">0L</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token punctuation">(</span>n <span class="token operator">&gt;</span> <span class="token punctuation">(</span><span class="token keyword">long</span><span class="token punctuation">)</span><span class="token class-name">Integer</span><span class="token punctuation">.</span>MAX_VALUE<span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token class-name">Integer</span><span class="token punctuation">.</span>MAX_VALUE <span class="token operator">:</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token keyword">volatile</span> <span class="token class-name">CounterCell</span><span class="token punctuation">[</span><span class="token punctuation">]</span> counterCells<span class="token punctuation">;</span>  <span class="token comment">// 计数器</span><span class="token annotation punctuation">@sun</span><span class="token punctuation">.</span>misc<span class="token punctuation">.</span><span class="token class-name">Contended</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">class</span> <span class="token class-name">CounterCell</span> <span class="token punctuation">{</span>  <span class="token comment">// @sun.misc.Contended 避免伪缓存</span>  <span class="token keyword">volatile</span> <span class="token keyword">long</span> value<span class="token punctuation">;</span>  <span class="token class-name">CounterCell</span><span class="token punctuation">(</span><span class="token keyword">long</span> x<span class="token punctuation">)</span> <span class="token punctuation">{</span> value <span class="token operator">=</span> x<span class="token punctuation">;</span> <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">final</span> <span class="token keyword">long</span> <span class="token function">sumCount</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">CounterCell</span><span class="token punctuation">[</span><span class="token punctuation">]</span> as <span class="token operator">=</span> counterCells<span class="token punctuation">;</span> <span class="token class-name">CounterCell</span> a<span class="token punctuation">;</span>  <span class="token keyword">long</span> sum <span class="token operator">=</span> baseCount<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>as <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> as<span class="token punctuation">.</span>length<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// 累计计数</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>a <span class="token operator">=</span> as<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span>        sum <span class="token operator">+=</span> a<span class="token punctuation">.</span>value<span class="token punctuation">;</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> sum<span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><h2 id="11-总结"><a href="#11-总结" class="headerlink" title="11.总结"></a>11.总结</h2><ul><li>首先 JDK1.8 的 CHM，没有使用 Segment 分段锁，而是直接锁定单个哈希桶</li><li>对数组中的哈希桶使用 CAS 操作，保证其可见性</li><li>对扩容是用，任务拆分，多线程同时扩容的方式，加速扩容</li><li>对 size 使用计数器思想</li><li>CHM 中对状态变量的应用，使得很多操作都得以无所化进行</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JDK源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JDK源码分析 </tag>
            
            <tag> ConcurrentHashMap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jdk源码分析(5)-LinkedHashMap</title>
      <link href="/2019/07/19/jdk-yuan-ma-fen-xi-5-linkedhashmap/"/>
      <url>/2019/07/19/jdk-yuan-ma-fen-xi-5-linkedhashmap/</url>
      
        <content type="html"><![CDATA[<h1 id="jdk源码分析-5-LinkedHashMap"><a href="#jdk源码分析-5-LinkedHashMap" class="headerlink" title="jdk源码分析(5)-LinkedHashMap"></a>jdk源码分析(5)-LinkedHashMap</h1><p><code>LinkedHashMap</code>实质是<code>HashMap+LinkedList</code>，提供了顺序访问的功能</p><h2 id="一、整体结构"><a href="#一、整体结构" class="headerlink" title="一、整体结构"></a>一、整体结构</h2><h3 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LinkedHashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span><span class="token punctuation">}</span></code></pre><p><img src="/images/20190719/4.png"></p><p>从上述定义中也能看到<code>LinkedHashMap</code>其实就是继承了<code>HashMap</code>，并加了双向链表记录顺序，代码和结构本身不难，但是其中结构的组织，代码复用这些地方十分值得我们学习；具体结构如图所示</p><p><img src="/images/20190719/5.png"></p><h3 id="2-构造函数和成员变量"><a href="#2-构造函数和成员变量" class="headerlink" title="2. 构造函数和成员变量"></a>2. 构造函数和成员变量</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">LinkedHashMap</span><span class="token punctuation">(</span><span class="token keyword">int</span> initialCapacity<span class="token punctuation">,</span> <span class="token keyword">float</span> loadFactor<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">public</span> <span class="token class-name">LinkedHashMap</span><span class="token punctuation">(</span><span class="token keyword">int</span> initialCapacity<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">public</span> <span class="token class-name">LinkedHashMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">public</span> <span class="token class-name">LinkedHashMap</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span> <span class="token keyword">extends</span> <span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token operator">?</span> <span class="token keyword">extends</span> <span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> m<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">public</span> <span class="token class-name">LinkedHashMap</span><span class="token punctuation">(</span><span class="token keyword">int</span> initialCapacity<span class="token punctuation">,</span> <span class="token keyword">float</span> loadFactor<span class="token punctuation">,</span> <span class="token keyword">boolean</span> accessOrder<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token comment">/** * The iteration ordering method for this linked hash map: &lt;tt&gt;true&lt;/tt&gt; * for access-order, &lt;tt&gt;false&lt;/tt&gt; for insertion-order. * @serial */</span> <span class="token keyword">final</span> <span class="token keyword">boolean</span> accessOrder<span class="token punctuation">;</span></code></pre><p>可以看到<code>LinkedHashMap</code>的5个构造函数和<code>HashMap</code>的作用基本是一样的，都是初始化<code>initialCapacity</code>和<code>loadFactor</code>，但是多了一个<code>accessOrder</code>，这也是<code>LinkedHashMap</code>最重要的一个成员变量了；</p><ul><li>当<code>accessOrder</code>为<code>true</code>的时候，表示<code>LinkedHashMap</code>中记录的是访问顺序，也是就没放get一个元素的时候，这个元素就会被移到链表的尾部；</li><li>当<code>accessOrder</code>为<code>false</code>的时候，表示<code>LinkedHashMap</code>中记录的是插入顺序；</li></ul><h3 id="3-Entry关系"><a href="#3-Entry关系" class="headerlink" title="3. Entry关系"></a>3. Entry关系</h3><p><img src="/images/20190719/6.png"></p><p>扎眼一看可能会觉得<code>HashMap</code>体系的节点继承关系比较混乱；一所以这样设计因为</p><ul><li><code>LinkedHashMap</code>继承至<code>HashMap</code>，其中的节点同样有普通节点和树节点两种；并且树节点很少使用；</li><li>现在的设计中，树节点是可以完全复用的，但是<code>HashMap</code>的树节点，会浪费双向链表的能力；</li><li>如果不这样设计，则至少需要两条继承关系，并且需要抽出双向链表的能力，整个继承体系以及方法的复用会变得非常复杂，不利于扩展；</li></ul><h2 id="二、重要方法"><a href="#二、重要方法" class="headerlink" title="二、重要方法"></a>二、重要方法</h2><p>上面我们已经讲了<code>LinkedHashMap</code>就是<code>HashMap+链表</code>，所以我们只需要在结构有可能改变的地方加上链表的修改就可以了，结构可能改变的地方只要有<code>put/get/replace</code>，这里需要注意<strong>扩容的时候虽然结构改变了，但是节点的顺序仍然保持不变</strong>，所以扩容可以完全复用；</p><h3 id="1-put-方法"><a href="#1-put-方法" class="headerlink" title="1. put 方法"></a>1. put 方法</h3><ul><li>未找到key时，直接在最后添加一个节点</li></ul><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token function">newNode</span><span class="token punctuation">(</span><span class="token keyword">int</span> hash<span class="token punctuation">,</span> <span class="token class-name">K</span> key<span class="token punctuation">,</span> <span class="token class-name">V</span> value<span class="token punctuation">,</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">LinkedHashMap</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> p <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LinkedHashMap</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>hash<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">linkNodeLast</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> p<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token function">newTreeNode</span><span class="token punctuation">(</span><span class="token keyword">int</span> hash<span class="token punctuation">,</span> <span class="token class-name">K</span> key<span class="token punctuation">,</span> <span class="token class-name">V</span> value<span class="token punctuation">,</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> p <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>hash<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> next<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">linkNodeLast</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> p<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">linkNodeLast</span><span class="token punctuation">(</span><span class="token class-name">LinkedHashMap</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> p<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">LinkedHashMap</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> last <span class="token operator">=</span> tail<span class="token punctuation">;</span>  tail <span class="token operator">=</span> p<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>last <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>    head <span class="token operator">=</span> p<span class="token punctuation">;</span>  <span class="token keyword">else</span> <span class="token punctuation">{</span>    p<span class="token punctuation">.</span>before <span class="token operator">=</span> last<span class="token punctuation">;</span>    last<span class="token punctuation">.</span>after <span class="token operator">=</span> p<span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>上面代码很简单，但是很清晰的将添加节点到最后的逻辑抽离的出来；</p><h3 id="2-get-方法"><a href="#2-get-方法" class="headerlink" title="2. get 方法"></a>2. get 方法</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">V</span> <span class="token function">get</span><span class="token punctuation">(</span><span class="token class-name">Object</span> key<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e <span class="token operator">=</span> <span class="token function">getNode</span><span class="token punctuation">(</span><span class="token function">hash</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>accessOrder<span class="token punctuation">)</span>    <span class="token function">afterNodeAccess</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> e<span class="token punctuation">.</span>value<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">public</span> <span class="token class-name">V</span> <span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token class-name">Object</span> key<span class="token punctuation">,</span> <span class="token class-name">V</span> defaultValue<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e<span class="token punctuation">;</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e <span class="token operator">=</span> <span class="token function">getNode</span><span class="token punctuation">(</span><span class="token function">hash</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>   <span class="token keyword">return</span> defaultValue<span class="token punctuation">;</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>accessOrder<span class="token punctuation">)</span>   <span class="token function">afterNodeAccess</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">return</span> e<span class="token punctuation">.</span>value<span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>get方法主要也是通过<code>afterNodeAccess</code>来维护链表位置关系；<br>以上就是<code>LinkedHashMap</code>链表位置关系调整的主要方法了；</p><h3 id="3-containsValue-方法"><a href="#3-containsValue-方法" class="headerlink" title="3. containsValue 方法"></a>3. containsValue 方法</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">containsValue</span><span class="token punctuation">(</span><span class="token class-name">Object</span> value<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">LinkedHashMap</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e <span class="token operator">=</span> head<span class="token punctuation">;</span> e <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">;</span> e <span class="token operator">=</span> e<span class="token punctuation">.</span>after<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token class-name">V</span> v <span class="token operator">=</span> e<span class="token punctuation">.</span>value<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>v <span class="token operator">==</span> value <span class="token operator">||</span> <span class="token punctuation">(</span>value <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> value<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>可以看到<code>LinkedHashMap</code>还重写了<code>containsValue</code>，在<code>HashMap</code>中寻找value的时候，需要遍历所有节点，他是遍历每个哈希桶，在依次遍历桶中的链表；而在<code>LinkedHashMap</code>里面要遍历所有节点的时候，就可以直接通过双向链表进行遍历了；</p><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><ul><li>总体而言<code>LinkedHashMap</code>的代码比较简单</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JDK源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JDK源码分析 </tag>
            
            <tag> LinkedHashMap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jdk源码分析(4)-HashMap</title>
      <link href="/2019/07/19/jdk-yuan-ma-fen-xi-4-hashmap/"/>
      <url>/2019/07/19/jdk-yuan-ma-fen-xi-4-hashmap/</url>
      
        <content type="html"><![CDATA[<h1 id="jdk源码分析-4-HashMap"><a href="#jdk源码分析-4-HashMap" class="headerlink" title="jdk源码分析(4)-HashMap"></a>jdk源码分析(4)-HashMap</h1><h2 id="1-HashMap简介"><a href="#1-HashMap简介" class="headerlink" title="1.HashMap简介"></a><strong>1.HashMap简介</strong></h2><p><code>HashMap</code>作为我们最常用的数据类型，当然有必要了解一下他内部是实现细节。相比于 JDK7 在JDK8 中引入了红黑树以及hash计算等方面的优化，使得 JDK8 中的<code>HashMap</code>效率要高于以往的所有版本，本文会详细介绍相关的优化，但是主要还是写 JDK8 的源码</p><p>特点：</p><ul><li>HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。</li><li>HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口。</li><li>HashMap 的实现不是同步的，这意味着它不是线程安全的。<strong>它的key、value都可以为null</strong>。此外，HashMap中的<strong>映射不是有序的</strong> </li></ul><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">AbstractMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span>  <span class="token keyword">implements</span> <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">,</span> <span class="token class-name">Cloneable</span><span class="token punctuation">,</span> <span class="token class-name">Serializable</span> <span class="token punctuation">{</span><span class="token punctuation">}</span></code></pre><p><img src="/images/20190719/1.png"></p><p>可以看到<code>HashMap</code>是完全基于<code>Map</code>接口实现的，其中<code>AbstractMap</code>是<code>Map</code>接口的骨架实现，提供了<code>Map</code>接口的最小实现。<br><code>HashMap</code>看名字也能猜到，他是基于哈希表实现的（数组+链表+红黑树）：</p><p><img src="/images/20190719/2.png"></p><h3 id="2-构造函数和成员变量"><a href="#2-构造函数和成员变量" class="headerlink" title="2. 构造函数和成员变量"></a>2. 构造函数和成员变量</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token comment">/**     *使用默认的容量及装载因子构造一个空的HashMap     */</span>    <span class="token keyword">public</span> <span class="token class-name">HashMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>loadFactor <span class="token operator">=</span> DEFAULT_LOAD_FACTOR<span class="token punctuation">;</span>        threshold <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span>DEFAULT_INITIAL_CAPACITY <span class="token operator">*</span> DEFAULT_LOAD_FACTOR<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//计算下次需要调整大小的极限值</span>        table <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Entry</span><span class="token punctuation">[</span>DEFAULT_INITIAL_CAPACITY<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment">//根据默认容量（16）初始化table</span>        <span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token comment">/**     * 根据给定的初始容量的装载因子创建一个空的HashMap     * 初始容量小于0或装载因子小于等于0将报异常      */</span>    <span class="token keyword">public</span> <span class="token class-name">HashMap</span><span class="token punctuation">(</span><span class="token keyword">int</span> initialCapacity<span class="token punctuation">,</span> <span class="token keyword">float</span> loadFactor<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>initialCapacity <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span>            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IllegalArgumentException</span><span class="token punctuation">(</span><span class="token string">"Illegal initial capacity: "</span> <span class="token operator">+</span>                                               initialCapacity<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>initialCapacity <span class="token operator">&gt;</span> MAXIMUM_CAPACITY<span class="token punctuation">)</span><span class="token comment">//调整最大容量</span>            initialCapacity <span class="token operator">=</span> MAXIMUM_CAPACITY<span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>loadFactor <span class="token operator">&lt;=</span> <span class="token number">0</span> <span class="token operator">||</span> <span class="token class-name">Float</span><span class="token punctuation">.</span><span class="token function">isNaN</span><span class="token punctuation">(</span>loadFactor<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IllegalArgumentException</span><span class="token punctuation">(</span><span class="token string">"Illegal load factor: "</span> <span class="token operator">+</span>                                               loadFactor<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> capacity <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token comment">//设置capacity为大于initialCapacity且是2的幂的最小值</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>capacity <span class="token operator">&lt;</span> initialCapacity<span class="token punctuation">)</span>            capacity <span class="token operator">&lt;&lt;=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>loadFactor <span class="token operator">=</span> loadFactor<span class="token punctuation">;</span>        threshold <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span>capacity <span class="token operator">*</span> loadFactor<span class="token punctuation">)</span><span class="token punctuation">;</span>        table <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Entry</span><span class="token punctuation">[</span>capacity<span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token comment">/**     *根据指定容量创建一个空的HashMap     */</span>    <span class="token keyword">public</span> <span class="token class-name">HashMap</span><span class="token punctuation">(</span><span class="token keyword">int</span> initialCapacity<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">(</span>initialCapacity<span class="token punctuation">,</span> DEFAULT_LOAD_FACTOR<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//调用上面的构造方法，容量为指定的容量，装载因子是默认值</span>    <span class="token punctuation">}</span><span class="token comment">/**     *通过传入的map创建一个HashMap，容量为默认容量（16）和(map.zise()/DEFAULT_LOAD_FACTORY)+1的较大者，装载因子为默认值     */</span>    <span class="token keyword">public</span> <span class="token class-name">HashMap</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span> <span class="token keyword">extends</span> <span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token operator">?</span> <span class="token keyword">extends</span> <span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> m<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">(</span><span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>m<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> DEFAULT_LOAD_FACTOR<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>                      DEFAULT_INITIAL_CAPACITY<span class="token punctuation">)</span><span class="token punctuation">,</span> DEFAULT_LOAD_FACTOR<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">putAllForCreate</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token comment">// ==========================成员变量=======================</span><span class="token comment">/**     * 默认的初始容量，必须是2的幂。     */</span>    <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> DEFAULT_INITIAL_CAPACITY <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">;</span>    <span class="token comment">/**     * 最大容量（必须是2的幂且小于2的30次方，传入容量过大将被这个值替换）     */</span>    <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> MAXIMUM_CAPACITY <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">30</span><span class="token punctuation">;</span>    <span class="token comment">/**     * 默认装载因子      */</span>    <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">float</span> DEFAULT_LOAD_FACTOR <span class="token operator">=</span> <span class="token number">0.75f</span><span class="token punctuation">;</span>    <span class="token comment">/**     * 存储数据的Entry数组，长度是2的幂。      */</span>    <span class="token keyword">transient</span> <span class="token class-name">Entry</span><span class="token punctuation">[</span><span class="token punctuation">]</span> table<span class="token punctuation">;</span>    <span class="token comment">/**     * map中保存的键值对的数量     */</span>    <span class="token keyword">transient</span> <span class="token keyword">int</span> size<span class="token punctuation">;</span>    <span class="token comment">/**     * 需要调整大小的极限值（容量*装载因子）     */</span>    <span class="token keyword">int</span> threshold<span class="token punctuation">;</span>    <span class="token comment">/**     *装载因子     */</span>    <span class="token keyword">final</span> <span class="token keyword">float</span> loadFactor<span class="token punctuation">;</span>    <span class="token comment">/**     * map结构被改变的次数     */</span>    <span class="token keyword">transient</span> <span class="token keyword">volatile</span> <span class="token keyword">int</span> modCount<span class="token punctuation">;</span></code></pre><p><code>HashMap</code>一共有四个构造函数，其主要作用就是初始化<code>loadFactor</code>和<code>threshold</code>两个参数：</p><ul><li>threshold：扩容的阈值，当放入的键值对大于这个阈值的时候，就会发生扩容；</li><li>loadFactor：负载系数，用于控制阈值的大小，即<code>threshold = table.length * loadFactor</code>；默认情况下负载系数等于0.75，当它值越大时：哈希桶空余的位置越少，空间利用率越高，同时哈希冲突也就越严重，效率也就越低；相反它值越小时：空间利用率越低，效率越高；而0.75是对于空间和效率的一个平衡，通常情况下不建议修改；</li></ul><p>但是对于上面构造函数当中<code>this.threshold = tableSizeFor(initialCapacity);</code>，这里的阈值并没有乘以负载系数，是因为在构造函数当中哈希桶<code>table[]</code>还没有初始化，在往里put数据的时候才会初始化，而<code>tableSizeFor</code>是为了得到大于等于<code>initialCapacity</code>的最小的2的幂；</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">transient</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> table<span class="token punctuation">;</span>            <span class="token comment">// 哈希桶</span><span class="token keyword">transient</span> <span class="token class-name">Set</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> entrySet<span class="token punctuation">;</span> <span class="token comment">// 映射关系Set视图</span><span class="token keyword">transient</span> <span class="token keyword">int</span> size<span class="token punctuation">;</span>                     <span class="token comment">// 键值对的数量</span><span class="token keyword">transient</span> <span class="token keyword">int</span> modCount<span class="token punctuation">;</span>                 <span class="token comment">// 结构修改次数，用于实现fail-fast机制</span></code></pre><p>哈希桶的结构如下：</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>  <span class="token keyword">final</span> <span class="token keyword">int</span> hash<span class="token punctuation">;</span>       <span class="token comment">// 用于寻址，避免重复计算</span>  <span class="token keyword">final</span> <span class="token class-name">K</span> key<span class="token punctuation">;</span>  <span class="token class-name">V</span> value<span class="token punctuation">;</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">;</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">int</span> <span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">return</span> <span class="token class-name">Objects</span><span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span> <span class="token operator">^</span> <span class="token class-name">Objects</span><span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>其中<code>Node&lt;K,V&gt; next</code>还有一个<code>TreeNode</code>子类用于实现红黑树，需要注意的是这里的<code>hashCode()</code>所计算的hash值只用于在遍历的时候获取hash值，并非寻址所用hash；</p><h2 id="3-HashMap的内部类Entry-lt-K-V-gt"><a href="#3-HashMap的内部类Entry-lt-K-V-gt" class="headerlink" title="3.HashMap的内部类Entry<K,V>"></a>3.<strong>HashMap的内部类Entry&lt;K,V&gt;</strong></h2><p><strong>HashMap底层是用一个Entry&lt;k,v&gt;数组实现的，每个Entry对象的内部又含有指向下一个Entry类型对象的引用</strong></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>        <span class="token keyword">final</span> <span class="token class-name">K</span> key<span class="token punctuation">;</span>        <span class="token class-name">V</span> value<span class="token punctuation">;</span>        <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">;</span><span class="token comment">//对下一个节点的引用（看到链表的内容，结合定义的Entry数组，是不是想到了哈希表的拉链法实现？！）</span>        <span class="token keyword">final</span> <span class="token keyword">int</span> hash<span class="token punctuation">;</span><span class="token comment">//哈希值</span>        <span class="token class-name">Entry</span><span class="token punctuation">(</span><span class="token keyword">int</span> h<span class="token punctuation">,</span> <span class="token class-name">K</span> k<span class="token punctuation">,</span> <span class="token class-name">V</span> v<span class="token punctuation">,</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>            value <span class="token operator">=</span> v<span class="token punctuation">;</span>            next <span class="token operator">=</span> n<span class="token punctuation">;</span>            key <span class="token operator">=</span> k<span class="token punctuation">;</span>            hash <span class="token operator">=</span> h<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token class-name">K</span> <span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> key<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token class-name">V</span> <span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> value<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token class-name">V</span> <span class="token function">setValue</span><span class="token punctuation">(</span><span class="token class-name">V</span> newValue<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token class-name">V</span> oldValue <span class="token operator">=</span> value<span class="token punctuation">;</span>            value <span class="token operator">=</span> newValue<span class="token punctuation">;</span>            <span class="token keyword">return</span> oldValue<span class="token punctuation">;</span><span class="token comment">//返回的是之前的Value</span>        <span class="token punctuation">}</span>        <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">boolean</span> <span class="token function">equals</span><span class="token punctuation">(</span><span class="token class-name">Object</span> o<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token punctuation">(</span>o <span class="token keyword">instanceof</span> <span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">//先判断类型是否一致</span>                <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>            <span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span> e <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token punctuation">.</span><span class="token class-name">Entry</span><span class="token punctuation">)</span>o<span class="token punctuation">;</span>            <span class="token class-name">Object</span> k1 <span class="token operator">=</span> <span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token class-name">Object</span> k2 <span class="token operator">=</span> e<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// Key相等且Value相等则两个Entry相等</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>k1 <span class="token operator">==</span> k2 <span class="token operator">||</span> <span class="token punctuation">(</span>k1 <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> k1<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>k2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token class-name">Object</span> v1 <span class="token operator">=</span> <span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token class-name">Object</span> v2 <span class="token operator">=</span> e<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>v1 <span class="token operator">==</span> v2 <span class="token operator">||</span> <span class="token punctuation">(</span>v1 <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> v1<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>v2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment">// hashCode是Key的hashCode和Value的hashCode的异或的结果</span>        <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">int</span> <span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token punctuation">(</span>key<span class="token operator">==</span><span class="token keyword">null</span>   <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> key<span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">^</span>                   <span class="token punctuation">(</span>value<span class="token operator">==</span><span class="token keyword">null</span> <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> value<span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment">// 重写toString方法，是输出更清晰</span>        <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token class-name">String</span> <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"="</span> <span class="token operator">+</span> <span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment">/**         *当调用put(k,v)方法存入键值对时，如果k已经存在，则该方法被调用（为什么没有内容？）         */</span>        <span class="token keyword">void</span> <span class="token function">recordAccess</span><span class="token punctuation">(</span><span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> m<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token punctuation">}</span>        <span class="token comment">/**         * 当Entry被从HashMap中移除时被调用（为什么没有内容？）         */</span>        <span class="token keyword">void</span> <span class="token function">recordRemoval</span><span class="token punctuation">(</span><span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> m<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span></code></pre><h2 id="4-Hash表"><a href="#4-Hash表" class="headerlink" title="4.Hash表"></a>4.Hash表</h2><p>既然是Hash表，那么最重要的肯定是寻址了，在<code>HashMap</code>中采用的是<strong>除留余数法</strong>，即<code>table[hash % length]</code>，但是在现代CPU中求余是最慢的操作，所以人们想到一种巧妙的方法来优化它，即length为2的指数幂时，<code>hash % length = hash &amp; (length-1)</code>，所以在构造函数中需要使用<code>tableSizeFor(int cap)</code>来调整初始容量；</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token comment">/** * Returns a power of two size for the given target capacity. */</span><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> <span class="token function">tableSizeFor</span><span class="token punctuation">(</span><span class="token keyword">int</span> cap<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">int</span> n <span class="token operator">=</span> cap <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span>  n <span class="token operator">|=</span> n <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">;</span>  n <span class="token operator">|=</span> n <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">2</span><span class="token punctuation">;</span>  n <span class="token operator">|=</span> n <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">4</span><span class="token punctuation">;</span>  n <span class="token operator">|=</span> n <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">8</span><span class="token punctuation">;</span>  n <span class="token operator">|=</span> n <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">16</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> <span class="token punctuation">(</span>n <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token number">1</span> <span class="token operator">:</span> <span class="token punctuation">(</span>n <span class="token operator">&gt;=</span> MAXIMUM_CAPACITY<span class="token punctuation">)</span> <span class="token operator">?</span> MAXIMUM_CAPACITY <span class="token operator">:</span> n <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>首先这里要明确：</p><ul><li>2的幂的二进制是，1后面全是0</li><li>有效位都是1的二进制加1，就可以得到2的幂</li></ul><p>因为int是4个字节32位，所以最多只需要将高位的16位与低位的16位做或运算就可以得到2的幂，而<code>int n = cap - 1;</code>是为了避免cap本身就是2的幂的情况；这个算是真是厉害，看了很久才看明白</p><p><strong>计算 hash</strong></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> <span class="token function">hash</span><span class="token punctuation">(</span><span class="token class-name">Object</span> key<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">int</span> h<span class="token punctuation">;</span>  <span class="token keyword">return</span> <span class="token punctuation">(</span>key <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token punctuation">(</span>h <span class="token operator">=</span> key<span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">^</span> <span class="token punctuation">(</span>h <span class="token operator">&gt;&gt;&gt;</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>这里重新计算hash是因为在<code>hash &amp; (length-1)</code>计算下标的时候，<strong>实际只有hash的低位参与的运算容易产生hash冲突</strong>，所以用异或是高位的16位也参与运算，以减小hash冲突，要理解这里首先要明白，</p><ul><li>＆ 操作之后只会保留下都是1的有效位</li><li>length-1（2的<strong>n</strong>次方-1）实际上就是n和1</li><li>＆ 操作之后hash所保留下来的也只有低位的n个有效位，所以实际只有hash的低位参与了运算</li></ul><h2 id="5-重要方法讲解"><a href="#5-重要方法讲解" class="headerlink" title="5.重要方法讲解"></a>5.重要方法讲解</h2><p>对于<code>Map</code>而言最重要的当然是<code>Get</code>和<code>Put</code>等操作了，所以下面将介绍与之相关的操作；</p><h3 id="1-put方法"><a href="#1-put方法" class="headerlink" title="1. put方法"></a>1. put方法</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">V</span> <span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">K</span> key<span class="token punctuation">,</span> <span class="token class-name">V</span> value<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">return</span> <span class="token function">putVal</span><span class="token punctuation">(</span><span class="token function">hash</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */</span><span class="token keyword">final</span> <span class="token class-name">V</span> <span class="token function">putVal</span><span class="token punctuation">(</span><span class="token keyword">int</span> hash<span class="token punctuation">,</span> <span class="token class-name">K</span> key<span class="token punctuation">,</span> <span class="token class-name">V</span> value<span class="token punctuation">,</span> <span class="token keyword">boolean</span> onlyIfAbsent<span class="token punctuation">,</span> <span class="token keyword">boolean</span> evict<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab<span class="token punctuation">;</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> p<span class="token punctuation">;</span> <span class="token keyword">int</span> n<span class="token punctuation">,</span> i<span class="token punctuation">;</span>  <span class="token comment">// 如果没有初始化哈希桶，就使用resize初始化</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>tab <span class="token operator">=</span> table<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">||</span> <span class="token punctuation">(</span>n <span class="token operator">=</span> tab<span class="token punctuation">.</span>length<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>    n <span class="token operator">=</span> <span class="token punctuation">(</span>tab <span class="token operator">=</span> <span class="token function">resize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>length<span class="token punctuation">;</span>  <span class="token comment">// 如果hash对应的哈希槽是空的，就直接放入</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>p <span class="token operator">=</span> tab<span class="token punctuation">[</span>i <span class="token operator">=</span> <span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> hash<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>    tab<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">newNode</span><span class="token punctuation">(</span>hash<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">else</span> <span class="token punctuation">{</span>    <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e<span class="token punctuation">;</span> <span class="token class-name">K</span> k<span class="token punctuation">;</span>    <span class="token comment">// 如果已经存在key，就替换旧值</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>p<span class="token punctuation">.</span>hash <span class="token operator">==</span> hash <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>k <span class="token operator">=</span> p<span class="token punctuation">.</span>key<span class="token punctuation">)</span> <span class="token operator">==</span> key <span class="token operator">||</span> <span class="token punctuation">(</span>key <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> key<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      e <span class="token operator">=</span> p<span class="token punctuation">;</span>    <span class="token comment">// 如果已经是树节点，就用putTreeVal遍历树赋值</span>    <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>p <span class="token keyword">instanceof</span> <span class="token class-name">TreeNode</span><span class="token punctuation">)</span>      e <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">)</span>p<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">putTreeVal</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> tab<span class="token punctuation">,</span> hash<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">else</span> <span class="token punctuation">{</span>      <span class="token comment">// 遍历链表</span>      <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> binCount <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token punctuation">;</span> <span class="token operator">++</span>binCount<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment">// 遍历到最后一个节点也没有找到，就新增一个节点</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e <span class="token operator">=</span> p<span class="token punctuation">.</span>next<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>          p<span class="token punctuation">.</span>next <span class="token operator">=</span> <span class="token function">newNode</span><span class="token punctuation">(</span>hash<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment">// 如果链表长度大于8，则转换为红黑树</span>          <span class="token keyword">if</span> <span class="token punctuation">(</span>binCount <span class="token operator">&gt;=</span> TREEIFY_THRESHOLD <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">// -1 for 1st</span>            <span class="token function">treeifyBin</span><span class="token punctuation">(</span>tab<span class="token punctuation">,</span> hash<span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token comment">// 找到key对应的节点则跳出遍历</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>e<span class="token punctuation">.</span>hash <span class="token operator">==</span> hash <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>k <span class="token operator">=</span> e<span class="token punctuation">.</span>key<span class="token punctuation">)</span> <span class="token operator">==</span> key <span class="token operator">||</span> <span class="token punctuation">(</span>key <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> key<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>          <span class="token keyword">break</span><span class="token punctuation">;</span>        p <span class="token operator">=</span> e<span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment">// e是最后指向的节点，如果不为空，说明已经存在key，则替换旧的value</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>e <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// existing mapping for key</span>      <span class="token class-name">V</span> oldValue <span class="token operator">=</span> e<span class="token punctuation">.</span>value<span class="token punctuation">;</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>onlyIfAbsent <span class="token operator">||</span> oldValue <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>        e<span class="token punctuation">.</span>value <span class="token operator">=</span> value<span class="token punctuation">;</span>      <span class="token function">afterNodeAccess</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">return</span> oldValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>  <span class="token comment">// 新增节点时结构改变modCount加1</span>  <span class="token operator">++</span>modCount<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">++</span>size <span class="token operator">&gt;</span> threshold<span class="token punctuation">)</span>    <span class="token function">resize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">afterNodeInsertion</span><span class="token punctuation">(</span>evict<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>具体过程如图所示:</p><p><img src="/images/20190719/3.png"></p><h3 id="2-resize方法"><a href="#2-resize方法" class="headerlink" title="2. resize方法"></a>2. resize方法</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">final</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">resize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> oldTab <span class="token operator">=</span> table<span class="token punctuation">;</span>  <span class="token keyword">int</span> oldCap <span class="token operator">=</span> <span class="token punctuation">(</span>oldTab <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> oldTab<span class="token punctuation">.</span>length<span class="token punctuation">;</span>  <span class="token keyword">int</span> oldThr <span class="token operator">=</span> threshold<span class="token punctuation">;</span>  <span class="token keyword">int</span> newCap<span class="token punctuation">,</span> newThr <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>oldCap <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment">// 如果hash桶已经完成初始化，并且已达最大容量，则直接返回</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>oldCap <span class="token operator">&gt;=</span> MAXIMUM_CAPACITY<span class="token punctuation">)</span> <span class="token punctuation">{</span>      threshold <span class="token operator">=</span> <span class="token class-name">Integer</span><span class="token punctuation">.</span>MAX_VALUE<span class="token punctuation">;</span>      <span class="token keyword">return</span> oldTab<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment">// 如果扩大2倍没有超过最大容量，则扩大两倍</span>    <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>newCap <span class="token operator">=</span> oldCap <span class="token operator">&lt;&lt;</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token generics"><span class="token punctuation">&lt;</span> MAXIMUM_CAPACITY <span class="token operator">&amp;</span><span class="token operator">&amp;</span> oldCap <span class="token punctuation">&gt;</span></span><span class="token operator">=</span> DEFAULT_INITIAL_CAPACITY<span class="token punctuation">)</span>      newThr <span class="token operator">=</span> oldThr <span class="token operator">&lt;&lt;</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">// double threshold</span>  <span class="token punctuation">}</span>  <span class="token comment">// 如果threshold已经初始化，则初始化容量为threshold</span>  <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>oldThr <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span>      <span class="token comment">// initial capacity was placed in threshold</span>    newCap <span class="token operator">=</span> oldThr<span class="token punctuation">;</span>  <span class="token comment">// 如果threshold和哈希桶都没有初始化，则使用默认值</span>  <span class="token keyword">else</span> <span class="token punctuation">{</span>                    <span class="token comment">// zero initial threshold signifies using defaults</span>    newCap <span class="token operator">=</span> DEFAULT_INITIAL_CAPACITY<span class="token punctuation">;</span>    newThr <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span>DEFAULT_LOAD_FACTOR <span class="token operator">*</span> DEFAULT_INITIAL_CAPACITY<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token comment">// 重新计算threshold</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>newThr <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">float</span> ft <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span>newCap <span class="token operator">*</span> loadFactor<span class="token punctuation">;</span>    newThr <span class="token operator">=</span> <span class="token punctuation">(</span>newCap <span class="token operator">&lt;</span> MAXIMUM_CAPACITY <span class="token operator">&amp;&amp;</span> ft <span class="token operator">&lt;</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span>MAXIMUM_CAPACITY <span class="token operator">?</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span>ft <span class="token operator">:</span> <span class="token class-name">Integer</span><span class="token punctuation">.</span>MAX_VALUE<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  threshold <span class="token operator">=</span> newThr<span class="token punctuation">;</span>  <span class="token annotation punctuation">@SuppressWarnings</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"rawtypes"</span><span class="token punctuation">,</span><span class="token string">"unchecked"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> newTab <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">new</span> <span class="token class-name">Node</span><span class="token punctuation">[</span>newCap<span class="token punctuation">]</span><span class="token punctuation">;</span>  table <span class="token operator">=</span> newTab<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>oldTab <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> oldCap<span class="token punctuation">;</span> <span class="token operator">++</span>j<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e<span class="token punctuation">;</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e <span class="token operator">=</span> oldTab<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        oldTab<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>        <span class="token comment">// 如果只有一个节点，则直接重新放置节点</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>e<span class="token punctuation">.</span>next <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>          newTab<span class="token punctuation">[</span>e<span class="token punctuation">.</span>hash <span class="token operator">&amp;</span> <span class="token punctuation">(</span>newCap <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> e<span class="token punctuation">;</span>        <span class="token comment">// 如果是树节点，则将红黑树拆分后，重新放置</span>        <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>e <span class="token keyword">instanceof</span> <span class="token class-name">TreeNode</span><span class="token punctuation">)</span>          <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">)</span>e<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> newTab<span class="token punctuation">,</span> j<span class="token punctuation">,</span> oldCap<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">// 将链表拆分为原位置和高位置两条链表</span>        <span class="token keyword">else</span> <span class="token punctuation">{</span> <span class="token comment">// preserve order</span>          <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> loHead <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">,</span> loTail <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>          <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> hiHead <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">,</span> hiTail <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>          <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">;</span>          <span class="token keyword">do</span> <span class="token punctuation">{</span>            next <span class="token operator">=</span> e<span class="token punctuation">.</span>next<span class="token punctuation">;</span>            <span class="token comment">// 节点重新放置后在原位置</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e<span class="token punctuation">.</span>hash <span class="token operator">&amp;</span> oldCap<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span>loTail <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>                loHead <span class="token operator">=</span> e<span class="token punctuation">;</span>              <span class="token keyword">else</span>                loTail<span class="token punctuation">.</span>next <span class="token operator">=</span> e<span class="token punctuation">;</span>              loTail <span class="token operator">=</span> e<span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token comment">// 节点重新放置后位置+oldCap</span>            <span class="token keyword">else</span> <span class="token punctuation">{</span>              <span class="token keyword">if</span> <span class="token punctuation">(</span>hiTail <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>                hiHead <span class="token operator">=</span> e<span class="token punctuation">;</span>              <span class="token keyword">else</span>                hiTail<span class="token punctuation">.</span>next <span class="token operator">=</span> e<span class="token punctuation">;</span>              hiTail <span class="token operator">=</span> e<span class="token punctuation">;</span>            <span class="token punctuation">}</span>          <span class="token punctuation">}</span> <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e <span class="token operator">=</span> next<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment">// 放置低位置链表</span>          <span class="token keyword">if</span> <span class="token punctuation">(</span>loTail <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            loTail<span class="token punctuation">.</span>next <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>            newTab<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> loHead<span class="token punctuation">;</span>          <span class="token punctuation">}</span>          <span class="token comment">// 放置高位置链表</span>          <span class="token keyword">if</span> <span class="token punctuation">(</span>hiTail <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            hiTail<span class="token punctuation">.</span>next <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>            newTab<span class="token punctuation">[</span>j <span class="token operator">+</span> oldCap<span class="token punctuation">]</span> <span class="token operator">=</span> hiHead<span class="token punctuation">;</span>          <span class="token punctuation">}</span>        <span class="token punctuation">}</span>      <span class="token punctuation">}</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> newTab<span class="token punctuation">}</span></code></pre><p>上面的扩容过程需要注意的是，因为哈希桶长度总是2的幂，所以在扩大两倍之后原来的节点只可能在原位置或者原位置+oldCap，具体判断是通过<code>(e.hash &amp; oldCap) == 0</code>实现的；</p><ul><li>之前将了 ＆ 操作只保留了都是1的有效位</li><li>oldCap 是2的n次方，实际也就是在n+1的位置为1，其余地方为0</li><li>因为扩容是扩大2倍，实际上也就是在hash上取了 n+1位，那么就只需要判断多取的第n+1位是否为0</li></ul><h3 id="3-get方法"><a href="#3-get方法" class="headerlink" title="3. get方法"></a>3. get方法</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">V</span> <span class="token function">get</span><span class="token punctuation">(</span><span class="token class-name">Object</span> key<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> e<span class="token punctuation">;</span>  <span class="token keyword">return</span> <span class="token punctuation">(</span>e <span class="token operator">=</span> <span class="token function">getNode</span><span class="token punctuation">(</span><span class="token function">hash</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">?</span> <span class="token keyword">null</span> <span class="token operator">:</span> e<span class="token punctuation">.</span>value<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">final</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token function">getNode</span><span class="token punctuation">(</span><span class="token keyword">int</span> hash<span class="token punctuation">,</span> <span class="token class-name">Object</span> key<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">[</span><span class="token punctuation">]</span> tab<span class="token punctuation">;</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> first<span class="token punctuation">,</span> e<span class="token punctuation">;</span> <span class="token keyword">int</span> n<span class="token punctuation">;</span> <span class="token class-name">K</span> k<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>tab <span class="token operator">=</span> table<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>n <span class="token operator">=</span> tab<span class="token punctuation">.</span>length<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>first <span class="token operator">=</span> tab<span class="token punctuation">[</span><span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> hash<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>first<span class="token punctuation">.</span>hash <span class="token operator">==</span> hash <span class="token operator">&amp;&amp;</span> <span class="token comment">// always check first node</span>      <span class="token punctuation">(</span><span class="token punctuation">(</span>k <span class="token operator">=</span> first<span class="token punctuation">.</span>key<span class="token punctuation">)</span> <span class="token operator">==</span> key <span class="token operator">||</span> <span class="token punctuation">(</span>key <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> key<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token keyword">return</span> first<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e <span class="token operator">=</span> first<span class="token punctuation">.</span>next<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>first <span class="token keyword">instanceof</span> <span class="token class-name">TreeNode</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">TreeNode</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">)</span>first<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getTreeNode</span><span class="token punctuation">(</span>hash<span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token keyword">do</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>e<span class="token punctuation">.</span>hash <span class="token operator">==</span> hash <span class="token operator">&amp;&amp;</span>          <span class="token punctuation">(</span><span class="token punctuation">(</span>k <span class="token operator">=</span> e<span class="token punctuation">.</span>key<span class="token punctuation">)</span> <span class="token operator">==</span> key <span class="token operator">||</span> <span class="token punctuation">(</span>key <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> key<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>          <span class="token keyword">return</span> e<span class="token punctuation">;</span>      <span class="token punctuation">}</span> <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e <span class="token operator">=</span> e<span class="token punctuation">.</span>next<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><h3 id="4-clone方法"><a href="#4-clone方法" class="headerlink" title="4. clone方法"></a>4. clone方法</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">Object</span> <span class="token function">clone</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> result<span class="token punctuation">;</span>  <span class="token keyword">try</span> <span class="token punctuation">{</span>    result <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">)</span><span class="token keyword">super</span><span class="token punctuation">.</span><span class="token function">clone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">CloneNotSupportedException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment">// this shouldn't happen, since we are Cloneable</span>    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">InternalError</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  result<span class="token punctuation">.</span><span class="token function">reinitialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  result<span class="token punctuation">.</span><span class="token function">putMapEntries</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>对于<code>clone</code>方法这里有一个需要注意的地方，<code>result.putMapEntries(this, false)</code>，这里在put节点的时候是用的this，所以这只是浅复制，会影响原map，所以在使用的时候需要注意一下；</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h2><ol><li>扩容需要重排所有节点特别损耗性能，所以估算map大小并给定一个合理的负载系数，就显得尤为重要了。</li><li>HashMap 是线程不安全的。</li><li>虽然 JDK8 中引入了红黑树，将极端hash的情况影响降到了最小，但是从上面的对比还是可以看到，一个好的hash对性能的影响仍然十分重大，所以写一个好的<code>hashCode()</code>也非常重要</li><li>HashMap 非线程安全</li><li>初始长度为16</li><li>允许键和值为null</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JDK源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JDK源码分析 </tag>
            
            <tag> HashMap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jdk源码分析(3)-LinkedList</title>
      <link href="/2019/07/18/jdk-yuan-ma-fen-xi-3-linkedlist/"/>
      <url>/2019/07/18/jdk-yuan-ma-fen-xi-3-linkedlist/</url>
      
        <content type="html"><![CDATA[<h1 id="jdk源码分析-3-LinkedList"><a href="#jdk源码分析-3-LinkedList" class="headerlink" title="jdk源码分析(3)-LinkedList"></a>jdk源码分析(3)-LinkedList</h1><h2 id="一、LinkedList简介"><a href="#一、LinkedList简介" class="headerlink" title="一、LinkedList简介"></a>一、<strong>LinkedList简介</strong></h2><p>  <strong>LinkedList是基于双向链表实现的，它也可以被当作堆栈、队列或双端队列进行操作。</strong></p><p><code>LinkedList</code>的源码大致分三个部分，双向循环链表的实现、List的API和Deque的API。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LinkedList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span>  <span class="token keyword">extends</span> <span class="token class-name">AbstractSequentialList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span>  <span class="token keyword">implements</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">,</span> <span class="token class-name">Deque</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">,</span> <span class="token class-name">Cloneable</span><span class="token punctuation">,</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">Serializable</span></code></pre><p><img src="/images/20190718/1.png"></p><p>从类定义和图中也能很清晰的看到，<code>LinkedList</code>的结构大致分为三个部分；同时和<code>ArrayList</code>相比，他并没有实现<code>RandomAccess</code>接口，所以他并不支持随机访问操作；另外可以看到他的<code>List</code>接口是通过<code>AbstractSequentialList</code>实现的，同时还实现了多个迭代器，表明他的访问操作时通过迭代器完成的.</p><h2 id="二、链表结构"><a href="#二、链表结构" class="headerlink" title="二、链表结构"></a>二、链表结构</h2><p><strong>常见链表</strong></p><p><img src="/images/20190718/2.png"></p><p><code>LinkedList</code>是基于双向循环链表实现的，所以如图所示，当对链表进行插入、删除等操作时，</p><ul><li>首先需要区分操作节点是否为首尾节点，并区分是否为空，</li><li>然后再变更相应<code>pre</code>和<code>next</code>的引用即可；</li></ul><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">void</span> <span class="token function">linkFirst</span><span class="token punctuation">(</span><span class="token class-name">E</span> e<span class="token punctuation">)</span><span class="token keyword">void</span> <span class="token function">linkLast</span><span class="token punctuation">(</span><span class="token class-name">E</span> e<span class="token punctuation">)</span><span class="token keyword">void</span> <span class="token function">linkBefore</span><span class="token punctuation">(</span><span class="token class-name">E</span> e<span class="token punctuation">,</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> succ<span class="token punctuation">)</span><span class="token class-name">E</span> <span class="token function">unlinkFirst</span><span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> f<span class="token punctuation">)</span><span class="token class-name">E</span> <span class="token function">unlinkLast</span><span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> l<span class="token punctuation">)</span><span class="token class-name">E</span> <span class="token function">unlink</span><span class="token punctuation">(</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> x<span class="token punctuation">)</span><span class="token comment">/** * Returns the (non-null) Node at the specified element index. */</span><span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token function">node</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// assert isElementIndex(index);</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>index <span class="token operator">&lt;</span> <span class="token punctuation">(</span>size <span class="token operator">&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> x <span class="token operator">=</span> first<span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> index<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>      x <span class="token operator">=</span> x<span class="token punctuation">.</span>next<span class="token punctuation">;</span>    <span class="token keyword">return</span> x<span class="token punctuation">;</span>  <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>    <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> x <span class="token operator">=</span> last<span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&gt;</span> index<span class="token punctuation">;</span> i<span class="token operator">--</span><span class="token punctuation">)</span>      x <span class="token operator">=</span> x<span class="token punctuation">.</span>prev<span class="token punctuation">;</span>    <span class="token keyword">return</span> x<span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>上面所列的方法封装了对双向循环链表常用操作，其中<code>node(int index)</code>是随机查询方法，这里通过判断<code>index</code>是前半段还是后半段，来确定遍历的方向以增加效率。<br>同时在<code>LinkedList</code>中有关<code>List</code>和<code>Deque</code>的API也是基于上面的封装的方法完成的</p><h2 id="三、LinkedList的成员变量"><a href="#三、LinkedList的成员变量" class="headerlink" title="三、LinkedList的成员变量"></a>三、<strong>LinkedList的成员变量</strong></h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> header <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token keyword">null</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">transient</span> <span class="token keyword">int</span> size <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span></code></pre><p>LinkedList有两个成员变量，表头 header 和长度size.</p><h2 id="四、LinkedList的构造函数"><a href="#四、LinkedList的构造函数" class="headerlink" title="四、LinkedList的构造函数"></a>四、<strong>LinkedList的构造函数</strong></h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">LinkedList</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//构造一个空链表</span>        header<span class="token punctuation">.</span>next <span class="token operator">=</span> header<span class="token punctuation">.</span>previous <span class="token operator">=</span> header<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token class-name">LinkedList</span><span class="token punctuation">(</span><span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span> <span class="token keyword">extends</span> <span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> c<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//将一个数据类型相同的集合添加到LinkedList的尾部</span>    <span class="token keyword">this</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">addAll</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span></code></pre><h2 id="五、LinkedList的内部类。"><a href="#五、LinkedList的内部类。" class="headerlink" title="五、LinkedList的内部类。"></a>五、<strong>LinkedList的内部类。</strong></h2><ul><li><p>Entry<e>是LinkedList的节点类，节点类包含：当前节点的值,前一节点，后一节点。该节点类是一个<strong>静态内部类：当内部类对象不需要访问外围类对象时，应该声明为静态内部类。</strong></e></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>  <span class="token class-name">E</span> element<span class="token punctuation">;</span>  <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">;</span>  <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> previous<span class="token punctuation">;</span>  <span class="token class-name">Entry</span><span class="token punctuation">(</span><span class="token class-name">E</span> element<span class="token punctuation">,</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">,</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> previous<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">this</span><span class="token punctuation">.</span>element <span class="token operator">=</span> element<span class="token punctuation">;</span>      <span class="token keyword">this</span><span class="token punctuation">.</span>next <span class="token operator">=</span> next<span class="token punctuation">;</span>      <span class="token keyword">this</span><span class="token punctuation">.</span>previous <span class="token operator">=</span> previous<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token punctuation">}</span></code></pre></li><li><p>ListItr 是 LinkedList 的迭代器类</p><p>&lt;!–hexoPostRenderEscape:</p><pre class="language-java" data-language="java"><code class="language-java"><br><span class="token keyword">private</span> <span class="token keyword">class</span> <span class="token class-name">ListItr</span> <span class="token keyword">implements</span> <span class="token class-name">ListIterator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span><br><span class="token keyword">private</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> lastReturned <span class="token operator">=</span> header<span class="token punctuation">;</span><span class="token comment">//上一次返回的节点</span><br><span class="token keyword">private</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">;</span><span class="token comment">//下一节点</span><br><span class="token keyword">private</span> <span class="token keyword">int</span> nextIndex<span class="token punctuation">;</span><span class="token comment">//下一节点的索引</span><br><span class="token keyword">private</span> <span class="token keyword">int</span> expectedModCount <span class="token operator">=</span> modCount<span class="token punctuation">;</span><span class="token comment">//!!!!!!期望的改变次数~ Java的 fail-fast 机制。</span><p></p></code></pre></li><code class="language-java"></code></ul><code class="language-java"><p><span class="token class-name">ListItr</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    <span class="token keyword">if</span> <span class="token punctuation">(</span>index <span class="token operator">&lt;</span> <span class="token number">0</span> <span class="token operator">||</span> index <span class="token operator">&gt;</span> size<span class="token punctuation">)</span><br>    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IndexOutOfBoundsException</span><span class="token punctuation">(</span><span class="token string">“Index: “</span><span class="token operator">+</span>index<span class="token operator">+</span><br>                        <span class="token string">“, Size: “</span><span class="token operator">+</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">if</span> <span class="token punctuation">(</span>index <span class="token operator">&lt;</span> <span class="token punctuation">(</span>size <span class="token operator">&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//size&gt;&gt;1是右移一位，即size/2 ,若索引值小于 size/2则从前开始</span><br>    next <span class="token operator">=</span> header<span class="token punctuation">.</span>next<span class="token punctuation">;</span><br>    <span class="token keyword">for</span> <span class="token punctuation">(</span>nextIndex<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> nextIndex<span class="token operator">&lt;</span>index<span class="token punctuation">;</span> nextIndex<span class="token operator">++</span><span class="token punctuation">)</span><br>        next <span class="token operator">=</span> next<span class="token punctuation">.</span>next<span class="token punctuation">;</span><br>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span><span class="token comment">//否则从后开始</span><br>    next <span class="token operator">=</span> header<span class="token punctuation">;</span><br>    <span class="token keyword">for</span> <span class="token punctuation">(</span>nextIndex<span class="token operator">=</span>size<span class="token punctuation">;</span> nextIndex<span class="token operator">&gt;</span>index<span class="token punctuation">;</span> nextIndex<span class="token operator">–</span><span class="token punctuation">)</span><br>        next <span class="token operator">=</span> next<span class="token punctuation">.</span>previous<span class="token punctuation">;</span><br>    <span class="token punctuation">}</span><br><span class="token punctuation">}</span></p><p><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//是否存在下一个元素   </span><br>    <span class="token keyword">return</span> nextIndex <span class="token operator">!=</span> size<span class="token punctuation">;</span><span class="token comment">//通过下一节点索引值是否等于size来判断是否到了最末尾</span><br><span class="token punctuation">}</span></p><p><span class="token keyword">public</span> <span class="token class-name">E</span> <span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    <span class="token function">checkForComodification</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">if</span> <span class="token punctuation">(</span>nextIndex <span class="token operator">==</span> size<span class="token punctuation">)</span><span class="token comment">//!!</span><br>    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">NoSuchElementException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></p><pre><code>lastReturned &lt;span class="token operator"&gt;=&lt;/span&gt; next&lt;span class="token punctuation"&gt;;&lt;/span&gt;next &lt;span class="token operator"&gt;=&lt;/span&gt; next&lt;span class="token punctuation"&gt;.&lt;/span&gt;next&lt;span class="token punctuation"&gt;;&lt;/span&gt;nextIndex&lt;span class="token operator"&gt;++&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;&lt;span class="token keyword"&gt;return&lt;/span&gt; lastReturned&lt;span class="token punctuation"&gt;.&lt;/span&gt;element&lt;span class="token punctuation"&gt;;&lt;/span&gt;</code></pre><p><span class="token punctuation">}</span></p><p><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">hasPrevious</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//是否存在上一个</span><br>    <span class="token keyword">return</span> nextIndex <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token comment">//通过下一节点的索引值是否等于0来判断是否在最前面即头节点，由此来判断是否有前节点</span><br><span class="token punctuation">}</span></p><p><span class="token keyword">public</span> <span class="token class-name">E</span> <span class="token function">previous</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//取得上一元素</span><br>    <span class="token keyword">if</span> <span class="token punctuation">(</span>nextIndex <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><br>    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">NoSuchElementException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></p><pre><code>lastReturned &lt;span class="token operator"&gt;=&lt;/span&gt; next &lt;span class="token operator"&gt;=&lt;/span&gt; next&lt;span class="token punctuation"&gt;.&lt;/span&gt;previous&lt;span class="token punctuation"&gt;;&lt;/span&gt;  &lt;span class="token comment"&gt;//??????&lt;/span&gt;nextIndex&lt;span class="token operator"&gt;--&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;&lt;span class="token function"&gt;checkForComodification&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;&lt;span class="token keyword"&gt;return&lt;/span&gt; lastReturned&lt;span class="token punctuation"&gt;.&lt;/span&gt;element&lt;span class="token punctuation"&gt;;&lt;/span&gt;</code></pre><p><span class="token punctuation">}</span></p><p><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">nextIndex</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    <span class="token keyword">return</span> nextIndex<span class="token punctuation">;</span><br><span class="token punctuation">}</span></p><p><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">previousIndex</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//上一元素的索引</span><br>    <span class="token keyword">return</span> nextIndex<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span><br><span class="token punctuation">}</span></p><p><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">remove</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//删除当前节点！！</span><br>           <span class="token function">checkForComodification</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>           <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> lastNext <span class="token operator">=</span> lastReturned<span class="token punctuation">.</span>next<span class="token punctuation">;</span><br>           <span class="token keyword">try</span> <span class="token punctuation">{</span><br>               <span class="token class-name">LinkedList</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">.</span><span class="token function">remove</span><span class="token punctuation">(</span>lastReturned<span class="token punctuation">)</span><span class="token punctuation">;</span><br>           <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">NoSuchElementException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>               <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IllegalStateException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>           <span class="token punctuation">}</span><br>    <span class="token keyword">if</span> <span class="token punctuation">(</span>next<span class="token operator">==</span>lastReturned<span class="token punctuation">)</span><br>               next <span class="token operator">=</span> lastNext<span class="token punctuation">;</span><br>           <span class="token keyword">else</span><br>    nextIndex<span class="token operator">–</span><span class="token punctuation">;</span><br>    lastReturned <span class="token operator">=</span> header<span class="token punctuation">;</span><br>    expectedModCount<span class="token operator">++</span><span class="token punctuation">;</span><br><span class="token punctuation">}</span></p><p><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">set</span><span class="token punctuation">(</span><span class="token class-name">E</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    <span class="token keyword">if</span> <span class="token punctuation">(</span>lastReturned <span class="token operator">==</span> header<span class="token punctuation">)</span><br>    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IllegalStateException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token function">checkForComodification</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    lastReturned<span class="token punctuation">.</span>element <span class="token operator">=</span> e<span class="token punctuation">;</span><br><span class="token punctuation">}</span></p><p><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">E</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//讲e添加到当前节点前面</span><br>    <span class="token function">checkForComodification</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    lastReturned <span class="token operator">=</span> header<span class="token punctuation">;</span><br>    <span class="token function">addBefore</span><span class="token punctuation">(</span>e<span class="token punctuation">,</span> next<span class="token punctuation">)</span><span class="token punctuation">;</span><br>    nextIndex<span class="token operator">++</span><span class="token punctuation">;</span><br>    expectedModCount<span class="token operator">++</span><span class="token punctuation">;</span><br><span class="token punctuation">}</span></p></code><p><code class="language-java"><span class="token keyword">final</span> <span class="token keyword">void</span> <span class="token function">checkForComodification</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//!!!!!判断 modCount是否等于 expectedModCount来实现fail-fast机制。</span><br>    <span class="token keyword">if</span> <span class="token punctuation">(</span>modCount <span class="token operator">!=</span> expectedModCount<span class="token punctuation">)</span><br>    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">ConcurrentModificationException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token punctuation">}</span><br>  </code>:hexoPostRenderEscape–&gt;</p><ul><li><p>DescendingIterator</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">class</span> <span class="token class-name">DescendingIterator</span> <span class="token keyword">implements</span> <span class="token class-name">Iterator</span> <span class="token punctuation">{</span>      <span class="token keyword">final</span> <span class="token class-name">ListItr</span> itr <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ListItr</span><span class="token punctuation">(</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">return</span> itr<span class="token punctuation">.</span><span class="token function">hasPrevious</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">public</span> <span class="token class-name">E</span> <span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>          <span class="token keyword">return</span> itr<span class="token punctuation">.</span><span class="token function">previous</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">remove</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>          itr<span class="token punctuation">.</span><span class="token function">remove</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>  <span class="token punctuation">}</span></code></pre></li></ul><h2 id="六、LinkedList的成员函数"><a href="#六、LinkedList的成员函数" class="headerlink" title="六、LinkedList的成员函数"></a>六、<strong>LinkedList的成员函数</strong></h2><ul><li><p>1.get类型的函数</p><pre class="language-JAVA" data-language="JAVA"><code class="language-JAVA">public E getFirst() {//取得第一个节点的值  if (size==0)      throw new NoSuchElementException();//时刻注意特殊情况的考虑  return header.next.element;  }  public E getLast()  {  if (size==0)      throw new NoSuchElementException();  return header.previous.element;//获得最后一个是 header.previous.element  }  public E removeFirst() {//移除第一个节点  return remove(header.next);//remove函数下面单独介绍  }  public E removeLast() {//移除最后一个节点  return remove(header.previous);  }  public void addFirst(E e) {//在  addBefore(e, header.next);  }  public void addLast(E e) {  addBefore(e, header);  }  public boolean contains(Object o) {      return indexOf(o) != -1;  }  public int size() {  return size;  }  public boolean add(E e) {//在最末尾添加值为e的节点，添加在header前即最末尾  addBefore(e, header);      return true;</code></pre></li><li><p>2.boolean remove(Object o)    /    E remove()     /     E remove(Entry<e> e)</e></p><pre class="language-JAVA" data-language="JAVA"><code class="language-JAVA">public boolean remove(Object o) {      if (o==null) {//即使是null也要查找到然后再移除          for (Entry&lt;E&gt; e = header.next; e != header; e = e.next) {              if (e.element==null) {                  remove(e);//调用下面的方法                  return true;              }          }      } else {          for (Entry&lt;E&gt; e = header.next; e != header; e = e.next) {              if (o.equals(e.element)) {                  remove(e);                  return true;              }          }      }      return false;  } private E remove(Entry&lt;E&gt; e) {  if (e == header)      throw new NoSuchElementException();//考虑头指针的特殊情况      E result = e.element;  e.previous.next = e.next;//!!!  e.next.previous = e.previous;//!!!      e.next = e.previous = null;//  ???不是特别理解      e.element = null;  size--;  modCount++;      return result;  }</code></pre></li><li><p>3.增删改查的一些方法</p><p>&lt;!–hexoPostRenderEscape:</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//清空LinkedList</span><p></p><pre><code>  &lt;span class="token class-name"&gt;Entry&lt;/span&gt;&lt;span class="token generics"&gt;&lt;span class="token punctuation"&gt;&amp;lt;&lt;/span&gt;&lt;span class="token class-name"&gt;E&lt;/span&gt;&lt;span class="token punctuation"&gt;&gt;&lt;/span&gt;&lt;/span&gt; e &lt;span class="token operator"&gt;=&lt;/span&gt; header&lt;span class="token punctuation"&gt;.&lt;/span&gt;next&lt;span class="token punctuation"&gt;;&lt;/span&gt;  &lt;span class="token keyword"&gt;while&lt;/span&gt; &lt;span class="token punctuation"&gt;(&lt;/span&gt;e &lt;span class="token operator"&gt;!=&lt;/span&gt; header&lt;span class="token punctuation"&gt;)&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;      &lt;span class="token class-name"&gt;Entry&lt;/span&gt;&lt;span class="token generics"&gt;&lt;span class="token punctuation"&gt;&amp;lt;&lt;/span&gt;&lt;span class="token class-name"&gt;E&lt;/span&gt;&lt;span class="token punctuation"&gt;&gt;&lt;/span&gt;&lt;/span&gt; next &lt;span class="token operator"&gt;=&lt;/span&gt; e&lt;span class="token punctuation"&gt;.&lt;/span&gt;next&lt;span class="token punctuation"&gt;;&lt;/span&gt;      e&lt;span class="token punctuation"&gt;.&lt;/span&gt;next &lt;span class="token operator"&gt;=&lt;/span&gt; e&lt;span class="token punctuation"&gt;.&lt;/span&gt;previous &lt;span class="token operator"&gt;=&lt;/span&gt; &lt;span class="token keyword"&gt;null&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;      e&lt;span class="token punctuation"&gt;.&lt;/span&gt;element &lt;span class="token operator"&gt;=&lt;/span&gt; &lt;span class="token keyword"&gt;null&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;      e &lt;span class="token operator"&gt;=&lt;/span&gt; next&lt;span class="token punctuation"&gt;;&lt;/span&gt;  &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;  header&lt;span class="token punctuation"&gt;.&lt;/span&gt;next &lt;span class="token operator"&gt;=&lt;/span&gt; header&lt;span class="token punctuation"&gt;.&lt;/span&gt;previous &lt;span class="token operator"&gt;=&lt;/span&gt; header&lt;span class="token punctuation"&gt;;&lt;/span&gt;  size &lt;span class="token operator"&gt;=&lt;/span&gt; &lt;span class="token number"&gt;0&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;</code></pre><p>  modCount<span class="token operator">++</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span></p><p>  <span class="token keyword">public</span> <span class="token class-name">E</span> <span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//获得某索引对应的节点值</span></p><pre><code>  &lt;span class="token keyword"&gt;return&lt;/span&gt; &lt;span class="token function"&gt;entry&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;index&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;element&lt;span class="token punctuation"&gt;;&lt;/span&gt;</code></pre><p>  <span class="token punctuation">}</span></p><p>  <span class="token keyword">public</span> <span class="token class-name">E</span> <span class="token function">set</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">,</span> <span class="token class-name">E</span> element<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//设置某索引的节点值</span></p><pre><code>  &lt;span class="token class-name"&gt;Entry&lt;/span&gt;&lt;span class="token generics"&gt;&lt;span class="token punctuation"&gt;&amp;lt;&lt;/span&gt;&lt;span class="token class-name"&gt;E&lt;/span&gt;&lt;span class="token punctuation"&gt;&gt;&lt;/span&gt;&lt;/span&gt; e &lt;span class="token operator"&gt;=&lt;/span&gt; &lt;span class="token function"&gt;entry&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;index&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;  &lt;span class="token class-name"&gt;E&lt;/span&gt; oldVal &lt;span class="token operator"&gt;=&lt;/span&gt; e&lt;span class="token punctuation"&gt;.&lt;/span&gt;element&lt;span class="token punctuation"&gt;;&lt;/span&gt;  e&lt;span class="token punctuation"&gt;.&lt;/span&gt;element &lt;span class="token operator"&gt;=&lt;/span&gt; element&lt;span class="token punctuation"&gt;;&lt;/span&gt;  &lt;span class="token keyword"&gt;return&lt;/span&gt; oldVal&lt;span class="token punctuation"&gt;;&lt;/span&gt;</code></pre><p>  <span class="token punctuation">}</span></p></code></pre></li><code class="language-java"></code></ul><code class="language-java"><pre><code>&lt;span class="token keyword"&gt;public&lt;/span&gt; &lt;span class="token keyword"&gt;void&lt;/span&gt; &lt;span class="token function"&gt;add&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token keyword"&gt;int&lt;/span&gt; index&lt;span class="token punctuation"&gt;,&lt;/span&gt; &lt;span class="token class-name"&gt;E&lt;/span&gt; element&lt;span class="token punctuation"&gt;)&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;    &lt;span class="token function"&gt;addBefore&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;element&lt;span class="token punctuation"&gt;,&lt;/span&gt; &lt;span class="token punctuation"&gt;(&lt;/span&gt;index&lt;span class="token operator"&gt;==&lt;/span&gt;size &lt;span class="token operator"&gt;?&lt;/span&gt; header &lt;span class="token operator"&gt;:&lt;/span&gt; &lt;span class="token function"&gt;entry&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;index&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;&lt;span class="token keyword"&gt;public&lt;/span&gt; &lt;span class="token class-name"&gt;E&lt;/span&gt; &lt;span class="token function"&gt;remove&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token keyword"&gt;int&lt;/span&gt; index&lt;span class="token punctuation"&gt;)&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;&lt;span class="token comment"&gt;//移除节点&lt;/span&gt;    &lt;span class="token keyword"&gt;return&lt;/span&gt; &lt;span class="token function"&gt;remove&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token function"&gt;entry&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;index&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;</code></pre></code><p><code class="language-java"></code>:hexoPostRenderEscape–&gt;</p><ul><li><p>4.Entry<e> entry(int index)</e></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token function">entry</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>index <span class="token operator">&lt;</span> <span class="token number">0</span> <span class="token operator">||</span> index <span class="token operator">&gt;=</span> size<span class="token punctuation">)</span>          <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IndexOutOfBoundsException</span><span class="token punctuation">(</span><span class="token string">"Index: "</span><span class="token operator">+</span>index<span class="token operator">+</span>                                              <span class="token string">", Size: "</span><span class="token operator">+</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token class-name">Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> e <span class="token operator">=</span> header<span class="token punctuation">;</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>index <span class="token operator">&lt;</span> <span class="token punctuation">(</span>size <span class="token operator">&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//若小于size/2，则从头遍历</span>          <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> index<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>              e <span class="token operator">=</span> e<span class="token punctuation">.</span>next<span class="token punctuation">;</span>      <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span><span class="token comment">//否则从尾遍历</span>          <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> size<span class="token punctuation">;</span> i <span class="token operator">&gt;</span> index<span class="token punctuation">;</span> i<span class="token operator">--</span><span class="token punctuation">)</span>              e <span class="token operator">=</span> e<span class="token punctuation">.</span>previous<span class="token punctuation">;</span>      <span class="token punctuation">}</span>      <span class="token keyword">return</span> e<span class="token punctuation">;</span>  <span class="token punctuation">}</span></code></pre></li></ul><h2 id="七、方法归类"><a href="#七、方法归类" class="headerlink" title="七、方法归类"></a>七、<strong>方法归类</strong></h2><p>a.LinkedList可以作为FIFO(先进先出)的队列，作为FIFO的队列时，下表的方法等价：</p><p>队列方法       等效方法<br>add(e)        addLast(e)<br>offer(e)      offerLast(e)<br>remove()      removeFirst()<br>poll()        pollFirst()<br>element()     getFirst()<br>peek()        peekFirst()</p><p>b.LinkedList可以作为LIFO(后进先出)的栈，作为LIFO的栈时，下表的方法等价：</p><p>栈方法        等效方法<br>push(e)      addFirst(e)<br>pop()        removeFirst()<br>peek()       peekFirst()</p><h2 id="八、总结"><a href="#八、总结" class="headerlink" title="八、总结"></a>八、<strong>总结</strong></h2><ul><li><p><strong>LinkedList是以双链表的形式实现的。</strong></p></li><li><p><strong>LinkedList即可以作为链表，还可以作为队列和栈。</strong></p></li><li><p><strong>LinkedList是 非 线程安全的。</strong></p></li><li><p>LinkedList 基于双向循环链表实现，随机访问比较慢，所以在遍历 List 的时候一定要注意。</p></li><li><p>LinkedList 可以添加重复元素，可以添加 null。</p></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JDK源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JDK源码分析 </tag>
            
            <tag> LinkedList </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jdk源码分析(2)-ArrayList</title>
      <link href="/2019/07/18/jdk-yuan-ma-fen-xi-2-arraylist/"/>
      <url>/2019/07/18/jdk-yuan-ma-fen-xi-2-arraylist/</url>
      
        <content type="html"><![CDATA[<h1 id="jdk源码分析-2-ArrayList"><a href="#jdk源码分析-2-ArrayList" class="headerlink" title="jdk源码分析(2)-ArrayList"></a>jdk源码分析(2)-ArrayList</h1><h2 id="1-ArrayList简介"><a href="#1-ArrayList简介" class="headerlink" title="1.ArrayList简介"></a><strong>1.ArrayList简介</strong></h2><p>ArrayList是基于Object[] 数组的，也就是我们常说的动态数组。它能很方便的实现数组的增加删除等操作。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">AbstractList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">E</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">,</span> <span class="token class-name">RandomAccess</span><span class="token punctuation">,</span> <span class="token class-name">Cloneable</span><span class="token punctuation">,</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">Serializable</span><span class="token operator">&lt;</span><span class="token operator">/</span>span<span class="token operator">&gt;</span><span class="token number">1.</span> <span class="token class-name">ArrayList</span>支持泛型，它继承自<span class="token class-name">AbstractList</span>，实现了<span class="token class-name">List</span>、<span class="token class-name">RandomAccess</span>、<span class="token class-name">Cloneable</span>、java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">Serializable</span>接口。<span class="token number">2.</span> <span class="token class-name">List</span>接口定义了列表必须实现的方法。<span class="token number">3.</span> <span class="token class-name">RandomAccess</span>是一个标记接口，接口内没有定义任何内容。<span class="token number">4.</span> 实现了<span class="token class-name">Cloneable</span>接口的类，可以调用<span class="token class-name">Object</span><span class="token punctuation">.</span>clone方法返回该对象的浅拷贝。<span class="token number">5.</span> 通过实现 java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">Serializable</span> 接口以实现序列化功能</code></pre><h2 id="2-ArrayList成员变量"><a href="#2-ArrayList成员变量" class="headerlink" title="2.ArrayList成员变量"></a><strong>2.ArrayList成员变量</strong></h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> DEFAULT_CAPACITY <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>                        <span class="token comment">// 默认容量</span><span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span> EMPTY_ELEMENTDATA <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">;</span>                  <span class="token comment">// 空实例的空数组对象</span><span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span> DEFAULTCAPACITY_EMPTY_ELEMENTDATA <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">;</span>  <span class="token comment">// 也是空数组对象，用于计算添加第一个元素时要膨胀多少</span><span class="token keyword">transient</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span> elementData<span class="token punctuation">;</span>                                        <span class="token comment">// 存储内容的数组</span><span class="token keyword">private</span> <span class="token keyword">int</span> size<span class="token punctuation">;</span>                                                      <span class="token comment">// 存储的数量</span></code></pre><p>**Java关键字 transient:**是为了在序列化时保护对象的某些域不被序列化</p><p>其中<code>elementData</code>被声明为了<code>transient</code>，那么ArrayList是如何实现序列化的呢？<br>查看<code>writeObject</code>和<code>readObject</code>的源码如下：</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">writeObject</span><span class="token punctuation">(</span>java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">ObjectOutputStream</span> s<span class="token punctuation">)</span> <span class="token keyword">throws</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">IOException</span> <span class="token punctuation">{</span>  <span class="token comment">// Write out element count, and any hidden stuff</span>  <span class="token keyword">int</span> expectedModCount <span class="token operator">=</span> modCount<span class="token punctuation">;</span>  s<span class="token punctuation">.</span><span class="token function">defaultWriteObject</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Write out size as capacity for behavioural compatibility with clone()</span>  s<span class="token punctuation">.</span><span class="token function">writeInt</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Write out all elements in the proper order.</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> i<span class="token operator">&lt;</span>size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    s<span class="token punctuation">.</span><span class="token function">writeObject</span><span class="token punctuation">(</span>elementData<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>modCount <span class="token operator">!=</span> expectedModCount<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">ConcurrentModificationException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">readObject</span><span class="token punctuation">(</span>java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">ObjectInputStream</span> s<span class="token punctuation">)</span> <span class="token keyword">throws</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">ClassNotFoundException</span> <span class="token punctuation">{</span>  elementData <span class="token operator">=</span> EMPTY_ELEMENTDATA<span class="token punctuation">;</span>  <span class="token comment">// Read in size, and any hidden stuff</span>  s<span class="token punctuation">.</span><span class="token function">defaultReadObject</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Read in capacity</span>  s<span class="token punctuation">.</span><span class="token function">readInt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// ignored</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>size <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment">// be like clone(), allocate array based upon size not capacity</span>    <span class="token keyword">int</span> capacity <span class="token operator">=</span> <span class="token function">calculateCapacity</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">SharedSecrets</span><span class="token punctuation">.</span><span class="token function">getJavaOISAccess</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">checkArray</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> capacity<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">ensureCapacityInternal</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span> a <span class="token operator">=</span> elementData<span class="token punctuation">;</span>    <span class="token comment">// Read in all elements in the proper order.</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> i<span class="token operator">&lt;</span>size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> s<span class="token punctuation">.</span><span class="token function">readObject</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>可以看到在序列化的时候是把<code>elementData</code>里面的元素逐个取出来放到<code>ObjectOutputStream</code>里面的；而在反序列化的时候也是把元素逐个拿出来放回到<code>elementData</code>里面的；</p><p>这样繁琐的操作，其中最重要的一个好处就是节省空间，因为<code>elementData</code>的大小是大于<code>ArrayList</code>中实际元素个数的。所以没必要将<code>elementData</code>整个序列化。</p><h2 id="3-ArrayList构造函数"><a href="#3-ArrayList构造函数" class="headerlink" title="3.ArrayList构造函数"></a><strong>3.ArrayList构造函数</strong></h2><p><code>ArrayList</code>的构造函数主要就是要初始化<code>elementData</code>和<code>size</code>，但是其中有一个注意点</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">ArrayList</span><span class="token punctuation">(</span><span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span> <span class="token keyword">extends</span> <span class="token class-name">E</span><span class="token punctuation">&gt;</span></span> c<span class="token punctuation">)</span> <span class="token punctuation">{</span>  elementData <span class="token operator">=</span> c<span class="token punctuation">.</span><span class="token function">toArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>size <span class="token operator">=</span> elementData<span class="token punctuation">.</span>length<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment">// c.toArray might (incorrectly) not return Object[] (see 6260652)</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>elementData<span class="token punctuation">.</span><span class="token function">getClass</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span>      elementData <span class="token operator">=</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">copyOf</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> size<span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>    <span class="token comment">// replace with empty array.</span>    <span class="token keyword">this</span><span class="token punctuation">.</span>elementData <span class="token operator">=</span> EMPTY_ELEMENTDATA<span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span>可以看到在<span class="token class-name">Collection</span><span class="token punctuation">.</span><span class="token function">toArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span>之后又判断了他的<span class="token class-name">Class</span>类型是不是<span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token keyword">class</span>，这个也注释了是一个bug<span class="token operator">!</span></code></pre><h2 id="4-常用方法"><a href="#4-常用方法" class="headerlink" title="4.常用方法"></a>4.常用方法</h2><p>由于<code>ArrayList</code>是基于数组的，所以他的api基本都是基于<code>System.arraycopy()</code>实现的；</p><p><code>public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length);</code></p><p>可以看到这是一个<code>native</code>方法，并且JVM有对这个方法做特殊的优化处理</p><h3 id="1、void-trimToSize"><a href="#1、void-trimToSize" class="headerlink" title="1、void trimToSize()"></a>1、<strong>void trimToSize()</strong></h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">trimToSize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//节约内存</span>    modCount<span class="token operator">++</span><span class="token punctuation">;</span><span class="token comment">//此变量记录ArrayList被改变的次数  ！！！超级注意！！！</span>    <span class="token keyword">int</span> oldCapacity <span class="token operator">=</span> elementData<span class="token punctuation">.</span>length<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>size <span class="token operator">&lt;</span> oldCapacity<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//!!size往往不等于elementData.length;elementData.length是数组的初始长度，size是实际内容的长度！！</span>            elementData <span class="token operator">=</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">copyOf</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token punctuation">}</span>modCount变量是记录<span class="token class-name">ArrayList</span>被改变的次数</code></pre><p><strong>ArrayList不是线程安全（异步）的</strong></p><p>ArrayList不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了map，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。</p><p>这一策略在源码中的实现是通过modCount域，modCount顾名思义就是修改次数，对ArrayList <strong>结构的修改</strong>（长度的变化，增加，删除；赋值不是结构变化）都将增加这个值，那么在迭代器初始化过程中会将这个值赋给迭代器的expectedModCount。在迭代过程中，判断modCount跟expectedModCount是否相等，如果不相等就表示已经有其他线程修改了ArrayList。<br>ArrayList中的mouCount是在他的父类Abstract中申明的。</p><p><code>protected transient int modCount = 0;</code></p><h3 id="2、void-ensureCapacity-int-minCapacity"><a href="#2、void-ensureCapacity-int-minCapacity" class="headerlink" title="2、void ensureCapacity(int minCapacity)"></a>2、<strong>void ensureCapacity(int minCapacity)</strong></h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">ensureCapacity</span><span class="token punctuation">(</span><span class="token keyword">int</span> minCapacity<span class="token punctuation">)</span> <span class="token punctuation">{</span>    modCount<span class="token operator">++</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> oldCapacity <span class="token operator">=</span> elementData<span class="token punctuation">.</span>length<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>minCapacity <span class="token operator">&gt;</span> oldCapacity<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token class-name">Object</span> oldData<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> elementData<span class="token punctuation">;</span>        <span class="token keyword">int</span> newCapacity <span class="token operator">=</span> <span class="token punctuation">(</span>oldCapacity <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token comment">//若传入参数大于原容量，先扩为  1.5*原容量+1</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>newCapacity <span class="token operator">&lt;</span> minCapacity<span class="token punctuation">)</span>        newCapacity <span class="token operator">=</span> minCapacity<span class="token punctuation">;</span><span class="token comment">//若扩为 1.5*原容量+1 后还是小于传入的参数，则把传入的参数作为新容量</span>            <span class="token comment">// minCapacity is usually close to size, so this is a win:</span>            elementData <span class="token operator">=</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">copyOf</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> newCapacity<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token punctuation">}</span></code></pre><p><strong>ArrayList需要扩容时至少都是扩为 1.5*原容量+1 ，若1.5*原容量+1 还是小于传入的参数，才把传入的参数作为新容量</strong>。</p><h3 id="3、boolean-contains-Object-o"><a href="#3、boolean-contains-Object-o" class="headerlink" title="3、boolean contains(Object o)"></a>3、<strong>boolean contains(Object o)</strong></h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">contains</span><span class="token punctuation">(</span><span class="token class-name">Object</span> o<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">return</span> <span class="token function">indexOf</span><span class="token punctuation">(</span>o<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span></code></pre><h3 id="4、int-indexOf-Object-o"><a href="#4、int-indexOf-Object-o" class="headerlink" title="4、int indexOf(Object o)"></a>4、<strong>int indexOf(Object o)</strong></h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">indexOf</span><span class="token punctuation">(</span><span class="token class-name">Object</span> o<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>o <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//定位是null也要定位的哦~</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>elementData<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">==</span><span class="token keyword">null</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> i<span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>o<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>elementData<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> i<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span></code></pre><h3 id="5、Object-toArray-T-toArray-T-a"><a href="#5、Object-toArray-T-toArray-T-a" class="headerlink" title="5、Object[] toArray()   /    T[] toArray(T[] a)"></a>5、<strong>Object[] toArray()   /   <t> T[] toArray(T[] a)</t></strong></h3><p>调用的是Arrays.copyOf(）</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">toArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">copyOf</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">public</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">&gt;</span></span> <span class="token class-name">T</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">toArray</span><span class="token punctuation">(</span><span class="token class-name">T</span><span class="token punctuation">[</span><span class="token punctuation">]</span> a<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span>length <span class="token operator">&lt;</span> size<span class="token punctuation">)</span>            <span class="token comment">// Make a new array of a's runtime type, but my contents:</span>            <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token class-name">T</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">copyOf</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> size<span class="token punctuation">,</span> a<span class="token punctuation">.</span><span class="token function">getClass</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//若传入的数组长度小于size（ArrayList实际长度）,则返回一个长度为size新的数组</span>    <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">arraycopy</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> a<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//若传入数组长度相等，则把elementData复制进传入数组</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span>length <span class="token operator">&gt;</span> size<span class="token punctuation">)</span><span class="token comment">//若传入的a的长度大于原本数组，则后面补null</span>            a<span class="token punctuation">[</span>size<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> a<span class="token punctuation">;</span>    <span class="token punctuation">}</span></code></pre><h3 id="6、E-set-int-index-E-element"><a href="#6、E-set-int-index-E-element" class="headerlink" title="6、E set(int index, E element)"></a>6、<strong>E set(int index, E element)</strong></h3><p>set是直接替换掉该位置元素；而add是插入该位置，其余元素后移。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">E</span> <span class="token function">set</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">,</span> <span class="token class-name">E</span> element<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token class-name">RangeCheck</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//参数检查的方法~~一定要时刻注意参数检查哦~~</span>    <span class="token class-name">E</span> oldValue <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">E</span><span class="token punctuation">)</span> elementData<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">;</span>    elementData<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> element<span class="token punctuation">;</span>    <span class="token keyword">return</span> oldValue<span class="token punctuation">;</span>    <span class="token punctuation">}</span></code></pre><h3 id="7、boolean-add-E-e-void-add-int-index-E-element"><a href="#7、boolean-add-E-e-void-add-int-index-E-element" class="headerlink" title="7、boolean add(E e)   /   void add(int index, E element)"></a>7、<strong>boolean add(E e)   /   void add(int index, E element)</strong></h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">E</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token function">ensureCapacity</span><span class="token punctuation">(</span>size <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// add()时先扩容！</span>    elementData<span class="token punctuation">[</span>size<span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> e<span class="token punctuation">;</span><span class="token comment">//!!写的很好，size++的同时还完成了在最后位置的赋值。之所以size++不会报边界溢出的错误是因为上面已经扩容了。</span>    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">,</span> <span class="token class-name">E</span> element<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>index <span class="token operator">&gt;</span> size <span class="token operator">||</span> index <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IndexOutOfBoundsException</span><span class="token punctuation">(</span><span class="token string">"Index: "</span><span class="token operator">+</span>index<span class="token operator">+</span><span class="token string">", Size: "</span><span class="token operator">+</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">ensureCapacity</span><span class="token punctuation">(</span>size<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Increments modCount!!</span>    <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">arraycopy</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> index<span class="token punctuation">,</span> elementData<span class="token punctuation">,</span> index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>size <span class="token operator">-</span> index<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//!!把elementData的数据从index-&gt;末尾全部复制到从index+1开始，复制长度无size-index</span>    elementData<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> element<span class="token punctuation">;</span><span class="token comment">//相当于把传入的element插入到空出的位置，即原index</span>    size<span class="token operator">++</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span></code></pre><h3 id="8、E-remove-int-index-boolean-remove-Object-o-void-fastRemove-int-index"><a href="#8、E-remove-int-index-boolean-remove-Object-o-void-fastRemove-int-index" class="headerlink" title="8、E remove(int index)    /    boolean remove(Object o)    /    void fastRemove(int index)"></a>8、<strong>E remove(int index)    /    boolean remove(Object o)    /    void fastRemove(int index)</strong></h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">E</span> <span class="token function">remove</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token class-name">RangeCheck</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span><span class="token punctuation">;</span>    modCount<span class="token operator">++</span><span class="token punctuation">;</span>    <span class="token class-name">E</span> oldValue <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">E</span><span class="token punctuation">)</span> elementData<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment">//得到需要返回的被remove掉的元素</span>    <span class="token keyword">int</span> numMoved <span class="token operator">=</span> size <span class="token operator">-</span> index <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token comment">//复制时复制的长度，</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>numMoved <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">arraycopy</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> index<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> elementData<span class="token punctuation">,</span> index<span class="token punctuation">,</span>numMoved<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//把原数组从index+1--&gt;末尾的数据复制到 index的位置，即相当于把原本index上的数据覆盖掉了，这样最后就空出了一个位置。</span><pre><code>elementData&lt;span class="token punctuation"&gt;[&lt;/span&gt;&lt;span class="token operator"&gt;--&lt;/span&gt;size&lt;span class="token punctuation"&gt;]&lt;/span&gt; &lt;span class="token operator"&gt;=&lt;/span&gt; &lt;span class="token keyword"&gt;null&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt; &lt;span class="token comment"&gt;// 先把size减一，在把最后一赋值为null&lt;/span&gt;&lt;span class="token keyword"&gt;return&lt;/span&gt; oldValue&lt;span class="token punctuation"&gt;;&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;</code></pre><p><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">remove</span><span class="token punctuation">(</span><span class="token class-name">Object</span> o<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    <span class="token keyword">if</span> <span class="token punctuation">(</span>o <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//!!判断是否为null ,养成编程好习惯</span><br>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> index <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> index <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> index<span class="token operator">++</span><span class="token punctuation">)</span><br>        <span class="token keyword">if</span> <span class="token punctuation">(</span>elementData<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>            <span class="token function">fastRemove</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//这肯定是在边界之类，所以可以快速移除</span><br>            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span><br>        <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span><br>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> index <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> index <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> index<span class="token operator">++</span><span class="token punctuation">)</span><br>        <span class="token keyword">if</span> <span class="token punctuation">(</span>o<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>elementData<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>            <span class="token function">fastRemove</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span><span class="token punctuation">;</span><br>            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span><br>        <span class="token punctuation">}</span><br>        <span class="token punctuation">}</span><br>    <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span><br>    <span class="token punctuation">}</span></p></code><p><code class="language-java"><span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">fastRemove</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">//快速移除！ 此方法跳过了边界检查这一步，且不会返回被移除的元素。平时还是不要用哦~~</span><br>        modCount<span class="token operator">++</span><span class="token punctuation">;</span><br>        <span class="token keyword">int</span> numMoved <span class="token operator">=</span> size <span class="token operator">-</span> index <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">;</span><br>        <span class="token keyword">if</span> <span class="token punctuation">(</span>numMoved <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><br>            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">arraycopy</span><span class="token punctuation">(</span>elementData<span class="token punctuation">,</span> index<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> elementData<span class="token punctuation">,</span> index<span class="token punctuation">,</span>numMoved<span class="token punctuation">)</span><span class="token punctuation">;</span><br>        elementData<span class="token punctuation">[</span><span class="token operator">–</span>size<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span> <span class="token comment">// Let gc do its work</span><br>    <span class="token punctuation">}</span><br></code></p></pre>:hexoPostRenderEscape–&gt;<p></p><h2 id="5-迭代方式"><a href="#5-迭代方式" class="headerlink" title="5.迭代方式"></a>5.迭代方式</h2><ul><li><h3 id="1-随机访问"><a href="#1-随机访问" class="headerlink" title="1. 随机访问"></a>1. 随机访问</h3><p>由于ArrayList实现了RandomAccess接口，它支持通过索引值去随机访问元素。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> len <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> len<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">String</span> s <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre></li><li><h3 id="2-迭代器遍历"><a href="#2-迭代器遍历" class="headerlink" title="2. 迭代器遍历"></a>2. 迭代器遍历</h3><p>这其实就是迭代器模式</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Iterator</span> iter <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">while</span> <span class="token punctuation">(</span>iter<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">String</span> s <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">)</span>iter<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre></li><li><h3 id="3-增强for循环遍历"><a href="#3-增强for循环遍历" class="headerlink" title="3. 增强for循环遍历"></a>3. 增强for循环遍历</h3><p>这其实是一个语法糖</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> s <span class="token operator">:</span> list<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span></code></pre></li><li><h3 id="4-增强for循环遍历的实现"><a href="#4-增强for循环遍历的实现" class="headerlink" title="4.增强for循环遍历的实现"></a>4.增强for循环遍历的实现</h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">test_List</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> list <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>list<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>list<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> s <span class="token operator">:</span> list<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre></li></ul><h2 id="6-fail-fast机制"><a href="#6-fail-fast机制" class="headerlink" title="6.fail-fast机制"></a>6.fail-fast机制</h2><p><code>fail-fast</code>是说当并发的对容器内容进行操作时，快速的抛出<code>ConcurrentModificationException</code>；但是这种快速失败操作无法得到保证，它不能保证一定会出现该错误，但是快速失败操作会尽最大努力抛出<code>ConcurrentModificationException</code>异常。所以我们程序的正确性不能完全依赖这个异常，只应用于bug检测。</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">protected</span> <span class="token keyword">transient</span> <span class="token keyword">int</span> modCount <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">private</span> <span class="token keyword">void</span> <span class="token function">checkForComodification</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">ArrayList</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">.</span>modCount <span class="token operator">!=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>modCount<span class="token punctuation">)</span>    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">ConcurrentModificationException</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>在<code>ArrayList</code>的<code>Iterator</code>和<code>SubList</code>中，每当进行内存操作时，都会先使用<code>checkForComodification</code>来检测内容是否已修改。</p><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7.总结"></a>7.总结</h2><p>a.ArrayList动态数组！</p><p>b.ArrayList 非线程安全，即 是异步的。 单线程才用ArrayList。</p><p>c.<code>ArrayList</code>整体来看就是一个更加安全和方便的数组，但是他的插入和删除操作也实在是蛋疼，对于这一点其实可以通过树或者跳表来解决</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JDK源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JDK源码分析 </tag>
            
            <tag> ArrayList </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jdk源码分析(1)-String</title>
      <link href="/2019/07/17/jdk-yuan-ma-fen-xi-1-string/"/>
      <url>/2019/07/17/jdk-yuan-ma-fen-xi-1-string/</url>
      
        <content type="html"><![CDATA[<h1 id="jdk源码分析-1-String"><a href="#jdk源码分析-1-String" class="headerlink" title="jdk源码分析(1)-String"></a>jdk源码分析(1)-String</h1><p>在此之前有无数次下定决心要把JDK的源码大致看一遍。直到最近突然意识到，因为对源码的了解不深导致踩了许多莫名其妙的坑，所以再次下定决心要把常用的类全部看一遍。。。</p><p>万事开头难 </p><p><strong>Java.lang.String</strong>  是在lang包下面的一个final类</p><h2 id="一、String-声明和成员变量（不可变性）"><a href="#一、String-声明和成员变量（不可变性）" class="headerlink" title="一、String 声明和成员变量（不可变性）"></a>一、String 声明和成员变量（不可变性）</h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token number">1.</span><span class="token class-name">String</span> 是静态类，不可以被继承，可以被序列化，实现了<span class="token class-name">Comparable</span>接口<span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">class</span> <span class="token class-name">String</span>    <span class="token keyword">implements</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span><span class="token class-name">Serializable</span><span class="token punctuation">,</span> <span class="token class-name">Comparable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">,</span> <span class="token class-name">CharSequence</span> <span class="token punctuation">{</span>    <span class="token number">2.</span><span class="token class-name">String</span>的大部分操作都是围绕value这个字符数组定义的。同时<span class="token class-name">String</span>为了并发和一些安全性的考虑被设计成了不可变的类型，表明一旦被初始化完成后就是不可改变的    <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token keyword">char</span> value<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>注意点：    <span class="token number">1.</span><span class="token class-name">String</span>被声明为<span class="token keyword">final</span>类型：表明<span class="token class-name">String</span>不能被继承，即不能通过继承的方式改变其中的value值。    <span class="token number">2.</span>value被声明为<span class="token keyword">final</span>类型：这个<span class="token keyword">final</span>并不能表示value这个字符数组的值不可变，    只是确定了value这个字符数组在内存中的位置是不可变的    <span class="token number">3.</span><span class="token class-name">String</span>并没有提供修改value<span class="token punctuation">[</span><span class="token punctuation">]</span>值得方法，并且所有的方法都不是直接返回value<span class="token punctuation">[</span><span class="token punctuation">]</span>，    而是copy value<span class="token punctuation">[</span><span class="token punctuation">]</span>中的值或者新建一个<span class="token class-name">String</span>对象。    所以在通常意义上<span class="token class-name">String</span>是不可变的，但是却不是绝对意义上的不可变</code></pre><p>我们可以通过以下几种形式修改value的值</p><ul><li>final char[] value，只定义了value所指向的内存地址不变，其中的值是可以变的，所以我们可以通过反射直接修改value的值  </li><li>通过unsafe类替换value[]</li><li>通过unsafe类，定位value[]的内存位置修改值</li></ul><h2 id="二、构造函数"><a href="#二、构造函数" class="headerlink" title="二、构造函数"></a>二、构造函数</h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token class-name">String</span> original<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">char</span> value<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">char</span> value<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> offset<span class="token punctuation">,</span> <span class="token keyword">int</span> count<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> codePoints<span class="token punctuation">,</span> <span class="token keyword">int</span> offset<span class="token punctuation">,</span> <span class="token keyword">int</span> count<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">byte</span> ascii<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> hibyte<span class="token punctuation">,</span> <span class="token keyword">int</span> offset<span class="token punctuation">,</span> <span class="token keyword">int</span> count<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">byte</span> ascii<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> hibyte<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">byte</span> bytes<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> offset<span class="token punctuation">,</span> <span class="token keyword">int</span> length<span class="token punctuation">,</span> <span class="token class-name">String</span> charsetName<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">byte</span> bytes<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> offset<span class="token punctuation">,</span> <span class="token keyword">int</span> length<span class="token punctuation">,</span> <span class="token class-name">Charset</span> charset<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">byte</span> bytes<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token class-name">Charset</span> charset<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">byte</span> bytes<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> offset<span class="token punctuation">,</span> <span class="token keyword">int</span> length<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">byte</span> bytes<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token class-name">StringBuffer</span> buffer<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">(</span><span class="token class-name">StringBuilder</span> builder<span class="token punctuation">)</span><span class="token number">1.</span> 以上<span class="token number">15</span>个构造方法除了最后一个，都是将传入的参数copy到value中，并生成hash。这也是符合string的不可变原则<span class="token class-name">String</span><span class="token punctuation">(</span><span class="token keyword">char</span><span class="token punctuation">[</span><span class="token punctuation">]</span> value<span class="token punctuation">,</span> <span class="token keyword">boolean</span> share<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token comment">// assert share : "unshared not supported";</span>  <span class="token keyword">this</span><span class="token punctuation">.</span>value <span class="token operator">=</span> value<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token number">2.</span> 上面这个构造函数没有复制value数组，而是持有引用，共享value数组。    这是为了加快中间过程string的产生，而最后得到的string都是持有自己独立的value，所以string任然是不可变的</code></pre><h2 id="三、常用方法"><a href="#三、常用方法" class="headerlink" title="三、常用方法"></a>三、常用方法</h2><p><strong>强调，String方法的所有返回值，都是new的一个新对象，以保证不可变性</strong></p><h3 id="1-String-equals"><a href="#1-String-equals" class="headerlink" title="1.String.equals"></a><strong>1.String.equals</strong></h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">equals</span><span class="token punctuation">(</span><span class="token class-name">Object</span> anObject<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token keyword">this</span> <span class="token operator">==</span> anObject<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>anObject <span class="token keyword">instanceof</span> <span class="token class-name">String</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token class-name">String</span> anotherString <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">)</span>anObject<span class="token punctuation">;</span>    <span class="token keyword">int</span> n <span class="token operator">=</span> value<span class="token punctuation">.</span>length<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>n <span class="token operator">==</span> anotherString<span class="token punctuation">.</span>value<span class="token punctuation">.</span>length<span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">char</span> v1<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">;</span>      <span class="token keyword">char</span> v2<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> anotherString<span class="token punctuation">.</span>value<span class="token punctuation">;</span>      <span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>      <span class="token keyword">while</span> <span class="token punctuation">(</span>n<span class="token operator">--</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>v1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">!=</span> v2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>      <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>      i<span class="token operator">++</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>   <span class="token punctuation">}</span> <span class="token punctuation">}</span> <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span><span class="token punctuation">}</span>equals首先比较是否指向同一个内存地址，在比较是不是<span class="token class-name">String</span>类，再是长度最后内容注意比较</code></pre><h3 id="2-String-hashCode"><a href="#2-String-hashCode" class="headerlink" title="2.String.hashCode"></a>2.<strong>String.hashCode</strong></h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token keyword">int</span> h <span class="token operator">=</span> hash<span class="token punctuation">;</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>h <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> value<span class="token punctuation">.</span>length <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">char</span> val<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> value<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      h <span class="token operator">=</span> <span class="token number">31</span> <span class="token operator">*</span> h <span class="token operator">+</span> val<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>  hash <span class="token operator">=</span> h<span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">return</span> h<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token number">1.</span>hashcode使用的数学公式： s<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">31</span><span class="token operator">^</span><span class="token punctuation">(</span>n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> s<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">31</span><span class="token operator">^</span><span class="token punctuation">(</span>n<span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">+</span> s<span class="token punctuation">[</span>n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token number">2.</span><span class="token class-name">String</span> 经常会用作 hashMap 的 key，希望尽量减少 <span class="token class-name">String</span> 的 hash 冲突（冲突是指 hash 值相同，从而导致 hashMap 的 node 链表过长，所以通常希望计算的 hash 值尽可能的分散，从而提高查询效率）<span class="token number">3.</span>选择<span class="token number">31</span>是因为，如果乘数是偶数，并且结果溢出，那么信息就会是丢失（与<span class="token number">2</span>相乘相当于移位操作）<span class="token number">31</span>是一个奇素数，并且<span class="token number">31</span>有个很好的特性（目前大多数虚拟机都支持的优化<span class="token punctuation">)</span><span class="token operator">:</span><span class="token number">31</span> <span class="token operator">*</span> i <span class="token operator">==</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;&lt;</span> <span class="token number">5</span><span class="token punctuation">)</span> <span class="token operator">-</span> i</code></pre><h3 id="3-String-intern"><a href="#3-String-intern" class="headerlink" title="3.String.intern"></a>3.<strong>String.intern</strong></h3><pre class="language-java" data-language="java"><code class="language-java"><span class="token comment">/** * Returns a canonical representation for the string object. * &lt;p&gt; * A pool of strings, initially empty, is maintained privately by the * class {@code String}. * &lt;p&gt; * When the intern method is invoked, if the pool already contains a * string equal to this {@code String} object as determined by * the {@link #equals(Object)} method, then the string from the pool is * returned. Otherwise, this {@code String} object is added to the * pool and a reference to this {@code String} object is returned. * &lt;p&gt; * It follows that for any two strings {@code s} and {@code t}, * {@code s.intern() == t.intern()} is {@code true} * if and only if {@code s.equals(t)} is {@code true}. * &lt;p&gt; * All literal strings and string-valued constant expressions are * interned. String literals are defined in section 3.10.5 of the * &lt;cite&gt;The Java&amp;trade; Language Specification&lt;/cite&gt;. * @return a string that has the same contents as this string, but is guaranteed to be from a pool of unique strings. */</span> <span class="token keyword">public</span> <span class="token keyword">native</span> <span class="token class-name">String</span> <span class="token function">intern</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> intern这是一个<span class="token keyword">native</span>方法，主要用来查询常量池的字符串 注释中也写了 <span class="token number">1.</span> 如果常量池中中存在当前字符串，就会直接返回此字符串（此时当前字符串和常量池中的字符串一定不相同） <span class="token number">2.</span> 如果常量池中没有，就将当前字符串加入常量池后再返回（此时和常量池的实现相关） <span class="token number">3.</span> 这里有关常量池的设计，使用了享元模式</code></pre><p>将字符串加入常量池的两种方式：</p><ul><li>编译期生成的各种字面量和符号引用</li><li>运行期间通过<code>intern</code>方法将常量放入常量池</li></ul><p>常量池在不同JDK中的区别:</p><ul><li>在 JDK6 以及以前的版本中，字符串的常量池是放在堆的 Perm 区的，Perm 区是一个类静态的区域，主要存储一些加载类的信息，常量池，方法片段等内容</li><li>在 JDK7 的版本中，字符串常量池已经从 Perm 区移到正常的 Java Heap 区域</li><li>在 JDK8 则直接使用 Meta 区代替了 Perm 区，并且可以动态调整 Mata 区的大小</li></ul><h2 id="四、string-其他方法"><a href="#四、string-其他方法" class="headerlink" title="四、string 其他方法"></a>四、string 其他方法</h2><p><strong>主要都是操作<code>CharSequence</code></strong></p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">public</span> <span class="token keyword">char</span> <span class="token function">charAt</span><span class="token punctuation">(</span><span class="token keyword">int</span> index<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token class-name">String</span> charsetName<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">equalsIgnoreCase</span><span class="token punctuation">(</span><span class="token class-name">String</span> anotherString<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span><span class="token class-name">String</span> anotherString<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">startsWith</span><span class="token punctuation">(</span><span class="token class-name">String</span> prefix<span class="token punctuation">,</span> <span class="token keyword">int</span> toffset<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">endsWith</span><span class="token punctuation">(</span><span class="token class-name">String</span> suffix<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">indexOf</span><span class="token punctuation">(</span><span class="token keyword">int</span> ch<span class="token punctuation">,</span> <span class="token keyword">int</span> fromIndex<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">lastIndexOf</span><span class="token punctuation">(</span><span class="token keyword">int</span> ch<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">substring</span><span class="token punctuation">(</span><span class="token keyword">int</span> beginIndex<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">concat</span><span class="token punctuation">(</span><span class="token class-name">String</span> str<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">replace</span><span class="token punctuation">(</span><span class="token keyword">char</span> oldChar<span class="token punctuation">,</span> <span class="token keyword">char</span> newChar<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">matches</span><span class="token punctuation">(</span><span class="token class-name">String</span> regex<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">matches</span><span class="token punctuation">(</span><span class="token class-name">String</span> regex<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">split</span><span class="token punctuation">(</span><span class="token class-name">String</span> regex<span class="token punctuation">,</span> <span class="token keyword">int</span> limit<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">join</span><span class="token punctuation">(</span><span class="token class-name">CharSequence</span> delimiter<span class="token punctuation">,</span> <span class="token class-name">CharSequence</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> elements<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">toLowerCase</span><span class="token punctuation">(</span><span class="token class-name">Locale</span> locale<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">toUpperCase</span><span class="token punctuation">(</span><span class="token class-name">Locale</span> locale<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">trim</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">char</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token function">toCharArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">format</span><span class="token punctuation">(</span><span class="token class-name">String</span> format<span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> args<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">valueOf</span><span class="token punctuation">(</span><span class="token class-name">Object</span> obj<span class="token punctuation">)</span>对于以上的方法的原理由于内容太多 不一一描述了</code></pre><h2 id="五、StringBuilder和StringBuffer"><a href="#五、StringBuilder和StringBuffer" class="headerlink" title="五、StringBuilder和StringBuffer"></a>五、StringBuilder和StringBuffer</h2><p>由于String对象是不可变的，所以进行字符串拼接的时候就可以使用<code>StringBuilder</code> 和<code>StringBuffer</code>两个类</p><p><img src="/images/20190717/1.png"></p><p>从图中可以看到<code>StringBuilder</code> 和<code>StringBuffer</code>也是实现的<code>CharSequence</code>接口，同时他们实现了<code>Appendable</code>接口，具有对字符串动态操作的能力.</p><p>从他们父类<code>AbstractStringBuilder</code>的源码来看:</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">abstract</span> <span class="token keyword">class</span> <span class="token class-name">AbstractStringBuilder</span> <span class="token keyword">implements</span> <span class="token class-name">Appendable</span><span class="token punctuation">,</span> <span class="token class-name">CharSequence</span> <span class="token punctuation">{</span>  <span class="token keyword">char</span><span class="token punctuation">[</span><span class="token punctuation">]</span> value<span class="token punctuation">;</span>  <span class="token keyword">int</span> count<span class="token punctuation">;</span>  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">ensureCapacity</span><span class="token punctuation">(</span><span class="token keyword">int</span> minimumCapacity<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>minimumCapacity <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span>    <span class="token function">ensureCapacityInternal</span><span class="token punctuation">(</span>minimumCapacity<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token punctuation">}</span>  <span class="token keyword">public</span> <span class="token class-name">AbstractStringBuilder</span> <span class="token function">append</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>   <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token punctuation">}</span>  <span class="token keyword">public</span> <span class="token class-name">AbstractStringBuilder</span> <span class="token function">insert</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>   <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token number">1.</span>他们同样持有一个字符数组 <span class="token keyword">char</span><span class="token punctuation">[</span><span class="token punctuation">]</span> value，并且每次在对字符串进行操作的时候需要首先对数组容量进行确定，不足的时候需要扩容<span class="token number">2.</span>他们每个对字符串进行操作的方法，都会返回自身，所以我们可以使用链式编程的方式进行操作。另外现在还有一种通过泛型类定义链式操作的方式<span class="token number">3.</span><span class="token class-name">StringBuilder</span> 和 <span class="token class-name">StringBuffer</span> 的 API 都是互相兼容的，只是<span class="token class-name">StringBuffer</span>的每个方法都用的 <span class="token keyword">synchronized</span> 进行同步，所以是线程安全的</code></pre><p>操作符重载：</p><ul><li>每当我们要就行字符串拼接的时候，自然会使用到<code>+</code>，同时<code>+</code>和<code>+=</code>也是 java 中仅有的两个重载操作符</li><li>可以直接使用<code>StringBuffer</code>或者<code>StringBuilder</code>以提高性能；当然如果遇到类似<code>String s = “a” + “b” + “c” + ...</code>类似的连续加号的时候，JVM 会自动优化为一个 StringBuilder。</li></ul><h2 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h2><ol><li>主要介绍了String的一些基础的知识 在中间有些方法的源码无法很详细的介绍 </li><li>万事开头难 这也算是我对string的一个总结吧</li><li>还有很多细节没有写完，比如 String 在用于锁对象时，需要使用 intern 来保证是同一把锁</li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JDK源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JDK源码分析 </tag>
            
            <tag> string </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线程介绍和创建</title>
      <link href="/2019/06/19/xian-cheng-jie-shao-he-chuang-jian/"/>
      <url>/2019/06/19/xian-cheng-jie-shao-he-chuang-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="多线程介绍和创建"><a href="#多线程介绍和创建" class="headerlink" title="多线程介绍和创建"></a><center>多线程介绍和创建</center></h1><h2 id="一-什么是线程"><a href="#一-什么是线程" class="headerlink" title="一 什么是线程"></a>一 什么是线程</h2><p>我的答案就是 启动一个jvm 就是启动了一个进程 然后操作系统就给进程分配内存空间， 然后jvm启动main方法，就是启动了一个main线程  然后就是在栈空间分配main线程的栈帧 就是进程的一条执行路径</p><p>简单理解就是liunx系统启动程序是以进程级别运行的, 进程是以线程为基本单位运行的, 粒度更细！</p><p><strong>在jvm启动的时候 至少启动了一个main线程和一个gc线程 当然还有其他的一些线程</strong></p><h2 id="二-线程和进程的区别"><a href="#二-线程和进程的区别" class="headerlink" title="二 线程和进程的区别"></a>二 线程和进程的区别</h2><ol><li>调度</li></ol><p>​    进程是操作系统分配资源的一个基本单位。线程是 CPU调度的基本单位。</p><ol start="2"><li><p>并发性</p><p>一个进程里面可以有多个线程执行</p></li><li><p>独立性</p><p>在同一进程中线程的独立性要比在不同的进程中独立性要低很多</p></li><li><p>系统开销</p><p>线程切换的开销低于进程切换的开销</p></li></ol><h2 id="三-java-thread-api"><a href="#三-java-thread-api" class="headerlink" title="三 java thread api"></a>三 java thread api</h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">A</span> <span class="token generics"><span class="token punctuation">&lt;</span>i<span class="token punctuation">&gt;</span></span>thread<span class="token operator">&lt;</span><span class="token operator">/</span>i<span class="token operator">&gt;</span> is a thread of execution in a program<span class="token punctuation">.</span> <span class="token class-name">The</span> <span class="token class-name">Java</span> <span class="token operator">*</span> <span class="token class-name">Virtual</span> <span class="token class-name">Machine</span> allows an application <span class="token keyword">to</span> <span class="token namespace">have</span> multiple threads of <span class="token operator">*</span> execution running concurrently<span class="token punctuation">.</span><span class="token class-name">When</span> a <span class="token class-name">Java</span> <span class="token class-name">Virtual</span> <span class="token class-name">Machine</span> starts up<span class="token punctuation">,</span> there is usually a single <span class="token operator">*</span> non<span class="token operator">-</span>daemon thread <span class="token punctuation">(</span>which typically calls the method named <span class="token operator">*</span> <span class="token generics"><span class="token punctuation">&lt;</span>code<span class="token punctuation">&gt;</span></span>main<span class="token operator">&lt;</span><span class="token operator">/</span>code<span class="token operator">&gt;</span> of some designated <span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">.</span> <span class="token class-name">The</span> <span class="token class-name">Java</span> <span class="token class-name">Virtual</span> <span class="token operator">*</span> <span class="token class-name">Machine</span> continues <span class="token keyword">to</span> <span class="token namespace">execute</span> threads until either of the following <span class="token operator">*</span> occurs<span class="token operator">:</span>  创建线程的<span class="token number">2</span>种方法：<span class="token class-name">There</span> are two ways <span class="token keyword">to</span> <span class="token namespace">create</span> a <span class="token keyword">new</span> thread of execution<span class="token punctuation">.</span> <span class="token class-name">One</span> is <span class="token keyword">to</span> <span class="token operator">*</span> declare a <span class="token keyword">class</span> <span class="token keyword">to</span> <span class="token namespace">be</span> a subclass of <span class="token generics"><span class="token punctuation">&lt;</span>code<span class="token punctuation">&gt;</span></span><span class="token class-name">Thread</span><span class="token operator">&lt;</span><span class="token operator">/</span>code<span class="token operator">&gt;</span><span class="token punctuation">.</span> <span class="token class-name">This</span> <span class="token operator">*</span> subclass should override the <span class="token generics"><span class="token punctuation">&lt;</span>code<span class="token punctuation">&gt;</span></span>run<span class="token operator">&lt;</span><span class="token operator">/</span>code<span class="token operator">&gt;</span> method of <span class="token keyword">class</span> <span class="token operator">*</span> <span class="token generics"><span class="token punctuation">&lt;</span>code<span class="token punctuation">&gt;</span></span><span class="token class-name">Thread</span><span class="token operator">&lt;</span><span class="token operator">/</span>code<span class="token operator">&gt;</span><span class="token punctuation">.</span> <span class="token class-name">An</span> instance of the subclass can then be <span class="token operator">*</span> allocated and started。 <span class="token comment">/**     * Causes this thread to begin execution; the Java Virtual Machine     * calls the &lt;code&gt;run&lt;/code&gt; method of this thread.     * &lt;p&gt;     * The result is that two threads are running concurrently: the     * current thread (which returns from the call to the     * &lt;code&gt;start&lt;/code&gt; method) and the other thread (which executes its     * &lt;code&gt;run&lt;/code&gt; method).     * &lt;p&gt;     * It is never legal to start a thread more than once.     * In particular, a thread may not be restarted once it has completed     * execution.     */</span><span class="token keyword">public</span> <span class="token keyword">synchronized</span> <span class="token keyword">void</span> <span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">// thread 的构造函数     </span><span class="token keyword">public</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token class-name">Runnable</span> target<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token class-name">Runnable</span> target<span class="token punctuation">,</span> <span class="token class-name">AccessControlContext</span> acc<span class="token punctuation">)</span>  <span class="token keyword">public</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token class-name">ThreadGroup</span> group<span class="token punctuation">,</span> <span class="token class-name">Runnable</span> target<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token class-name">String</span> name<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token class-name">ThreadGroup</span> group<span class="token punctuation">,</span> <span class="token class-name">String</span> name<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token class-name">Runnable</span> target<span class="token punctuation">,</span> <span class="token class-name">String</span> name<span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token class-name">ThreadGroup</span> group<span class="token punctuation">,</span> <span class="token class-name">Runnable</span> target<span class="token punctuation">,</span> <span class="token class-name">String</span> name<span class="token punctuation">)</span>   <span class="token comment">//      stackSize 线程栈内存的大小 这个是比较重要的参数</span><span class="token keyword">public</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token class-name">ThreadGroup</span> group<span class="token punctuation">,</span> <span class="token class-name">Runnable</span> target<span class="token punctuation">,</span> <span class="token class-name">String</span> name<span class="token punctuation">,</span><span class="token keyword">long</span> stackSize<span class="token punctuation">)</span>       </code></pre><h2 id="四-java创建线程"><a href="#四-java创建线程" class="headerlink" title="四 java创建线程"></a>四 java创建线程</h2><ol><li><p>继承Thread</p><p>&lt;!–hexoPostRenderEscape:</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TryConcurrency</span> <span class="token punctuation">{</span><br> <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span><span class="token punctuation">{</span><p></p><pre><code> &lt;span class="token keyword"&gt;new&lt;/span&gt; &lt;span class="token class-name"&gt;Thread&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt; &lt;span class="token operator"&gt;-&gt;&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;     &lt;span class="token keyword"&gt;while&lt;/span&gt; &lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token boolean"&gt;true&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;         &lt;span class="token class-name"&gt;System&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;out&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;println&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token string"&gt;"我是"&lt;/span&gt; &lt;span class="token operator"&gt;+&lt;/span&gt; &lt;span class="token class-name"&gt;Thread&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;currentThread&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;         &lt;span class="token keyword"&gt;try&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;             &lt;span class="token class-name"&gt;Thread&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;sleep&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token number"&gt;1000&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;         &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt; &lt;span class="token keyword"&gt;catch&lt;/span&gt; &lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token class-name"&gt;InterruptedException&lt;/span&gt; e&lt;span class="token punctuation"&gt;)&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;             e&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;printStackTrace&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;         &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;     &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;start&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;</code></pre><p> <span class="token punctuation">}</span><br><span class="token punctuation">}</span></p></code></pre></li><code class="language-java"></code></ol><code class="language-java"></code><p><code class="language-java">我是<span class="token class-name">Thread</span><span class="token punctuation">[</span><span class="token class-name">Thread</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span>main<span class="token punctuation">]</span><br>我是<span class="token class-name">Thread</span><span class="token punctuation">[</span><span class="token class-name">Thread</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span>main<span class="token punctuation">]</span><br>我是<span class="token class-name">Thread</span><span class="token punctuation">[</span><span class="token class-name">Thread</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span>main<span class="token punctuation">]</span></code>:hexoPostRenderEscape–&gt;</p><ol start="2"><li><p>实现Runable</p><pre class="language-none"><code class="language-none">Runnable r = () -&gt; {      while (true){          System.out.println("我是实现了Runnable: " + Thread.currentThread());          try {              Thread.sleep(1000);          } catch (InterruptedException e) {              e.printStackTrace();          }      }    };    new Thread(r).start();</code></pre></li><li><p>使用Callable</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token class-name">Callable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> c <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>         <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>         <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> <span class="token number">100000</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>             sum <span class="token operator">+=</span> i<span class="token punctuation">;</span>         <span class="token punctuation">}</span>         <span class="token keyword">return</span> sum<span class="token punctuation">;</span>     <span class="token punctuation">}</span><span class="token punctuation">;</span>     <span class="token class-name">FutureTask</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> result <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FutureTask</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token keyword">try</span> <span class="token punctuation">{</span>         <span class="token class-name">Integer</span> o <span class="token operator">=</span> result<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>o<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">InterruptedException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>         e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ExecutionException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>         e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token punctuation">}</span><span class="token number">705082704</span></code></pre></li><li><p>使用线程池</p><pre class="language-java" data-language="java"><code class="language-java"><span class="token comment">//构造一个线程池</span>     <span class="token class-name">ThreadPoolExecutor</span> threadPool <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ThreadPoolExecutor</span><span class="token punctuation">(</span>             <span class="token number">1</span><span class="token punctuation">,</span>             <span class="token number">1</span><span class="token punctuation">,</span>             <span class="token number">10</span><span class="token punctuation">,</span>             <span class="token class-name">TimeUnit</span><span class="token punctuation">.</span>SECONDS<span class="token punctuation">,</span>             <span class="token keyword">new</span> <span class="token class-name">ArrayBlockingQueue</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>             <span class="token keyword">new</span> <span class="token class-name">ThreadPoolExecutor</span><span class="token punctuation">.</span><span class="token class-name">DiscardOldestPolicy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     threadPool<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>         <span class="token keyword">try</span> <span class="token punctuation">{</span>             <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                 <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"----"</span><span class="token operator">+</span><span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">currentThread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                 <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>             <span class="token punctuation">}</span>         <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>             e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token punctuation">}</span><span class="token keyword">finally</span><span class="token punctuation">{</span>             threadPool<span class="token punctuation">.</span><span class="token function">shutdown</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 关闭线程池</span>         <span class="token punctuation">}</span>     <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li></ol><h2 id="四-线程的生命周期"><a href="#四-线程的生命周期" class="headerlink" title="四 线程的生命周期"></a>四 线程的生命周期</h2><ul><li>线程状态<ul><li>new  —   new Thread()  </li><li>runnable   — start()</li><li>running  </li><li>block</li><li>termate</li></ul></li><li>线程的start方法不能调用2次</li><li>start方法使用了模板设计模式 start - start0是本地方法  run方法其实就是一个模板方法 需要实现的方法</li></ul><h2 id="五-模拟银行排队叫号"><a href="#五-模拟银行排队叫号" class="headerlink" title="五 模拟银行排队叫号"></a>五 模拟银行排队叫号</h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TickWindow</span> <span class="token keyword">extends</span> <span class="token class-name">Thread</span><span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">String</span> name<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token class-name">TickWindow</span><span class="token punctuation">(</span><span class="token class-name">String</span> name<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>name <span class="token operator">=</span> name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">int</span> MAX <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">;</span>    <span class="token comment">// 加static 有问题 和 不加static 有线程安全问题</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">int</span> index <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>index <span class="token operator">&lt;=</span> MAX<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"当前柜台是: "</span><span class="token operator">+</span>name<span class="token operator">+</span><span class="token string">" 当前号码是： index "</span> <span class="token operator">+</span> index<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Bank</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">new</span> <span class="token class-name">TickWindow</span><span class="token punctuation">(</span><span class="token string">"一号柜台"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">new</span> <span class="token class-name">TickWindow</span><span class="token punctuation">(</span><span class="token string">"二号柜台"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">new</span> <span class="token class-name">TickWindow</span><span class="token punctuation">(</span><span class="token string">"三号柜台"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h2 id="六-用runabble接口分离线程和业务逻辑"><a href="#六-用runabble接口分离线程和业务逻辑" class="headerlink" title="六 用runabble接口分离线程和业务逻辑"></a>六 用runabble接口分离线程和业务逻辑</h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestRunnable</span> <span class="token keyword">implements</span> <span class="token class-name">Runnable</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token class-name">TestRunnable</span> testRunnable <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TestRunnable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span>testRunnable<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span>testRunnable<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span>testRunnable<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> MAX <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">;</span>    <span class="token comment">//这里有一个线程安全的问题</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> index <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>     <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>index <span class="token operator">&lt;=</span> MAX<span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">currentThread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"  hello ----&gt; "</span> <span class="token operator">+</span> index<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">;</span><pre><code>        &lt;span class="token keyword"&gt;try&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;            &lt;span class="token class-name"&gt;Thread&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;sleep&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token number"&gt;1&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;        &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt; &lt;span class="token keyword"&gt;catch&lt;/span&gt; &lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token class-name"&gt;InterruptedException&lt;/span&gt; e&lt;span class="token punctuation"&gt;)&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;            e&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;printStackTrace&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;        &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;    &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;</code></pre><p><span class="token punctuation">}</span></p></code><p><code class="language-java"><span class="token operator"><em></em></span><em><span class="token operator"></span></em> 这种方式其实是使用了策略模式</code></p></pre>:hexoPostRenderEscape–&gt;<p></p><h2 id="七-Thread的api"><a href="#七-Thread的api" class="headerlink" title="七 Thread的api"></a>七 Thread的api</h2><pre class="language-java" data-language="java"><code class="language-java"><span class="token number">1.</span>  守护线程api t<span class="token punctuation">.</span><span class="token function">setDaemon</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token operator">*</span> <span class="token class-name">Marks</span> <span class="token keyword">this</span> thread as either a <span class="token punctuation">{</span><span class="token annotation punctuation">@linkplain</span> #isDaemon daemon<span class="token punctuation">}</span> thread     <span class="token operator">*</span> or a user thread<span class="token punctuation">.</span> <span class="token class-name">The</span> <span class="token class-name">Java</span> <span class="token class-name">Virtual</span> <span class="token class-name">Machine</span> exits when the only     <span class="token operator">*</span> threads running are all daemon threads<span class="token punctuation">.</span>     <span class="token operator">*</span>     <span class="token operator">*</span> <span class="token generics"><span class="token punctuation">&lt;</span>p<span class="token punctuation">&gt;</span></span> <span class="token class-name">This</span> method must be invoked before the thread is started<span class="token punctuation">.</span>    <span class="token comment">// 设置线程为守护线程</span>    <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">void</span> <span class="token function">setDaemon</span><span class="token punctuation">(</span><span class="token keyword">boolean</span> on<span class="token punctuation">)</span>     <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token class-name">Thread</span> t <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-&gt;</span><span class="token punctuation">{</span>            <span class="token keyword">try</span> <span class="token punctuation">{</span>                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">currentThread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"running"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">currentThread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"Done"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">InterruptedException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>                e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">// 守护线程意思是  主线程死亡 守护线程不管是什么状态 也死亡</span>        t<span class="token punctuation">.</span><span class="token function">setDaemon</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 必须要在start()前面</span>        t<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">currentThread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token number">2.</span> 线程id        t1<span class="token punctuation">.</span><span class="token function">getId</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token number">3.</span> 线程名称     t1<span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token number">4.</span> 线程优先级   t1<span class="token punctuation">.</span><span class="token function">setPriority</span><span class="token punctuation">(</span><span class="token class-name">Thread</span><span class="token punctuation">.</span>MAX_PRIORITY<span class="token punctuation">)</span><span class="token punctuation">;</span> 用处并不是很大<span class="token number">5.</span> 线程状态     <span class="token class-name">State</span> <span class="token function">getState</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token number">6.</span> 线程的<span class="token function">join</span><span class="token punctuation">(</span><span class="token punctuation">)</span>方法        <span class="token operator">*</span> <span class="token class-name">Waits</span> <span class="token keyword">for</span> <span class="token keyword">this</span> thread <span class="token keyword">to</span> <span class="token namespace">die<span class="token punctuation">.</span></span>     <span class="token operator">*</span>     <span class="token operator">*</span> <span class="token generics"><span class="token punctuation">&lt;</span>p<span class="token punctuation">&gt;</span></span> <span class="token class-name">An</span> invocation of <span class="token keyword">this</span> method behaves in exactly the same     <span class="token operator">*</span> way as the invocation    <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">void</span> <span class="token function">join</span><span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">synchronized</span> <span class="token keyword">void</span> <span class="token function">join</span><span class="token punctuation">(</span><span class="token keyword">long</span> millis<span class="token punctuation">,</span> <span class="token keyword">int</span> nanos<span class="token punctuation">)</span>    <span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">synchronized</span> <span class="token keyword">void</span> <span class="token function">join</span><span class="token punctuation">(</span><span class="token keyword">long</span> millis<span class="token punctuation">)</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>        <span class="token class-name">Thread</span> t1 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-&gt;</span><span class="token punctuation">{</span>            <span class="token class-name">IntStream</span><span class="token punctuation">.</span><span class="token function">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span>i<span class="token operator">-&gt;</span><span class="token punctuation">{</span>                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">currentThread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" --&gt; "</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span><pre><code>        &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    t1&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;start&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    &lt;span class="token comment"&gt;//放到start之后&lt;/span&gt;    &lt;span class="token comment"&gt;//先把t1 先执行完  再执行主线程   main线程等t1结束&lt;/span&gt;    t1&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;join&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    &lt;span class="token class-name"&gt;IntStream&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;range&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token number"&gt;1&lt;/span&gt;&lt;span class="token punctuation"&gt;,&lt;/span&gt; &lt;span class="token number"&gt;1000&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;forEach&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;i&lt;span class="token operator"&gt;-&gt;&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;        &lt;span class="token class-name"&gt;System&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;out&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;println&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token class-name"&gt;Thread&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;currentThread&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;getName&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt; &lt;span class="token operator"&gt;+&lt;/span&gt; &lt;span class="token string"&gt;" --&gt; "&lt;/span&gt; &lt;span class="token operator"&gt;+&lt;/span&gt; i&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;</code></pre><p><span class="token number">7.</span> 中断线程 <span class="token function">interrupt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>     <span class="token operator"><em></em></span><em> <span class="token class-name">Interrupts</span> <span class="token keyword">this</span> thread<span class="token punctuation">.</span><br>     <span class="token operator"></span></em><br>     <span class="token operator"><em></em></span><em> <span class="token generics"><span class="token punctuation">&lt;</span>p<span class="token punctuation">&gt;</span></span> <span class="token class-name">Unless</span> the current thread is interrupting itself<span class="token punctuation">,</span> which is<br>     <span class="token operator"></span></em> always permitted<span class="token punctuation">,</span> the <span class="token punctuation">{</span><span class="token annotation punctuation">@link</span> #<span class="token function">checkAccess</span><span class="token punctuation">(</span><span class="token punctuation">)</span> checkAccess<span class="token punctuation">}</span> method<br>     <span class="token operator"><em></em></span><em> of <span class="token keyword">this</span> thread is invoked<span class="token punctuation">,</span> which may cause a <span class="token punctuation">{</span><span class="token annotation punctuation">@link</span><br>     <span class="token operator"></span></em> <span class="token class-name">SecurityException</span><span class="token punctuation">}</span> <span class="token keyword">to</span> <span class="token namespace">be</span> thrown<span class="token punctuation">.</span></p><pre><code>&lt;span class="token keyword"&gt;public&lt;/span&gt; &lt;span class="token keyword"&gt;void&lt;/span&gt; &lt;span class="token function"&gt;interrupt&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token keyword"&gt;public&lt;/span&gt; &lt;span class="token keyword"&gt;static&lt;/span&gt; &lt;span class="token keyword"&gt;boolean&lt;/span&gt; &lt;span class="token function"&gt;interrupted&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token keyword"&gt;public&lt;/span&gt; &lt;span class="token keyword"&gt;boolean&lt;/span&gt; &lt;span class="token function"&gt;isInterrupted&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token keyword"&gt;private&lt;/span&gt; &lt;span class="token keyword"&gt;native&lt;/span&gt; &lt;span class="token keyword"&gt;boolean&lt;/span&gt; &lt;span class="token function"&gt;isInterrupted&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token keyword"&gt;boolean&lt;/span&gt; &lt;span class="token class-name"&gt;ClearInterrupted&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;&lt;span class="token keyword"&gt;public&lt;/span&gt; &lt;span class="token keyword"&gt;static&lt;/span&gt; &lt;span class="token keyword"&gt;void&lt;/span&gt; &lt;span class="token function"&gt;main&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token class-name"&gt;String&lt;/span&gt;&lt;span class="token punctuation"&gt;[&lt;/span&gt;&lt;span class="token punctuation"&gt;]&lt;/span&gt; args&lt;span class="token punctuation"&gt;)&lt;/span&gt; &lt;span class="token keyword"&gt;throws&lt;/span&gt; &lt;span class="token class-name"&gt;InterruptedException&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;    &lt;span class="token class-name"&gt;Thread&lt;/span&gt; t1 &lt;span class="token operator"&gt;=&lt;/span&gt; &lt;span class="token keyword"&gt;new&lt;/span&gt; &lt;span class="token class-name"&gt;Thread&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token operator"&gt;-&gt;&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;        &lt;span class="token keyword"&gt;while&lt;/span&gt; &lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token boolean"&gt;true&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;            &lt;span class="token keyword"&gt;try&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;                &lt;span class="token class-name"&gt;Thread&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;sleep&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token number"&gt;10&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;            &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt; &lt;span class="token keyword"&gt;catch&lt;/span&gt; &lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token class-name"&gt;InterruptedException&lt;/span&gt; e&lt;span class="token punctuation"&gt;)&lt;/span&gt; &lt;span class="token punctuation"&gt;&amp;#123;&lt;/span&gt;                &lt;span class="token class-name"&gt;System&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;out&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;println&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token string"&gt;"interrupte"&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;                e&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;printStackTrace&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;                &lt;span class="token keyword"&gt;break&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;            &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;        &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;    &lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    t1&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;start&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    &lt;span class="token class-name"&gt;Thread&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;sleep&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token number"&gt;100&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    &lt;span class="token class-name"&gt;System&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;out&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;println&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;t1&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;isInterrupted&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    t1&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;interrupt&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;    &lt;span class="token class-name"&gt;System&lt;/span&gt;&lt;span class="token punctuation"&gt;.&lt;/span&gt;out&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;println&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;t1&lt;span class="token punctuation"&gt;.&lt;/span&gt;&lt;span class="token function"&gt;isInterrupted&lt;/span&gt;&lt;span class="token punctuation"&gt;(&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;)&lt;/span&gt;&lt;span class="token punctuation"&gt;;&lt;/span&gt;&lt;span class="token punctuation"&gt;&amp;#125;&lt;/span&gt;</code></pre></code><p><code class="language-java"><span class="token number">8.</span> 优雅的结束线程<br>    </code></p></pre>:hexoPostRenderEscape–&gt;<p></p><h2 id="八-线程的数据同步和synchronized"><a href="#八-线程的数据同步和synchronized" class="headerlink" title="八 线程的数据同步和synchronized"></a>八 线程的数据同步和synchronized</h2><h2 id="九-死锁"><a href="#九-死锁" class="headerlink" title="九 死锁"></a>九 死锁</h2><h2 id="十-线程之间的通讯"><a href="#十-线程之间的通讯" class="headerlink" title="十 线程之间的通讯"></a>十 线程之间的通讯</h2><h2 id="十一-消费者和生产者-wait和notifiy"><a href="#十一-消费者和生产者-wait和notifiy" class="headerlink" title="十一 消费者和生产者 wait和notifiy"></a>十一 消费者和生产者 wait和notifiy</h2><h2 id="十二-wait和sleep的区别"><a href="#十二-wait和sleep的区别" class="headerlink" title="十二 wait和sleep的区别"></a>十二 wait和sleep的区别</h2><h2 id="十三-线程组"><a href="#十三-线程组" class="headerlink" title="十三 线程组"></a>十三 线程组</h2><h2 id="十四-实现自己的LOCK"><a href="#十四-实现自己的LOCK" class="headerlink" title="十四 实现自己的LOCK"></a>十四 实现自己的LOCK</h2><h2 id="十五-捕获线程运行中的异常"><a href="#十五-捕获线程运行中的异常" class="headerlink" title="十五 捕获线程运行中的异常"></a>十五 捕获线程运行中的异常</h2><h2 id="十六-自定义线程池"><a href="#十六-自定义线程池" class="headerlink" title="十六 自定义线程池"></a>十六 自定义线程池</h2><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> JAVA多线程高并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA多线程高并发 </tag>
            
            <tag> 线程介绍和创建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo搭建博客以及美化一</title>
      <link href="/2018/09/19/hexo-da-jian-bo-ke-yi-ji-mei-hua-yi/"/>
      <url>/2018/09/19/hexo-da-jian-bo-ke-yi-ji-mei-hua-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="hexo搭建博客以及美化一"><a href="#hexo搭建博客以及美化一" class="headerlink" title="hexo搭建博客以及美化一"></a><center>hexo搭建博客以及美化一</center></h1><h3 id="1-hexo搭建"><a href="#1-hexo搭建" class="headerlink" title="1 hexo搭建"></a>1 hexo搭建</h3><p>１　先说一下我的搭建的一些信息</p><pre><code>我的操作系统是ubuntu18.04　在这之上搭建的至于windows系统，我没搭建过所以不知道　可以参考</code></pre><p>2    安装hexo</p><blockquote><p>1 安装git 这个我就不说了太简单了   git –version</p></blockquote><blockquote><p>2 安装node js </p></blockquote><pre class="language-none"><code class="language-none">sudo tar -xJf node-v6.11.2-linux-x64.tar.xz -C /usr/localsudo ln -s /usr/local/node-v6.11.2-linux-x64/bin/node /usr/bin/nodesudo ln -s /usr/local/node-v6.11.2-linux-x64/bin/npm /usr/bin/npmnode  -v    npm -v</code></pre><blockquote><p>3 安装hexo</p></blockquote><pre class="language-none"><code class="language-none">安装hexo:    sudo npm install -g hexo在.bashrc　那么我的是在.zshrc中配置hexo的环境变量:    export PATH=/usr/local/node-v6.11.2-linux-x64/lib/node_modules/hexo/bin:$PATH初始化博客目录:    我的是在家目录下　hexo init解释一下各个文件或者目录:    node_modules：是依赖包    public：存放的是生成的页面    scaffolds：命令生成文章等的模板    source：用命令创建的各种文章    themes：主题    _config.yml：整个博客的配置    db.json：source解析所得到的    package.json：项目所需模块项目的配置信息</code></pre><p>3　目前只是简单配置next主题 因为我用的就是这个主题</p><pre class="language-none"><code class="language-none">hexo初始化之后默认的主题是landscape在家目录下的themes目录中:    cd themes/next    git clone https://github.com/iissnan/hexo-theme-next更新主题NexT:    cd themes/next    git pull    切换成NexT主题，在hexo根文件夹下，编辑_config.yml文件    这个是站点配置文件:    修改为：　theme: next切换后，用命令清除下缓存:    hexo clean执行hexo s本地产看NexT主题效果:    hexo s切换主题 cd blog/themes/next    vim _config.yaml    这个是主题配置文件    在列表中选择一款自己喜欢的主题风格。    # Schemes    scheme: Muse  //默认主题    #scheme: Mist    #scheme: Pisces    #scheme: Gemini        我是这个主题风格：scheme: Gemini设置Menu:    默认只有两个首页和归档    如果还要添加，编辑themes/next/_config.yml：    menu:          home: / || home         //首页          about: /about/ || user    //关于          tags: /tags/ || tags        //标签          categories: /categories/ || th    //分类          archives: /archives/ || archive    //归档         sitemap: /sitemap.xml || sitemap    //站点地图         commonweal: /404/ || heartbeat    //404页面    没有创建Menu对应的文件夹，Blog/source文件目录中只有_post目录    初始化对应的Menu文件夹:        比如要创建标签文件夹，终端中输入（前提在Hexo文件路径下）：            hexo new page "tags"            hexo new page "about"            hexo new page "categories"            hexo new page "archives"        成功之后在blog/source目录就有tags     about        categories archives 等目录        编辑Blog/source/tags中index.md文件，添加type: "tags"，其他Menu也同理创建。        ---        title: 标签        date: 2017-07-13 11:16:00        type: "tags"        comments: false        ---        ---        title: 分类        date: 2017-07-13 11:17:07        type: "categories"        comments: false        ---</code></pre><p><code>ok 到目前为止hexo next主题的基本配置就ｏｋ了 下面就是对页面的各种优化</code></p><p><strong>主题配置文件</strong>：　blog/themes/next/_config.yaml<br><strong>站点配置文件</strong>：　blog/_config.yam</p><p>4 设置动态背景</p><pre class="language-none"><code class="language-none">主题配置文件中找到canvas_nest，设置成ture就OK啦。# Canvas-nestcanvas_nest: ture</code></pre><p>5 在右上角或者左上角实现fork me on github</p><p>在<a href="https://blog.github.com/2008-12-19-github-ribbons/">GitHub Ribbons</a>或<a href="http://tholman.com/github-corners/">GitHub Corners</a>选择一款你喜欢的挂饰，拷贝方框内的代码：</p><pre class="language-none"><code class="language-none">将刚刚复制的挂饰代码，添加到Blog/themes/next/layout/_layout.swig文件中，添加位置如下图所示(放在&lt;div class="headband"&gt;&lt;/div&gt;下方)：&lt;a href="https://github.com/shuigedeng"&gt;&lt;img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png" alt="Fork me on GitHub"&gt;&lt;/a</code></pre><p>6 添加RSS</p><pre class="language-none"><code class="language-none">切换到Blog文件夹（hexo init的文件夹）下安装Hexo插件    npm install --save hexo-generator-feed安装成功之后，编辑Blog/_config.yml文件，在文件末尾添加    # Extensions    ## Plugins: http://hexo.io/plugins/    plugins: hexo-generate-feed    配置主题_config.yml文件，command+f搜索rss，在后面加上/atom.xml    # Set rss to false to disable feed link.    # Leave rss as empty to use site's feed link.    # Set rss to specific value if you have burned your feed already.    rss: /atom.xml //注意：有一个空格hexo s  查看效果        </code></pre><p>7 在文章末尾添加“文章结束”标记</p><pre class="language-none"><code class="language-none"></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>storm的2种运行方法</title>
      <link href="/2018/09/14/storm-de-2-chong-yun-xing-fang-fa/"/>
      <url>/2018/09/14/storm-de-2-chong-yun-xing-fang-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="storm的2种运行方法"><a href="#storm的2种运行方法" class="headerlink" title="storm的2种运行方法"></a><center>storm的2种运行方法</center></h1><p>先简单介绍一下我的信息</p><p>开发工具：ｉｄｅａ<br>ｓｔｏｒｍ版本：1.0.3</p><p>一下都以wordcount为例子</p><h4 id="1-storm集群运行"><a href="#1-storm集群运行" class="headerlink" title="1 storm集群运行"></a>1 storm集群运行</h4><p>1 pom文件：</p><pre class="language-none"><code class="language-none">&lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;            &lt;artifactId&gt;storm-core&lt;/artifactId&gt;                &lt;version&gt;1.0.3&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;finalName&gt;wordcount&lt;/finalName&gt;        &lt;plugins&gt;            &lt;!--&lt;plugin&gt;--&gt;                &lt;!--&lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;--&gt;                &lt;!--&lt;configuration&gt;--&gt;                    &lt;!--&lt;descriptorRefs&gt;--&gt;                        &lt;!--&lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;--&gt;                    &lt;!--&lt;/descriptorRefs&gt;--&gt;                    &lt;!--&lt;archive&gt;--&gt;                        &lt;!--&lt;manifest&gt;--&gt;                            &lt;!--&lt;mainClass&gt;com.datachina.storm.WordCountStorm&lt;/mainClass&gt;--&gt;                        &lt;!--&lt;/manifest&gt;--&gt;                    &lt;!--&lt;/archive&gt;--&gt;                &lt;!--&lt;/configuration&gt;--&gt;                &lt;!--&lt;executions&gt;--&gt;                    &lt;!--&lt;execution&gt;--&gt;                        &lt;!--&lt;id&gt;make-assembly&lt;/id&gt;--&gt;                        &lt;!--&lt;phase&gt;package&lt;/phase&gt;--&gt;                        &lt;!--&lt;goals&gt;--&gt;                            &lt;!--&lt;goal&gt;single&lt;/goal&gt;--&gt;                        &lt;!--&lt;/goals&gt;--&gt;                    &lt;!--&lt;/execution&gt;--&gt;                &lt;!--&lt;/executions&gt;--&gt;            &lt;!--&lt;/plugin&gt;--&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;source&gt;1.8&lt;/source&gt;                    &lt;target&gt;1.8&lt;/target&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;</code></pre><p>2 运行主类</p><pre class="language-none"><code class="language-none">public class WordCountStorm {    public static void main(String[] args) throws InvalidTopologyException, AuthorizationException, AlreadyAliveException {        TopologyBuilder builder = new TopologyBuilder();        builder.setSpout("mySpout", new MySpout(), 2);        builder.setBolt("mySplitBolt", new MySplitBolt(), 4).shuffleGrouping("mySpout");        builder.setBolt("myCountBolt", new MyCountBolt(), 2).fieldsGrouping("mySplitBolt", new Fields("word"));        //2、创建一个configuration，用来指定当前topology 需要的worker的数量        Config config = new Config();        config.setNumWorkers(2);        //3、提交任务  -----两种模式 本地模式和集群模式        StormSubmitter.submitTopology("mywordcount", config, builder.createTopology());//        LocalCluster localCluster = new LocalCluster();//        localCluster.submitTopology("mywordcount",config,builder.createTopology());    }}</code></pre><p>3 打包</p><p><img src="/images/20190914/1.png"></p><p><img src="/images/20190914/2.png"></p><p>4 上传ｊａｒ包到ｍａｓｔｅｒ节点</p><p><code>scp wordcount.jar hadoop@192.168.56.93:~/</code></p><p>5 启动任务</p><p><code>storm jar wordcount.jar com.datachina.storm.WordCountStorm wordcount</code></p><p><img src="/images/20190914/3.png"></p><p>看到finished submitting topology : mywordcount表示任务提交成功</p><p>6 ui 页面</p><p><img src="/images/20190914/4.png"></p><p>也可以看到任务在运行</p><p>７ kill 任务</p><p>可以用命令ｋｉｌｌ也可以在ＵＩ界面ｋｉｌｌ</p><p><code>storm kill mywordcount </code></p><h4 id="2-storm本地运行"><a href="#2-storm本地运行" class="headerlink" title="2 storm本地运行"></a>2 storm本地运行</h4><p>１ pom文件和上面的一样</p><p>2 主类：</p><pre class="language-none"><code class="language-none">public class WordCountStorm {    public static void main(String[] args) throws InvalidTopologyException, AuthorizationException, AlreadyAliveException {        TopologyBuilder builder = new TopologyBuilder();        builder.setSpout("mySpout", new MySpout(), 2);        builder.setBolt("mySplitBolt", new MySplitBolt(), 4).shuffleGrouping("mySpout");        builder.setBolt("myCountBolt", new MyCountBolt(), 2).fieldsGrouping("mySplitBolt", new Fields("word"));        //2、创建一个configuration，用来指定当前topology 需要的worker的数量        Config config = new Config();        config.setNumWorkers(2);        //3、提交任务  -----两种模式 本地模式和集群模式//        StormSubmitter.submitTopology("mywordcount", config, builder.createTopology());        LocalCluster localCluster = new LocalCluster();        localCluster.submitTopology("mywordcount",config,builder.createTopology());    }}</code></pre><p>3 直接运行ｍａｉｎ方法</p><p>4 运行结果如下：</p><pre class="language-none"><code class="language-none">count{a=821, i=822, loser=821}count{a=821, i=823, loser=821}count{a=822, i=823, loser=821}count{a=822, i=823, loser=822}count{a=822, i=824, loser=822}count{a=823, i=824, loser=822}count{a=823, i=824, loser=823}count{a=823, i=825, loser=823}count{a=824, i=825, loser=823}count{a=824, i=825, loser=824}count{a=824, i=826, loser=824}count{a=825, i=826, loser=824}count{a=825, i=826, loser=825}count{a=825, i=827, loser=825}count{a=826, i=827, loser=825}count{a=826, i=827, loser=826}count{a=826, i=828, loser=826}count{a=827, i=828, loser=826}count{a=827, i=828, loser=827}count{a=827, i=829, loser=827}count{a=828, i=829, loser=827}count{a=828, i=829, loser=828}count{a=828, i=830, loser=828}count{a=829, i=830, loser=828}</code></pre><p>程序运行没问题!</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> storm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop的４种运行方法</title>
      <link href="/2018/09/12/hadoop-de-4chong-yun-xing-fang-fa/"/>
      <url>/2018/09/12/hadoop-de-4chong-yun-xing-fang-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="hadoop的４种运行方法"><a href="#hadoop的４种运行方法" class="headerlink" title="hadoop的４种运行方法"></a><center>hadoop的４种运行方法</center></h1><p>介绍一下我一些信息：</p><p>我是在ubuntu18.04　上开发的mapreduce程序 ，　</p><p>我的hadoop集群是在我电脑的３台虚拟机上安装的集群，　</p><p>并且开发工具是ｉｄｅａ　！</p><p>以下实例我都用wordcount程序演示</p><h4 id="1-mapreduce程序本地运行-输入数据在本地-输出数据在本地"><a href="#1-mapreduce程序本地运行-输入数据在本地-输出数据在本地" class="headerlink" title="1 mapreduce程序本地运行　输入数据在本地　输出数据在本地"></a>1 mapreduce程序本地运行　输入数据在本地　输出数据在本地</h4><p><code>idea运行程序</code></p><p>输入数据在本地就是在我ubuntu18.04的电脑上:/home/dengtao/wordcount/input　<br>输出数据也是在我本地电脑上: /home/dengtao/wordcount/output</p><p>在我的WordCountDriver中配置文件是这样的：</p><pre class="language-none"><code class="language-none">Configuration conf = new Configuration();conf.set("mapreduce.framework.name", "local");　可以要也可以不要//指定job的输入原始文件所在目录FileInputFormat.setInputPaths(job, new Path("/home/dengtao/wordcount/input"));//指定job的输出结果所在目录FileOutputFormat.setOutputPath(job, new Path("/home/dengtao/wordcount/output"));</code></pre><p>在idea中直接运行main方法　　最后的效果是这样的：</p><p><img src="/images/20180912/23.png"></p><p><img src="/images/20180912/24.png"></p><p><img src="/images/20180912/25.png"></p><h4 id="2-mapreduce程序本地运行-输入数据在hdfs-输出数据在hdfs"><a href="#2-mapreduce程序本地运行-输入数据在hdfs-输出数据在hdfs" class="headerlink" title="2 mapreduce程序本地运行　输入数据在hdfs　输出数据在hdfs"></a>2 mapreduce程序本地运行　输入数据在hdfs　输出数据在hdfs</h4><p><code>idea运行程序</code></p><p>输入数据在hdfs://hadoop-master/wordcount/input　</p><p>输出数据在hhdfs://hadoop-master/wordcount/ouput　</p><p>在我的WordCountDriver中配置文件是这样的：</p><pre class="language-none"><code class="language-none">Configuration conf = new Configuration();conf.set("fs.defaultFS", "hdfs://hadoop-master:9000");conf.set("HADOOP_USER_NAME", "hadoop");//指定job的输入原始文件所在目录FileInputFormat.setInputPaths(job, new Path("hdfs://hadoop-master:9000/wordcount/input"));//指定job的输出结果所在目录FileOutputFormat.setOutputPath(job, new Path("hdfs://hadoop-master:9000/wordcount/output3"));</code></pre><p><code>前提先启动hadoop集群</code></p><p>在idea中直接运行main方法　最后的效果是这样的：</p><p><img src="/images/20180912/26.png"></p><p><img src="/images/20180912/27.png"></p><p><img src="/images/20180912/28.png"></p><h4 id="3-mapreduce程序在yarn上运行-输入数据在hdfs-输出数据在hdfs"><a href="#3-mapreduce程序在yarn上运行-输入数据在hdfs-输出数据在hdfs" class="headerlink" title="3 mapreduce程序在yarn上运行 输入数据在hdfs  输出数据在hdfs"></a>3 mapreduce程序在yarn上运行 输入数据在hdfs  输出数据在hdfs</h4><p><code>不在上idea运行程序</code></p><p>这一种方法是要将ｍｒ程序打成ｊａｒ包上传到Ｈａｄｏｏｐ集群，　然后提交任务给ｙａｒｎ运行</p><p>配置文件：　<br>１　pom文件：</p><pre class="language-none"><code class="language-none">&lt;build&gt;        &lt;finalName&gt;wordcount&lt;/finalName&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;source&gt;1.8&lt;/source&gt;                    &lt;target&gt;1.8&lt;/target&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;</code></pre><p>2  主配置文件：</p><pre class="language-none"><code class="language-none">Configuration conf = new Configuration();conf.set("fs.defaultFS", "hdfs://hadoop-master:9000");conf.set("HADOOP_USER_NAME", "hadoop");conf.set("mapreduce.framework.name", "yarn");conf.set("yarn.resoucemanager.hostname", "hadoop-master");//指定job的输入原始文件所在目录FileInputFormat.setInputPaths(job, new Path("hdfs://hadoop-master:9000/wordcount/input"));//指定job的输出结果所在目录FileOutputFormat.setOutputPath(job, new Path("hdfs://hadoop-master:9000/wordcount/output4"));</code></pre><p>3 打成jar包上传到Ｈａｄｏｏｐ集群</p><p><img src="/images/20180912/29.png"></p><p><img src="/images/20180912/30.png"></p><p><img src="/images/20180912/31.png"></p><p><code>scp wordcount.jar hadoop@192.168.56.90:~/ </code></p><p>4 在hadoop集群上运行mr程序</p><p><code>hadoop jar wordcount.jar  com.datachina.hadoop.mapreduce.wordcount.WordCountDriver </code></p><p><img src="/images/20180912/32.png"></p><p><img src="/images/20180912/33.png"></p><h4 id="4-mapreduce程序在yarn上运行-输入数据在hdfs-输出数据在hdfs"><a href="#4-mapreduce程序在yarn上运行-输入数据在hdfs-输出数据在hdfs" class="headerlink" title="4 mapreduce程序在yarn上运行 输入数据在hdfs  输出数据在hdfs"></a>4 mapreduce程序在yarn上运行 输入数据在hdfs  输出数据在hdfs</h4><p><strong>也就是说idea远程调试mapreduce程序</strong></p><p><code>idea运行程序</code></p><p>配置文件：　<br>１　pom文件：</p><pre class="language-none"><code class="language-none">&lt;build&gt;        &lt;finalName&gt;wordcount&lt;/finalName&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;source&gt;1.8&lt;/source&gt;                    &lt;target&gt;1.8&lt;/target&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;</code></pre><p>2  主配置文件：</p><pre class="language-none"><code class="language-none">Configuration conf = new Configuration();conf.set("fs.defaultFS", "hdfs://hadoop-master:9000");conf.set("HADOOP_USER_NAME", "hadoop");conf.set("mapreduce.framework.name", "yarn");conf.set("yarn.resoucemanager.hostname", "hadoop-master");conf.set("yarn.resourcemanager.address", "hadoop-master:8032");Job job = Job.getInstance(conf);job.setJar("/home/dengtao/myProject/java/hadoop-project/myself-hadoop-learn-code/target/wordcount.jar");//指定job的输入原始文件所在目录FileInputFormat.setInputPaths(job, new Path("hdfs://hadoop-master:9000/wordcount/input"));//指定job的输出结果所在目录FileOutputFormat.setOutputPath(job, new Path("hdfs://hadoop-master:9000/wordcount/output5"));</code></pre><p>3 打成jar包</p><p><img src="/images/20180912/29.png"></p><p><img src="/images/20180912/30.png"></p><p>4 运行mapreduce程序</p><p>为什么？</p><pre class="language-none"><code class="language-none">2018-09-12 17:13:08,688 WARN [org.apache.hadoop.util.NativeCodeLoader] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable2018-09-12 17:13:09,239 INFO [org.apache.hadoop.yarn.client.RMProxy] - Connecting to ResourceManager at hadoop-master/192.168.56.90:80322018-09-12 17:13:09,629 WARN [org.apache.hadoop.mapreduce.JobResourceUploader] - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.2018-09-12 17:13:10,781 INFO [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] - Total input paths to process : 12018-09-12 17:13:10,902 INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:12018-09-12 17:13:10,996 INFO [org.apache.hadoop.mapreduce.JobSubmitter] - Submitting tokens for job: job_1536743562408_00012018-09-12 17:13:11,258 INFO [org.apache.hadoop.yarn.client.api.impl.YarnClientImpl] - Submitted application application_1536743562408_00012018-09-12 17:13:11,287 INFO [org.apache.hadoop.mapreduce.Job] - The url to track the job: http://hadoop-master:8088/proxy/application_1536743562408_0001/2018-09-12 17:13:11,287 INFO [org.apache.hadoop.mapreduce.Job] - Running job: job_1536743562408_0001</code></pre><p>程序运行到Ｒunning job 卡着不动了？？？？？？</p><p><code> **经过一个晚上的调试我终于知道是怎么回事了**</code></p><p>1 配置文件修改</p><pre class="language-none"><code class="language-none">Configuration conf = new Configuration();设置系统用户System.setProperty("HADOOP_USER_NAME", "hadoop");conf.set("fs.defaultFS", "hdfs://hadoop-master:9000");//        conf.set("HADOOP_USER_NAME", "hadoop");conf.set("mapreduce.framework.name", "yarn");conf.set("yarn.resoucemanager.hostname", "hadoop-master");修改地方一：conf.set("yarn.resourcemanager.address", "hadoop-master:8032");conf.set("yarn.resourcemanager.resource-tracker.address", "hadoop-master:8031");conf.set("yarn.resourcemanager.scheduler.address", "hadoop-master:8030");以上３个配置是我在Ｈａｄｏｏｐ集群的yarn-site.xml中是没有配置的！如果是在Ｈａｄｏｏｐ集群上运行jar包的话　默认是hadoop-master:8032 或者是hadoop-master:8031等等　但是我在用ｉｄｅａ远程调试ｊａｒ的话那么上面的配置的值是0.0.0.0:8032或者0.0.0.0:8031所以程序会停着不动修改地方二：在hadoop集群上启动：　mr-jobhistory-daemon.sh start historyserverconf.set("mapreduce.jobhistory.address", "hadoop-master:10020");此处是配置一些内存管理,默认是可以不用配置的,但是一旦mr报出内存错误那么就可以设置这几个内存管理的值//        conf.set("yarn.nodemanager.resource.memory-mb", "3072");//        conf.set("yarn.scheduler.minimum-allocation-mb", "2048");//        conf.set("yarn.nodemanager.vmem-pmem-ratio", "2.1");Job job = Job.getInstance(conf);job.setJar("/home/dengtao/myProject/java/hadoop-project/myself-hadoop-learn-code/target/wordcount.jar");//        job.setJarByClass(WordCountDriver.class);如果是远程调试的话一定要在Ｈａｄｏｏｐ集群上开启：mr-jobhistory-daemon.sh start historyserver...</code></pre><p>最终我的主文件为：</p><p><img src="/images/20180912/34.png"></p><p><img src="/images/20180912/35.png"></p><p><img src="/images/20180912/35.png"></p><h3 id="5-总结一下上面４种mapreduce程序的运行方式"><a href="#5-总结一下上面４种mapreduce程序的运行方式" class="headerlink" title="5 总结一下上面４种mapreduce程序的运行方式"></a>5 总结一下上面４种mapreduce程序的运行方式</h3><blockquote><p>上面的４种方式仅仅只是Ｈａｄｏｏｐ集群不是ＨＡ机制下的mr程序运行方式</p></blockquote><blockquote><p>如果hadoop集群是ha的话：配置会有一些改动  下次再写吧！</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubunt18.04 配置ss</title>
      <link href="/2018/09/12/ubunt18.04-pei-zhi-ss/"/>
      <url>/2018/09/12/ubunt18.04-pei-zhi-ss/</url>
      
        <content type="html"><![CDATA[<h1 id="ubunt18-04-配置ss"><a href="#ubunt18-04-配置ss" class="headerlink" title=" ubunt18.04 配置ss "></a><center> ubunt18.04 配置ss </center></h1><h3 id="1-购买服务器"><a href="#1-购买服务器" class="headerlink" title="1 购买服务器"></a>1 购买服务器</h3><p>我是在这个网站购买的：<a href="https://www.vultr.com/">https://www.vultr.com/</a>　<br>相对来说比阿里云和腾讯云性价比高</p><p>１．注册账号</p><p><img src="/images/20180912/1.png"></p><p>Email address：输入一个邮箱</p><p>password：输入你要设置的密码</p><p>最后点“create account”创建帐号，随后到你的注册邮箱进行验证，打开邮箱点击邮件中Vultr发送的验证连接即可，验证完成就可以给账户充值。</p><h3 id="2-账户充值："><a href="#2-账户充值：" class="headerlink" title="2 .    账户充值："></a>2 .    账户充值：</h3><p><img src="/images/20180912/2.png"></p><p>点页面左侧“Billing”，支持信用卡、PayPal、比特币和支付宝，最低充值10美元起，从上面链接进入冲10美元可以获赠25美元，这样算下来10美元可以免费使用7个月的服务器，还是很划算的。</p><h3 id="3-充值完毕后点击页面右上角的“-”号进行选购VPS方案。"><a href="#3-充值完毕后点击页面右上角的“-”号进行选购VPS方案。" class="headerlink" title="3 . 充值完毕后点击页面右上角的“+”号进行选购VPS方案。"></a>3 . 充值完毕后点击页面右上角的“+”号进行选购VPS方案。</h3><p><img src="/images/20180912/3.png"></p><h3 id="4-然后选择服务器位置（ps：大陆用户推荐日本服务器和洛杉矶的服务器）"><a href="#4-然后选择服务器位置（ps：大陆用户推荐日本服务器和洛杉矶的服务器）" class="headerlink" title="4 . 然后选择服务器位置（ps：大陆用户推荐日本服务器和洛杉矶的服务器）"></a>4 . 然后选择服务器位置（ps：大陆用户推荐日本服务器和洛杉矶的服务器）</h3><p><img src="/images/20180912/4.png"></p><p>选择系统（ps：系统推荐64位centos）</p><p>选择配置（ps：推荐5美元/月的配置）最后就是点击deploy now完成配置</p><p><img src="/images/20180912/5.png"></p><h3 id="5-查看VPS配置信息"><a href="#5-查看VPS配置信息" class="headerlink" title="5 . 查看VPS配置信息"></a>5 . 查看VPS配置信息</h3><p><img src="/images/20180912/6.png"></p><p><img src="/images/20180912/7.png"></p><p>ps: 图中的是我自己创建的服务器的ip地址我已经destory了！</p><h3 id="6-ssh登录"><a href="#6-ssh登录" class="headerlink" title="6 . ssh登录"></a>6 . ssh登录</h3><p>在terminal中我的电脑是ubuntu18.04 　windows的我没用过哈！</p><p><code>ssh root@139.180.200.97</code> </p><p>然后密码就填服务器中的密码</p><p><img src="/images/20180912/8.png"></p><h3 id="7-安装ss服务器"><a href="#7-安装ss服务器" class="headerlink" title="7 . 安装ss服务器"></a>7 . 安装ss服务器</h3><p>中文版：</p><blockquote><p>wget –no-check-certificate -O shadowsocks-libev_CN.sh <a href="https://raw.githubusercontent.com/uxh/shadowsocks_bash/master/shadowsocks-libev_CN.sh">https://raw.githubusercontent.com/uxh/shadowsocks_bash/master/shadowsocks-libev_CN.sh</a> &amp;&amp; bash shadowsocks-libev_CN.sh</p></blockquote><p>英文版：（如果中文版执行后出现乱码，那么请使用这个）:</p><blockquote><p>wget –no-check-certificate -O shadowsocks-libev.sh <a href="https://raw.githubusercontent.com/uxh/shadowsocks_bash/master/shadowsocks-libev.sh">https://raw.githubusercontent.com/uxh/shadowsocks_bash/master/shadowsocks-libev.sh</a> &amp;&amp; bash shadowsocks-libev.sh</p></blockquote><p>如图，回车继续</p><p><img src="/images/20180912/9.png"></p><p>中文版的基本上大家都能看得懂，输入 1 选择安装服务，回车</p><p><img src="/images/20180912/10.png"></p><p>按照下图中的提示，我们首先依次输入 SS 的各项信息，然后回车继续即可。</p><p>PS：如果有信息输入错误需要更改时，请按住 Ctrl 键后再按删除键，直接按删除键是不能删除的。</p><p><img src="/images/20180912/11.png"></p><p>大约 2~5 分钟即可安装完成，完成后保存SS信息，就能使用了。</p><p><img src="/images/20180912/12.png"></p><p>注意：一定要保存上图的SS信息以免忘记。</p><h3 id="8-在自己的电脑上安装ss客户端"><a href="#8-在自己的电脑上安装ss客户端" class="headerlink" title="8 . 在自己的电脑上安装ss客户端"></a>8 . 在自己的电脑上安装ss客户端</h3><pre class="language-none"><code class="language-none">sudo apt-get install shadowsocks-qt5 sudo add-apt-repository ppa:hzwhuang/ss-qt5vim /etc/apt/sources.list.d/hzwhuang-ubuntu-ss-qt5-bionic.listsudo vim /etc/apt/sources.list.d/hzwhuang-ubuntu-ss-qt5-bionic.list这一步是把xenial main　换成　bionic mainsudo apt-get install shadowsocks-qt5</code></pre><p>然后打开qt5　如图</p><p><img src="/images/20180912/13.png"></p><p>然后点连接　－－　添加　如图</p><p><img src="/images/20180912/14.png"></p><p>输入信息点击ok就行了</p><h3 id="9-配置google浏览器vpn"><a href="#9-配置google浏览器vpn" class="headerlink" title="9 . 配置google浏览器vpn"></a>9 . 配置google浏览器vpn</h3><p>在浏览器上安装proxy switchyomega插件</p><p>点击新建情景模式 　如图：</p><p><img src="/images/20180912/15.png"></p><p>然后在proxy switchyomega插件图标上 左键点击ss就可以翻墙了！</p><h3 id="10-在ubuntu-18-04上配置全局代理"><a href="#10-在ubuntu-18-04上配置全局代理" class="headerlink" title="10 . 　在ubuntu 18.04上配置全局代理"></a>10 . 　在ubuntu 18.04上配置全局代理</h3><p>1 安装GenPAC</p><p>2  完成之后，下载gfwlist<br>genpac –pac-proxy “SOCKS5 127.0.0.1:1080”  –pac-proxy=”SOCKS5 127.0.0.1:1080” –gfwlist-url=<a href="https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</a> –output=”autoproxy.pac” </p><p>找到下载下来的 autoproxy.pac文件，然后进入：设置—网络—网络代理，选择自动，URL 指向该文件路径即可，url 格式为：</p><p>file:///home/{user}/autoproxy.pac</p><p><img src="/images/20180912/16.png"></p><p>3 配置浏览器</p><p>此处以火狐为例：首选项——网络代理—— 设置，选择 “使用系统代理设置” 即可</p><p><img src="/images/20180912/17.png"></p><p>4 这样，浏览器就能正常使用代理了。</p><p><img src="/images/20180912/18.png"></p><h3 id="11-配置终端也可以使用vpn"><a href="#11-配置终端也可以使用vpn" class="headerlink" title="11 . 配置终端也可以使用vpn　　"></a>11 . 配置终端也可以使用vpn　　</h3><p>１　安装并配置 privoxy 之安装 privoxy<br><code>sudo apt install privoxy</code></p><p>2    配置privoxy<br><code>sudo gedit /etc/privoxy/config</code> </p><p> 打开文件找到4.1节 listen-address，找到#listen-address 127.0.0.1:8118，取消注释</p><p> <img src="/images/20180912/19.png"></p><p>找到5.2节forward-socks4, forward-socks4a, forward-socks5 and forward-socks5t，</p><p>找到#forward-socks5t / 127.0.0.1:9050 .（后面的.很重要，不能舍弃，端口值可能和我的不一样，改成1080即可）。</p><p> <img src="/images/20180912/20.png"></p><p> 修改完之后，重启 privoxy：</p><p><code>$ sudo /etc/init.d/privoxy restart</code></p><p> <img src="/images/20180912/21.png"></p><p> 再修改~/.bashrc</p><p>$ sudo gedit ~/.bashrc  因为我用的是zsh　所以的配置文件是在.zshrc中</p><p>打开文件后，加入：</p><pre class="language-none"><code class="language-none">export http_proxy="127.0.0.1:8118"export https_proxy="127.0.0.1:8118"export ftp_proxy="127.0.0.1:8118"</code></pre><p>保存退出后，终端也就可以使用代理了，我们来试一下 curl：</p><p><code>curl   www.google.com</code></p><p>有返回，则说明配置成功。</p><h3 id="12-为-Git-配置代理"><a href="#12-为-Git-配置代理" class="headerlink" title="12 .  为 Git 配置代理"></a>12 .  为 Git 配置代理</h3><p>为 git 配置代理 比如说：$ git clone <a href="https://chromium.googlesource.com/external/webrtc">https://chromium.googlesource.com/external/webrtc</a></p><p>会报错：</p><p>正克隆到 ‘webrtc’… </p><p>fatal: unable to access ‘<a href="https://chromium.googlesource.com/external/webrtc/'">https://chromium.googlesource.com/external/webrtc/'</a>: </p><p>Failed to connect to chromium.googlesource.com port 443: 连接超时</p><p>所以需先为 git 配置代理：</p><pre class="language-none"><code class="language-none">$ git config --global http.proxy 'socks5://127.0.0.1:1080' $ git config --global https.proxy 'socks5://127.0.0.1:1080'</code></pre><p>配置好就能 正常clone了：</p><p> <img src="/images/20180912/22.png"></p><p> 如果要关闭代理可使用一下命令：</p><pre class="language-none"><code class="language-none">$ git config --global --unset http.proxy$ git config --global --unset https.proxy</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ubunt18.04 配置ss </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>storm 自己的理解,遇到的问题记录三</title>
      <link href="/2018/08/30/storm-zi-ji-de-li-jie-yu-dao-de-wen-ti-ji-lu-san/"/>
      <url>/2018/08/30/storm-zi-ji-de-li-jie-yu-dao-de-wen-ti-ji-lu-san/</url>
      
        <content type="html"><![CDATA[<h1 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a><center>kafka</center></h1><h2 id="1、Kafka是什么"><a href="#1、Kafka是什么" class="headerlink" title="1、Kafka是什么"></a>1、Kafka是什么</h2><p>在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算。</p><p>KAFKA + STORM +REDIS</p><pre><code>• Apache Kafka是一个开源消息系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。• Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。• Kafka是一个分布式消息队列：生产者、消费者的功能。它提供了类似于JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现。• Kafka对消息保存时根据Topic进行归类，发送消息者称为Producer,消息接受者称为Consumer,此外kafka集群有多个kafka实例组成，每个实例(server)成为broker。• 无论是kafka集群，还是producer和consumer都依赖于zookeeper集群保存一些meta信息，来保证系统可用性</code></pre><h2 id="2、JMS是什么"><a href="#2、JMS是什么" class="headerlink" title="2、JMS是什么"></a>2、JMS是什么</h2><p>2.1、JMS的基础</p><pre class="language-none"><code class="language-none">JMS是什么：JMS是Java提供的一套技术规范JMS干什么用：用来异构系统 集成通信，缓解系统瓶颈，提高系统的伸缩性增强系统用户体验，使得系统模块化和组件化变得可行并更加灵活通过什么方式：生产消费者模式（生产者、服务器、消费者）</code></pre><p>jdk，kafka，activemq……</p><p>2.2、JMS消息传输模型</p><pre><code>• 点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）</code></pre><p>点对点模型通常是一个基于拉取或者轮询的消息传送模型，这种模型从队列中请求信息，而不是将消息推送到客户端。这个模型的特点是发送到队列的消息被一个且只有一个接收者接收处理，即使有多个消息监听者也是如此。</p><pre><code>• 发布/订阅模式（一对多，数据生产后，推送给所有订阅者）</code></pre><p>发布订阅模型则是一个基于推送的消息传送模型。发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息，即时当前订阅者不可用，处于离线状态。</p><p>queue.put（object）  数据生产<br>queue.take(object)    数据消费</p><p>2.3、JMS核心组件</p><pre><code>• Destination：消息发送的目的地，也就是前面说的Queue和Topic。• Message ：从字面上就可以看出是被发送的消息。• Producer： 消息的生产者，要发送一个消息，必须通过这个生产者来发送。• MessageConsumer： 与生产者相对应，这是消息的消费者或接收者，通过它来接收一个消息。</code></pre><p>通过与ConnectionFactory可以获得一个connection<br>通过connection可以获得一个session会话。</p><p>2.4、常见的类JMS消息服务器</p><pre class="language-none"><code class="language-none">JMS消息服务器 ActiveMQ分布式消息中间件 Metamorphosis分布式消息中间件 RocketMQ.NET消息中间件 DotNetMQ基于HBase的消息队列 HQueueGo 的 MQ 框架 KiteQAMQP消息服务器 RabbitMQ MemcacheQ 是一个基于 MemcacheDB 的消息队列服务器。</code></pre><p>3、为什么需要消息队列（重要）</p><p><font style="color:red">消息系统的核心作用就是三点：解耦，异步和并行</font></p><p>4、Kafka核心组件</p><pre><code>• Topic ：消息根据Topic进行归类• Producer：发送消息者• Consumer：消息接受者• broker：每个kafka实例(server)• Zookeeper：依赖集群保存meta信息。</code></pre><p><img src="/images/20180830/4.png">    </p><p>5  关于kakfa集群部署在我的其他文档中有　可以自己查找</p><p>6 Kafka常用操作命令</p><pre class="language-none"><code class="language-none">    • 查看当前服务器中的所有topicbin/kafka-topics.sh --list --zookeeper  zk01:2181    • 创建topic./kafka-topics.sh --create --zookeeper mini1:2181 --replication-factor 1 --partitions 3 --topic first    • 删除topicsh bin/kafka-topics.sh --delete --zookeeper zk01:2181 --topic test需要server.properties中设置delete.topic.enable=true否则只是标记删除或者直接重启。    • 通过shell命令发送消息kafka-console-producer.sh --broker-list kafka01:9092 --topic itheima    • 通过shell消费消息sh bin/kafka-console-consumer.sh --zookeeper zk01:2181 --from-beginning --topic test1    • 查看消费位置sh kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper zk01:2181 --group testGroup    • 查看某个Topic的详情sh kafka-topics.sh --topic test --describe --zookeeper zk01:2181</code></pre><h2 id="3-kafka总结"><a href="#3-kafka总结" class="headerlink" title="3 kafka总结"></a>3 kafka总结</h2><p><strong>kfaka是什么东西?</strong></p><pre class="language-none"><code class="language-none">类JMS消息队列，结合JMS中的两种模式，可以有多个消费者主动拉取数据，在JMS中只有点对点模式才有消费者主动拉取数据。kafka是一个生产-消费模型。Producer：生产者，只负责数据生产，生产者的代码可以集成到任务系统中。               数据的分发策略由producer决定，默认是defaultPartition  Utils.abs(key.hashCode) % numPartitionsBroker：当前服务器上的Kafka进程,俗称拉皮条。只管数据存储，不管是谁生产，不管是谁消费。            在集群中每个broker都有一个唯一brokerid，不得重复。Topic:目标发送的目的地，这是一个逻辑上的概念，落到磁盘上是一个partition的目录。partition的目录中有多个segment组合(index,log)            一个Topic对应多个partition[0,1,2,3]，一个partition对应多个segment组合。一个segment有默认的大小是1G。            每个partition可以设置多个副本(replication-factor 1),会从所有的副本中选取一个leader出来。所有读写操作都是通过leader来进行的。            特别强调，和mysql中主从有区别，mysql做主从是为了读写分离，在kafka中读写操作都是leader。ConsumerGroup：数据消费者组，ConsumerGroup可以有多个，每个ConsumerGroup消费的数据都是一样的。                   可以把多个consumer线程划分为一个组，组里面所有成员共同消费一个topic的数据，组员之间不能重复消费。</code></pre><p><strong>kafka生产数据时的分组策略</strong></p><pre><code>默认是defaultPartition  Utils.abs(key.hashCode) % numPartitions上文中的key是producer在发送数据时传入的，produer.send(KeyedMessage(topic,myPartitionKey,messageContent))</code></pre><p><strong>kafka如何保证数据的完全生产</strong></p><pre><code>ack机制：broker表示发来的数据已确认接收无误，表示数据已经保存到磁盘。0：不等待broker返回确认消息1：等待topic中某个partition leader保存成功的状态反馈-1：等待topic中某个partition 所有副本都保存成功的状态反馈    </code></pre><p><strong>broker如何保存数据</strong></p><pre><code>在理论环境下，broker按照顺序读写的机制，可以每秒保存600M的数据。主要通过pagecache机制，尽可能的利用当前物理机器上的空闲内存来做缓存。当前topic所属的broker，必定有一个该topic的partition，partition是一个磁盘目录。partition的目录中有多个segment组合(index,log)    </code></pre><p><strong>partition如何分布在不同的broker上</strong></p><pre><code>int i = 0list{kafka01,kafka02,kafka03}for(int i=0;i&lt;5;i++){    brIndex = i%broker;    hostName = list.get(brIndex)}</code></pre><p><strong>consumerGroup的组员和partition之间如何做负载均衡</strong></p><pre><code>最好是一一对应，一个partition对应一个consumer。如果consumer的数量过多，必然有空闲的consumer。算法：    假如topic1,具有如下partitions: P0,P1,P2,P3    加入group中,有如下consumer: C1,C2    首先根据partition索引号对partitions排序: P0,P1,P2,P3    根据consumer.id排序: C0,C1    计算倍数: M = [P0,P1,P2,P3].size / [C0,C1].size,本例值M=2(向上取整)    然后依次分配partitions: C0 = [P0,P1],C1=[P2,P3],即Ci = [P(i * M),P((i + 1) * M -1)]</code></pre><p><strong>如何保证kafka消费者消费数据是全局有序的</strong></p><pre><code>伪命题如果要全局有序的，必须保证生产有序，存储有序，消费有序。由于生产可以做集群，存储可以分片，消费可以设置为一个consumerGroup，要保证全局有序，就需要保证每个环节都有序。只有一个可能，就是一个生产者，一个partition，一个消费者。这种场景和大数据应用场景相悖。    </code></pre><h2 id="4kafka原理"><a href="#4kafka原理" class="headerlink" title="4kafka原理"></a>4kafka原理</h2><p><img src="/images/20180830/%E5%9B%BE-4%E3%80%81Kafka%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.png">    </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> storm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>storm 自己的理解,遇到的问题记录二</title>
      <link href="/2018/08/29/storm-zi-ji-de-li-jie-yu-dao-de-wen-ti-ji-lu-er/"/>
      <url>/2018/08/29/storm-zi-ji-de-li-jie-yu-dao-de-wen-ti-ji-lu-er/</url>
      
        <content type="html"><![CDATA[<h1 id="storm-自己的理解-遇到的问题记录二"><a href="#storm-自己的理解-遇到的问题记录二" class="headerlink" title="storm 自己的理解,遇到的问题记录二"></a><center>storm 自己的理解,遇到的问题记录二</center></h1><h2 id="0-Storm程序的并发机制-并发怎么设置？-lt-最重要的-gt"><a href="#0-Storm程序的并发机制-并发怎么设置？-lt-最重要的-gt" class="headerlink" title="0 Storm程序的并发机制 并发怎么设置？<最重要的>"></a>0 Storm程序的并发机制 并发怎么设置？&lt;最重要的&gt;</h2><p>1 概念</p><ul><li><p>Workers (JVMs): 在一个物理节点上可以运行一个或多个独立的JVM 进程。一个Topology可以包含一个或多个worker(并行的跑在不同的物理机上), 所以worker process就是执行一个topology的子集, 并且worker只能对应于一个topology&nbsp;</p></li><li><p>Executors (threads): 在一个worker JVM进程中运行着多个Java线程。一个executor线程可以执行一个或多个tasks。但一般默认每个executor只执行一个task。一个worker可以包含一个或多个executor, 每个component (spout或bolt)至少对应于一个executor, 所以可以说executor执行一个compenent的子集, 同时一个executor只能对应于一个component。&nbsp;</p></li><li><p>Tasks(bolt/spout instances)：Task就是具体的处理逻辑对象，每一个Spout和Bolt会被当作很多task在整个集群里面执行。每一个task对应到一个线程，而stream grouping则是定义怎么从一堆task发射tuple到另外一堆task。你可以调用TopologyBuilder.setSpout和TopBuilder.setBolt来设置并行度 — 也就是有多少个task。&nbsp;</p></li></ul><p>2 配置并行度</p><blockquote><p>对于并发度的配置, 在storm里面可以在多个地方进行配置, 优先级为：<br>defaults.yaml &lt; storm.yaml &lt; topology-specific configuration<br>&lt; internal component-specific configuration &lt; external component-specific configuration&nbsp;</p></blockquote><blockquote><p>worker processes的数目, 可以通过配置文件和代码中配置, worker就是执行进程, 所以考虑并发的效果, 数目至少应该大亍machines的数目&nbsp;</p></blockquote><blockquote><p>executor的数目, component的并发线程数，只能在代码中配置(通过setBolt和setSpout的参数), 例如, setBolt(“green-bolt”, new GreenBolt(), 2)&nbsp;</p></blockquote><blockquote><p> tasks的数目, 可以不配置, 默认和executor1:1, 也可以通过setNumTasks()配置&nbsp;<br>Topology的worker数通过config设置，即执行该topology的worker（java）进程数。它可以通过 storm rebalance 命令任意调整。&nbsp;</p></blockquote><pre class="language-none"><code class="language-none">Config conf =&nbsp;newConfig();conf.setNumWorkers(2);&nbsp;//用2个workertopologyBuilder.setSpout("blue-spout",&nbsp;newBlueSpout(),&nbsp;2);&nbsp;//设置2个并发度topologyBuilder.setBolt("green-bolt",&nbsp;newGreenBolt(),&nbsp;2).setNumTasks(4).shuffleGrouping("blue-spout");&nbsp;//设置2个并发度，4个任务topologyBuilder.setBolt("yellow-bolt",&nbsp;newYellowBolt(),&nbsp;6).shuffleGrouping("green-bolt"); //设置6个并发度StormSubmitter.submitTopology("mytopology", conf, topologyBuilder.createTopology());</code></pre><p><font style="color:red">3个组件的并发度加起来是10，就是说拓扑一共有10个executor，一共有2个worker，每个worker产生10 / 2 = 5条线程。<br>绿色的bolt配置成2个executor和4个task。为此每个executor为这个bolt运行2个task。</font></p><p>3  动态的改变并行度:<br>Storm支持在不 restart topology 的情况下, 动态的改变(增减) worker processes 的数目和 executors 的数目, 称为rebalancing. 通过Storm web UI，或者通过storm rebalance命令实现</p><pre class="language-none"><code class="language-none">storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10</code></pre><h2 id="1-Storm-任务提交的过程或者说流程"><a href="#1-Storm-任务提交的过程或者说流程" class="headerlink" title="1 Storm 任务提交的过程或者说流程"></a>1 Storm 任务提交的过程或者说流程</h2><p><img src="/images/20180829/4.png"></p><pre class="language-none"><code class="language-none">TopologyMetricsRunnable.TaskStartEvent[oldAssignment=&lt;null&gt;,newAssignment=Assignment[masterCodeDir=C:\Users\MAOXIA~1\AppData\Local\Temp\\e73862a8-f7e7-41f3-883d-af494618bc9f\nimbus\stormdist\double11-1-1458909887,nodeHost={61ce10a7-1e78-4c47-9fb3-c21f43a331ba=192.168.1.106},taskStartTimeSecs={1=1458909910, 2=1458909910, 3=1458909910, 4=1458909910, 5=1458909910, 6=1458909910, 7=1458909910, 8=1458909910},workers=[ResourceWorkerSlot[hostname=192.168.1.106,memSize=0,cpu=0,tasks=[1, 2, 3, 4, 5, 6, 7, 8],jvm=&lt;null&gt;,nodeId=61ce10a7-1e78-4c47-9fb3-c21f43a331ba,port=6900]],timeStamp=1458909910633,type=Assign],task2Component=&lt;null&gt;,clusterName=&lt;null&gt;,topologyId=double11-1-1458909887,timestamp=0]</code></pre><p><img src="/images/20180829/5.png"></p><p><img src="/images/20180829/6.png"></p><p>在storm任务提交中需要涉及到zk，所以看一下storm在zk上的目录树:<br><strong>Storm组件本地目录树</strong>:</p><p><img src="/images/20180830/1.png"></p><p><strong>Storm zookeeper目录树</strong>:</p><p><img src="/images/20180830/2.png"></p><p>集群如何启动，任务如何执行:</p><pre class="language-none"><code class="language-none">java -server nimubs，supervisor    client---&gt;createTopology(序列化)---&gt;提交jar到nimbuinbox---&gt;nimbus分配任务(task总数/worker数)---写到zk。                                        启动worker&lt;------识别自己的任务&lt;----supervisor----&gt;watch----zk                                                        启动Spout/Bolt----TaskInfo&lt;------worker----&gt;zk</code></pre><h2 id="2-Storm内部的通信机制"><a href="#2-Storm内部的通信机制" class="headerlink" title="2 Storm内部的通信机制"></a>2 Storm内部的通信机制</h2><p><img src="/images/20180830/%E5%9B%BE-2%E3%80%81Storm%E9%80%9A%E4%BF%A1%E6%9C%BA%E5%88%B6%E5%9B%BE%E8%A7%A3.png"></p><ul><li>Worker进程间通信(Netty、ZeroMQ)</li></ul><p>Worker间的通信经常需要通过网络跨节点进行，Storm使用ZeroMQ或Netty(0.9以后默认使用)作为进程间通信的消息框架。</p><p>Worker进程内部通信：不同worker的thread通信使用LMAX Disruptor来完成。</p><p>不同topologey之间的通信，Storm不负责，需要自己想办法实现，例如使用kafka等；    </p><p>Netty:</p><pre class="language-none"><code class="language-none">Netty是一个NIO client-server(客户端服务器)框架，使用Netty可以快速开发网络应用，例如服务器和客户端协议。Netty提供了一种新的方式来使开发网络应用程序，这种新的方式使得它很容易使用和有很强的扩展性。Netty的内部实现时很复杂的，但是Netty提供了简单易用的api从网络处理代码中解耦业务逻辑。Netty是完全基于NIO实现的，所以整个Netty都是异步的。</code></pre><p>ZeroMQ:</p><pre class="language-none"><code class="language-none">ZeroMQ是一种基于消息队列的多线程网络库，其对套接字类型、连接处理、帧、甚至路由的底层细节进行抽象，提供跨越多种传输协议的套接字。ZeroMQ是网络通信中新的一层，介于应用层和传输层之间（按照TCP/IP划分），其是一个可伸缩层，可并行运行，分散在分布式系统间。ZeroMQ定位为：一个简单好用的传输层，像框架一样的一个socket library，他使得Socket编程更加简单、简洁和性能更高。是一个消息处理队列库，可在多个线程、内核和主机盒之间弹性伸缩。ZMQ的明确目标是“成为标准网络协议栈的一部分，之后进入Linux内核”。</code></pre><p><img src="/images/20180830/3.png"></p><p>1.对于worker进程来说，为了管理流入和传出的消息，每个worker进程有一个独立的接收线程(对配置的TCP端口supervisor.slots.ports进行监听);<br>对应Worker接收线程，每个worker存在一个独立的发送线程，它负责从worker的transfer-queue中读取消息，并通过网络发送给其他worker</p><p>2.每个executor有自己的incoming-queue和outgoing-queue。<br>Worker接收线程将收到的消息通过task编号传递给对应的executor(一个或多个)的incoming-queues;</p><p>3.每个executor有单独的线程分别来处理spout/bolt的业务逻辑，业务逻辑输出的中间数据会存放在outgoing-queue中，当executor的outgoing-queue中的tuple达到一定的阀值，executor的发送线程将批量获取outgoing-queue中的tuple,并发送到transfer-queue中。</p><p>4.每个worker进程控制一个或多个executor线程，用户可在代码中进行配置。其实就是我们在代码中设置的并发度个数。</p><ul><li>Worker 内部通信技术(Disruptor)<br>Disruptor的来历:</li></ul><blockquote><p>一个公司的业务与技术的关系，一般可以分为三个阶段。第一个阶段就是跟着业务跑。第二个阶段是经历了几年的时间，才达到的驱动业务阶段。第三个阶段，技术引领业务的发展乃至企业的发展。所以我们在学习Disruptor这个技术时，不得不提LMAX这个机构，因为Disruptor这门技术就是由LMAX公司开发并开源的。</p></blockquote><blockquote><p>LMAX是在英国注册并受到FSA监管（监管号码为509778）的外汇黄金交易所。LMAX也是欧洲第一家也是唯一一家采用多边交易设施Multilateral Trading Facility（MTF）拥有交易所牌照和经纪商牌照的欧洲顶级金融公司</p></blockquote><blockquote><p>LAMX拥有最迅捷的交易平台，顶级技术支持。LMAX交易所使用“（MTF）分裂器Disruptor”技术，可以在极短时间内（一般在3百万秒之一内）处理订单，在一个线程里每秒处理6百万订单。所有订单均为撮合成交形式，无一例外。多边交易设施（MTF）曾经用来设计伦敦证券交易 所（london Stock Exchange）、德国证券及衍生工具交易所（Deutsche Borse）和欧洲证券交易所（Euronext）。</p></blockquote><blockquote><p>2011年LMAX凭借该技术获得了金融行业技术评选大赛的最佳交易系统奖和甲骨文“公爵杯”创新编程框架奖。</p></blockquote><p>Disruptor是什么:</p><pre class="language-none"><code class="language-none">1、 简单理解：Disruptor是一个Queue。Disruptor是实现了“队列”的功能，而且是一个有界队列。而队列的应用场景自然就是“生产者-消费者”模型。2、 在JDK中Queue有很多实现类，包括不限于ArrayBlockingQueue、LinkBlockingQueue，这两个底层的数据结构分别是数组和链表。数组查询快，链表增删快，能够适应大多数应用场景。3、 但是ArrayBlockingQueue、LinkBlockingQueue都是线程安全的。涉及到线程安全，就会有synchronized、lock等关键字，这就意味着CPU会打架。 4、 Disruptor一种线程之间信息无锁的交换方式（使用CAS（Compare And Swap/Set）操作）。</code></pre><p>Disruptor主要特点:</p><pre class="language-none"><code class="language-none">1、 没有竞争=没有锁=非常快。2、 所有访问者都记录自己的序号的实现方式，允许多个生产者与多个消费者共享相同的数据结构。3、 在每个对象中都能跟踪序列号（ring buffer，claim Strategy，生产者和消费者），加上神奇的cache line padding，就意味着没有为伪共享和非预期的竞争。</code></pre><p>Disruptor 核心技术点:</p><pre class="language-none"><code class="language-none">Disruptor可以看成一个事件监听或消息机制，在队列中一边生产者放入消息，另外一边消费者并行取出处理.底层是单个数据结构：一个ring buffer。每个生产者和消费者都有一个次序计算器，以显示当前缓冲工作方式。每个生产者消费者能够操作自己的次序计数器的能够读取对方的计数器，生产者能够读取消费者的计算器确保其在没有锁的情况下是可写的。核心组件:    • Ring Buffer 环形的缓冲区，负责对通过 Disruptor 进行交换的数据（事件）进行存储和更新。    • Sequence 通过顺序递增的序号来编号管理通过其进行交换的数据（事件），对数据(事件)的处理过程总是沿着序号逐个递增处理。    • RingBuffer底层是个数组，次序计算器是一个64bit long 整数型，平滑增长。</code></pre><h2 id="3-Storm-消息容错机制-即：ack-fail机制"><a href="#3-Storm-消息容错机制-即：ack-fail机制" class="headerlink" title="3 Storm 消息容错机制 即：ack-fail机制"></a>3 Storm 消息容错机制 即：ack-fail机制</h2><p>1 总体介绍</p><ul><li><p>在storm中，可靠的信息处理机制是从spout开始的。</p></li><li><p>一个提供了可靠的处理机制的spout需要记录他发射出去的tuple，当下游bolt处理tuple或者子tuple失败时spout能够重新发射。</p></li><li><p>Storm通过调用Spout的nextTuple()发送一个tuple。为实现可靠的消息处理，首先要给每个发出的tuple带上唯一的ID，并且将ID作为参数传递给SoputOutputCollector的emit()方法：collector.emit(new Values(“value1”,”value2”), msgId); messageid就是用来标示唯一的tupke的，而rootid是随机生成的</p></li><li><p>给每个tuple指定ID告诉Storm系统，无论处理成功还是失败，spout都要接收tuple树上所有节点返回的通知。如果处理成功，spout的ack()方法将会对编号是msgId的消息应答确认；如果处理失败或者超时，会调用fail()方法。 </p></li></ul><p>2 基本实现</p><ul><li><p>Storm 系统中有一组叫做”acker”的特殊的任务，它们负责跟踪DAG（有向无环图）中的每个消息。</p></li><li><p>acker任务保存了spout id到一对值的映射。第一个值就是spout的任务id，通过这个id，acker就知道消息处理完成时该通知哪个spout任务。第二个值是一个64bit的数字，我们称之为”ack val”， 它是树中所有消息的随机id的异或计算结果。</p></li><li><p>ack val表示了整棵树的的状态，无论这棵树多大，只需要这个固定大小的数字就可以跟踪整棵树。当消息被创建和被应答的时候都会有相同的消息id发送过来做异或。&nbsp;每当acker发现一棵树的ack val值为0的时候，它就知道这棵树已经被完全处理了</p></li></ul><p>3 可靠性配置<br>有三种方法可以去掉消息的可靠性： </p><blockquote><p>1 将参数Config.TOPOLOGY_ACKERS设置为0，通过此方法，当Spout发送一个消息的时候，它的ack方法将立刻被调用； </p></blockquote><blockquote><p>2 Spout发送一个消息时，不指定此消息的messageID。当需要关闭特定消息可靠性的时候，可以使用此方法； </p></blockquote><blockquote><p>3 最后，如果你不在意某个消息派生出来的子孙消息的可靠性，则此消息派生出来的子消息在发送时不要做锚定，即在emit方法中不指定输入消息。因为这些子孙消息没有被锚定在任何tuple tree中，因此他们的失败不会引起任何spout重新发送消息。</p></blockquote><h2 id="4自己动手写一个storm框架"><a href="#4自己动手写一个storm框架" class="headerlink" title="4自己动手写一个storm框架"></a>4自己动手写一个storm框架</h2><p>[实现数据执行的框架]<br>        spout—–线程1<br>        incomingQueue——queue<br>        bolt1—–线程2<br>        incomingQueue——queue<br>        bolt2—–线程3</p><pre><code>    需要技术：        线程池-----&gt;Exeutes.newFixPool(3)        队列-------&gt;ArrayBolckingQueue(1000)    伪代码：        MyStrom{            main(){            //1、配置一个线程池            //2、向线程池中提交任务                spoutOutPutQueue = new ArrayBolckingQueue(1000)                submit(new MySpout(spoutOutPutQueue))------collector.emit(tuple)------spoutOutPutQueue                bolt1OutPutQueue = new ArrayBolckingQueue(1000)                submit(new MyBolt1(spoutOutPutQueue,bolt1OutPutQueue))------&gt;spoutOutPutQueue----&gt;bolt1.execute(),collector.emit(tuple)------bolt1OutPutQueue                submit(new MyBolt1(bolt1OutPutQueue))------&gt;spoutOutPutQueue----&gt;bolt1.execute()                }        }</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> storm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>storm 自己的理解,遇到的问题记录一</title>
      <link href="/2018/08/29/storm-zi-ji-de-li-jie-yu-dao-de-wen-ti-ji-lu-yi/"/>
      <url>/2018/08/29/storm-zi-ji-de-li-jie-yu-dao-de-wen-ti-ji-lu-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="storm-自己的理解-遇到的问题记录一"><a href="#storm-自己的理解-遇到的问题记录一" class="headerlink" title="storm 自己的理解,遇到的问题记录一"></a><center>storm 自己的理解,遇到的问题记录一</center></h1><h2 id="1-离线计算"><a href="#1-离线计算" class="headerlink" title="1 离线计算"></a>1 离线计算</h2><p>离线计算：批量获取数据、批量传输数据、周期性批量计算数据、数据展示</p><p>代表技术：Sqoop批量导入数据、HDFS批量存储数据、MapReduce批量计算数据、Hive批量计算数据、***任务调度</p><p>1，hivesql<br>2、调度平台<br>3、Hadoop集群运维<br>4、数据清洗（脚本语言）<br>5、元数据管理<br>6、数据稽查<br>7、数据仓库模型架构</p><h2 id="2-流式计算，或者叫实时计算"><a href="#2-流式计算，或者叫实时计算" class="headerlink" title="2 流式计算，或者叫实时计算"></a>2 流式计算，或者叫实时计算</h2><p>流式计算：数据实时产生、数据实时传输、数据实时计算、实时展示</p><p>代表技术：Flume实时获取数据、Kafka/metaq实时数据存储、Storm/JStorm实时数据计算、Redis实时结果缓存、持久化存储(mysql)。</p><p>一句话总结：将源源不断产生的数据实时收集并实时计算，尽可能快的得到计算结果</p><p>他们的区别就是：</p><p><strong>最大的区别：实时收集、实时计算、实时展示</strong></p><h2 id="3-Storm是什么？"><a href="#3-Storm是什么？" class="headerlink" title="3 Storm是什么？"></a>3 Storm是什么？</h2><p>storm 官网：<a href="http://storm.apache.org/index.html">http://storm.apache.org/index.html</a>　在里面介绍了storm是什么!</p><pre class="language-none"><code class="language-none">Apache Storm is a free and open source distributed realtime computation system. Storm makes it easy to reliably process unbounded streams of data, doing for realtime processing what Hadoop did for batch processing. Storm is simple, can be used with any programming language, and is a lot of fun to use!我大概翻译一下：    Apache Storm是一个免费的开源分布式实时计算系统。     Storm可以轻松可靠地处理无限数据流，实现Hadoop对批处理所做的实时处理。    Storm非常简单，可以与任何编程语言一起使用，并且使用起来很有趣！还有关于版本的问题：    http://storm.apache.org/2018/06/04/storm122-released.html    可以在官网上查询到每个版本都有那些新特性，　增强了那些包，　修复了那些bug，关于这个版本的文档．还有一个问题就是jstrom：    jstorm是阿里重新写了storm,用java语言，现在jstorm的代码已经大部分都迁移到storm主流程序里面了，    所以现在用storm和jstrom没有什么本质的区别！</code></pre><p>Storm用来实时处理数据．</p><p>**<font style="color:red">特点</font>**：低延迟、高可用、分布式、可扩展、数据不丢失。提供简单容易理解的接口，便于开发。</p><h2 id="4-Storm与Hadoop的区别"><a href="#4-Storm与Hadoop的区别" class="headerlink" title="4 Storm与Hadoop的区别"></a>4 Storm与Hadoop的区别</h2><pre><code>• Storm用于实时计算    Hadoop用于离线计算。• Storm处理的数据保存在内存中，源源不断    Hadoop处理的数据保存在文件系统中，一批一批。• Storm的数据通过网络传输进来    Hadoop的数据保存在磁盘中。• Storm与Hadoop的编程模型相似</code></pre><h2 id="5-storm典型的运用场景"><a href="#5-storm典型的运用场景" class="headerlink" title="5 storm典型的运用场景"></a>5 storm典型的运用场景</h2><p>1.运用场景：</p><ul><li>日志分析<blockquote><p>从海量日志中分析出特定的数据，并将分析的结果存入外部存储器用来辅佐决策。</p></blockquote></li><li>管道系统<blockquote><p>将一个数据从一个系统传输到另外一个系统，比如将数据库同步到Hadoop</p></blockquote></li><li>消息转化器<blockquote><p>将接受到的消息按照某种格式进行转化，存储到另外一个系统如消息中间件    </p></blockquote></li></ul><p>2.典型案例：</p><ul><li><p>淘-实时分析系统：实时分析用户的属性，并反馈给搜索引擎</p></li><li><p>携程-网站性能监控：实时分析系统监控携程网的网站性能</p></li><li><p>阿里妈妈-用户画像：实时计算用户的兴趣数据</p></li><li><p>一个游戏新版本上线，有一个实时分析系统，收集游戏中的数据，运营或者开发者可以在上线后几秒钟得到持续不断更新的游戏监控报告和分析结果，然后马上针对游戏的参数 和平衡性进行调整。这样就能够大大缩短游戏迭代周期，加强游戏的生命力。</p></li><li><p>实时计算在腾讯的运用：精准推荐（广点通广告推荐、新闻推荐、视频推荐、游戏道具推荐）；实时分析（微信运营数据门户、效果统计、订单画像分析）；实时监控（实时监控平台、游戏内接口调用）</p></li><li><p>精准投放广告</p></li></ul><h2 id="6-storm的核心组件和架构-lt-重点-gt"><a href="#6-storm的核心组件和架构-lt-重点-gt" class="headerlink" title="6 storm的核心组件和架构 <重点>"></a>6 storm的核心组件和架构 &lt;重点&gt;</h2><p><img src="/images/20180829/1.png"></p><ul><li><p><font style="color:red">Nimbus</font>：负责资源分配和任务调度。</p></li><li><p><font style="color:red">Supervisor</font>：负责接受nimbus分配的任务，启动和停止属于自己管理的worker进程。—通过配置文件设置当前supervisor上启动多少个worker。</p></li><li><p><font style="color:red">Worker</font>：运行具体处理组件逻辑的进程。Worker运行的任务类型只有两种，一种是Spout任务，一种是Bolt任务。</p></li><li><p><font style="color:red">Task</font>：worker中每一个spout/bolt的线程称为一个task. 在storm0.8之后，task不再与物理线程对应，不同spout/bolt的task可能会共享一个物理线程，该线程称为executor。</p></li></ul><h2 id="7-Storm编程模型-lt-重点-gt"><a href="#7-Storm编程模型-lt-重点-gt" class="headerlink" title="7 Storm编程模型 <重点>"></a>7 Storm编程模型 &lt;重点&gt;</h2><p><img src="/images/20180829/2.png"></p><ul><li><p><font style="color:red">Topology</font>：Storm中运行的一个实时应用程序的名称。（拓扑）</p></li><li><p><font style="color:red">Spout</font>：在一个topology中获取源数据流的组件。<br>通常情况下spout会从外部数据源中读取数据，然后转换为topology内部的源数据。</p></li><li><p><font style="color:red">Bolt</font>：接受数据然后执行处理的组件,用户可以在其中执行自己想要的操作。</p></li><li><p><font style="color:red">Tuple</font>：一次消息传递的基本单元，理解为一组消息就是一个Tuple。</p></li><li><p><font style="color:red">Stream</font>：表示数据的流向。</p></li><li><p><font style="color:red">Stream grouping</font>：即消息的partition方法。Storm中提供若干种实用的grouping方式，包括shuffle, fields hash, all, global, none, direct和localOrShuffle等<br>&lt;!–hexoPostRenderEscape:</p><pre class="language-none"><code class="language-none">Stream Grouping定义了一个流在Bolt任务间该如何被切分。这里有Storm提供的6个Stream Grouping类型：<p></p></code></pre></li><code class="language-none"></code></ul><code class="language-none"><p>1.Shuffle Grouping: 随机分组， 随机派发stream里面的tuple，保证每个bolt接收到的tuple数目大致相同。</p><p>2.Fields Grouping：按字段分组，比如按userid来分组，具有同样userid的tuple会被分到相同的Bolts里的一个task，而不同的userid则会被分配到不同的bolts里的task。</p><p>3.All Grouping：广播发送，对于每一个tuple，所有的bolts都会收到。</p><p>4.Global Grouping：全局分组， 这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task。</p><p>5.Non Grouping：不分组，这stream grouping个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果， 有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行。</p><p>6.Direct Grouping： 直接分组， 这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过TopologyContext来获取处理它的消息的task的id （OutputCollector.emit方法也会返回task的id）。</p></code><ol start="7"><code class="language-none"></code><li><code class="language-none">Local or shuffle grouping：如果目标bolt有一个或者多个task在同一个工作进程中，tuple将会被随机发生给这些tasks。否则，和普通的Shuffle Grouping行为一致。</code>:hexoPostRenderEscape–&gt;</li></ol><h2 id="8-流式计算一般架构图-lt-重点-gt"><a href="#8-流式计算一般架构图-lt-重点-gt" class="headerlink" title="8 流式计算一般架构图 <重点>"></a>8 流式计算一般架构图 &lt;重点&gt;</h2><p><img src="/images/20180829/3.png"></p><blockquote><p>其中flume用来获取数据。<br> Kafka用来临时保存数据。<br>Strom用来计算数据。<br> Redis是个内存数据库，用来保存数据。</p></blockquote><h2 id="9-关于storm集群部署的问题可以参考我大数据的一些常用大数据软件的安装"><a href="#9-关于storm集群部署的问题可以参考我大数据的一些常用大数据软件的安装" class="headerlink" title="9 关于storm集群部署的问题可以参考我大数据的一些常用大数据软件的安装"></a>9 关于storm集群部署的问题可以参考我大数据的一些常用大数据软件的安装</h2><p>我这是只说一下重点：</p><pre class="language-none"><code class="language-none">1、部署成功之后，启动storm集群。    依次启动集群的各种角色2、查看nimbus的日志信息在nimbus的服务器上cd /export/servers/storm/logstail -100f /export/servers/storm/logs/nimbus.log3、查看ui运行日志信息在ui的服务器上，一般和nimbus一个服务器cd /export/servers/storm/logstail -100f /export/servers/storm/logs/ui.log4、查看supervisor运行日志信息在supervisor服务上cd /export/servers/storm/logstail -100f /export/servers/storm/logs/supervisor.log5、查看supervisor上worker运行日志信息在supervisor服务上cd /export/servers/storm/logstail -100f /export/servers/storm/logs/worker-6702.log访问nimbus.host:/8080，即可看到storm的ui界面。</code></pre><p>Storm常用操作命令:</p><p><font style="color:red">有许多简单且有用的命令可以用来管理拓扑，它们可以提交、杀死、禁用、再平衡拓扑。</font></p><pre class="language-none"><code class="language-none">1.提交任务命令格式：    storm jar 【jar路径】 【拓扑包名.拓扑类名】 【拓扑名称】bin/storm jar examples/storm-starter/storm-starter-topologies-0.9.6.jar storm.starter.WordCountTopology wordcount2.杀死任务命令格式：    storm kill 【拓扑名称】 -w 10（执行kill命令时可以通过-w [等待秒数]指定拓扑停用以后的等待时间）storm kill topology-name -w 103.停用任务命令格式：    storm deactivte  【拓扑名称】storm deactivte topology-name我们能够挂起或停用运行中的拓扑。当停用拓扑时，所有已分发的元组都会得到处理，但是spouts的nextTuple方法不会被调用。销毁一个拓扑，可以使用kill命令。它会以一种安全的方式销毁一个拓扑，首先停用拓扑，在等待拓扑消息的时间段内允许拓扑完成当前的数据流。4.启用任务命令格式：storm activate【拓扑名称】        storm activate topology-name5.重新部署任务命令格式：storm rebalance  【拓扑名称】        storm rebalance topology-name再平衡使你重分配集群任务。这是个很强大的命令。比如，你向一个运行中的集群增加了节点。再平衡命令将会停用拓扑，然后在相应超时时间之后重分配工人，并重启拓扑。</code></pre><h2 id="10-做一下总结"><a href="#10-做一下总结" class="headerlink" title="10 做一下总结"></a>10 做一下总结</h2><p>1、编程模型</p><blockquote><p>DataSource：外部数据源</p></blockquote><blockquote><p>Spout：接受外部数据源的组件，将外部数据源转化成Storm内部的数据，以Tuple为基本的传输单元下发给Bolt</p></blockquote><blockquote><p>Bolt:接受Spout发送的数据，或上游的bolt的发送的数据。根据业务逻辑进行处理。发送给下一个Bolt或者是存储到某种介质上。介质可以是Redis可以是mysql，或者其他。</p></blockquote><blockquote><p>Tuple：Storm内部中数据传输的基本单元，里面封装了一个List对象，用来保存数据。</p></blockquote><blockquote><p>StreamGrouping:数据分组策略:<br>7种：shuffleGrouping(Random函数),Non Grouping(Random函数),FieldGrouping(Hash取模)、Local or ShuffleGrouping 本地或随机，优先本地。</p></blockquote><p>2、并发度</p><blockquote><p>用户指定的一个任务，可以被多个线程执行，并发度的数量等于线程的数量。一个任务的多个线程，会被运行在多个Worker（JVM）上，有一种类似于平均算法的负载均衡策略。尽可能减少网络IO，和Hadoop中的MapReduce中的本地计算的道理一样。</p></blockquote><p>3、架构</p><blockquote><p>Nimbus：任务分配</p></blockquote><blockquote><p>Supervisor：接受任务，并启动worker。worker的数量根据端口号来的。</p></blockquote><blockquote><p>Worker:执行任务的具体组件（其实就是一个JVM）,可以执行两种类型的任务，Spout任务或者bolt任务。</p></blockquote><blockquote><p>Task：Task=线程=executor。 一个Task属于一个Spout或者Bolt并发任务。</p></blockquote><blockquote><p>Zookeeper：保存任务分配的信息、心跳信息、元数据信息。</p></blockquote><p>4、Worker与topology</p><blockquote><p>一个worker只属于一个topology,每个worker中运行的task只能属于这个topology。    反之，一个topology包含多个worker，其实就是这个topology运行在多个worker上。</p></blockquote><blockquote><p>一个topology要求的worker数量如果不被满足，集群在任务分配时，根据现有的worker先运行topology。如果当前集群中worker数量为0，那么最新提交的topology将只会被标识active，不会运行，只有当集群有了空闲资源之后，才会被运行。</p></blockquote><p>最后来张图最能显示strom各个组件之间的关系：</p><p><img src="/images/20180829/%E5%9B%BE-1%E3%80%81Storm%E6%9E%B6%E6%9E%84%E5%8F%8A%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E5%9B%BE%E8%A7%A3.png">    </p><h2 id="10现在动手写一个storm基本的程序wordcount"><a href="#10现在动手写一个storm基本的程序wordcount" class="headerlink" title="10现在动手写一个storm基本的程序wordcount"></a>10现在动手写一个storm基本的程序wordcount</h2><p>在idea中创建maven项目,这个我就不说了</p><ul><li>pom文件： 我这里使用的版本的是1.0.3 并且我组自己安装的storm集群也是这个版本</li></ul><pre class="language-none"><code class="language-none">&lt;dependencies&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;    &lt;artifactId&gt;storm-core&lt;/artifactId&gt;    &lt;version&gt;1.0.3&lt;/version&gt;&lt;/dependency&gt;   &lt;/dependencies&gt;</code></pre><ul><li>WordCountTopologMain.java   storm启动主类</li></ul><pre class="language-none"><code class="language-none">package cn.itcast.storm;import backtype.storm.Config;import backtype.storm.LocalCluster;import backtype.storm.StormSubmitter;import backtype.storm.generated.AlreadyAliveException;import backtype.storm.generated.InvalidTopologyException;import backtype.storm.topology.TopologyBuilder;import backtype.storm.tuple.Fields;public class WordCountTopologMain {    public static void main(String[] args) throws AlreadyAliveException, InvalidTopologyException {//1、准备一个TopologyBuilderTopologyBuilder topologyBuilder = new TopologyBuilder();topologyBuilder.setSpout("mySpout",new MySpout(),2);topologyBuilder.setBolt("mybolt1",new MySplitBolt(),2).shuffleGrouping("mySpout"); topologyBuilder.setBolt("mybolt2",new MyCountBolt(),4).fieldsGrouping("mybolt1", new Fields("word"));//topologyBuilder.setBolt("mybolt2",new MyCountBolt(),4).shuffleGrouping("mybolt1");//config.setNumWorkers(2);        /**         * i         * am         * lilei         * love         * hanmeimei         *///2、创建一个configuration，用来指定当前topology 需要的worker的数量Config config =  new Config();config.setNumWorkers(2);//3、提交任务  -----两种模式 本地模式和集群模式 StormSubmitter.submitTopology("mywordcount",config,topologyBuilder.createTopology());LocalCluster localCluster = new LocalCluster();localCluster.submitTopology("mywordcount",config,topologyBuilder.createTopology());    }}</code></pre><ul><li>MySpout.java １.spout获取数据  2. 向bolt通过tuple类型射数据</li></ul><pre class="language-none"><code class="language-none">package cn.itcast.storm;import backtype.storm.spout.SpoutOutputCollector;import backtype.storm.task.TopologyContext;import backtype.storm.topology.IRichSpout;import backtype.storm.topology.OutputFieldsDeclarer;import backtype.storm.topology.base.BaseRichSpout;import backtype.storm.tuple.Fields;import backtype.storm.tuple.Values;import java.util.Map;public class MySpout extends BaseRichSpout {    SpoutOutputCollector collector; //初始化方法 public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {        this.collector = collector;}//storm 框架在 while(true) 调用nextTuple方法public void nextTuple() {        collector.emit(new Values("i am lilei love hanmeimei"));}public void declareOutputFields(OutputFieldsDeclarer declarer) {       declarer.declare(new Fields("love"));    }}</code></pre><ul><li>MySplitBolt.java  1.切割spout发射过来的数据　2.处理后向其他的bolt继续发射数据</li></ul><pre class="language-none"><code class="language-none">package cn.itcast.storm;import backtype.storm.task.OutputCollector;import backtype.storm.task.TopologyContext;import backtype.storm.topology.IBasicBolt;import backtype.storm.topology.IRichBolt;import backtype.storm.topology.OutputFieldsDeclarer;import backtype.storm.topology.base.BaseRichBolt;import backtype.storm.tuple.Fields;import backtype.storm.tuple.Tuple;import backtype.storm.tuple.Values;import java.util.Map;public class MySplitBolt extends BaseRichBolt {    OutputCollector collector;//初始化方法public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) {        this.collector = collector;}// 被storm框架 while(true) 循环调用  传入参数tuplepublic void execute(Tuple input) {        String line = input.getString(0);        String[] arrWords = line.split(" ");        for (String word:arrWords){            collector.emit(new Values(word,1));        }    }public void declareOutputFields(OutputFieldsDeclarer declarer) {        declarer.declare(new Fields("word","num"));    }}</code></pre><ul><li>MyCountBolt.java 做最后的单词计数</li></ul><pre class="language-none"><code class="language-none">package cn.itcast.storm;import org.apache.storm.task.OutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.topology.base.BaseRichBolt;import org.apache.storm.tuple.Tuple;import java.util.HashMap;import java.util.Map;public class MyCountBolt extends BaseRichBolt {    OutputCollector collector;    Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;();    @Override    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) {        this.collector = collector;    }    @Override    public void execute(Tuple input) {        String word = input.getString(0);        Integer num = input.getInteger(1);        System.out.println(Thread.currentThread().getId() + "    word:"+word);        if (map.containsKey(word)){            Integer count = map.get(word);            map.put(word,count + num);        }else {            map.put(word,num);        }        System.out.println("count:"+map);    }    @Override    public void declareOutputFields(OutputFieldsDeclarer declarer) {       //不輸出    }}</code></pre><ul><li>在idea中就可以直接运行ｍａｉｎ方法以本地模式运行，　如果是集群模式需要先打包成ｊａｒ　然后上传到服务器上通过storm　jar运行！</li></ul><p>看一下我运行的一些数据吧：速度很快！很快</p><pre class="language-none"><code class="language-none">136    word:amcount:{am=82525}136    word:amcount:{am=82526}136    word:amcount:{am=82527}136    word:amcount:{am=82528}136    word:amcount:{am=82529}136    word:amcount:{am=82530}136    word:amcount:{am=82531}136    word:amcount:{am=82532}136    word:amcount:{am=82533}</code></pre><h2 id="记录二-写storm提交任务的流程，-内部通信机制，-消息容错机制-自己动手写一个类似storm的框架"><a href="#记录二-写storm提交任务的流程，-内部通信机制，-消息容错机制-自己动手写一个类似storm的框架" class="headerlink" title="记录二 写storm提交任务的流程，　内部通信机制，　消息容错机制, 　自己动手写一个类似storm的框架!"></a>记录二 写storm提交任务的流程，　内部通信机制，　消息容错机制, 　自己动手写一个类似storm的框架!</h2><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> storm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark SQL基础三</title>
      <link href="/2018/08/28/spark-sql-ji-chu-san/"/>
      <url>/2018/08/28/spark-sql-ji-chu-san/</url>
      
        <content type="html"><![CDATA[<h1 id="spark-SQL基础三"><a href="#spark-SQL基础三" class="headerlink" title=" spark SQL基础三"></a><center> spark SQL基础三</center></h1><h2 id="1-目标"><a href="#1-目标" class="headerlink" title="1 目标"></a>1 目标</h2><pre class="language-none"><code class="language-none">1.1. 掌握Spark SQL的原理1.2. 掌握DataFrame数据结构和使用方式1.3. 熟练使用Spark SQL完成计算任务</code></pre><h2 id="2-Spark-SQL"><a href="#2-Spark-SQL" class="headerlink" title="2. Spark SQL"></a>2. Spark SQL</h2><h3 id="2-1-Spark-SQL概述"><a href="#2-1-Spark-SQL概述" class="headerlink" title="2.1. Spark SQL概述"></a>2.1. Spark SQL概述</h3><h4 id="2-1-1-什么是Spark-SQL"><a href="#2-1-1-什么是Spark-SQL" class="headerlink" title="2.1.1. 什么是Spark SQL"></a>2.1.1. 什么是Spark SQL</h4><p><img src="/images/20180828/9.png"></p><p>Spark SQL是Spark用来处理结构化数据的一个模块，它提供了一个编程抽象叫做DataFrame并且作为分布式SQL查询引擎的作用。</p><h4 id="2-1-2-为什么要学习Spark-SQL"><a href="#2-1-2-为什么要学习Spark-SQL" class="headerlink" title="2.1.2. 为什么要学习Spark SQL"></a>2.1.2. 为什么要学习Spark SQL</h4><p>我们已经学习了Hive，它是将Hive SQL转换成MapReduce然后提交到集群上执行，大大简化了编写MapReduce的程序的复杂性，由于MapReduce这种计算模型执行效率比较慢。所有Spark SQL的应运而生，它是将Spark SQL转换成RDD，然后提交到集群执行，执行效率非常快！</p><p>1.易整合</p><p><img src="/images/20180828/10.png"></p><p>2.统一的数据访问方式</p><p><img src="/images/20180828/11.png"></p><p>3.兼容Hive</p><p><img src="/images/20180828/12.png"></p><p>4.标准的数据连接</p><p><img src="/images/20180828/13.png"></p><h3 id="2-2-DataFrames"><a href="#2-2-DataFrames" class="headerlink" title="2.2. DataFrames"></a>2.2. DataFrames</h3><h4 id="2-2-1-什么是DataFrames"><a href="#2-2-1-什么是DataFrames" class="headerlink" title="2.2.1. 什么是DataFrames"></a>2.2.1. 什么是DataFrames</h4><p>与RDD类似，DataFrame也是一个分布式数据容器。然而DataFrame更像传统数据库的二维表格，除了数据以外，还记录数据的结构信息，即schema。同时，与Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）。从API易用性的角度上 看，DataFrame API提供的是一套高层的关系操作，比函数式的RDD API要更加友好，门槛更低。由于与R和Pandas的DataFrame类似，Spark DataFrame很好地继承了传统单机数据分析的开发体验。</p><p><img src="/images/20180828/14.png"></p><h4 id="2-2-2-创建DataFrames"><a href="#2-2-2-创建DataFrames" class="headerlink" title="2.2.2. 创建DataFrames"></a>2.2.2. 创建DataFrames</h4><p>&nbsp;在Spark SQL中SQLContext是创建DataFrames和执行SQL的入口，在spark-1.5.2中已经内置了一个sqlContext<br>&nbsp;<br>&nbsp;<img src="/images/20180828/15.png">&nbsp;&nbsp;</p><pre class="language-none"><code class="language-none">1.在本地创建一个文件，有三列，分别是id、name、age，用空格分隔，然后上传到hdfs上hdfs dfs -put person.txt /2.在spark shell执行下面命令，读取数据，将每一行的数据使用列分隔符分割val lineRDD = sc.textFile("hdfs://node1.itcast.cn:9000/person.txt").map(_.split(" "))3.定义case class（相当于表的schema）case class Person(id:Int, name:String, age:Int)4.将RDD和case class关联val personRDD = lineRDD.map(x =&gt; Person(x(0).toInt, x(1), x(2).toInt))5.将RDD转换成DataFrameval personDF = personRDD.toDF6.对DataFrame进行处理personDF.show</code></pre><p>&nbsp;<img src="/images/20180828/16.png">&nbsp;&nbsp;</p><h3 id="2-3-DataFrame常用操作"><a href="#2-3-DataFrame常用操作" class="headerlink" title="2.3. DataFrame常用操作"></a>2.3. DataFrame常用操作</h3><h4 id="2-3-1-DSL风格语法"><a href="#2-3-1-DSL风格语法" class="headerlink" title="2.3.1. DSL风格语法"></a>2.3.1. DSL风格语法</h4><pre class="language-none"><code class="language-none">//查看DataFrame中的内容personDF.show//查看DataFrame部分列中的内容personDF.select(personDF.col("name")).showpersonDF.select(col("name"), col("age")).showpersonDF.select("name").show//打印DataFrame的Schema信息personDF.printSchema//查询所有的name和age，并将age+1personDF.select(col("id"), col("name"), col("age") + 1).showpersonDF.select(personDF("id"), personDF("name"), personDF("age") + 1).show</code></pre><p>&nbsp;<img src="/images/20180828/17.png"><br>&nbsp;<br>&nbsp;</p><pre class="language-none"><code class="language-none">&nbsp;//过滤age大于等于18的personDF.filter(col("age") &gt;= 18).show</code></pre><br>&nbsp;<br>&nbsp;&nbsp;<img src="/images/20180828/18.png"><br>&nbsp;&nbsp;<br>&nbsp;&nbsp;<pre class="language-none"><code class="language-none">&nbsp;&nbsp;//按年龄进行分组并统计相同年龄的人数personDF.groupBy("age").count().show()</code></pre><br>&nbsp;&nbsp;<br><img src="/images/20180828/19.png"><p></p><h3 id="2-3-2-SQL风格语法"><a href="#2-3-2-SQL风格语法" class="headerlink" title="2.3.2. SQL风格语法"></a>2.3.2. SQL风格语法</h3><p>如果想使用SQL风格的语法，需要将DataFrame注册成表<br>personDF.registerTempTable(“t_person”)</p><p>//查询年龄最大的前两名<br>sqlContext.sql(“select * from t_person order by age desc limit 2”).show</p><p><img src="/images/20180828/20.png"></p><p>//显示表的Schema信息<br>sqlContext.sql(“desc t_person”).show</p><p><img src="/images/20180828/21.png"></p><h2 id="3-以编程方式执行Spark-SQL查询"><a href="#3-以编程方式执行Spark-SQL查询" class="headerlink" title="3. 以编程方式执行Spark SQL查询"></a>3. 以编程方式执行Spark SQL查询</h2><h3 id="3-1-编写Spark-SQL查询程序"><a href="#3-1-编写Spark-SQL查询程序" class="headerlink" title="3.1. 编写Spark SQL查询程序"></a>3.1. 编写Spark SQL查询程序</h3><p>前面我们学习了如何在Spark Shell中使用SQL完成查询，现在我们来实现在自定义的程序中编写Spark SQL查询程序。首先在maven项目的pom.xml中添加Spark SQL的依赖</p><pre class="language-none"><code class="language-none">&lt;dependency&gt;    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;    &lt;artifactId&gt;spark-sql_2.10&lt;/artifactId&gt;    &lt;version&gt;1.5.2&lt;/version&gt;&lt;/dependency&gt;</code></pre><h4 id="3-1-1-通过反射推断Schema"><a href="#3-1-1-通过反射推断Schema" class="headerlink" title="3.1.1. 通过反射推断Schema"></a>3.1.1. 通过反射推断Schema</h4><p>创建一个object为cn.itcast.spark.sql.InferringSchema</p><pre class="language-none"><code class="language-none">package cn.itcast.spark.sqlimport org.apache.spark.{SparkConf, SparkContext}import org.apache.spark.sql.SQLContextobject InferringSchema {  def main(args: Array[String]) {    //创建SparkConf()并设置App名称    val conf = new SparkConf().setAppName("SQL-1")    //SQLContext要依赖SparkContext    val sc = new SparkContext(conf)    //创建SQLContext    val sqlContext = new SQLContext(sc)    //从指定的地址创建RDD    val lineRDD = sc.textFile(args(0)).map(_.split(" "))    //创建case class    //将RDD和case class关联    val personRDD = lineRDD.map(x =&gt; Person(x(0).toInt, x(1), x(2).toInt))    //导入隐式转换，如果不到人无法将RDD转换成DataFrame    //将RDD转换成DataFrame    import sqlContext.implicits._    val personDF = personRDD.toDF    //注册表    personDF.registerTempTable("t_person")    //传入SQL    val df = sqlContext.sql("select * from t_person order by age desc limit 2")    //将结果以JSON的方式存储到指定位置    df.write.json(args(1))    //停止Spark Context    sc.stop()  }}//case class一定要放到外面case class Person(id: Int, name: String, age: Int)</code></pre><p>将程序打成jar包，上传到spark集群，提交Spark任务<br>/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-submit <br>–class cn.itcast.spark.sql.InferringSchema <br>–master spark://node1.itcast.cn:7077 <br>/root/spark-mvn-1.0-SNAPSHOT.jar <br>hdfs://node1.itcast.cn:9000/person.txt <br>hdfs://node1.itcast.cn:9000/out </p><p>查看运行结果<br>hdfs dfs -cat  hdfs://node1.itcast.cn:9000/out/part-r-*</p><h4 id="3-1-2-通过StructType直接指定Schema"><a href="#3-1-2-通过StructType直接指定Schema" class="headerlink" title="3.1.2. 通过StructType直接指定Schema"></a>3.1.2. 通过StructType直接指定Schema</h4><p>创建一个object为cn.itcast.spark.sql.SpecifyingSchema</p><pre class="language-none"><code class="language-none">package cn.itcast.spark.sqlimport org.apache.spark.sql.{Row, SQLContext}import org.apache.spark.sql.types._import org.apache.spark.{SparkContext, SparkConf}/**  * Created by ZX on 2015/12/11.  */object SpecifyingSchema {  def main(args: Array[String]) {    //创建SparkConf()并设置App名称    val conf = new SparkConf().setAppName("SQL-2")    //SQLContext要依赖SparkContext    val sc = new SparkContext(conf)    //创建SQLContext    val sqlContext = new SQLContext(sc)    //从指定的地址创建RDD    val personRDD = sc.textFile(args(0)).map(_.split(" "))    //通过StructType直接指定每个字段的schema    val schema = StructType(      List(        StructField("id", IntegerType, true),        StructField("name", StringType, true),        StructField("age", IntegerType, true)      )    )    //将RDD映射到rowRDD    val rowRDD = personRDD.map(p =&gt; Row(p(0).toInt, p(1).trim, p(2).toInt))    //将schema信息应用到rowRDD上    val personDataFrame = sqlContext.createDataFrame(rowRDD, schema)    //注册表    personDataFrame.registerTempTable("t_person")    //执行SQL    val df = sqlContext.sql("select * from t_person order by age desc limit 4")    //将结果以JSON的方式存储到指定位置    df.write.json(args(1))    //停止Spark Context    sc.stop()  }}</code></pre><p>将程序打成jar包，上传到spark集群，提交Spark任务<br>/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-submit <br>–class cn.itcast.spark.sql.InferringSchema <br>–master spark://node1.itcast.cn:7077 <br>/root/spark-mvn-1.0-SNAPSHOT.jar <br>hdfs://node1.itcast.cn:9000/person.txt <br>hdfs://node1.itcast.cn:9000/out1 </p><p>查看结果<br>hdfs dfs -cat  hdfs://node1.itcast.cn:9000/out1/part-r-*</p><h2 id="4-数据源"><a href="#4-数据源" class="headerlink" title="4. 数据源"></a>4. 数据源</h2><h3 id="4-1-JDBC"><a href="#4-1-JDBC" class="headerlink" title="4.1. JDBC"></a>4.1. JDBC</h3><p>Spark SQL可以通过JDBC从关系型数据库中读取数据的方式创建DataFrame，通过对DataFrame一系列的计算后，还可以将数据再写回关系型数据库中。</p><h4 id="4-1-1-从MySQL中加载数据（Spark-Shell方式）"><a href="#4-1-1-从MySQL中加载数据（Spark-Shell方式）" class="headerlink" title="4.1.1. 从MySQL中加载数据（Spark Shell方式）"></a>4.1.1. 从MySQL中加载数据（Spark Shell方式）</h4><pre><code>1. 启动Spark Shell，必须指定mysql连接驱动jar包</code></pre><p>/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-shell <br>–master spark://node1.itcast.cn:7077 <br>–jars /usr/local/spark-1.5.2-bin-hadoop2.6/mysql-connector-java-5.1.35-bin.jar <br>–driver-class-path /usr/local/spark-1.5.2-bin-hadoop2.6/mysql-connector-java-5.1.35-bin.jar </p><pre><code>2. 从mysql中加载数据</code></pre><p>val jdbcDF = sqlContext.read.format(“jdbc”).options(Map(“url” -&gt; “jdbc:mysql://192.168.10.1:3306/bigdata”, “driver” -&gt; “com.mysql.jdbc.Driver”, “dbtable” -&gt; “person”, “user” -&gt; “root”, “password” -&gt; “123456”)).load()</p><pre><code>3. 执行查询</code></pre><p>jdbcDF.show()</p><p><img src="/images/20180828/22.png"></p><h4 id="4-1-2-将数据写入到MySQL中（打jar包方式）"><a href="#4-1-2-将数据写入到MySQL中（打jar包方式）" class="headerlink" title="4.1.2. 将数据写入到MySQL中（打jar包方式）"></a>4.1.2. 将数据写入到MySQL中（打jar包方式）</h4><p>1.编写Spark SQL程序</p><pre class="language-none"><code class="language-none">    package cn.itcast.spark.sqlimport java.util.Propertiesimport org.apache.spark.sql.{SQLContext, Row}import org.apache.spark.sql.types.{StringType, IntegerType, StructField, StructType}import org.apache.spark.{SparkConf, SparkContext}object JdbcRDD {  def main(args: Array[String]) {    val conf = new SparkConf().setAppName("MySQL-Demo")    val sc = new SparkContext(conf)    val sqlContext = new SQLContext(sc)    //通过并行化创建RDD    val personRDD = sc.parallelize(Array("1 tom 5", "2 jerry 3", "3 kitty 6")).map(_.split(" "))    //通过StructType直接指定每个字段的schema    val schema = StructType(      List(        StructField("id", IntegerType, true),        StructField("name", StringType, true),        StructField("age", IntegerType, true)      )    )    //将RDD映射到rowRDD    val rowRDD = personRDD.map(p =&gt; Row(p(0).toInt, p(1).trim, p(2).toInt))    //将schema信息应用到rowRDD上    val personDataFrame = sqlContext.createDataFrame(rowRDD, schema)    //创建Properties存储数据库相关属性    val prop = new Properties()    prop.put("user", "root")    prop.put("password", "123456")    //将数据追加到数据库    personDataFrame.write.mode("append").jdbc("jdbc:mysql://192.168.10.1:3306/bigdata", "bigdata.person", prop)    //停止SparkContext    sc.stop()  }}    </code></pre><p>2.用maven将程序打包</p><p>3.将Jar包提交到spark集群<br>/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-submit <br>–class cn.itcast.spark.sql.JdbcRDD <br>–master spark://node1.itcast.cn:7077 <br>–jars /usr/local/spark-1.5.2-bin-hadoop2.6/mysql-connector-java-5.1.35-bin.jar <br>–driver-class-path /usr/local/spark-1.5.2-bin-hadoop2.6/mysql-connector-java-5.1.35-bin.jar <br>/root/spark-mvn-1.0-SNAPSHOT.jar </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark RDD基础二</title>
      <link href="/2018/08/28/spark-rdd-ji-chu-er/"/>
      <url>/2018/08/28/spark-rdd-ji-chu-er/</url>
      
        <content type="html"><![CDATA[<h1 id="spark-RDD基础二"><a href="#spark-RDD基础二" class="headerlink" title=" spark RDD基础二"></a><center> spark RDD基础二</center></h1><h2 id="1-目标"><a href="#1-目标" class="headerlink" title="1.目标"></a>1.目标</h2><pre class="language-none"><code class="language-none">使用RDD的算子完成计算掌握RDD的原理</code></pre><h2 id="2-弹性分布式数据集RDD"><a href="#2-弹性分布式数据集RDD" class="headerlink" title="2.弹性分布式数据集RDD"></a>2.弹性分布式数据集RDD</h2><h3 id="2-1RDD概述"><a href="#2-1RDD概述" class="headerlink" title="2.1RDD概述"></a>2.1RDD概述</h3><h4 id="2-1-1-什么是RDD"><a href="#2-1-1-什么是RDD" class="headerlink" title="2.1.1. 什么是RDD"></a>2.1.1. 什么是RDD</h4><p>RDD（Resilient Distributed Dataset）叫做分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。RDD具有数据流模型的特点：自动容错、位置感知性调度和可伸缩性。RDD允许用户在执行多个查询时显式地将工作集缓存在内存中，后续的查询能够重用工作集，这极大地提升了查询速度。</p><h4 id="2-1-2-RDD的属性"><a href="#2-1-2-RDD的属性" class="headerlink" title="2.1.2. RDD的属性"></a>2.1.2. RDD的属性</h4><p><img src="/images/20180828/3.png"></p><pre class="language-none"><code class="language-none">1） 一组分片（Partition），即数据集的基本组成单位。对于RDD来说，每个分片都会被一个计算任务处理，并决定并行计算的粒度。用户可以在创建RDD时指定RDD的分片个数，如果没有指定，那么就会采用默认值。默认值就是程序所分配到的CPU Core的数目。2） 一个计算每个分区的函数。Spark中RDD的计算是以分片为单位的，每个RDD都会实现compute函数以达到这个目的。compute函数会对迭代器进行复合，不需要保存每次计算的结果。3） RDD之间的依赖关系。RDD的每次转换都会生成一个新的RDD，所以RDD之间就会形成类似于流水线一样的前后依赖关系。在部分分区数据丢失时，Spark可以通过这个依赖关系重新计算丢失的分区数据，而不是对RDD的所有分区进行重新计算。4） 一个Partitioner，即RDD的分片函数。当前Spark中实现了两种类型的分片函数，一个是基于哈希的HashPartitioner，另外一个是基于范围的RangePartitioner。只有对于于key-value的RDD，才会有Partitioner，非key-value的RDD的Parititioner的值是None。Partitioner函数不但决定了RDD本身的分片数量，也决定了parent RDD Shuffle输出时的分片数量。5） 一个列表，存储存取每个Partition的优先位置（preferred location）。对于一个HDFS文件来说，这个列表保存的就是每个Partition所在的块的位置。按照“移动数据不如移动计算”的理念，Spark在进行任务调度的时候，会尽可能地将计算任务分配到其所要处理数据块的存储位置。</code></pre><h3 id="2-2-创建RDD"><a href="#2-2-创建RDD" class="headerlink" title="2.2. 创建RDD"></a>2.2. 创建RDD</h3><pre><code>1） 由一个已经存在的Scala集合创建。</code></pre><p>val rdd1 = sc.parallelize(Array(1,2,3,4,5,6,7,8))</p><pre><code>2） 由外部存储系统的数据集创建，包括本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、Cassandra、HBase等</code></pre><p>val rdd2 = sc.textFile(“hdfs://node1.itcast.cn:9000/words.txt”)</p><h2 id="2-3RDD编程API"><a href="#2-3RDD编程API" class="headerlink" title="2.3RDD编程API"></a>2.3RDD编程API</h2><h3 id="2-3-1-Transformation"><a href="#2-3-1-Transformation" class="headerlink" title="2.3.1. Transformation"></a>2.3.1. Transformation</h3><p>RDD中的所有转换都是延迟加载的，也就是说，它们并不会直接计算结果。相反的，它们只是记住这些应用到基础数据集（例如一个文件）上的转换动作。只有当发生一个要求返回结果给Driver的动作时，这些转换才会真正运行。这种设计让Spark更加有效率地运行。</p><p>常用的Transformation：</p><pre class="language-none"><code class="language-none">转换    含义map(func)    返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成filter(func)    返回一个新的RDD，该RDD由经过func函数计算后返回值为true的输入元素组成flatMap(func)    类似于map，但是每一个输入元素可以被映射为0或多个输出元素（所以func应该返回一个序列，而不是单一元素）mapPartitions(func)    类似于map，但独立地在RDD的每一个分片上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] =&gt; Iterator[U]mapPartitionsWithIndex(func)    类似于mapPartitions，但func带有一个整数参数表示分片的索引值，因此在类型为T的RDD上运行时，func的函数类型必须是(Int, Interator[T]) =&gt; Iterator[U]sample(withReplacement, fraction, seed)    根据fraction指定的比例对数据进行采样，可以选择是否使用随机数进行替换，seed用于指定随机数生成器种子union(otherDataset)    对源RDD和参数RDD求并集后返回一个新的RDDintersection(otherDataset)    对源RDD和参数RDD求交集后返回一个新的RDDdistinct([numTasks]))    对源RDD进行去重后返回一个新的RDDgroupByKey([numTasks])        在一个(K,V)的RDD上调用，返回一个(K, Iterator[V])的RDDreduceByKey(func, [numTasks])    在一个(K,V)的RDD上调用，返回一个(K,V)的RDD，使用指定的reduce函数，将相同key的值聚合到一起，与groupByKey类似，reduce任务的个数可以通过第二个可选的参数来设置aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])sortByKey([ascending], [numTasks])    在一个(K,V)的RDD上调用，K必须实现Ordered接口，返回一个按照key进行排序的(K,V)的RDDsortBy(func,[ascending], [numTasks])    与sortByKey类似，但是更灵活join(otherDataset, [numTasks])    在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素对在一起的(K,(V,W))的RDDcogroup(otherDataset, [numTasks])    在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable&lt;V&gt;,Iterable&lt;W&gt;))类型的RDDcartesian(otherDataset)    笛卡尔积pipe(command, [envVars])coalesce(numPartitions)    repartition(numPartitions)repartitionAndSortWithinPartitions(partitioner)</code></pre><h3 id="2-3-2Action"><a href="#2-3-2Action" class="headerlink" title="2.3.2Action"></a>2.3.2Action</h3><pre class="language-none"><code class="language-none">动作    含义reduce(func)    通过func函数聚集RDD中的所有元素，这个功能必须是课交换且可并联的collect()    在驱动程序中，以数组的形式返回数据集的所有元素count()    返回RDD的元素个数first()    返回RDD的第一个元素（类似于take(1)）take(n)    返回一个由数据集的前n个元素组成的数组takeSample(withReplacement,num, [seed])    返回一个数组，该数组由从数据集中随机采样的num个元素组成，可以选择是否用随机数替换不足的部分，seed用于指定随机数生成器种子takeOrdered(n,&nbsp;[ordering])saveAsTextFile(path)    将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本saveAsSequenceFile(path)&nbsp;    将数据集中的元素以Hadoop sequencefile的格式保存到指定的目录下，可以使HDFS或者其他Hadoop支持的文件系统。saveAsObjectFile(path)&nbsp;countByKey()    针对(K,V)类型的RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数。foreach(func)    在数据集的每一个元素上，运行函数func进行更新。</code></pre><h3 id="2-3-3WordCount中的RDD"><a href="#2-3-3WordCount中的RDD" class="headerlink" title="2.3.3WordCount中的RDD"></a>2.3.3WordCount中的RDD</h3><p><img src="/images/20180828/4.png"></p><h3 id="2-3-4练习"><a href="#2-3-4练习" class="headerlink" title="2.3.4练习"></a>2.3.4练习</h3><pre class="language-none"><code class="language-none">启动spark-shell/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-shell --master spark://node1.itcast.cn:7077 练习1：//通过并行化生成rddval rdd1 = sc.parallelize(List(5, 6, 4, 7, 3, 8, 2, 9, 1, 10))//对rdd1里的每一个元素乘2然后排序val rdd2 = rdd1.map(_ * 2).sortBy(x =&gt; x, true)//过滤出大于等于十的元素val rdd3 = rdd2.filter(_ &gt;= 10)//将元素以数组的方式在客户端显示rdd3.collect练习2：val rdd1 = sc.parallelize(Array("a b c", "d e f", "h i j"))//将rdd1里面的每一个元素先切分在压平val rdd2 = rdd1.flatMap(_.split(' '))rdd2.collect练习3：val rdd1 = sc.parallelize(List(5, 6, 4, 3))val rdd2 = sc.parallelize(List(1, 2, 3, 4))//求并集val rdd3 = rdd1.union(rdd2)//求交集val rdd4 = rdd1.intersection(rdd2)//去重rdd3.distinct.collectrdd4.collect练习4：val rdd1 = sc.parallelize(List(("tom", 1), ("jerry", 3), ("kitty", 2)))val rdd2 = sc.parallelize(List(("jerry", 2), ("tom", 1), ("shuke", 2)))//求jionval rdd3 = rdd1.join(rdd2)rdd3.collect//求并集val rdd4 = rdd1 union rdd2//按key进行分组rdd4.groupByKeyrdd4.collect练习5：val rdd1 = sc.parallelize(List(("tom", 1), ("tom", 2), ("jerry", 3), ("kitty", 2)))val rdd2 = sc.parallelize(List(("jerry", 2), ("tom", 1), ("shuke", 2)))//cogroupval rdd3 = rdd1.cogroup(rdd2)//注意cogroup与groupByKey的区别rdd3.collect练习6：val rdd1 = sc.parallelize(List(1, 2, 3, 4, 5))//reduce聚合val rdd2 = rdd1.reduce(_ + _)rdd2.collect练习7：val rdd1 = sc.parallelize(List(("tom", 1), ("jerry", 3), ("kitty", 2),  ("shuke", 1)))val rdd2 = sc.parallelize(List(("jerry", 2), ("tom", 3), ("shuke", 2), ("kitty", 5)))val rdd3 = rdd1.union(rdd2)//按key进行聚合val rdd4 = rdd3.reduceByKey(_ + _)rdd4.collect//按value的降序排序val rdd5 = rdd4.map(t =&gt; (t._2, t._1)).sortByKey(false).map(t =&gt; (t._2, t._1))rdd5.collect//想要了解更多，访问下面的地址http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html</code></pre><h3 id="2-4RDD的依赖关系"><a href="#2-4RDD的依赖关系" class="headerlink" title="2.4RDD的依赖关系"></a>2.4RDD的依赖关系</h3><p>RDD和它依赖的父RDD（s）的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）。</p><p><img src="/images/20180828/5.png"></p><h4 id="2-4-1-窄依赖"><a href="#2-4-1-窄依赖" class="headerlink" title="2.4.1. 窄依赖"></a>2.4.1. 窄依赖</h4><p>窄依赖指的是每一个父RDD的Partition最多被子RDD的一个Partition使用<br>总结：窄依赖我们形象的比喻为独生子女</p><h4 id="2-4-2-宽依赖"><a href="#2-4-2-宽依赖" class="headerlink" title="2.4.2. 宽依赖"></a>2.4.2. 宽依赖</h4><p>宽依赖指的是多个子RDD的Partition会依赖同一个父RDD的Partition<br>总结：窄依赖我们形象的比喻为超生</p><h4 id="2-4-3-Lineage"><a href="#2-4-3-Lineage" class="headerlink" title="2.4.3. Lineage"></a>2.4.3. Lineage</h4><p>RDD只支持粗粒度转换，即在大量记录上执行的单个操作。将创建RDD的一系列Lineage（即血统）记录下来，以便恢复丢失的分区。RDD的Lineage会记录RDD的元数据信息和转换行为，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p><h3 id="2-5-RDD的缓存"><a href="#2-5-RDD的缓存" class="headerlink" title="2.5. RDD的缓存"></a>2.5. RDD的缓存</h3><p>Spark速度非常快的原因之一，就是在不同操作中可以在内存中持久化或缓存个数据集。当持久化某个RDD后，每一个节点都将把计算的分片结果保存在内存中，并在对此RDD或衍生出的RDD进行的其他动作中重用。这使得后续的动作变得更加迅速。RDD相关的持久化和缓存，是Spark最重要的特征之一。可以说，缓存是Spark构建迭代式算法和快速交互式查询的关键。</p><h4 id="2-5-1-RDD缓存方式"><a href="#2-5-1-RDD缓存方式" class="headerlink" title="2.5.1. RDD缓存方式"></a>2.5.1. RDD缓存方式</h4><p>RDD通过persist方法或cache方法可以将前面的计算结果缓存，但是并不是这两个方法被调用时立即缓存，而是触发后面的action时，该RDD将会被缓存在计算节点的内存中，并供后面重用。</p><p><img src="/images/20180828/6.png"></p><p>通过查看源码发现cache最终也是调用了persist方法，默认的存储级别都是仅在内存存储一份，Spark的存储级别还有好多种，存储级别在object StorageLevel中定义的。</p><p><img src="/images/20180828/7.png"></p><p>缓存有可能丢失，或者存储存储于内存的数据由于内存不足而被删除，RDD的缓存容错机制保证了即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列转换，丢失的数据会被重算，由于RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。</p><h3 id="2-6-DAG的生成"><a href="#2-6-DAG的生成" class="headerlink" title="2.6. DAG的生成"></a>2.6. DAG的生成</h3><p>DAG(Directed Acyclic Graph)叫做有向无环图，原始的RDD通过一系列的转换就就形成了DAG，根据RDD之间的依赖关系的不同将DAG划分成不同的Stage，对于窄依赖，partition的转换处理在Stage中完成计算。对于宽依赖，由于有Shuffle的存在，只能在parent RDD处理完成后，才能开始接下来的计算，因此宽依赖是划分Stage的依据。</p><p><img src="/images/20180828/8.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark基础一</title>
      <link href="/2018/08/28/spark-ji-chu-yi/"/>
      <url>/2018/08/28/spark-ji-chu-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="spark基础一"><a href="#spark基础一" class="headerlink" title="spark基础一"></a><center>spark基础一</center></h1><h2 id="1-目标"><a href="#1-目标" class="headerlink" title="1 目标"></a>1 目标</h2><pre class="language-none"><code class="language-none">熟悉Spark相关概念搭建Spark集群编写简单的Spark应用程序</code></pre><h2 id="2Spark概述"><a href="#2Spark概述" class="headerlink" title="2Spark概述"></a>2Spark概述</h2><h3 id="2-1什么是Spark（官网：http-spark-apache-org）"><a href="#2-1什么是Spark（官网：http-spark-apache-org）" class="headerlink" title="2.1什么是Spark（官网：http://spark.apache.org）"></a>2.1什么是Spark（官网：<a href="http://spark.apache.org)/">http://spark.apache.org）</a></h3><pre class="language-none"><code class="language-none">Spark是一种快速、通用、可扩展的大数据分析引擎，2009年诞生于加州大学伯克利分校AMPLab，2010年开源，2013年6月成为Apache孵化项目，2014年2月成为Apache顶级项目。目前，Spark生态系统已经发展成为一个包含多个子项目的集合，其中包含SparkSQL、Spark&nbsp;Streaming、GraphX、MLlib等子项目，Spark是基于内存计算的大数据并行计算框架。Spark基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性，允许用户将Spark部署在大量廉价硬件之上，形成集群。Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于凤巢、大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。</code></pre><h3 id="2-2为什么要学Spark"><a href="#2-2为什么要学Spark" class="headerlink" title="2.2为什么要学Spark"></a>2.2为什么要学Spark</h3><p>中间结果输出：基于MapReduce的计算引擎通常会将中间结果输出到磁盘上，进行存储和容错。出于任务管道承接的，考虑，当一些查询翻译到MapReduce任务时，往往会产生多个Stage，而这些串联的Stage又依赖于底层文件系统（如HDFS）来存储每一个Stage的输出结果</p><p><font style="color: red">Spark是MapReduce的替代方案，而且兼容HDFS、Hive，可融入Hadoop的生态系统，以弥补MapReduce的不足。</font></p><h3 id="2-3Spark特点"><a href="#2-3Spark特点" class="headerlink" title="2.3Spark特点"></a>2.3Spark特点</h3><p>1**.快**<br>与Hadoop的MapReduce相比，Spark基于内存的运算要快100倍以上，基于硬盘的运算也要快10倍以上。Spark实现了高效的DAG执行引擎，可以通过基于内存来高效处理数据流。</p><p>2.<strong>易用</strong><br>Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。</p><p>3.<strong>通用</strong><br>Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark&nbsp;SQL）、实时流处理（Spark&nbsp;Streaming）、机器学习（Spark&nbsp;MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。</p><p>4.<strong>兼容性</strong><br>Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache&nbsp;Mesos作为它的资源管理和调度器，器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人都可以非常容易地部署和使用Spark。此外，Spark还提供了在EC2上部署Standalone的Spark集群的工具。</p><h2 id="3-spark集群安装"><a href="#3-spark集群安装" class="headerlink" title="3.spark集群安装"></a>3.spark集群安装</h2><pre class="language-none"><code class="language-none">3.1. 安装3.1.1. 机器部署准备两台以上Linux服务器，安装好JDK1.73.1.2. 下载Spark安装包</code></pre><p><img src="/images/20180828/1.png"></p><pre class="language-none"><code class="language-none">http://www.apache.org/dyn/closer.lua/spark/spark-1.5.2/spark-1.5.2-bin-hadoop2.6.tgz上传解压安装包上传spark-1.5.2-bin-hadoop2.6.tgz安装包到Linux上解压安装包到指定位置tar -zxvf spark-1.5.2-bin-hadoop2.6.tgz -C /usr/local3.1.3. 配置Spark进入到Spark安装目录cd /usr/local/spark-1.5.2-bin-hadoop2.6进入conf目录并重命名并修改spark-env.sh.template文件cd conf/mv spark-env.sh.template spark-env.shvi spark-env.sh在该配置文件中添加如下配置export JAVA_HOME=/usr/java/jdk1.7.0_45export SPARK_MASTER_IP=node1.itcast.cnexport SPARK_MASTER_PORT=7077保存退出重命名并修改slaves.template文件mv slaves.template slavesvi slaves在该文件中添加子节点所在的位置（Worker节点）node2.itcast.cnnode3.itcast.cnnode4.itcast.cn保存退出将配置好的Spark拷贝到其他节点上scp -r spark-1.5.2-bin-hadoop2.6/ node2.itcast.cn:/usr/local/scp -r spark-1.5.2-bin-hadoop2.6/ node3.itcast.cn:/usr/local/scp -r spark-1.5.2-bin-hadoop2.6/ node4.itcast.cn:/usr/local/Spark集群配置完毕，目前是1个Master，3个Work，在node1.itcast.cn上启动Spark集群/usr/local/spark-1.5.2-bin-hadoop2.6/sbin/start-all.sh启动后执行jps命令，主节点上有Master进程，其他子节点上有Work进行，登录Spark管理界面查看集群状态（主节点）：http://node1.itcast.cn:8080/</code></pre><p><img src="/images/20180828/2.png"></p><pre class="language-none"><code class="language-none">到此为止，Spark集群安装完毕，但是有一个很大的问题，那就是Master节点存在单点故障，要解决此问题，就要借助zookeeper，并且启动至少两个Master节点来实现高可靠，配置方式比较简单：Spark集群规划：node1，node2是Master；node3，node4，node5是Worker安装配置zk集群，并启动zk集群停止spark所有服务，修改配置文件spark-env.sh，在该配置文件中删掉SPARK_MASTER_IP并添加如下配置export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=zk1,zk2,zk3 -Dspark.deploy.zookeeper.dir=/spark"1.在node1节点上修改slaves配置文件内容指定worker节点2.在node1上执行sbin/start-all.sh脚本，然后在node2上执行sbin/start-master.sh启动第二个Master</code></pre><h2 id="4执行Spark程序"><a href="#4执行Spark程序" class="headerlink" title="4执行Spark程序"></a>4执行Spark程序</h2><h3 id="4-1-执行第一个spark程序"><a href="#4-1-执行第一个spark程序" class="headerlink" title="4.1. 执行第一个spark程序"></a>4.1. 执行第一个spark程序</h3><pre class="language-none"><code class="language-none">/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-submit \--class org.apache.spark.examples.SparkPi \--master spark://node1.itcast.cn:7077 \--executor-memory 1G \--total-executor-cores 2 \/usr/local/spark-1.5.2-bin-hadoop2.6/lib/spark-examples-1.5.2-hadoop2.6.0.jar \100</code></pre><p>该算法是利用蒙特·卡罗算法求PI</p><h3 id="4-2-启动Spark-Shell"><a href="#4-2-启动Spark-Shell" class="headerlink" title="4.2. 启动Spark Shell"></a>4.2. 启动Spark Shell</h3><p>spark-shell是Spark自带的交互式Shell程序，方便用户进行交互式编程，用户可以在该命令行下用scala编写spark程序。</p><h4 id="4-2-1-启动spark-shell"><a href="#4-2-1-启动spark-shell" class="headerlink" title="4.2.1. 启动spark shell"></a>4.2.1. 启动spark shell</h4><pre class="language-none"><code class="language-none">/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-shell \--master spark://node1.itcast.cn:7077 \--executor-memory 2g \--total-executor-cores 2</code></pre><p>参数说明：<br>–master spark://node1.itcast.cn:7077 指定Master的地址<br>–executor-memory 2g 指定每个worker可用内存为2G<br>–total-executor-cores 2 指定整个集群使用的cup核数为2个</p><p>注意：<br>如果启动spark shell时没有指定master地址，但是也可以正常启动spark shell和执行spark shell中的程序，其实是启动了spark的local模式，该模式仅在本机启动一个进程，没有与集群建立联系。</p><p>Spark Shell中已经默认将SparkContext类初始化为对象sc。用户代码如果需要用到，则直接应用sc即可</p><h4 id="4-2-2-在spark-shell中编写WordCount程序"><a href="#4-2-2-在spark-shell中编写WordCount程序" class="headerlink" title="4.2.2. 在spark shell中编写WordCount程序"></a>4.2.2. 在spark shell中编写WordCount程序</h4><pre class="language-none"><code class="language-none">    1. 首先启动hdfs    2. 向hdfs上传一个文件到hdfs://node1.itcast.cn:9000/words.txt    3. 在spark shell中用scala语言编写spark程序sc.textFile("hdfs://node1.itcast.cn:9000/words.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).saveAsTextFile("hdfs://node1.itcast.cn:9000/out")4. 使用hdfs命令查看结果hdfs dfs -ls hdfs://node1.itcast.cn:9000/out/p*说明：sc是SparkContext对象，该对象时提交spark程序的入口textFile(hdfs://node1.itcast.cn:9000/words.txt)是hdfs中读取数据flatMap(_.split(" "))先map在压平map((_,1))将单词和1构成元组reduceByKey(_+_)按照key进行reduce，并将value累加saveAsTextFile("hdfs://node1.itcast.cn:9000/out")将结果写入到hdfs中</code></pre><h3 id="4-3-在IDEA中编写WordCount程序"><a href="#4-3-在IDEA中编写WordCount程序" class="headerlink" title="4.3. 在IDEA中编写WordCount程序"></a>4.3. 在IDEA中编写WordCount程序</h3><p>spark shell仅在测试和验证我们的程序时使用的较多，在生产环境中，通常会在IDE中编制程序，然后打成jar包，然后提交到集群，最常用的是创建一个Maven项目，利用Maven来管理jar包的依赖。</p><p>1.创建一个项目</p><p>2.选择Maven项目，然后点击next</p><p>3.填写maven的GAV，然后点击next</p><p>4.填写项目名称，然后点击finish</p><p>5.创建好maven项目后，点击Enable Auto-Import</p><p>6.配置Maven的pom.xml</p><pre class="language-none"><code class="language-none">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0"         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;cn.itcast.spark&lt;/groupId&gt;    &lt;artifactId&gt;spark-mvn&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;properties&gt;        &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt;        &lt;encoding&gt;UTF-8&lt;/encoding&gt;        &lt;scala.version&gt;2.10.6&lt;/scala.version&gt;        &lt;scala.compat.version&gt;2.10&lt;/scala.compat.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;            &lt;artifactId&gt;scala-library&lt;/artifactId&gt;            &lt;version&gt;${scala.version}&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;            &lt;artifactId&gt;spark-core_2.10&lt;/artifactId&gt;            &lt;version&gt;1.5.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;            &lt;artifactId&gt;spark-streaming_2.10&lt;/artifactId&gt;            &lt;version&gt;1.5.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;            &lt;version&gt;2.6.2&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;        &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt;                &lt;artifactId&gt;scala-maven-plugin&lt;/artifactId&gt;                &lt;version&gt;3.2.0&lt;/version&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;goals&gt;                            &lt;goal&gt;compile&lt;/goal&gt;                            &lt;goal&gt;testCompile&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;args&gt;                                &lt;arg&gt;-make:transitive&lt;/arg&gt;                                &lt;arg&gt;-dependencyfile&lt;/arg&gt;                                &lt;arg&gt;${project.build.directory}/.scala_dependencies&lt;/arg&gt;                            &lt;/args&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;                &lt;version&gt;2.18.1&lt;/version&gt;                &lt;configuration&gt;                    &lt;useFile&gt;false&lt;/useFile&gt;                    &lt;disableXmlReport&gt;true&lt;/disableXmlReport&gt;                    &lt;includes&gt;                        &lt;include&gt;**/*Test.*&lt;/include&gt;                        &lt;include&gt;**/*Suite.*&lt;/include&gt;                    &lt;/includes&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;                &lt;version&gt;2.3&lt;/version&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;phase&gt;package&lt;/phase&gt;                        &lt;goals&gt;                            &lt;goal&gt;shade&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;filters&gt;                                &lt;filter&gt;                                    &lt;artifact&gt;*:*&lt;/artifact&gt;                                    &lt;excludes&gt;                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;                                    &lt;/excludes&gt;                                &lt;/filter&gt;                            &lt;/filters&gt;                            &lt;transformers&gt;                                &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt;                                    &lt;mainClass&gt;cn.itcast.spark.WordCount&lt;/mainClass&gt;                                &lt;/transformer&gt;                            &lt;/transformers&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><p>7.将src/main/java和src/test/java分别修改成src/main/scala和src/test/scala，与pom.xml中的配置保持一致</p><p>8.新建一个scala class，类型为Object</p><p>9.编写spark程序</p><pre class="language-none"><code class="language-none">package cn.itcast.sparkimport org.apache.spark.{SparkContext, SparkConf}object WordCount {  def main(args: Array[String]) {    //创建SparkConf()并设置App名称    val conf = new SparkConf().setAppName("WC")    //创建SparkContext，该对象是提交spark App的入口    val sc = new SparkContext(conf)    //使用sc创建RDD并执行相应的transformation和action    sc.textFile(args(0)).flatMap(_.split(" ")).map((_, 1)).reduceByKey(_+_, 1).sortBy(_._2, false).saveAsTextFile(args(1))    //停止sc，结束该任务    sc.stop()  }}</code></pre><p>10.使用Maven打包：首先修改pom.xml中的main class<br>点击idea右侧的Maven Project选项<br>点击Lifecycle,选择clean和package，然后点击Run Maven Build</p><p>11.选择编译成功的jar包，并将该jar上传到Spark集群中的某个节点上</p><p>12.首先启动hdfs和Spark集群<br>启动hdfs<br>/usr/local/hadoop-2.6.1/sbin/start-dfs.sh<br>启动spark<br>/usr/local/spark-1.5.2-bin-hadoop2.6/sbin/start-all.sh</p><p>13.使用spark-submit命令提交Spark应用（注意参数的顺序）<br>/usr/local/spark-1.5.2-bin-hadoop2.6/bin/spark-submit <br>–class cn.itcast.spark.WordCount <br>–master spark://node1.itcast.cn:7077 <br>–executor-memory 2G <br>–total-executor-cores 4 <br>/root/spark-mvn-1.0-SNAPSHOT.jar <br>hdfs://node1.itcast.cn:9000/words.txt <br>hdfs://node1.itcast.cn:9000/out</p><p>14.查看程序执行结果<br>hdfs dfs -cat hdfs://node1.itcast.cn:9000/out/part-00000<br>(hello,6)<br>(tom,3)<br>(kitty,2)<br>(jerry,1)</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scala学习四</title>
      <link href="/2018/08/27/scala-xue-xi-si/"/>
      <url>/2018/08/27/scala-xue-xi-si/</url>
      
        <content type="html"><![CDATA[<h1 id="scala编程实战基础四"><a href="#scala编程实战基础四" class="headerlink" title="scala编程实战基础四"></a><center>scala编程实战基础四</center></h1><h2 id="1目标"><a href="#1目标" class="headerlink" title="1目标"></a>1目标</h2><pre class="language-none"><code class="language-none">熟练使用Scala编写程序</code></pre><h2 id="2项目概述"><a href="#2项目概述" class="headerlink" title="2项目概述"></a>2项目概述</h2><h3 id="2-1-需求"><a href="#2-1-需求" class="headerlink" title="2.1. 需求"></a>2.1. 需求</h3><p>目前大多数的分布式架构底层通信都是通过RPC实现的，RPC框架非常多，比如前我们学过的Hadoop项目的RPC通信框架，但是Hadoop在设计之初就是为了运行长达数小时的批量而设计的，在某些极端的情况下，任务提交的延迟很高，所有Hadoop的RPC显得有些笨重。</p><p>Spark 的RPC是通过Akka类库实现的，Akka用Scala语言开发，基于Actor并发模型实现，Akka具有高可靠、高性能、可扩展等特点，使用Akka可以轻松实现分布式RPC功能。</p><h3 id="2-2-Akka简介"><a href="#2-2-Akka简介" class="headerlink" title="2.2. Akka简介"></a>2.2. Akka简介</h3><p>Akka基于Actor模型，提供了一个用于构建可扩展的（Scalable）、弹性的（Resilient）、快速响应的（Responsive）应用程序的平台。</p><p>Actor模型：在计算机科学领域，Actor模型是一个并行计算（Concurrent Computation）模型，它把actor作为并行计算的基本元素来对待：为响应一个接收到的消息，一个actor能够自己做出一些决策，如创建更多的actor，或发送更多的消息，或者确定如何去响应接收到的下一个消息。</p><p><img src="/images/20180827/57.png"></p><p>Actor是Akka中最核心的概念，它是一个封装了状态和行为的对象，Actor之间可以通过交换消息的方式进行通信，每个Actor都有自己的收件箱（Mailbox）。通过Actor能够简化锁及线程管理，可以非常容易地开发出正确地并发程序和并行系统，Actor具有如下特性：</p><p>1.提供了一种高级抽象，能够简化在并发（Concurrency）/并行（Parallelism）应用场景下的编程开发<br>2.提供了异步非阻塞的、高性能的事件驱动编程模型<br>3.超级轻量级事件处理（每GB堆内存几百万Actor）</p><h2 id="3项目实现"><a href="#3项目实现" class="headerlink" title="3项目实现"></a>3项目实现</h2><h3 id="3-1架构图"><a href="#3-1架构图" class="headerlink" title="3.1架构图"></a>3.1架构图</h3><p><img src="/images/20180827/58.png"></p><h3 id="3-2重要类介绍"><a href="#3-2重要类介绍" class="headerlink" title="3.2重要类介绍"></a>3.2重要类介绍</h3><h4 id="3-2-1-ActorSystem"><a href="#3-2-1-ActorSystem" class="headerlink" title="3.2.1. ActorSystem"></a>3.2.1. ActorSystem</h4><p>在Akka中，ActorSystem是一个重量级的结构，他需要分配多个线程，所以在实际应用中，ActorSystem通常是一个单例对象，我们可以使用这个ActorSystem创建很多Actor。</p><h4 id="3-2-2-Actor"><a href="#3-2-2-Actor" class="headerlink" title="3.2.2. Actor"></a>3.2.2. Actor</h4><p>在Akka中，Actor负责通信，在Actor中有一些重要的生命周期方法。</p><pre><code>1. preStart()方法：该方法在Actor对象构造方法执行后执行，整个Actor生命周期中仅执行一次。2. receive()方法：该方法在Actor的preStart方法执行完成后执行，用于接收消息，会被反复执行。</code></pre><h3 id="3-3Master类"><a href="#3-3Master类" class="headerlink" title="3.3Master类"></a>3.3Master类</h3><pre class="language-none"><code class="language-none">package cn.itcast.sparkimport scala.concurrent.duration._import akka.actor.{Props, ActorSystem, Actor}import akka.actor.Actor.Receiveimport com.typesafe.config.ConfigFactoryimport scala.collection.mutable/**  * Master为整个集群中的主节点  * Master继承了Actor  */class Master extends Actor{  //保存WorkerID和Work信息的map  val idToWorker = new mutable.HashMap[String, WorkerInfo]  //保存所有Worker信息的Set  val workers = new mutable.HashSet[WorkerInfo]  //Worker超时时间  val WORKER_TIMEOUT = 10 * 1000  //重新receive方法  //导入隐式转换，用于启动定时器  import context.dispatcher  //构造方法执行完执行一次  override def preStart(): Unit = {    //启动定时器，定时执行    context.system.scheduler.schedule(0 millis, WORKER_TIMEOUT millis, self, CheckOfTimeOutWorker)  }  //该方法会被反复执行，用于接收消息，通过case class模式匹配接收消息  override def receive: Receive = {    //Worker向Master发送的注册消息    case RegisterWorker(id, workerHost, memory, cores) =&gt; {      if(!idToWorker.contains(id)) {        val worker = new WorkerInfo(id, workerHost, memory, cores)        workers.add(worker)        idToWorker(id) = worker        sender ! RegisteredWorker("192.168.10.1")      }    }    //Worker向Master发送的心跳消息    case HeartBeat(workerId) =&gt; {      val workerInfo = idToWorker(workerId)      workerInfo.lastHeartbeat = System.currentTimeMillis()    }    //Master自己向自己发送的定期检查超时Worker的消息    case CheckOfTimeOutWorker =&gt; {      val currentTime = System.currentTimeMillis()      val toRemove = workers.filter(w =&gt; currentTime - w.lastHeartbeat &gt; WORKER_TIMEOUT).toArray      for(worker &lt;- toRemove){        workers -= worker        idToWorker.remove(worker.id)      }      println("worker size: " + workers.size)    }  }}object Master {  //程序执行入口  def main(args: Array[String]) {    val host = "192.168.10.1"    val port = 8888    //创建ActorSystem的必要参数    val configStr =      s"""         |akka.actor.provider = "akka.remote.RemoteActorRefProvider"         |akka.remote.netty.tcp.hostname = "$host"         |akka.remote.netty.tcp.port = "$port"       """.stripMargin    val config = ConfigFactory.parseString(configStr)    //ActorSystem是单例的，用来创建Actor    val actorSystem = ActorSystem.create("MasterActorSystem", config)    //启动Actor，Master会被实例化，生命周期方法会被调用    actorSystem.actorOf(Props[Master], "Master")  }}</code></pre><h3 id="3-4Worker类"><a href="#3-4Worker类" class="headerlink" title="3.4Worker类"></a>3.4Worker类</h3><pre class="language-none"><code class="language-none">package cn.itcast.sparkimport java.util.UUIDimport scala.concurrent.duration._import akka.actor.{ActorSelection, Props, ActorSystem, Actor}import akka.actor.Actor.Receiveimport com.typesafe.config.ConfigFactory/**  * Worker为整个集群的从节点  * Worker继承了Actor  */class Worker extends Actor{  //Worker端持有Master端的引用（代理对象）  var master: ActorSelection = null  //生成一个UUID，作为Worker的标识  val id = UUID.randomUUID().toString  //构造方法执行完执行一次  override def preStart(): Unit = {    //Worker向MasterActorSystem发送建立连接请求    master = context.system.actorSelection("akka.tcp://MasterActorSystem@192.168.10.1:8888/user/Master")    //Worker向Master发送注册消息    master ! RegisterWorker(id, "192.168.10.1", 10240, 8)  }  //该方法会被反复执行，用于接收消息，通过case class模式匹配接收消息  override def receive: Receive = {    //Master向Worker的反馈信息    case RegisteredWorker(masterUrl) =&gt; {      import context.dispatcher      //启动定时任务，向Master发送心跳      context.system.scheduler.schedule(0 millis, 5000 millis, self, SendHeartBeat)    }    case SendHeartBeat =&gt; {      println("worker send heartbeat")      master ! HeartBeat(id)    }  }}object Worker {  def main(args: Array[String]) {    val clientPort = 2552    //创建WorkerActorSystem的必要参数    val configStr =      s"""         |akka.actor.provider = "akka.remote.RemoteActorRefProvider"         |akka.remote.netty.tcp.port = $clientPort       """.stripMargin    val config = ConfigFactory.parseString(configStr)    val actorSystem = ActorSystem("WorkerActorSystem", config)    //启动Actor，Master会被实例化，生命周期方法会被调用    actorSystem.actorOf(Props[Worker], "Worker")  }}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> scala </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> scala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scala学习三</title>
      <link href="/2018/08/27/scala-xue-xi-san/"/>
      <url>/2018/08/27/scala-xue-xi-san/</url>
      
        <content type="html"><![CDATA[<h1 id="scala高级特性基础三"><a href="#scala高级特性基础三" class="headerlink" title="scala高级特性基础三"></a><center>scala高级特性基础三</center></h1><h2 id="1-目标"><a href="#1-目标" class="headerlink" title="1 目标"></a>1 目标</h2><pre class="language-none"><code class="language-none">目标一：深入理解高阶函数目标二：深入理解隐式转换</code></pre><h2 id="2-高阶函数"><a href="#2-高阶函数" class="headerlink" title="2 高阶函数"></a>2 高阶函数</h2><h3 id="2-1-概念"><a href="#2-1-概念" class="headerlink" title="2.1. 概念"></a>2.1. 概念</h3><p>Scala混合了面向对象和函数式的特性，我们通常将可以做为参数传递到方法中的表达式叫做函数。在函数式编程语言中，函数是“头等公民”，高阶函数包含：作为值的函数、匿名函数、闭包、柯里化等等。</p><h3 id="2-2-作为值的函数"><a href="#2-2-作为值的函数" class="headerlink" title="2.2. 作为值的函数"></a>2.2. 作为值的函数</h3><p>可以像任何其他数据类型一样被传递和操作的函数，每当你想要给算法传入具体动作时这个特性就会变得非常有用。</p><p><img src="/images/20180827/51.png"></p><p>定义函数时格式：val 变量名 = (输入参数类型和个数) =&gt; 函数实现和返回值类型和个数<br>“=”表示将函数赋给一个变量<br>“=&gt;”左面表示输入参数名称、类型和个数，右边表示函数的实现和返回值类型和参数个数</p><h3 id="2-3-匿名函数"><a href="#2-3-匿名函数" class="headerlink" title="2.3. 匿名函数"></a>2.3. 匿名函数</h3><p><code>在Scala中，你不需要给每一个函数命名，没有将函数赋给变量的函数叫做匿名函数</code></p><p><img src="/images/20180827/52.png"></p><p><code>由于Scala可以自动推断出参数的类型，所有可以写的跟精简一些</code></p><p><img src="/images/20180827/53.png"></p><p><code>还记得神奇的下划线吗？这才是终极方式</code></p><p><img src="/images/20180827/54.png"></p><h3 id="2-4-将方法转换成函数"><a href="#2-4-将方法转换成函数" class="headerlink" title="2.4. 将方法转换成函数"></a>2.4. 将方法转换成函数</h3><p>在Scala中，方法和函数是不一样的，最本质的区别是函数可以做为参数传递到方法中<br>但是方法可以被转换成函数，神奇的下划线又出场了</p><p><img src="/images/20180827/55.png"></p><h3 id="2-5-柯里化"><a href="#2-5-柯里化" class="headerlink" title="2.5. 柯里化"></a>2.5. 柯里化</h3><p>柯里化指的是将原来接受两个参数的方法变成新的接受一个参数的方法的过程</p><p><img src="/images/20180827/56.png"></p><h3 id="2-6例子"><a href="#2-6例子" class="headerlink" title="2.6例子"></a>2.6例子</h3><pre class="language-none"><code class="language-none">package cn.itcast.scalaobject FunDemo {  def main(args: Array[String]) {    def f2(x: Int) = x * 2    val f3 = (x: Int) =&gt; x * 3    val f4: (Int) =&gt; Int = { x =&gt; x * 4 }    val f4a: (Int) =&gt; Int = _ * 4    val f5 = (_: Int) * 5    val list = List(1, 2, 3, 4, 5)    var new_list: List[Int] = null    //第一种：最直观的方式 (Int) =&gt; Int    //new_list = list.map((x: Int) =&gt; x * 3)    //第二种：由于map方法知道你会传入一个类型为(Int) =&gt; Int的函数，你可以简写    //new_list = list.map((x) =&gt; x * 3)    //第三种：对于只有一个参数的函数，你可以省去参数外围的()    //new_list = list.map(x =&gt; x * 3)    //第四种：(终极方式)如果参数在=&gt;右侧只出现一次，可以使用_    new_list = list.map(_ * 3)    new_list.foreach(println(_))    var a = Array(1,2,3)    a.map(_* 3)  }}</code></pre><h2 id="3-隐式转换和隐式参数"><a href="#3-隐式转换和隐式参数" class="headerlink" title="3.隐式转换和隐式参数"></a>3.隐式转换和隐式参数</h2><h3 id="3-1-概念"><a href="#3-1-概念" class="headerlink" title="3.1. 概念"></a>3.1. 概念</h3><p>隐式转换和隐式参数是Scala中两个非常强大的功能，利用隐式转换和隐式参数，你可以提供优雅的类库，对类库的使用者隐匿掉那些枯燥乏味的细节</p><h3 id="3-2-作用"><a href="#3-2-作用" class="headerlink" title="3.2. 作用"></a>3.2. 作用</h3><p>隐式的对类的方法进行增强，丰富现有类库的功</p><h3 id="3-3-隐式转换函数"><a href="#3-3-隐式转换函数" class="headerlink" title="3.3. 隐式转换函数"></a>3.3. 隐式转换函数</h3><p>是指那种以implicit关键字声明的带有单个参数的函数</p><h3 id="3-4隐式转换例子"><a href="#3-4隐式转换例子" class="headerlink" title="3.4隐式转换例子"></a>3.4隐式转换例子</h3><pre class="language-none"><code class="language-none">package cn.itcast.impliimport java.io.Fileimport scala.io.Source//隐式的增强File类的方法class RichFile(val from: File) {  def read = Source.fromFile(from.getPath).mkString}object RichFile {  //隐式转换方法  implicit def file2RichFile(from: File) = new RichFile(from)}object MainApp{  def main(args: Array[String]): Unit = {    //导入隐式转换    import RichFile._    //import RichFile.file2RichFile    println(new File("c://words.txt").read)  }}package cn.itcast.scalaimport java.awt.GridLayout/**  * Created by ZX on 2015/11/13.  */object ImplicitContext{  //implicit def girl2Ordered(g : Girl) = new Ordered[Girl]{  //  override def compare(that: Girl): Int = if (g.faceValue &gt; that.faceValue) 1 else -1  //}  implicit object OrderingGirl extends Ordering[Girl]{    override def compare(x: Girl, y: Girl): Int = if (x.faceValue &gt; y.faceValue) 1 else -1  }}class Girl(var name: String, var faceValue: Double){  override def toString: String = s"name : $name, faveValue : $faceValue"}//class MissRight[T &lt;% Ordered[T]](f: T, s: T){//  def choose() = if(f &gt; s) f else s//}//class MissRight[T](f: T, s: T){//  def choose()(implicit ord: T =&gt; Ordered[T]) = if (f &gt; s) f else s//}class MissRight[T: Ordering](val f: T, val s: T){  def choose()(implicit ord: Ordering[T]) = if(ord.gt(f, s)) f else s}object MissRight {  def main(args: Array[String]) {    import ImplicitContext.OrderingGirl    val g1 = new Girl("yuihatano", 99)    val g2 = new Girl("jzmb", 98)    val mr = new MissRight(g1, g2)    val result = mr.choose()    println(result)  }}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> scala </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> scala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scala学习二</title>
      <link href="/2018/08/27/scala-xue-xi-er/"/>
      <url>/2018/08/27/scala-xue-xi-er/</url>
      
        <content type="html"><![CDATA[<h1 id="scala-Actor基础二"><a href="#scala-Actor基础二" class="headerlink" title="scala Actor基础二"></a><center>scala Actor基础二</center></h1><h2 id="1-目标"><a href="#1-目标" class="headerlink" title="1.目标"></a>1.目标</h2><pre class="language-none"><code class="language-none">熟悉Scala Actor并发编程为学习Akka做准备注：Scala Actor是scala 2.10.x版本及以前版本的Actor。Scala在2.11.x版本中将Akka加入其中，作为其默认的Actor，老版本的Actor已经废弃</code></pre><h2 id="2什么是Scala-Actor"><a href="#2什么是Scala-Actor" class="headerlink" title="2什么是Scala Actor"></a>2什么是Scala Actor</h2><h3 id="2-1-概念"><a href="#2-1-概念" class="headerlink" title="2.1. 概念"></a>2.1. 概念</h3><p>Scala中的Actor能够实现并行编程的强大功能，它是基于事件模型的并发机制，Scala是运用消息（message）的发送、接收来实现多线程的。使用Scala能够更容易地实现多线程应用的开发。</p><h3 id="2-2传统java并发编程与Scala-Actor编程的区别"><a href="#2-2传统java并发编程与Scala-Actor编程的区别" class="headerlink" title="2.2传统java并发编程与Scala Actor编程的区别"></a>2.2传统java并发编程与Scala Actor编程的区别</h3><p><img src="/images/20180827/50.png"></p><p>对于Java，我们都知道它的多线程实现需要对共享资源（变量、对象等）使用synchronized 关键字进行代码块同步、对象锁互斥等等。而且，常常一大块的try…catch语句块中加上wait方法、notify方法、notifyAll方法是让人很头疼的。原因就在于Java中多数使用的是可变状态的对象资源，对这些资源进行共享来实现多线程编程的话，控制好资源竞争与防止对象状态被意外修改是非常重要的，而对象状态的不变性也是较难以保证的。 而在Scala中，我们可以通过复制不可变状态的资源（即对象，Scala中一切都是对象，连函数、方法也是）的一个副本，再基于Actor的消息发送、接收机制进行并行编程</p><h3 id="2-3-Actor方法执行顺序"><a href="#2-3-Actor方法执行顺序" class="headerlink" title="2.3. Actor方法执行顺序"></a>2.3. Actor方法执行顺序</h3><pre><code>1. 首先调用start()方法启动Actor2. 调用start()方法后其act()方法会被执行3. 向Actor发送消息</code></pre><h3 id="2-4发送消息的方式"><a href="#2-4发送消息的方式" class="headerlink" title="2.4发送消息的方式"></a>2.4发送消息的方式</h3><pre class="language-none"><code class="language-none">!    发送异步消息，没有返回值。!?    发送同步消息，等待返回值。!!    发送异步消息，返回值是 Future[Any]。</code></pre><h2 id="3-Actor实战"><a href="#3-Actor实战" class="headerlink" title="3 Actor实战"></a>3 Actor实战</h2><h3 id="3-1第一个例子"><a href="#3-1第一个例子" class="headerlink" title="3.1第一个例子"></a>3.1第一个例子</h3><pre class="language-none"><code class="language-none">package cn.itcast.actor//注意导包是scala.actors.Actorimport scala.actors.Actorobject MyActor1 extends Actor{  //重新act方法  def act(){    for(i &lt;- 1 to 10){      println("actor-1 " + i)      Thread.sleep(2000)    }  }}object MyActor2 extends Actor{  //重新act方法  def act(){    for(i &lt;- 1 to 10){      println("actor-2 " + i)      Thread.sleep(2000)    }  }}object ActorTest extends App{  //启动Actor  MyActor1.start()  MyActor2.start()}</code></pre><p>说明：上面分别调用了两个单例对象的start()方法，他们的act()方法会被执行，相同与在java中开启了两个线程，线程的run()方法会被执行<br>注意：这两个Actor是并行执行的，act()方法中的for循环执行完成后actor程序就退出</p><h3 id="3-2第二个例子（可以不断地接收消息）"><a href="#3-2第二个例子（可以不断地接收消息）" class="headerlink" title="3.2第二个例子（可以不断地接收消息）"></a>3.2第二个例子（可以不断地接收消息）</h3><pre class="language-none"><code class="language-none">package cn.itcast.actorimport scala.actors.Actor/**  * Created by ZX on 2016/4/4.  */class MyActor extends Actor {  override def act(): Unit = {    while (true) {      receive {        case "start" =&gt; {          println("starting ...")          Thread.sleep(5000)          println("started")        }        case "stop" =&gt; {          println("stopping ...")          Thread.sleep(5000)          println("stopped ...")        }      }    }  }}object MyActor {  def main(args: Array[String]) {    val actor = new MyActor    actor.start()    actor ! "start"    actor ! "stop"    println("消息发送完成！")  }}</code></pre><p>说明：在act()方法中加入了while (true) 循环，就可以不停的接收消息<br>注意：发送start消息和stop的消息是异步的，但是Actor接收到消息执行的过程是同步的按顺序执行</p><h3 id="3-3-第三个例子（react方式会复用线程，比receive更高效）"><a href="#3-3-第三个例子（react方式会复用线程，比receive更高效）" class="headerlink" title="3.3 第三个例子（react方式会复用线程，比receive更高效）"></a>3.3 第三个例子（react方式会复用线程，比receive更高效）</h3><pre class="language-none"><code class="language-none">package cn.itcast.actorimport scala.actors.Actor/**  * Created by ZX on 2016/4/4.  */class YourActor extends Actor {  override def act(): Unit = {    loop {      react {        case "start" =&gt; {          println("starting ...")          Thread.sleep(5000)          println("started")        }        case "stop" =&gt; {          println("stopping ...")          Thread.sleep(8000)          println("stopped ...")        }      }    }  }}object YourActor {  def main(args: Array[String]) {    val actor = new YourActor    actor.start()    actor ! "start"    actor ! "stop"    println("消息发送完成！")  }}</code></pre><p>说明：&nbsp;react 如果要反复执行消息处理，react外层要用loop，不能用while</p><h3 id="3-4第四个例子（结合case-class发送消息）"><a href="#3-4第四个例子（结合case-class发送消息）" class="headerlink" title="3.4第四个例子（结合case class发送消息）"></a>3.4第四个例子（结合case class发送消息）</h3><pre class="language-none"><code class="language-none">package cn.itcast.actorpackage cn.itcast.actorimport scala.actors.Actorclass AppleActor extends Actor {  def act(): Unit = {    while (true) {      receive {        case "start" =&gt; println("starting ...")        case SyncMsg(id, msg) =&gt; {          println(id + ",sync " + msg)          Thread.sleep(5000)          sender ! ReplyMsg(3,"finished")        }        case AsyncMsg(id, msg) =&gt; {          println(id + ",async " + msg)          Thread.sleep(5000)        }      }    }  }}object AppleActor {  def main(args: Array[String]) {    val a = new AppleActor    a.start()    //异步消息    a ! AsyncMsg(1, "hello actor")    println("异步消息发送完成")    //同步消息    //val content = a.!?(1000, SyncMsg(2, "hello actor"))    //println(content)    val reply = a !! SyncMsg(2, "hello actor")    println(reply.isSet)    //println("123")    val c = reply.apply()    println(reply.isSet)    println(c)  }}case class SyncMsg(id : Int, msg: String)case class AsyncMsg(id : Int, msg: String)case class ReplyMsg(id : Int, msg: String)</code></pre><h2 id="4练习"><a href="#4练习" class="headerlink" title="4练习"></a>4练习</h2><p>用actor并发编程写一个单机版的WorldCount，将多个文件作为输入，计算完成后将多个任务汇总，得到最终的结果</p><pre class="language-none"><code class="language-none">package cn.itcast.actorimport java.io.Fileimport scala.actors.{Actor, Future}import scala.collection.mutableimport scala.io.Source/**  * Created by ZX on 2016/4/4.  */class Task extends Actor {  override def act(): Unit = {    loop {      react {        case SubmitTask(fileName) =&gt; {          val contents = Source.fromFile(new File(fileName)).mkString          val arr = contents.split("\r\n")          val result = arr.flatMap(_.split(" ")).map((_, 1)).groupBy(_._1).mapValues(_.length)          //val result = arr.flatMap(_.split(" ")).map((_, 1)).groupBy(_._1).mapValues(_.foldLeft(0)(_ + _._2))          sender ! ResultTask(result)        }        case StopTask =&gt; {          exit()        }      }    }  }}object WorkCount {  def main(args: Array[String]) {    val files = Array("c://words.txt", "c://words.log")    val replaySet = new mutable.HashSet[Future[Any]]    val resultList = new mutable.ListBuffer[ResultTask]    for(f &lt;- files) {      val t = new Task      val replay = t.start() !! SubmitTask(f)      replaySet += replay    }    while(replaySet.size &gt; 0){      val toCumpute = replaySet.filter(_.isSet)      for(r &lt;- toCumpute){        val result = r.apply()        resultList += result.asInstanceOf[ResultTask]        replaySet.remove(r)      }      Thread.sleep(100)    }    val finalResult = resultList.map(_.result).flatten.groupBy(_._1).mapValues(x =&gt; x.foldLeft(0)(_ + _._2))    println(finalResult)  }}case class SubmitTask(fileName: String)case object StopTaskcase class ResultTask(result: Map[String, Int])</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> scala </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> scala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scala学习一</title>
      <link href="/2018/08/27/scala-xue-xi-yi/"/>
      <url>/2018/08/27/scala-xue-xi-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="scala基础一"><a href="#scala基础一" class="headerlink" title="scala基础一"></a><center>scala基础一</center></h1><h2 id="1-目标"><a href="#1-目标" class="headerlink" title="1 目标"></a>1 目标</h2><pre class="language-none"><code class="language-none">目标1：（初级）熟练使用scala编写Spark程序目标2：（中级）动手编写一个简易Spark通信框架目标3：（高级）为阅读Spark内核源码做准备</code></pre><h2 id="2-Scala概述"><a href="#2-Scala概述" class="headerlink" title="2 Scala概述"></a>2 Scala概述</h2><h3 id="2-1什么是Scala"><a href="#2-1什么是Scala" class="headerlink" title="2.1什么是Scala"></a>2.1什么是Scala</h3><p>Scala是一种多范式的编程语言，其设计的初衷是要集成面向对象编程和函数式编程的各种特性。Scala运行于Java平台（Java虚拟机），并兼容现有的Java程序。</p><p><img src="/images/20180827/.png"></p><h3 id="2-2"><a href="#2-2" class="headerlink" title="2.2"></a>2.2</h3><pre class="language-none"><code class="language-none">1. 优雅：这是框架设计师第一个要考虑的问题，框架的用户是应用开发程序员，API是否优雅直接影响用户体验。2. 速度快：Scala语言表达能力强，一行代码抵得上Java多行，开发速度快；Scala是静态编译的，所以和JRuby,Groovy比起来速度会快很多。3. &nbsp;能融合到Hadoop生态圈：Hadoop现在是大数据事实标准，Spark并不是要取代Hadoop，而是要完善Hadoop生态。JVM语言大部分可能会想到Java，但Java做出来的API太丑，或者想实现一个优雅的API太费劲。&nbsp;</code></pre><h2 id="3-Scala编译器安装"><a href="#3-Scala编译器安装" class="headerlink" title="3 Scala编译器安装"></a>3 Scala编译器安装</h2><pre class="language-none"><code class="language-none">3.1. 安装JDK因为Scala是运行在JVM平台上的，所以安装Scala之前要安装JDK3.2. 安装Scala3.2.1. Windows安装Scala编译器访问Scala官网http://www.scala-lang.org/下载Scala编译器安装包，目前最新版本是2.12.x，但是目前大多数的框架都是用2.10.x编写开发的，所以这里推荐2.10.x版本，下载scala-2.10.6.msi后点击下一步就可以了3.2.2. Linux安装Scala编译器下载Scala地址http://downloads.typesafe.com/scala/2.10.6/scala-2.10.6.tgz然后解压Scala到指定目录tar -zxvf scala-2.10.6.tgz -C /usr/java配置环境变量，将scala加入到PATH中vi /etc/profileexport JAVA_HOME=/usr/java/jdk1.7.0_45export PATH=$PATH:$JAVA_HOME/bin:/usr/java/scala-2.10.6/bin</code></pre><h2 id="4-Scala基础"><a href="#4-Scala基础" class="headerlink" title="4 Scala基础"></a>4 Scala基础</h2><h3 id="4-1-声明变量"><a href="#4-1-声明变量" class="headerlink" title="4.1 声明变量"></a>4.1 声明变量</h3><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/6.  */object VariableDemo {  def main(args: Array[String]) {    //使用val定义的变量值是不可变的，相当于java里用final修饰的变量    val i = 1    //使用var定义的变量是可变得，在Scala中鼓励使用val    var s = "hello"    //Scala编译器会自动推断变量的类型，必要的时候可以指定类型    //变量名在前，类型在后    val str: String = "itcast"  }}</code></pre><h3 id="4-2-常用类型"><a href="#4-2-常用类型" class="headerlink" title="4.2. 常用类型"></a>4.2. 常用类型</h3><p>Scala和Java一样，有7种数值类型Byte、Char、Short、Int、Long、Float和Double（无包装类型）和一个Boolean类型</p><h3 id="4-3-条件表达式"><a href="#4-3-条件表达式" class="headerlink" title="4.3. 条件表达式"></a>4.3. 条件表达式</h3><p>Scala的的条件表达式比较简洁，例如</p><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/7.  */object ConditionDemo {  def main(args: Array[String]) {    val x = 1    //判断x的值，将结果赋给y    val y = if (x &gt; 0) 1 else -1    //打印y的值    println(y)    //支持混合类型表达式    val z = if (x &gt; 1) 1 else "error"    //打印z的值    println(z)    //如果缺失else，相当于if (x &gt; 2) 1 else ()    val m = if (x &gt; 2) 1    println(m)    //在scala中每个表达式都有值，scala中有个Unit类，写做(),相当于Java中的void    val n = if (x &gt; 2) 1 else ()    println(n)    //if和else if    val k = if (x &lt; 0) 0    else if (x &gt;= 1) 1 else -1    println(k)  }}</code></pre><h3 id="4-4-块表达式"><a href="#4-4-块表达式" class="headerlink" title="4.4 块表达式"></a>4.4 块表达式</h3><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/7.  */object BlockExpressionDemo {  def main(args: Array[String]) {    val x = 0    //在scala中{}中课包含一系列表达式，块中最后一个表达式的值就是块的值    //下面就是一个块表达式    val result = {      if (x &lt; 0){        -1      } else if(x &gt;= 1) {        1      } else {        "error"      }    }    //result的值就是块表达式的结果    println(result)  }}</code></pre><h3 id="4-5-循环"><a href="#4-5-循环" class="headerlink" title="4.5. 循环"></a>4.5. 循环</h3><p>在scala中有for循环和while循环，用for循环比较多<br>for循环语法结构：for (i &lt;- 表达式/数组/集合)</p><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/7.  */object ForDemo {  def main(args: Array[String]) {    //for(i &lt;- 表达式),表达式1 to 10返回一个Range（区间）    //每次循环将区间中的一个值赋给i    for (i &lt;- 1 to 10)      println(i)    //for(i &lt;- 数组)    val arr = Array("a", "b", "c")    for (i &lt;- arr)      println(i)    //高级for循环    //每个生成器都可以带一个条件，注意：if前面没有分号    for(i &lt;- 1 to 3; j &lt;- 1 to 3 if i != j)      print((10 * i + j) + " ")    println()    //for推导式：如果for循环的循环体以yield开始，则该循环会构建出一个集合    //每次迭代生成集合中的一个值    val v = for (i &lt;- 1 to 10) yield i * 10    println(v)  }}</code></pre><h3 id="4-6-调用方法和函数"><a href="#4-6-调用方法和函数" class="headerlink" title="4.6. 调用方法和函数"></a>4.6. 调用方法和函数</h3><p>Scala中的+ - * / %等操作符的作用与Java一样，位操作符 &amp; | ^ &gt;&gt; &lt;&lt;也一样。只是有<br>一点特别的：这些操作符实际上是方法。例如：<br>a + b<br>是如下方法调用的简写：<br>    a. +(b)<br>a 方法 b可以写成 a.方法(b)</p><h3 id="4-7定义方法和函数"><a href="#4-7定义方法和函数" class="headerlink" title="4.7定义方法和函数"></a>4.7定义方法和函数</h3><h4 id="4-7-1定义方法"><a href="#4-7-1定义方法" class="headerlink" title="4.7.1定义方法"></a>4.7.1定义方法</h4><p><img src="/images/20180827/36.png"></p><p><code>方法的返回值类型可以不写，编译器可以自动推断出来，但是对于递归函数，必须指定返回类型</code></p><h4 id="4-7-2定义函数"><a href="#4-7-2定义函数" class="headerlink" title="4.7.2定义函数"></a>4.7.2定义函数</h4><p><img src="/images/20180827/37.png"></p><h4 id="4-7-3方法和函数的区别"><a href="#4-7-3方法和函数的区别" class="headerlink" title="4.7.3方法和函数的区别"></a>4.7.3方法和函数的区别</h4><p>在函数式编程语言中，函数是“头等公民”，它可以像任何其他数据类型一样被传递和操作<br>案例：首先定义一个方法，再定义一个函数，然后将函数传递到方法里面</p><p><img src="/images/20180827/38.png"></p><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/11.  */object MethodAndFunctionDemo {  //定义一个方法  //方法m2参数要求是一个函数，函数的参数必须是两个Int类型  //返回值类型也是Int类型  def m1(f: (Int, Int) =&gt; Int) : Int = {    f(2, 6)  }  //定义一个函数f1，参数是两个Int类型，返回值是一个Int类型  val f1 = (x: Int, y: Int) =&gt; x + y  //再定义一个函数f2  val f2 = (m: Int, n: Int) =&gt; m * n  //main方法  def main(args: Array[String]) {    //调用m1方法，并传入f1函数    val r1 = m1(f1)    println(r1)    //调用m1方法，并传入f2函数    val r2 = m1(f2)    println(r2)  }}</code></pre><h4 id="4-7-4将方法转换成函数（神奇的下划线）"><a href="#4-7-4将方法转换成函数（神奇的下划线）" class="headerlink" title="4.7.4将方法转换成函数（神奇的下划线）"></a>4.7.4将方法转换成函数（神奇的下划线）</h4><p><img src="/images/20180827/39.png"></p><h2 id="5-数组、映射、元组、集合"><a href="#5-数组、映射、元组、集合" class="headerlink" title="5 数组、映射、元组、集合"></a>5 数组、映射、元组、集合</h2><h3 id="5-1数组"><a href="#5-1数组" class="headerlink" title="5.1数组"></a>5.1数组</h3><h4 id="5-1-1定长数组和变长数组"><a href="#5-1-1定长数组和变长数组" class="headerlink" title="5.1.1定长数组和变长数组"></a>5.1.1定长数组和变长数组</h4><pre class="language-none"><code class="language-none">package cn.itcast.scalaimport scala.collection.mutable.ArrayBuffer/**  * Created by ZX on 2015/11/11.  */object ArrayDemo {  def main(args: Array[String]) {    //初始化一个长度为8的定长数组，其所有元素均为0    val arr1 = new Array[Int](8)    //直接打印定长数组，内容为数组的hashcode值    println(arr1)    //将数组转换成数组缓冲，就可以看到原数组中的内容了    //toBuffer会将数组转换长数组缓冲    println(arr1.toBuffer)    //注意：如果new，相当于调用了数组的apply方法，直接为数组赋值    //初始化一个长度为1的定长数组    val arr2 = Array[Int](10)    println(arr2.toBuffer)    //定义一个长度为3的定长数组    val arr3 = Array("hadoop", "storm", "spark")    //使用()来访问元素    println(arr3(2))    //////////////////////////////////////////////////    //变长数组（数组缓冲）    //如果想使用数组缓冲，需要导入import scala.collection.mutable.ArrayBuffer包    val ab = ArrayBuffer[Int]()    //向数组缓冲的尾部追加一个元素    //+=尾部追加元素    ab += 1    //追加多个元素    ab += (2, 3, 4, 5)    //追加一个数组++=    ab ++= Array(6, 7)    //追加一个数组缓冲    ab ++= ArrayBuffer(8,9)    //打印数组缓冲ab    //在数组某个位置插入元素用insert    ab.insert(0, -1, 0)    //删除数组某个位置的元素用remove    ab.remove(8, 2)    println(ab)  }}</code></pre><h4 id="5-1-2遍历数组"><a href="#5-1-2遍历数组" class="headerlink" title="5.1.2遍历数组"></a>5.1.2遍历数组</h4><p>1.增强for循环<br>2.好用的until会生成脚标，0 until 10 包含0不包含10</p><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/12.  */object ForArrayDemo {  def main(args: Array[String]) {    //初始化一个数组    val arr = Array(1,2,3,4,5,6,7,8)    //增强for循环    for(i &lt;- arr)      println(i)    //好用的until会生成一个Range    //reverse是将前面生成的Range反转    for(i &lt;- (0 until arr.length).reverse)      println(arr(i))  }}</code></pre><h4 id="5-1-3-数组转换"><a href="#5-1-3-数组转换" class="headerlink" title="5.1.3. 数组转换"></a>5.1.3. 数组转换</h4><p>yield关键字将原始的数组进行转换会产生一个新的数组，原始的数组不变</p><p><img src="/images/20180827/40.png"></p><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/12.  */object ArrayYieldDemo {  def main(args: Array[String]) {    //定义一个数组    val arr = Array(1, 2, 3, 4, 5, 6, 7, 8, 9)    //将偶数取出乘以10后再生成一个新的数组    val res = for (e &lt;- arr if e % 2 == 0) yield e * 10    println(res.toBuffer)    //更高级的写法,用着更爽    //filter是过滤，接收一个返回值为boolean的函数    //map相当于将数组中的每一个元素取出来，应用传进去的函数    val r = arr.filter(_ % 2 == 0).map(_ * 10)    println(r.toBuffer)  }}</code></pre><h4 id="5-1-4-数组常用算法"><a href="#5-1-4-数组常用算法" class="headerlink" title="5.1.4. 数组常用算法"></a>5.1.4. 数组常用算法</h4><p>在Scala中，数组上的某些方法对数组进行相应的操作非常方便！</p><p><img src="/images/20180827/41.png"></p><h3 id="5-2-映射"><a href="#5-2-映射" class="headerlink" title="5.2. 映射"></a>5.2. 映射</h3><p>在Scala中，把哈希表这种数据结构叫做映射</p><h4 id="5-2-1-构建映射"><a href="#5-2-1-构建映射" class="headerlink" title="5.2.1 构建映射"></a>5.2.1 构建映射</h4><p><img src="/images/20180827/42.png"></p><h4 id="5-2-2获取和修改映射中的值"><a href="#5-2-2获取和修改映射中的值" class="headerlink" title="5.2.2获取和修改映射中的值"></a>5.2.2获取和修改映射中的值</h4><p><img src="/images/20180827/43.png"></p><p><code>好用的getOrElse</code></p><p><img src="/images/20180827/44.png"></p><p><code>注意：在Scala中，有两种Map，一个是immutable包下的Map，该Map中的内容不可变；另一个是mutable包下的Map，该Map中的内容可变</code></p><p><img src="/images/20180827/45.png"></p><p>注意：通常我们在创建一个集合是会用val这个关键字修饰一个变量（相当于java中的final），那么就意味着该变量的引用不可变，该引用中的内容是不是可变，取决于这个引用指向的集合的类型</p><h3 id="5-3-元组"><a href="#5-3-元组" class="headerlink" title="5.3. 元组"></a>5.3. 元组</h3><p>映射是K/V对偶的集合，对偶是元组的最简单形式，元组可以装着多个不同类型的值。</p><h4 id="5-3-1创建元组"><a href="#5-3-1创建元组" class="headerlink" title="5.3.1创建元组"></a>5.3.1创建元组</h4><p><img src="/images/20180827/46.png"></p><h4 id="5-3-2获取元组中的值"><a href="#5-3-2获取元组中的值" class="headerlink" title="5.3.2获取元组中的值"></a>5.3.2获取元组中的值</h4><p><img src="/images/20180827/47.png"></p><h4 id="5-3-3将对偶的集合转换成映射"><a href="#5-3-3将对偶的集合转换成映射" class="headerlink" title="5.3.3将对偶的集合转换成映射"></a>5.3.3将对偶的集合转换成映射</h4><p><img src="/images/20180827/48.png"></p><h4 id="5-3-4拉链操作"><a href="#5-3-4拉链操作" class="headerlink" title="5.3.4拉链操作"></a>5.3.4拉链操作</h4><p><img src="/images/20180827/48.png"></p><p>注意：如果两个数组的元素个数不一致，拉链操作后生成的数组的长度为较小的那个数组的元素个数</p><h3 id="5-4-集合"><a href="#5-4-集合" class="headerlink" title="5.4. 集合"></a>5.4. 集合</h3><p>Scala的集合有三大类：序列Seq、集Set、映射Map，所有的集合都扩展自Iterable特质<br>在Scala中集合有可变（mutable）和不可变（immutable）两种类型，immutable类型的集合初始化后就不能改变了（注意与val修饰的变量进行区别）</p><h4 id="5-4-1-序列"><a href="#5-4-1-序列" class="headerlink" title="5.4.1. 序列"></a>5.4.1. 序列</h4><p>不可变的序列 import scala.collection.immutable._<br>在Scala中列表要么为空（Nil表示空列表）要么是一个head元素加上一个tail列表。</p><p>9 :: List(5, 2)  :: 操作符是将给定的头和尾创建一个新的列表<br>注意：:: 操作符是右结合的，如9 :: 5 :: 2 :: Nil相当于 9 :: (5 :: (2 :: Nil))</p><pre class="language-none"><code class="language-none">package cn.itcast.collectobject ImmutListDemo {  def main(args: Array[String]) {    //创建一个不可变的集合    val lst1 = List(1,2,3)    //将0插入到lst1的前面生成一个新的List    val lst2 = 0 :: lst1    val lst3 = lst1.::(0)    val lst4 = 0 +: lst1    val lst5 = lst1.+:(0)    //将一个元素添加到lst1的后面产生一个新的集合    val lst6 = lst1 :+ 3    val lst0 = List(4,5,6)    //将2个list合并成一个新的List    val lst7 = lst1 ++ lst0    //将lst1插入到lst0前面生成一个新的集合    val lst8 = lst1 ++: lst0    //将lst0插入到lst1前面生成一个新的集合    val lst9 = lst1.:::(lst0)    println(lst9)  }}</code></pre><p><code>可变的序列 import scala.collection.mutable._</code></p><pre class="language-none"><code class="language-none">package cn.itcast.collectimport scala.collection.mutable.ListBufferobject MutListDemo extends App{  //构建一个可变列表，初始有3个元素1,2,3  val lst0 = ListBuffer[Int](1,2,3)  //创建一个空的可变列表  val lst1 = new ListBuffer[Int]  //向lst1中追加元素，注意：没有生成新的集合  lst1 += 4  lst1.append(5)  //将lst1中的元素最近到lst0中， 注意：没有生成新的集合  lst0 ++= lst1  //将lst0和lst1合并成一个新的ListBuffer 注意：生成了一个集合  val lst2= lst0 ++ lst1  //将元素追加到lst0的后面生成一个新的集合  val lst3 = lst0 :+ 5}</code></pre><h3 id="5-5-Set"><a href="#5-5-Set" class="headerlink" title="5.5. Set"></a>5.5. Set</h3><p><code>不可变的Set</code></p><pre class="language-none"><code class="language-none">package cn.itcast.collectimport scala.collection.immutable.HashSetobject ImmutSetDemo extends App{  val set1 = new HashSet[Int]()  //将元素和set1合并生成一个新的set，原有set不变  val set2 = set1 + 4  //set中元素不能重复  val set3 = set1 ++ Set(5, 6, 7)  val set0 = Set(1,3,4) ++ set1  println(set0.getClass)}</code></pre><p><code>可变的Set</code></p><pre class="language-none"><code class="language-none">package cn.itcast.collectimport scala.collection.mutableobject MutSetDemo extends App{  //创建一个可变的HashSet  val set1 = new mutable.HashSet[Int]()  //向HashSet中添加元素  set1 += 2  //add等价于+=  set1.add(4)  set1 ++= Set(1,3,5)  println(set1)  //删除一个元素  set1 -= 5  set1.remove(2)  println(set1)}</code></pre><h3 id="5-6-Map"><a href="#5-6-Map" class="headerlink" title="5.6 Map"></a>5.6 Map</h3><pre class="language-none"><code class="language-none">package cn.itcast.collectimport scala.collection.mutableobject MutMapDemo extends App{  val map1 = new mutable.HashMap[String, Int]()  //向map中添加数据  map1("spark") = 1  map1 += (("hadoop", 2))  map1.put("storm", 3)  println(map1)  //从map中移除元素  map1 -= "spark"  map1.remove("hadoop")  println(map1)}</code></pre><h2 id="6-类、对象、继承、特质"><a href="#6-类、对象、继承、特质" class="headerlink" title="6. 类、对象、继承、特质"></a>6. 类、对象、继承、特质</h2><p>Scala的类与Java、C++的类比起来更简洁，学完之后你会更爱Scala！！！</p><h3 id="6-1-类"><a href="#6-1-类" class="headerlink" title="6.1. 类"></a>6.1. 类</h3><h4 id="6-1-1-类的定义"><a href="#6-1-1-类的定义" class="headerlink" title="6.1.1. 类的定义"></a>6.1.1. 类的定义</h4><pre class="language-none"><code class="language-none">//在Scala中，类并不用声明为public。//Scala源文件中可以包含多个类，所有这些类都具有公有可见性。class Person {  //用val修饰的变量是只读属性，有getter但没有setter  //（相当与Java中用final修饰的变量）  val id = "9527"  //用var修饰的变量既有getter又有setter  var age: Int = 18  //类私有字段,只能在类的内部使用  private var name: String = "唐伯虎"  //对象私有字段,访问权限更加严格的，Person类的方法只能访问到当前对象的字段  private[this] val pet = "小强"}</code></pre><h4 id="6-1-2-构造器"><a href="#6-1-2-构造器" class="headerlink" title="6.1.2. 构造器"></a>6.1.2. 构造器</h4><p>注意：主构造器会执行类定义中的所有语句</p><pre class="language-none"><code class="language-none">/**  *每个类都有主构造器，主构造器的参数直接放置类名后面，与类交织在一起  */class Student(val name: String, val age: Int){  //主构造器会执行类定义中的所有语句  println("执行主构造器")  try {    println("读取文件")    throw new IOException("io exception")  } catch {    case e: NullPointerException =&gt; println("打印异常Exception : " + e)    case e: IOException =&gt; println("打印异常Exception : " + e)  } finally {    println("执行finally部分")  }  private var gender = "male"  //用this关键字定义辅助构造器  def this(name: String, age: Int, gender: String){    //每个辅助构造器必须以主构造器或其他的辅助构造器的调用开始    this(name, age)    println("执行辅助构造器")    this.gender = gender  }}/**  *构造器参数可以不带val或var，如果不带val或var的参数至少被一个方法所使用，  *那么它将会被提升为字段  *///在类名后面加private就变成了私有的class Queen private(val name: String, prop: Array[String], private var age: Int = 18){  println(prop.size)  //prop被下面的方法使用后，prop就变成了不可变得对象私有字段，等同于private[this] val prop  //如果没有被方法使用该参数将不被保存为字段，仅仅是一个可以被主构造器中的代码访问的普通参数  def description = name + " is " + age + " years old with " + prop.toBuffer}object Queen{  def main(args: Array[String]) {    //私有的构造器，只有在其伴生对象中使用    val q = new Queen("hatano", Array("蜡烛", "皮鞭"), 20)    println(q.description())  }}</code></pre><h3 id="6-2-对象"><a href="#6-2-对象" class="headerlink" title="6.2. 对象"></a>6.2. 对象</h3><h4 id="6-2-1-单例对象"><a href="#6-2-1-单例对象" class="headerlink" title="6.2.1. 单例对象"></a>6.2.1. 单例对象</h4><p>在Scala中没有静态方法和静态字段，但是可以使用object这个语法结构来达到同样的目的<br>    1. 存放工具方法和常量<br>    2. 高效共享单个不可变的实例<br>    3. 单例模式</p><pre class="language-none"><code class="language-none">package cn.itcast.scalaimport scala.collection.mutable.ArrayBuffer/**  * Created by ZX on 2015/11/14.  */object SingletonDemo {  def main(args: Array[String]) {    //单例对象，不需要new，用【类名.方法】调用对象中的方法    val session = SessionFactory.getSession()    println(session)  }}object SessionFactory{  //该部分相当于java中的静态块  var counts = 5  val sessions = new ArrayBuffer[Session]()  while(counts &gt; 0){    sessions += new Session    counts -= 1  }  //在object中的方法相当于java中的静态方法  def getSession(): Session ={    sessions.remove(0)  }}class Session{}</code></pre><h4 id="6-2-2-伴生对象"><a href="#6-2-2-伴生对象" class="headerlink" title="6.2.2. 伴生对象"></a>6.2.2. 伴生对象</h4><p>在Scala的类中，与类名相同的对象叫做伴生对象，类和伴生对象之间可以相互访问私有的方法和属性</p><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/14.  */class Dog {  val id = 1  private var name = "itcast"  def printName(): Unit ={    //在Dog类中可以访问伴生对象Dog的私有属性    println(Dog.CONSTANT + name )  }}/**  * 伴生对象  */object Dog {  //伴生对象中的私有属性  private val CONSTANT = "汪汪汪 : "  def main(args: Array[String]) {    val p = new Dog    //访问私有的字段name    p.name = "123"    p.printName()  }}</code></pre><h4 id="6-2-3-apply方法"><a href="#6-2-3-apply方法" class="headerlink" title="6.2.3. apply方法"></a>6.2.3. apply方法</h4><p>通常我们会在类的伴生对象中定义apply方法，当遇到类名(参数1,…参数n)时apply方法会被调用</p><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/14.  */object ApplyDemo {  def main(args: Array[String]) {    //调用了Array伴生对象的apply方法    //def apply(x: Int, xs: Int*): Array[Int]    //arr1中只有一个元素5    val arr1 = Array(5)    println(arr1.toBuffer)    //new了一个长度为5的array，数组里面包含5个null    var arr2 = new Array(5)  }}</code></pre><h4 id="6-2-4-应用程序对象"><a href="#6-2-4-应用程序对象" class="headerlink" title="6.2.4. 应用程序对象"></a>6.2.4. 应用程序对象</h4><p>Scala程序都必须从一个对象的main方法开始，可以通过扩展App特质，不写main方法。</p><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/14.  */object AppObjectDemo extends App{  //不用写main方法  println("I love you Scala")}</code></pre><h3 id="6-3-继承"><a href="#6-3-继承" class="headerlink" title="6.3. 继承"></a>6.3. 继承</h3><h4 id="6-3-1-扩展类"><a href="#6-3-1-扩展类" class="headerlink" title="6.3.1. 扩展类"></a>6.3.1. 扩展类</h4><p>在Scala中扩展类的方式和Java一样都是使用extends关键字</p><h4 id="6-3-2-重写方法"><a href="#6-3-2-重写方法" class="headerlink" title="6.3.2. 重写方法"></a>6.3.2. 重写方法</h4><p>在Scala中重写一个非抽象的方法必须使用override修饰符</p><h4 id="6-3-3类型检查和转换"><a href="#6-3-3类型检查和转换" class="headerlink" title="6.3.3类型检查和转换"></a>6.3.3类型检查和转换</h4><pre class="language-none"><code class="language-none">Scala                       Javaobj.isInstanceOf[C]    obj instanceof Cobj.asInstanceOf[C]    (C)objclassOf[C]                C.class</code></pre><h4 id="6-3-4超类的构造"><a href="#6-3-4超类的构造" class="headerlink" title="6.3.4超类的构造"></a>6.3.4超类的构造</h4><pre class="language-none"><code class="language-none">package cn.itcast.scala/**  * Created by ZX on 2015/11/10.  */object ClazzDemo {  def main(args: Array[String]) {    //val h = new Human    //println(h.fight)  }}trait Flyable{  def fly(): Unit ={    println("I can fly")  }  def fight(): String}abstract class Animal {  def run(): Int  val name: String}class Human extends Animal with Flyable{  val name = "abc"  //打印几次"ABC"?  val t1,t2,(a, b, c) = {    println("ABC")    (1,2,3)  }  println(a)  println(t1._1)  //在Scala中重写一个非抽象方法必须用override修饰  override def fight(): String = {    "fight with 棒子"  }  //在子类中重写超类的抽象方法时，不需要使用override关键字，写了也可以  def run(): Int = {    1  }}</code></pre><h2 id="7-模式匹配和样例类"><a href="#7-模式匹配和样例类" class="headerlink" title="7 模式匹配和样例类"></a>7 模式匹配和样例类</h2><p>Scala有一个十分强大的模式匹配机制，可以应用到很多场合：如switch语句、类型检查等。<br>并且Scala还提供了样例类，对模式匹配进行了优化，可以快速进行匹配</p><h3 id="7-1匹配字符串"><a href="#7-1匹配字符串" class="headerlink" title="7.1匹配字符串"></a>7.1匹配字符串</h3><pre class="language-none"><code class="language-none">package cn.itcast.casesimport scala.util.Randomobject CaseDemo01 extends App{  val arr = Array("YoshizawaAkiho", "YuiHatano", "AoiSola")  val name = arr(Random.nextInt(arr.length))  name match {    case "YoshizawaAkiho" =&gt; println("吉泽老师...")    case "YuiHatano" =&gt; println("波多老师...")    case _ =&gt; println("真不知道你们在说什么...")  }}</code></pre><h3 id="7-2匹配类型"><a href="#7-2匹配类型" class="headerlink" title="7.2匹配类型"></a>7.2匹配类型</h3><pre class="language-none"><code class="language-none">package cn.itcast.casesimport scala.util.Randomobject CaseDemo01 extends App{  //val v = if(x &gt;= 5) 1 else if(x &lt; 2) 2.0 else "hello"  val arr = Array("hello", 1, 2.0, CaseDemo)  val v = arr(Random.nextInt(4))  println(v)  v match {    case x: Int =&gt; println("Int " + x)    case y: Double if(y &gt;= 0) =&gt; println("Double "+ y)    case z: String =&gt; println("String " + z)    case _ =&gt; throw new Exception("not match exception")  }}</code></pre><p>注意：case y: Double if(y &gt;= 0) =&gt; …<br>模式匹配的时候还可以添加守卫条件。如不符合守卫条件，将掉入case _中</p><h3 id="7-3匹配数组、元组"><a href="#7-3匹配数组、元组" class="headerlink" title="7.3匹配数组、元组"></a>7.3匹配数组、元组</h3><pre class="language-none"><code class="language-none">package cn.itcast.casesobject CaseDemo03 extends App{  val arr = Array(1, 3, 5)  arr match {    case Array(1, x, y) =&gt; println(x + " " + y)    case Array(0) =&gt; println("only 0")    case Array(0, _*) =&gt; println("0 ...")    case _ =&gt; println("something else")  }  val lst = List(3, -1)  lst match {    case 0 :: Nil =&gt; println("only 0")    case x :: y :: Nil =&gt; println(s"x: $x y: $y")    case 0 :: tail =&gt; println("0 ...")    case _ =&gt; println("something else")  }  val tup = (2, 3, 7)  tup match {    case (1, x, y) =&gt; println(s"1, $x , $y")    case (_, z, 5) =&gt; println(z)    case  _ =&gt; println("else")  }}</code></pre><p>注意：在Scala中列表要么为空（Nil表示空列表）要么是一个head元素加上一个tail列表。<br>9 :: List(5, 2)  :: 操作符是将给定的头和尾创建一个新的列表<br>注意：:: 操作符是右结合的，如9 :: 5 :: 2 :: Nil相当于 9 :: (5 :: (2 :: Nil))</p><h3 id="7-4-样例类"><a href="#7-4-样例类" class="headerlink" title="7.4. 样例类"></a>7.4. 样例类</h3><p>在Scala中样例类是一中特殊的类，可用于模式匹配。case class是多例的，后面要跟构造参数，case object是单例的</p><pre class="language-none"><code class="language-none">package cn.itcast.casesimport scala.util.Randomcase class SubmitTask(id: String, name: String)case class HeartBeat(time: Long)case object CheckTimeOutTaskobject CaseDemo04 extends App{  val arr = Array(CheckTimeOutTask, HeartBeat(12333), SubmitTask("0001", "task-0001"))  arr(Random.nextInt(arr.length)) match {    case SubmitTask(id, name) =&gt; {      println(s"$id, $name")//前面需要加上s, $id直接取id的值    }    case HeartBeat(time) =&gt; {      println(time)    }    case CheckTimeOutTask =&gt; {      println("check")    }  }}</code></pre><h3 id="7-5-Option类型"><a href="#7-5-Option类型" class="headerlink" title="7.5. Option类型"></a>7.5. Option类型</h3><p>在Scala中Option类型样例类用来表示可能存在或也可能不存在的值(Option的子类有Some和None)。Some包装了某个值，None表示没有值</p><pre class="language-none"><code class="language-none">package cn.itcast.casesobject OptionDemo {  def main(args: Array[String]) {    val map = Map("a" -&gt; 1, "b" -&gt; 2)    val v = map.get("b") match {      case Some(i) =&gt; i      case None =&gt; 0    }    println(v)    //更好的方式    val v1 = map.getOrElse("c", 0)    println(v1)  }}</code></pre><h3 id="7-6-偏函数"><a href="#7-6-偏函数" class="headerlink" title="7.6. 偏函数"></a>7.6. 偏函数</h3><p>被包在花括号内没有match的一组case语句是一个偏函数，它是PartialFunction[A, B]的一个实例，A代表参数类型，B代表返回类型，常用作输入模式匹配</p><pre class="language-none"><code class="language-none">package cn.itcast.casesobject PartialFuncDemo  {  def func1: PartialFunction[String, Int] = {    case "one" =&gt; 1    case "two" =&gt; 2    case _ =&gt; -1  }  def func2(num: String) : Int = num match {    case "one" =&gt; 1    case "two" =&gt; 2    case _ =&gt; -1  }  def main(args: Array[String]) {    println(func1("one"))    println(func2("one"))  }}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> scala </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> scala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mahout学习一</title>
      <link href="/2018/08/27/mahout-xue-xi-yi/"/>
      <url>/2018/08/27/mahout-xue-xi-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="Mahout协同过滤基础一"><a href="#Mahout协同过滤基础一" class="headerlink" title="Mahout协同过滤基础一"></a><center>Mahout协同过滤基础一</center></h1><h2 id="1-Mahout是什么"><a href="#1-Mahout是什么" class="headerlink" title="1.Mahout是什么"></a>1.Mahout是什么</h2><pre class="language-none"><code class="language-none">• Mahout是一个算法库,集成了很多算法。• Apache&nbsp;Mahout&nbsp;是&nbsp;Apache&nbsp;Software&nbsp;Foundation（ASF）旗下的一个开源项目，提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。• Mahout项目目前已经有了多个公共发行版本。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。• 通过使用&nbsp;Apache&nbsp;Hadoop&nbsp;库，Mahout&nbsp;可以有效地扩展到Hadoop集群。• Mahout&nbsp;的创始人&nbsp;Grant&nbsp;Ingersoll&nbsp;介绍了机器学习的基本概念，并演示了如何使用&nbsp;Mahout&nbsp;来实现文档集群、提出建议和组织内容。</code></pre><h2 id="2-Mahout能做什么"><a href="#2-Mahout能做什么" class="headerlink" title="2.Mahout能做什么"></a>2.Mahout能做什么</h2><h3 id="2-1、推荐引擎"><a href="#2-1、推荐引擎" class="headerlink" title="2.1、推荐引擎"></a>2.1、推荐引擎</h3><p>在目前采用的机器学习技术中，推荐引擎是最容易被一眼认出来的，也是应用范围最广的。服务商或网站会根据你过去的行为为你推荐书籍、电影或文章。<br>在部署了推荐系统的电子商务中，亚马逊大概是最有名的。亚马逊基于用户的交易行为和网站记录为你推荐你可能喜欢的商品。</p><p>而facebook这样的社交网络则利用推荐技术为你找到最可能尚未关联的朋友。<br>同时，这一技术也被各大知名国内网站所使用，如腾讯、人人、京东、淘宝。</p><h3 id="2-2、聚类"><a href="#2-2、聚类" class="headerlink" title="2.2、聚类"></a>2.2、聚类</h3><p>顾名思义，物以类聚，人以群分。聚类是把具有共同属性的物品进行归类。<br>Google&nbsp;news使用聚类技术通过标题把新闻文章进行分组，从而按照逻辑线索来显示新闻，而并非给出所有新闻的原始列表。</p><h3 id="2-3、分类"><a href="#2-3、分类" class="headerlink" title="2.3、分类"></a>2.3、分类</h3><p>分类技术决定了一个事物多大程度上从属于某种类别或类型，或者多大程度上具有或者不具有某些属性。与聚类一样，分类无处不在，但更多隐身于幕后。通常这些系统会考察类别中的大量实例，来学习推到出分类的规则。<br>雅虎邮箱基于用户以前对正常右键和垃圾邮件的报告，以及电子右键自身的特征，来判别到来的消息是否是垃圾邮件。</p><h2 id="3、Mahout协同过滤算法"><a href="#3、Mahout协同过滤算法" class="headerlink" title="3、Mahout协同过滤算法"></a>3、Mahout协同过滤算法</h2><p>Mahout使用了Taste来提高协同过滤算法的实现，它是一个基于Java实现的可扩展的，高效的推荐引擎。Taste既实现了最基本的基于用户的和基于内容的推荐算法，同时也提供了扩展接口，使用户可以方便的定义和实现自己的推荐算法。同时，Taste不仅仅只适用于Java应用程序，它可以作为内部服务器的一个组件以HTTP和Web Service的形式向外界提供推荐的逻辑。Taste的设计使它能满足企业对推荐引擎在性能、灵活性和可扩展性等方面的要求。</p><p>Taste主要包括以下几个接口：</p><pre class="language-none"><code class="language-none">• DataModel&nbsp;是用户喜好信息的抽象接口，它的具体实现支持从任意类型的数据源抽取用户喜好信息。Taste 默认提供 JDBCDataModel 和 FileDataModel，分别支持从数据库和文件中读取用户的喜好信息。• UserSimilarity&nbsp;和&nbsp;ItemSimilarity&nbsp;。UserSimilarity 用于定义两个用户间的相似度，它是基于协同过滤的推荐引擎的核心部分，可以用来计算用户的“邻居”，这里我们将与当前用户口味相似的用户称为他的邻居。ItemSimilarity 类似的，计算Item之间的相似度。• UserNeighborhood&nbsp;用于基于用户相似度的推荐方法中，推荐的内容是基于找到与当前用户喜好相似的邻居用户的方式产生的。UserNeighborhood 定义了确定邻居用户的方法，具体实现一般是基于 UserSimilarity 计算得到的。• Recommender&nbsp;是推荐引擎的抽象接口，Taste 中的核心组件。程序中，为它提供一个 DataModel，它可以计算出对不同用户的推荐内容。实际应用中，主要使用它的实现类 GenericUserBasedRecommender 或者 GenericItemBasedRecommender，分别实现基于用户相似度的推荐引擎或者基于内容的推荐引擎。• RecommenderEvaluator&nbsp;：评分器。• RecommenderIRStatsEvaluator&nbsp;：搜集推荐性能相关的指标，包括准确率、召回率等等。</code></pre><h3 id="3-1、DataModel"><a href="#3-1、DataModel" class="headerlink" title="3.1、DataModel"></a>3.1、DataModel</h3><pre class="language-none"><code class="language-none">• org.apache.mahout.cf.taste.impl.model.GenericDataModel• org.apache.mahout.cf.taste.impl.model.GenericBooleanPrefDataModel• org.apache.mahout.cf.taste.impl.model.PlusAnonymousUserDataModel• org.apache.mahout.cf.taste.impl.model.file.FileDataModel• org.apache.mahout.cf.taste.impl.model.hbase.HBaseDataModel• org.apache.mahout.cf.taste.impl.model.cassandra.CassandraDataModel• org.apache.mahout.cf.taste.impl.model.mongodb.MongoDBDataModel• org.apache.mahout.cf.taste.impl.model.jdbc.SQL92JDBCDataModel• org.apache.mahout.cf.taste.impl.model.jdbc.MySQLJDBCDataModel• org.apache.mahout.cf.taste.impl.model.jdbc.PostgreSQLJDBCDataModel• org.apache.mahout.cf.taste.impl.model.jdbc.GenericJDBCDataModel• org.apache.mahout.cf.taste.impl.model.jdbc.SQL92BooleanPrefJDBCDataModel• org.apache.mahout.cf.taste.impl.model.jdbc.MySQLBooleanPrefJDBCDataModel• org.apache.mahout.cf.taste.impl.model.jdbc.PostgreBooleanPrefSQLJDBCDataModel• org.apache.mahout.cf.taste.impl.model.jdbc.ReloadFromJDBCDataModel&nbsp; &nbsp; 从类名上就可以大概猜出来每个DataModel的用途，奇怪的是竟然没有HDFS的DataModel，有人实现了一个，请参考&nbsp;MAHOUT-1579&nbsp;。</code></pre><h3 id="3-2、相似度"><a href="#3-2、相似度" class="headerlink" title="3.2、相似度"></a>3.2、相似度</h3><pre class="language-none"><code class="language-none">UserSimilarity&nbsp;和&nbsp;ItemSimilarity&nbsp;相似度实现有以下几种：    • CityBlockSimilarity&nbsp;：基于Manhattan距离相似度    • EuclideanDistanceSimilarity&nbsp;：基于欧几里德距离计算相似度    • LogLikelihoodSimilarity&nbsp;：基于对数似然比的相似度    • PearsonCorrelationSimilarity&nbsp;：基于皮尔逊相关系数计算相似度    • SpearmanCorrelationSimilarity&nbsp;：基于皮尔斯曼相关系数相似度    • TanimotoCoefficientSimilarity&nbsp;：基于谷本系数计算相似度    • UncenteredCosineSimilarity&nbsp;：计算 Cosine 相似度</code></pre><h3 id="3-3、最近邻域"><a href="#3-3、最近邻域" class="headerlink" title="3.3、最近邻域"></a>3.3、最近邻域</h3><pre class="language-none"><code class="language-none">UserNeighborhood 主要实现有两种：    • NearestNUserNeighborhood：对每个用户取固定数量N个最近邻居    • ThresholdUserNeighborhood：对每个用户基于一定的限制，取落在相似度限制以内的所有用户为邻居    </code></pre><h3 id="3-4、推荐引擎"><a href="#3-4、推荐引擎" class="headerlink" title="3.4、推荐引擎"></a>3.4、推荐引擎</h3><pre class="language-none"><code class="language-none">Recommender分为以下几种实现：    • GenericUserBasedRecommender：基于用户的推荐引擎    • GenericBooleanPrefUserBasedRecommender：基于用户的无偏好值推荐引擎    • GenericItemBasedRecommender：基于物品的推荐引擎    • GenericBooleanPrefItemBasedRecommender：基于物品的无偏好值推荐引擎    </code></pre><h3 id="3-5、推荐系统评测"><a href="#3-5、推荐系统评测" class="headerlink" title="3.5、推荐系统评测"></a>3.5、推荐系统评测</h3><pre class="language-none"><code class="language-none">RecommenderEvaluator有以下几种实现：    • AverageAbsoluteDifferenceRecommenderEvaluator&nbsp;：计算平均差值    • RMSRecommenderEvaluator&nbsp;：计算均方根差    </code></pre><h2 id="4-Mahout协同过滤算法编程"><a href="#4-Mahout协同过滤算法编程" class="headerlink" title="4.Mahout协同过滤算法编程"></a>4.Mahout协同过滤算法编程</h2><h3 id="4-1-创建Maven项目：详见《创建一个Maven项目》"><a href="#4-1-创建Maven项目：详见《创建一个Maven项目》" class="headerlink" title="4.1  创建Maven项目：详见《创建一个Maven项目》"></a>4.1  创建Maven项目：详见《创建一个Maven项目》</h3><h3 id="4-2导入Mahout依赖"><a href="#4-2导入Mahout依赖" class="headerlink" title="4.2导入Mahout依赖"></a>4.2导入Mahout依赖</h3><p><img src="/images/20180827/25.png">    </p><h3 id="4-3、下载电影评分数据"><a href="#4-3、下载电影评分数据" class="headerlink" title="4.3、下载电影评分数据"></a>4.3、下载电影评分数据</h3><p>下载地址：<a href="http://grouplens.org/datasets/movielens/">http://grouplens.org/datasets/movielens/</a><br>数据类别：7.2万用户对1万部电影的百万级评价和10万个标签数据</p><p><img src="/images/20180827/26.png">   </p><p><code>本例数据：本例中只需要使用评分数据</code></p><p><img src="/images/20180827/27.png">   </p><h3 id="4-4、编写基于用户的推荐"><a href="#4-4、编写基于用户的推荐" class="headerlink" title="4.4、编写基于用户的推荐"></a>4.4、编写基于用户的推荐</h3><p><img src="/images/20180827/28.png">  </p><p><img src="/images/20180827/29.png">  </p><h3 id="4-5编写基于物品的推荐"><a href="#4-5编写基于物品的推荐" class="headerlink" title="4.5编写基于物品的推荐"></a>4.5编写基于物品的推荐</h3><p><img src="/images/20180827/30.png">  </p><p><img src="/images/20180827/31.png">  </p><h3 id="4-6评估推荐模型"><a href="#4-6评估推荐模型" class="headerlink" title="4.6评估推荐模型&nbsp;"></a>4.6评估推荐模型&nbsp;</h3><p><img src="/images/20180827/32.png">  </p><h3 id="4-7、获取推荐的查准率和查全率"><a href="#4-7、获取推荐的查准率和查全率" class="headerlink" title="4.7、获取推荐的查准率和查全率"></a>4.7、获取推荐的查准率和查全率</h3><p><img src="/images/20180827/33.png">  </p><p><img src="/images/20180827/34.png">  </p><h2 id="4-Mahout运行在Hadoop集群"><a href="#4-Mahout运行在Hadoop集群" class="headerlink" title="4.Mahout运行在Hadoop集群"></a>4.Mahout运行在Hadoop集群</h2><h3 id="4-1、Hadoop-执行脚本"><a href="#4-1、Hadoop-执行脚本" class="headerlink" title="4.1、Hadoop 执行脚本"></a>4.1、Hadoop 执行脚本</h3><p>hadoop jar mahout-examples-0.9-job.jar org.apache.mahout.cf.taste.hadoop.item.RecommenderJob –input /sanbox/movie/10M.txt –output /sanbox/movie/r -s SIMILARITY_LOGLIKELIHOOD</p><p>参数说明</p><pre><code>    • --input(path)&nbsp;: 存储用户偏好数据的目录，该目录下可以包含一个或多个存储用户偏好数据的文本文件；    • --output(path)&nbsp;: 结算结果的输出目录    • --numRecommendations (integer)&nbsp;: 为每个用户推荐的item数量，默认为10    • --usersFile (path)&nbsp;: 指定一个包含了一个或多个存储userID的文件路径，仅为该路径下所有文件包含的userID做推荐计算 (该选项可选)    • --itemsFile (path)&nbsp;: 指定一个包含了一个或多个存储itemID的文件路径，仅为该路径下所有文件包含的itemID做推荐计算 (该选项可选)    • --filterFile (path)&nbsp;: 指定一个路径，该路径下的文件包含了[userID,itemID]&nbsp;值对，userID和itemID用逗号分隔。计算结果将不会为user推荐&nbsp;[userID,itemID]&nbsp;值对中包含的item (该选项可选)    • --booleanData (boolean)&nbsp;: 如果输入数据不包含偏好数值，则将该参数设置为true，默认为false    • --maxPrefsPerUser (integer)&nbsp;: 在最后计算推荐结果的阶段，针对每一个user使用的偏好数据的最大数量，默认为10    • --minPrefsPerUser (integer)&nbsp;: 在相似度计算中，忽略所有偏好数据量少于该值的用户，默认为1    • --maxSimilaritiesPerItem (integer)&nbsp;: 针对每个item的相似度最大值，默认为100    • --maxPrefsPerUserInItemSimilarity (integer)&nbsp;: 在item相似度计算阶段，针对每个用户考虑的偏好数据最大数量，默认为1000    • --similarityClassname (classname)&nbsp;: 向量相似度计算类    • outputPathForSimilarityMatrix&nbsp;：SimilarityMatrix输出目录    • --randomSeed&nbsp;：随机种子 --&nbsp;sequencefileOutput&nbsp;：序列文件输出路径    • --tempDir (path)&nbsp;: 存储临时文件的目录，默认为当前用户的home目录下的temp目录    • --threshold (double)&nbsp;: 忽略相似度低于该阀值的item对</code></pre><h3 id="4-2、-执行结果"><a href="#4-2、-执行结果" class="headerlink" title="4.2、 执行结果"></a>4.2、 执行结果</h3><p>上面命令运行完成之后，会在当前用户的hdfs主目录生成temp目录，该目录可由&nbsp;–tempDir (path)&nbsp;参数设置</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> mahout </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> mahout </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用户画像基础一</title>
      <link href="/2018/08/27/yong-hu-hua-xiang-ji-chu-yi/"/>
      <url>/2018/08/27/yong-hu-hua-xiang-ji-chu-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="用户画像基础一"><a href="#用户画像基础一" class="headerlink" title="用户画像基础一"></a><center>用户画像基础一</center></h1><h2 id="1、用户画像是什么"><a href="#1、用户画像是什么" class="headerlink" title="1、用户画像是什么"></a>1、用户画像是什么</h2><p>用户画像（User Profile），作为大数据的根基，它完美地抽象出一个用户的信息全貌，为进一步精准、快速地分析用户行为习惯、消费习惯等重要信息，提供了足够的数据基础，奠定了大数据时代的基石。</p><p>男，31岁，已婚，收入1万以上，爱美食，团购达人，喜欢红酒配香烟。这样一串描述即为用户画像的典型案例。如果用一句话来描述，即：用户信息标签化。</p><p><img src="/images/20180827/22.png"></p><p>用户画像，即用户信息标签化，就是企业通过收集与分析消费者社会属性、生活习惯、消费行为等主要信息的数据之后，完美地抽象出一个用户的商业全貌作是企业应用大数据技术的基本方式。用户画像为企业提供了足够的信息基础，能够帮助企业快速找到精准用户群体以及用户需求等更为广泛的反馈信息。</p><p>用户画像有很多的的标签组成，每个标签都规定了观察、认识、描述用户的角度。标签根据企业业务的发展情况，或多或少，对外而言都是一个整体，这个整体称之为用户画像。</p><h2 id="2、为什么需要用户画像"><a href="#2、为什么需要用户画像" class="headerlink" title="2、为什么需要用户画像"></a>2、为什么需要用户画像</h2><p>用户画像的核心工作是为用户打标签，打标签的重要目的之一是为了让人能够理解并且方便计算机处理，如，可以做分类统计：喜欢红酒的用户有多少？喜欢红酒的人群中，男、女比例是多少？</p><p>也可以做数据挖掘工作：利用关联规则计算，喜欢红酒的人通常喜欢什么运动品牌？利用聚类算法分析，喜欢红酒的人年龄段分布情况？</p><p>大数据处理，离不开计算机的运算，标签提供了一种便捷的方式，使得计算机能够程序化处理与人相关的信息，甚至通过算法、模型能够“理解” 人。当计算机具备这样的能力后，无论是搜索引擎、推荐引擎、广告投放等各种应用领域，都将能进一步提升精准度，提高信息获取的效率。</p><p><img src="/images/20180827/23.png"></p><p>用户画像本质就是从业务角度出发对用户进行分析，了解用户需求，寻找目标客户。另外一个方面就是，金融企业利用统计的信息，开发出适合目标客户的产品。</p><p>提到用户画像，很多厂商都会提到360度用户画像，其实经常360度客户画像是一个广告宣传用语，根本不存数据可以全面描述客户，透彻了解客户。人是非常复杂的动物，信息纬度非常复杂，仅仅依靠外部信息来刻画客户内心需要根本不可能。</p><p>用户画像一词具有很重的场景因素，不同企业对于用户画像有着不同对理解和需求。举个例子，金融行业和汽车行业对于用户画像需求的信息完全不一样，信息纬度也不同，对画像结果要求也不同。每个行业都有一套适合自己行业的用户画像方法，但是其核心都是为客户服务，为业务场景服务。</p><h2 id="3、用户画像怎么设计"><a href="#3、用户画像怎么设计" class="headerlink" title="3、用户画像怎么设计"></a>3、用户画像怎么设计</h2><p>一个标签通常是人为规定的高度精炼的特征标识。</p><p>如年龄段标签：25~35岁，地域标签：北京，标签呈现出两个重要特征：语义化，人能很方便地理解每个标签含义。这也使得用户画像模型具备实际意义。能够较好的满足业务需求。</p><p>如，判断用户偏好。短文本，每个标签通常只表示一种含义，标签本身无需再做过多文本分析等预处理工作，这为利用机器提取标准化信息提供了便利。</p><p>人制定标签规则，并能够通过标签快速读出其中的信息，机器方便做标签提取、聚合分析。所以，用户画像，即：用户标签，向我们展示了一种朴素、简洁的方法用于描述用户信息。</p><h3 id="3-1-数据源分析"><a href="#3-1-数据源分析" class="headerlink" title="3.1 数据源分析"></a>3.1 数据源分析</h3><p>构建用户画像是为了还原用户信息，因此数据来源于：所有用户相关的数据。</p><p>对于用户相关数据的分类，引入一种重要的分类思想：封闭性的分类方式。如，世界上分为两种人，一种是学英语的人，一种是不学英语的人；客户分三类，高价值客户，中价值客户，低价值客户；产品生命周期分为，投入期、成长期、成熟期、衰退期…所有的子分类将构成了类目空间的全部集合。</p><p>这样的分类方式，有助于后续不断枚举并迭代补充遗漏的信息维度。不必担心架构上对每一层分类没有考虑完整，造成维度遗漏留下扩展性隐患。另外，不同的分类方式根据应用场景，业务需求的不同，也许各有道理，按需划分即可。</p><p>本文将用户数据划分为静态信息数据、动态信息数据两大类。</p><h4 id="3-1-1、静态信息数据"><a href="#3-1-1、静态信息数据" class="headerlink" title="3.1.1、静态信息数据"></a>3.1.1、静态信息数据</h4><p>用户相对稳定的信息，如图所示，主要包括人口属性、商业属性等方面数据。这类信息，自成标签，如果企业有真实信息则无需过多建模预测，更多的是数据清洗工作，因此这方面信息的数据建模不是本篇文章重点。</p><h4 id="3-1-2、动态信息数据"><a href="#3-1-2、动态信息数据" class="headerlink" title="3.1.2、动态信息数据"></a>3.1.2、动态信息数据</h4><p>用户不断变化的行为信息，如果存在上帝，每一个人的行为都在时刻被上帝那双无形的眼睛监控着，广义上讲，一个用户打开网页，买了一个杯子；与该用户傍晚溜了趟狗，白天取了一次钱，打了一个哈欠等等一样都是上帝眼中的用户行为。当行为集中到互联网，乃至电商，用户行为就会聚焦很多，如上图所示：浏览凡客首页、浏览休闲鞋单品页、搜索帆布鞋、发表关于鞋品质的微博、赞“双十一大促给力”的微博消息。等等均可看作互联网用户行为。</p><p>本篇文章以互联网电商用户，为主要分析对象，暂不考虑线下用户行为数据（分析方法雷同，只是数据获取途径，用户识别方式有些差异）。</p><p>在互联网上，用户行为，可以看作用户动态信息的唯一数据来源。如何对用户行为数据构建数据模型，分析出用户标签，将是本文着重介绍的内容。</p><h3 id="3-2-目标分析"><a href="#3-2-目标分析" class="headerlink" title="3.2 目标分析"></a>3.2 目标分析</h3><p>用户画像的目标是通过分析用户行为，最终为每个用户打上标签，以及该标签的权重。<br>如，红酒 0.8、李宁 0.6。<br>标签，表征了内容，用户对该内容有兴趣、偏好、需求等等。<br>权重，表征了指数，用户的兴趣、偏好指数，也可能表征用户的需求度，可以简单的理解为可信度，概率。</p><h3 id="3-3-数据建模方法"><a href="#3-3-数据建模方法" class="headerlink" title="3.3 数据建模方法"></a>3.3 数据建模方法</h3><p>下面内容将详细介绍，如何根据用户行为，构建模型产出标签、权重。一个事件模型包括：时间、地点、人物三个要素。每一次用户行为本质上是一次随机事件，可以详细描述为：什么用户，在什么时间，什么地点，做了什么事</p><h4 id="3-3-1、什么用户"><a href="#3-3-1、什么用户" class="headerlink" title="3.3.1、什么用户"></a>3.3.1、什么用户</h4><p>关键在于对用户的标识，用户标识的目的是为了区分用户、单点定位。</p><p>以上列举了互联网主要的用户标识方法，获取方式由易到难。视企业的用户粘性，可以获取的标识信息有所差异。</p><h4 id="3-3-2、什么时间"><a href="#3-3-2、什么时间" class="headerlink" title="3.3.2、什么时间"></a>3.3.2、什么时间</h4><p>时间包括两个重要信息，时间戳+时间长度。时间戳，为了标识用户行为的时间点，如，1395121950（精度到秒），1395121950.083612（精度到微秒），通常采用精度到秒的时间戳即可。因为微秒的时间戳精度并不可靠。浏览器时间精度，准确度最多也只能到毫秒。时间长度，为了标识用户在某一页面的停留时间。</p><h4 id="3-3-3、什么地点"><a href="#3-3-3、什么地点" class="headerlink" title="3.3.3、什么地点"></a>3.3.3、什么地点</h4><p>用户接触点，Touch Point。对于每个用户接触点。潜在包含了两层信息：网址 + 内容。网址：每一个url链接（页面/屏幕），即定位了一个互联网页面地址，或者某个产品的特定页面。可以是PC上某电商网站的页面url，也可以是手机上的微博，微信等应用某个功能页面，某款产品应用的特定画面。如，长城红酒单品页，微信订阅号页面，某游戏的过关页。</p><h4 id="3-3-4、什么内容"><a href="#3-3-4、什么内容" class="headerlink" title="3.3.4、什么内容"></a>3.3.4、什么内容</h4><p>每个url网址（页面/屏幕）中的内容。可以是单品的相关信息：类别、品牌、描述、属性、网站信息等等。如，红酒，长城，干红，对于每个互联网接触点，其中网址决定了权重；内容决定了标签。</p><p>注：接触点可以是网址，也可以是某个产品的特定功能界面。如，同样一瓶矿泉水，超市卖1元，火车上卖3元，景区卖5元。商品的售卖价值，不在于成本，更在于售卖地点。标签均是矿泉水，但接触点的不同体现出了权重差异。这里的权重可以理解为用户对于矿泉水的需求程度不同。即，愿意支付的价值不同。</p><p>标签 权重<br>矿泉水 1 // 超市<br>矿泉水 3 // 火车<br>矿泉水 5 // 景区    </p><p>案例：你是我的优乐美，优乐美用户 促销</p><p>类似的，用户在京东商城浏览红酒信息，与在品尚红酒网浏览红酒信息，表现出对红酒喜好度也是有差异的。这里的关注点是不同的网址，存在权重差异，权重模型的构建，需要根据各自的业务需求构建。</p><p>所以，网址本身表征了用户的标签偏好权重。网址对应的内容体现了标签信息。</p><h4 id="3-3-5、什么事"><a href="#3-3-5、什么事" class="headerlink" title="3.3.5、什么事"></a>3.3.5、什么事</h4><p>用户行为类型，对于电商有如下典型行为：浏览、添加购物车、搜索、评论、购买、点击赞、收藏 等等。</p><p>不同的行为类型，对于接触点的内容产生的标签信息，具有不同的权重。如，购买权重计为5，浏览计为1<br>红酒 1 // 浏览红酒<br>红酒 5 // 购买红酒</p><p>综合上述分析，用户画像的数据模型，可以概括为下面的公式：用户标识 + 时间 + 行为类型 + 接触点（网址+内容），某用户因为在什么时间、地点、做了什么事。所以会打上**标签。</p><p>用户标签的权重可能随时间的增加而衰减，因此定义时间为衰减因子r，行为类型、网址决定了权重，内容决定了标签，进一步转换为公式：<br>标签权重=衰减因子×行为权重×网址子权重</p><p>如：用户A，昨天在品尚红酒网浏览一瓶价值238元的长城干红葡萄酒信息。<br>标签：红酒，长城<br>时间：因为是昨天的行为，假设衰减因子为：r=0.95<br>行为类型：浏览行为记为权重1<br>地点：品尚红酒单品页的网址子权重记为 0.9（相比京东红酒单品页的0.7）</p><p>假设用户对红酒出于真的喜欢，才会去专业的红酒网选购，而不再综合商城选购。</p><p>则用户偏好标签是：红酒，权重是0.95*0.7 * 1=0.665，即，用户Ａ：红酒 0.665、长城 0.665。</p><p>上述模型权重值的选取只是举例参考，具体的权重值需要根据业务需求二次建模，这里强调的是如何从整体思考，去构建用户画像模型，进而能够逐步细化模型。</p><h2 id="4、用户画像怎么开发"><a href="#4、用户画像怎么开发" class="headerlink" title="4、用户画像怎么开发"></a>4、用户画像怎么开发</h2><p><img src="/images/20180827/24.png"></p><p><code>人口属性、资产特征、营销特性、兴趣爱好、购物爱好、需求特征</code></p><h2 id="5、用户画像工作坚持的原则-金融企业"><a href="#5、用户画像工作坚持的原则-金融企业" class="headerlink" title="5、用户画像工作坚持的原则(金融企业)"></a>5、用户画像工作坚持的原则(金融企业)</h2><p>市场上用户画像的方法很多，许多企业也提供用户画像服务，将用户画像提升到很有逼格一件事。金融企业是最早开始用户画像的行业，由于拥有丰富的数据，金融企业在进行用户画像时，对众多纬度的数据无从下手，总是认为用户画像数据纬度越多越好，画像数据越丰富越好，某些输入的数据还设定了权重甚至建立了模型，搞的用户画像是一个巨大而复杂的工程。但是费力很大力气进行了画像之后，却发现只剩下了用户画像，和业务相聚甚远，没有办法直接支持业务运营，投入精力巨大但是回报微小，可以说是得不偿失，无法向领导交代。</p><p>事实上，用户画像涉及数据的纬度需要业务场景结合，既要简单干练又要和业务强相关，既要筛选便捷又要方便进一步操作。用户画像需要坚持三个原则，分别是人口属性和信用信息为主，强相关信息为主，定性数据为主。下面就分别展开进行解释和分析。</p><h3 id="5-1、信用信息和人口属性为主"><a href="#5-1、信用信息和人口属性为主" class="headerlink" title="5.1、信用信息和人口属性为主"></a>5.1、信用信息和人口属性为主</h3><p>描述一个用户的信息很多，信用信息是用户画像中重要的信息，信用信息是描述一个人在社会中的消费能力信息。任何企业进行用户画像的目的是寻找目标客户，其必须是具有潜在消费能力的用户。信用信息可以直接证明客户的消费能力，是用户画像中最重要和基础的信息。一句戏言，所有的信息都是信用信息就是这个道理。其包含消费者工作、收入、学历、财产等信息。</p><p>定位完目标客户之后，金融企业需要触达客户，人口属性信息就是起到触达客户的作用，人口属性信息包含姓名、性别，电话号码，邮件地址，家庭住址等信息。这些信息可以帮助金融企业联系客户，将产品和服务推销给客户。</p><h3 id="5-2、采用强相关信息，忽略弱相关信息"><a href="#5-2、采用强相关信息，忽略弱相关信息" class="headerlink" title="5.2、采用强相关信息，忽略弱相关信息"></a>5.2、采用强相关信息，忽略弱相关信息</h3><p>我们需要介绍一下强相关信息和弱相关信息。强相关信息就是同场景需求直接相关的信息，其可以是因果信息，也可以是相关程度很高的信息。</p><p>如果定义采用0到1作为相关系数取值范围的化，0.6以上的相关系数就应该定义为强相关信息。例如在其他条件相同的前提下，35岁左右人的平均工资高于平均年龄为30岁的人，计算机专业毕业的学生平均工资高于哲学专业学生，从事金融行业工作的平均工资高于从事纺织行业的平均工资，上海的平均工资超过海南省平均工资。从这些信息可以看出来人的年龄、学历、职业、地点对收入的影响较大，同收入高低是强相关关系。简单的将，对信用信息影响较大的信息就是强相关信息，反之则是弱相关信息。</p><p>用户其他的信息，例如用户的身高、体重、姓名、星座等信息，很难从概率上分析出其对消费能力的影响，这些弱相关信息，这些信息就不应该放到用户画像中进行分析，对用户的信用消费能力影响很小，不具有较大的商业价值。</p><p>用户画像和用户分析时，需要考虑强相关信息，不要考虑弱相关信息，这是用户画像的一个原则。</p><h3 id="5-3将定量的信息归类为定性的信息"><a href="#5-3将定量的信息归类为定性的信息" class="headerlink" title="5.3将定量的信息归类为定性的信息"></a>5.3将定量的信息归类为定性的信息</h3><p>用户画像的目的是为产品筛选出目标客户，定量的信息不利于对客户进行筛选，需要将定量信息转化为定性信息，通过信息类别来筛选人群。</p><p>例如可以将年龄段对客户进行划分，18岁-25岁定义为年轻人，25岁-35岁定义为中青年，36-45定义为中年人等。可以参考个人收入信息，将人群定义为高收入人群，中等收入人群，低收入人群。参考资产信息也可以将客户定义为高、中、低级别。定性信息的类别和方式方法，金融可以从自身业务出发，没有固定的模式。</p><p>将金融企业各类定量信息，集中在一起，对定性信息进行分类，并进行定性化，有利与对用户进行筛选，快速定位目标客户，是用户画像的另外一个原则。</p><h3 id="5-4、用户画像的方法介绍，不要太复杂"><a href="#5-4、用户画像的方法介绍，不要太复杂" class="headerlink" title="5.4、用户画像的方法介绍，不要太复杂"></a>5.4、用户画像的方法介绍，不要太复杂</h3><p>金融企业需要结合业务需求进行用户画像，从实用角度出发，我们可以将用户画像信息分成五类信息。分别是人口属性，信用属性，消费特征，兴趣爱好，社交属性。它们基本覆盖了业务需求所需要的强相关信息，结合外部场景数据将会产生巨大的商业价值。我们先了解下用户画像的五大类信息的作用，以及涉及的强相关信息。特别复杂的用户画像纬度例如八个纬度，十个纬度信息都不利于商业应用，不建议金融企业进行采用，其他具有价值的信息，基本上都可以归纳到这五个纬度。金融企业达到其商业需求，从这五个纬度信息进行应用就可以了，不需要过于复杂用户画像这个工作，同时商业意义也不太大。</p><h4 id="5-4-1、人口属性"><a href="#5-4-1、人口属性" class="headerlink" title="5.4.1、人口属性"></a>5.4.1、人口属性</h4><p>用于描述一个人基本特征的信息，主要作用是帮助金融企业知道客户是谁，如何触达用户。姓名，性别，年龄，电话号码，邮箱，家庭住址都属于人口属性信息。</p><h4 id="5-4-2、信用属性"><a href="#5-4-2、信用属性" class="headerlink" title="5.4.2、信用属性"></a>5.4.2、信用属性</h4><p>用于描述用户收入潜力和收入情况，支付能力。帮助企业了解客户资产情况和信用情况，有利于定位目标客户。客户职业、收入、资产、负债、学历、信用评分等都属于信用信息。</p><h4 id="5-4-3、消费特征"><a href="#5-4-3、消费特征" class="headerlink" title="5.4.3、消费特征"></a>5.4.3、消费特征</h4><p>用于描述客户主要消费习惯和消费偏好，用于寻找高频和高价值客户。帮助企业依据客户消费特点推荐相关金融产品和服务，转化率将非常高。为了便于筛选客户，可以参考客户的消费记录将客户直接定性为某些消费特征人群，例如差旅人群，境外游人群，旅游人群，餐饮用户，汽车用户，母婴用户，理财人群等。</p><h4 id="5-4-4、兴趣爱好"><a href="#5-4-4、兴趣爱好" class="headerlink" title="5.4.4、兴趣爱好"></a>5.4.4、兴趣爱好</h4><p>用于描述客户具有哪方面的兴趣爱好，在这些兴趣方面可能消费偏好比较高。帮助企业了解客户兴趣和消费倾向，定向进行活动营销。兴趣爱好的信息可能会和消费特征中部分信息有重复，区别在于数据来源不同。消费特征来源于已有的消费记录，但是购买的物品和服务不一定是自己享用，但是兴趣爱好代表本人的真实兴趣。例如户外运动爱好者，旅游爱好者，电影爱好者，科技发烧友，健身爱好者，奢侈品爱好者等。兴趣爱好的信息可能来源于社交信息和客户位置信息。</p><h4 id="5-5、金融企业用户画像的基本步骤"><a href="#5-5、金融企业用户画像的基本步骤" class="headerlink" title="5.5、金融企业用户画像的基本步骤"></a>5.5、金融企业用户画像的基本步骤</h4><p>参考金融企业的数据类型和业务需求，可以将金融企业用户画像工作进行细化。基本上从数据集中到数据处理，从强相关数据到定性分类数据，从引入外部数据到依据业务场景进行筛选目标用户。</p><h4 id="5-5-1、画像相关数据的整理和集中"><a href="#5-5-1、画像相关数据的整理和集中" class="headerlink" title="5.5.1、画像相关数据的整理和集中"></a>5.5.1、画像相关数据的整理和集中</h4><p>金融企业内部的信息分布在不同的系统中，一般情况下，人口属性信息主要集中在客户关系管理系统，信用信息主要集中在交易系统和产品系统之中，也集中在客户关系管理系统中，消费特征主要集中在渠道和产品系统中。</p><p>兴趣爱好和社交信息需要从外部引入，例如客户的行为轨迹可以代表其兴趣爱好和品牌爱好，移动设备到位置信息可以提供较为准确的兴趣爱好信息。社交信息，可以借助于金融行业自身的文本挖掘能力进行采集和分析，也是可以借助于厂商的技术能力在社交网站上直接获得。社交信息往往是实时信息，商业价值较高，转化率也较高，是大数据预测方面的主要信息来源。例如用户在社交网站上提出罗马哪里好玩的问题，就代表用户未来可能有出国旅游的需求；如果客户在对比两款汽车的优良，客户购买汽车的可能性就较大。金融企业可以及时介入，为客户提供金融服务。</p><p>客户画像数据主要分为五类，人口属性、信用信息、消费特征、兴趣爱好、社交信息。这些数据都分布在不同的信息系统，金融企业都上线了数据仓库（DW），所有画像相关的强相关信息都可以从数据仓库里面整理和集中，并且依据画像商业需求，利用跑批作业，加工数据，生成用户画像的原始数据。</p><p>数据仓库成为用户画像数据的主要处理工具，依据业务场景和画像需求将原始数据进行分类、筛选、归纳、加工等，生成用户画像需要的原始数据。</p><p>用户画像的纬度信息不是越多越好，只需要找到这五大类画像信息强相关信息，同业务场景强相关信息，同产品和目标客户强相关信息即可。根本不存在360度的用户画像信息，也不存在丰富的信息可以完全了解客户，另外数据的实效性也要重点考虑。</p><h4 id="5-5-2、找到同业务场景强相关数据"><a href="#5-5-2、找到同业务场景强相关数据" class="headerlink" title="5.5.2、找到同业务场景强相关数据"></a>5.5.2、找到同业务场景强相关数据</h4><p>依据用户画像的原则，所有画像信息应该是五大分类的强相关信息。强相关信息是指同业务场景强相关信息，可以帮助金融行业定位目标客户，了解客户潜在需求，开发需求产品。</p><p>只有强相关信息才能帮助金融企业有效结合业务需求，创造商业价值。例如姓名、手机号、家庭地址就是能够触达客户的强人口属性信息，收入、学历、职业、资产就是客户信用信息的强相关信息。差旅人群、境外游人群、汽车用户、旅游人群、母婴人群就是消费特征的强相关信息。摄影爱好者、游戏爱好者、健身爱好者、电影人群、户外爱好者就是客户兴趣爱好的强相关信息。社交媒体上发表的旅游需求，旅游攻略，理财咨询，汽车需求，房产需求等信息代表了用户的内心需求，是社交信息场景应用的强相关信息。</p><p>金融企业内部信息较多，在用户画像阶段不需要对所有信息都采用，只需要采用同业务场景和目标客户强相关的信息即可，这样有助于提高产品转化率，降低投资回报率（ROI），有利于简单找到业务应用场景，在数据变现过程中也容易实现。</p><p>千万不要将用户画像工作搞的过于复杂，同业务场景关系不大，这样就让很多金融企业特别是领导失去用户画像的兴趣，看不到用户画像的商业，不愿意在大数据领域投资。为企业带来商业价值才是用户画像工作的主要动力和主要目的。</p><h4 id="5-5-3、对数据进行分类和标签化（定量to定性）"><a href="#5-5-3、对数据进行分类和标签化（定量to定性）" class="headerlink" title="5.5.3、对数据进行分类和标签化（定量to定性）"></a>5.5.3、对数据进行分类和标签化（定量to定性）</h4><p>金融企业集中了所有信息之后，依据业务需求，对信息进行加工整理，需要对定量的信息进行定性，方便信息分类和筛选。这部分工作建议在数据仓库进行，不建议在大数据管理平台（DMP）里进行加工。</p><p>定性信息进行定量分类是用户画像的一个重要工作环节，具有较高的业务场景要求，考验用户画像商业需求的转化。其主要目的是帮助企业将复杂数据简单化，将交易数据定性进行归类，并且融入商业分析的要求，对数据进行商业加工。例如可以将客户按照年龄区间分为学生，青年，中青年，中年，中老年，老年等人生阶段。源于各人生阶段的金融服务需求不同，在寻找目标客户时，可以通过人生阶段进行目标客户定位。企业可以利用客户的收入、学历、资产等情况将客户分为低、中、高端客户，并依据其金融服务需求，提供不同的金融服务。可以参考其金融消费记录和资产信息，以及交易产品，购买的产品，将客户消费特征进行定性描述，区分出电商客户，理财客户，保险客户，稳健投资客户，激进投资客户，餐饮客户，旅游客户，高端客户，公务员客户等。利用外部的数据可以将定性客户的兴趣爱好，例如户外爱好者，奢侈品爱好者，科技产品发烧友，摄影爱好者，高端汽车需求者等信息。</p><p>将定量信息归纳为定性信息，并依据业务需求进行标签化，有助于金融企业找到目标客户，并且了解客户的潜在需求，为金融行业的产品找到目标客户，进行精准营销，降低营销成本，提高产品转化率。另外金融企业还可以依据客户的消费特征、兴趣爱好、社交信息及时为客户推荐产品，设计产品，优化产品流程。提高产品销售的活跃率，帮助金融企业更好地为客户设计产品。</p><h4 id="5-5-4、依据业务需求引入外部数据"><a href="#5-5-4、依据业务需求引入外部数据" class="headerlink" title="5.5.4、依据业务需求引入外部数据"></a>5.5.4、依据业务需求引入外部数据</h4><p>利用数据进行画像目的主要是为业务场景提供数据支持，包括寻找到产品的目标客户和触达客户。金融企业自身的数据不足以了解客户的消费特征、兴趣爱好、社交信息。</p><p>金融企业可以引入外部信息来丰富客户画像信息，例如引入银联和电商的信息来丰富消费特征信息，引入移动大数据的位置信息来丰富客户的兴趣爱好信息，引入外部厂商的数据来丰富社交信息等。</p><p>外部信息的纬度较多，内容也很丰富，但是如何引入外部信息是一项具有挑战的工作。外部信息在引入时需要考虑几个问题，分别是外部数据的覆盖率，如何和内部数据打通，和内部信息的匹配率，以及信息的相关程度，还有数据的鲜活度，这些都是引入外部信息的主要考虑纬度。外部数据鱼龙混杂，数据的合规性也是金融企业在引入外部数据时的一个重要考虑，敏感的信息例如手机号、家庭住址、身份证号在引入或匹配时都应该注意隐私问题，基本的原则是不进行数据交换，可以进行数据匹配和验证。</p><p>外部数据不会集中在某一家，需要金融企业花费大量时间进行寻找。外部数据和内部数据的打通是个很复杂的问题，手机号／设备号／身份证号的MD5数值匹配是一种好的方法，不涉及隐私数据的交换，可以进行唯一匹配。依据行业内部的经验，没有一家企业外部数据可以满足企业要求，外部数据的引入需要多方面数据。一般情况下，数据覆盖率达到70%以上，就是一个非常高的覆盖率。覆盖率达到20%以上就可以进行商业应用了。</p><p>金融行业外部数据源较好合作方有银联、芝麻信用、运营商、中航信、腾云天下、腾讯、微博、前海征信，各大电商平台等。市场上数据提供商已经很多，并且数据质量都不错，需要金融行业一家一家去挖掘，或者委托一个厂商代理引入也可以。独立第三方帮助金融行业引入外部数据可以降低数据交易成本，同时也可以降低数据合规风险，是一个不错的尝试。另外各大城市和区域的大数据交易平台，也是一个较好的外部数据引入方式。</p><h4 id="5-5-5、按照业务需求进行筛选客户（DMP的作用）"><a href="#5-5-5、按照业务需求进行筛选客户（DMP的作用）" class="headerlink" title="5.5.5、按照业务需求进行筛选客户（DMP的作用）"></a>5.5.5、按照业务需求进行筛选客户（DMP的作用）</h4><p>用户画像主要目的是让金融企业挖掘已有的数据价值，利用数据画像技术寻找到目标客户和客户的潜在需求，进行产品推销和设计改良产品。</p><p>用户画像从业务场景出发，实现数据商业变现重要方式。用户画像是数据思维运营过程中的一个重要闭环，帮助金融企业利用数据进行精细化运营和市场营销，以及产品设计。用户画像就是一切以数据商业化运营为中心，以商业场景为主，帮助金融企业深度分析客户，找到目标客户。</p><p>DMP（大数据管理平台）在整个用户画像过程中起到了一个数据变现的作用。从技术角度来讲，DMP将画像数据进行标签化，利用机器学习算法来找到相似人群，同业务场景深度结合，筛选出具有价值的数据和客户，定位目标客户，触达客户，对营销效果进行记录和反馈。大数据管理平台DMP过去主要应用在广告行业，在金融行业应用不多，未来会成为数据商业应用的主要平台。</p><p>DMP可以帮助信用卡公司筛选出未来一个月可能进行分期付款的客户，电子产品重度购买客户，筛选出金融理财客户，筛选出高端客户（在本行资产很少，但是在他行资产很多），筛选出保障险种，寿险，教育险，车险等客户，筛选出稳健投资人，激进投资人，财富管理等方面等客户，并且可以触达这些客户，提高产品转化率，利用数据进行价值变现。DMP还可以了解客户的消费习惯、兴趣爱好、以及近期需求，为客户定制金融产品和服务，进行跨界营销。利用客户的消费偏好，提高产品转化率，提高用户黏度。</p><p>DMP还作为引入外部数据的平台，将外部具有价值的数据引入到金融企业内部，补充用户画像数据，创建不同业务应用场景和商业需求，特别是移动大数据、电商数据、社交数据的应用，可以帮助金融企业来进行数据价值变现，让用户画像离商业应用更加近一些，体现用户画像的商业价值。</p><p>用户画像的关键不是360度分析客户，而是为企业带来商业价值，离开了商业价值谈用户画像就是耍流氓。金融企业用户画像项目出发点一定要从业务需求出发，从强相关数据出发，从业务场景应用出发。用户画像的本质就是深度分析客户，掌握具有价值数据，找到目标客户，按照客户需求来定制产品，利用数据实现价值变现。</p><h2 id="6、银行用户画像实践介绍"><a href="#6、银行用户画像实践介绍" class="headerlink" title="6、银行用户画像实践介绍"></a>6、银行用户画像实践介绍</h2><p>银行具有丰富的交易数据、个人属性数据、消费数据、信用数据和客户数据，用户画像的需求较大。但是缺少社交信息和兴趣爱好信息。</p><p>到银行网点来办业务的人年纪偏大，未来消费者主要在网上进行业务办理。银行接触不到客户，无法了解客户需求，缺少触达客户的手段。分析客户、了解客户、找到目标客户、为客户设计其需要的产品，成了银行进行用户画像的主要目的。银行的主要业务需求集中在消费金融、财富管理、融资服务，用户画像要从这几个角度出发，寻找目标客户。</p><p>银行的客户数据很丰富，数据类型和总量较多，系统也很多。可以严格遵循用户画像的五大步骤。先利用数据仓库进行数据集中，筛选出强相关信息，对定量信息定性化，生成DMP需要的数据。利用DMP进行基础标签和应用定制，结合业务场景需求，进行目标客户筛选或对用户进行深度分析。同时利用DMP引入外部数据，完善数据场景设计，提高目标客户精准度。找到触达客户的方式，对客户进行营销，并对营销效果进行反馈，衡量数据产品的商业价值。利用反馈数据来修正营销活动和提高ROI。形成市场营销的闭环，实现数据商业价值变现的闭环。另外DMP还可以深度分析客户，依据客户的消费特征、兴趣爱好、社交需求、信用信息来开发设计产品，为金融企业的产品开发提供数据支撑，并为产品销售方式提供场景数据。</p><p>简单介绍一些DMP可以做到的数据场景变现。</p><pre class="language-none"><code class="language-none">A 寻找分期客户利用发卡机构数据＋自身数据＋信用卡数据，发现信用卡消费超过其月收入的用户，推荐其进行消费分期。B 寻找高端资产客户利用发卡机构数据＋移动位置数据（别墅／高档小区）＋物业费代扣数据＋银行自身数据＋汽车型号数据，发现在银行资产较少，在其他行资产较多的用户，为其提供高端资产管理服务。ookilllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllC 寻找理财客户利用自身数据（交易＋工资）＋移动端理财客户端／电商活跃数据。发现客户将工资／资产转到外部，但是电商消费不活跃客户，其互联网理财可能性较大，可以为其提供理财服务，将资金留在本行。D 寻找境外游客户利用自身卡消费数据＋移动设备位置信息＋社交好境外强相关数据（攻略，航线，景点，费用），寻找境外游客户为其提供金融服务。E 寻找贷款客户利用自身数据（人口属性＋信用信息）＋移动设备位置信息＋社交购房／消费强相关信息，寻找即将购车／购房的目标客户，为其提供金融服务（抵押贷款／消费贷款）。</code></pre><h2 id="7、保险行业用户画像实践"><a href="#7、保险行业用户画像实践" class="headerlink" title="7、保险行业用户画像实践"></a>7、保险行业用户画像实践</h2><p>保险行业的产品是一个长周期产品，保险客户再次购买保险产品的转化率很高，经营好老客户是保险公司一项重要任务。保险公司内部的交易系统不多，交易方式不是很复杂，数据主要集中在产品系统和交易系统之中，客户关系管理系统中也包含丰富了信息，但是数据集中在很多保险公司还没有完成，数据仓库建设可能需要在用户画像建设前完成。</p><p>保险公司主要数据有人口属性信息，信用信息，产品销售信息，客户家人信息。缺少兴趣爱好、消费特征、社交信息等信息。保险产品主要有寿险，车险，保障，财产险，意外险，养老险，旅游险。</p><p>保险行业DMP用户画像的业务场景都是围绕保险产品进行的，简单的应用场景可以是。<br>A<br>依据自身数据（个人属性）＋外部养车App活跃情况，为保险公司找到车险客户。</p><p>B<br>依据自身数据（个人属性）＋移动设备位置信息，为保险企业找到商旅人群，推销意外险和保障险。</p><p>C<br>依据自身数据（家人数据）＋人生阶段信息，为用户推荐理财保险，寿险，保障保险，养老险，教育险。</p><p>D<br>依据自身数据＋外部数据，为高端人士提供财产险和寿险。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据仓库基础一</title>
      <link href="/2018/08/27/shu-ju-cang-ku-ji-chu-yi/"/>
      <url>/2018/08/27/shu-ju-cang-ku-ji-chu-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="数据仓库基础一"><a href="#数据仓库基础一" class="headerlink" title=" 数据仓库基础一"></a><center> 数据仓库基础一</center></h1><h2 id="1、数据仓库是什么"><a href="#1、数据仓库是什么" class="headerlink" title="1、数据仓库是什么"></a>1、数据仓库是什么</h2><p><code>能干什么？</code></p><p>1、年度销售目标的指定，需要根据以往的历史报表进行决策，不能拍脑袋。</p><p>2、如何优化业务流程</p><pre class="language-none"><code class="language-none">案例1：一个电商网站订单的完成包括：浏览、下单、支付、物流，其中物流环节可能和中通、申通、韵达等快递公司合作。快递公司每派送一个订单，都会有订单派送的确认时间，可以根据订单派送时间来分析哪个快递公司比较快捷高效，从而选择与哪些快递公司合作，剔除哪些快递公司，增加用户友好型。</code></pre><p><img src="/images/20180827/1.png"></p><pre class="language-none"><code class="language-none">案例2：互联网中国需要对APP进行推广，考核的主要目标是下载安装，有些第三方渠道会对这些数据造假，比如某个渠道在凌晨批量下载，点赞操作，操作步骤一致。通过数据分析，分析出应用的名称和安装时间，来判断一个渠道的是否优质、是否作假。</code></pre><h2 id="2、数据仓库的特点"><a href="#2、数据仓库的特点" class="headerlink" title="2、数据仓库的特点"></a>2、数据仓库的特点</h2><pre class="language-none"><code class="language-none">1、数据仓库是面向主题的，比如商品主题，订单主题。（领导关注那些方面）传统数据库面向应用，提供什么功能。数据仓库面向分析，提供那些主题的分析。从规模来讲依次是，数据仓库、数据集市、数据报表。2、数据仓库是集成的，数据源是分散的，来自不同的应用。数据仓库中的综合数据，不能从源数据中直接得到，一般会经过etl过程（数据抽取、数据转换、数据加载）。数据抽取一般会定时的进行抽取，避免对业务系统造成影响，一般叫做T-1抽取、T+1抽取。  目前企业对数据的实时性要求越来越高，比如实时监控一个实时的活动效果，并根据效果进行不同策略的营销手段，保持活动的效果。3、数据仓库是不更新的，数据仓库反应的是一段相当长的时间内的数据内容，主要的操作集中在数据查询上。 一般数据结果计算出来之后，特别是明细数据，会存放在关系数据库中，因为主流的报表工具都支持数据库。对数据库的查询，最基本的操作是创建索引，比如300万的数据根据手机号查询需要十几秒，创建btree索引之后，需要几十毫秒。4、数据仓库中的数据是随着时间而变化的。</code></pre><h2 id="3、数据仓库的发展历程"><a href="#3、数据仓库的发展历程" class="headerlink" title="3、数据仓库的发展历程"></a>3、数据仓库的发展历程</h2><p>第一阶段：简单报表阶段<br>    解决日常工作中业务人员需要的报表，为领导生成简单的汇总数据<br>    大数据库+前段报表的形式</p><p>第二阶段：数据集市阶段<br>    按照不同部门、不同业务人员的需要，进行一定的数据采集，整理，并进行多维度报表的展现，能够提供对特定业务指导。<br>    业务部门对数据的口径不一致，产生的汇总数据不一致。对大领导来看，就需要一个标准的口径。</p><p>第三阶段：数据仓库阶段<br>    对整个企业的数据进行采集，整理，并且能够按照各个业务部门的需要，提供跨部门的，完全一致的业务报表数据，能够通过数据仓库生成对业务具有指导性的数据，同为为领导决策提供全面的数据支持。</p><p>数据仓库和数据集市的区别，在于数据模型的支持。沉默用户的计算，没有沉默字段的标识，需要些复杂的sql，有沉默字段的话，一个简单的sql就能搞定。</p><p>其他：城市商品表</p><h2 id="4、数据库与数据仓库的区别"><a href="#4、数据库与数据仓库的区别" class="headerlink" title="4、数据库与数据仓库的区别"></a>4、数据库与数据仓库的区别</h2><p>1、数据仓库是集成的，数据库为单一的业务提供服务。</p><p>2、BI结构：数据整合层、数据服务层、应用分析层、信息展现层</p><p><img src="/images/20180827/2.png"></p><p>3、数据层库结构<br>ODS(临时存储层)，一般都是贴源设计、业务数据库是什么，ODS层就是什么</p><p>PDW(数据仓库层)，将年月日，拆分成年、月、日字段，一般采用Int类型;通过ODS层到DW层的etl脚本对数据进行数据清洗，进行设计。分部门根据业务需求进行设计。如果没有业务需求，就根据源系统的表结构和自己建模经验去处理。<br>DM(数据集市层)，维度建模，星形模型，雪花模型。需要什么数据就去拉取什么数据。</p><p>APP（应用层），报表展现，需要的数据，与DM层处于同一级别。</p><p><img src="/images/20180827/3.png"></p><p>4、ODS层分为增量更新或者全量更新；PDW层一致的、准确的、干净的数据，一般遵循数据库三范式设计。</p><p>5、为什么数据仓库需要分层？</p><p><img src="/images/20180827/4.png"></p><h2 id="5、数据质量检查"><a href="#5、数据质量检查" class="headerlink" title="5、数据质量检查"></a>5、数据质量检查</h2><p>保证报表数据的正确性、稳定性，通过告警机制尽可能快的发现异常、尽可能快的解决问题。<br>出错的次数太多之后，领导会对你失去信心，该辞职了。</p><p>检查方法：<br>    1、 数据行数据的比较<br>    2、 行数有变化，但是指标有变化。对领导关系的重点指标进行筛选。</p><p><img src="/images/20180827/5.png">    </p><p><img src="/images/20180827/6.png"></p><p><code>在领导发现问题之前，解决问题。</code></p><p><img src="/images/20180827/7.png"></p><h2 id="6、元数据管理"><a href="#6、元数据管理" class="headerlink" title="6、元数据管理"></a>6、元数据管理</h2><p><code>元数据：数据的数据，记录数据从哪里到哪里去，中间如何转化的。</code></p><p><img src="/images/20180827/8.png"></p><p><code>元数据分为技术元数据和业务元数据</code></p><p><img src="/images/20180827/9.png"></p><p><code>元数据中的数据都有哪些？</code></p><p><img src="/images/20180827/10.png"></p><h2 id="7、数据仓库命名规范"><a href="#7、数据仓库命名规范" class="headerlink" title="7、数据仓库命名规范"></a>7、数据仓库命名规范</h2><h2 id="8、缓慢变化维"><a href="#8、缓慢变化维" class="headerlink" title="8、缓慢变化维"></a>8、缓慢变化维</h2><p><img src="/images/20180827/11.png"></p><p><code>如何解决缓慢变化维带来的影响？</code></p><p><img src="/images/20180827/12.png"></p><p><code>上图中position有变化</code></p><p><img src="/images/20180827/13.png"></p><p><code>上图中多了一条记录</code></p><p><img src="/images/20180827/14.png"></p><h2 id="9、数据仓库建模"><a href="#9、数据仓库建模" class="headerlink" title="9、数据仓库建模"></a>9、数据仓库建模</h2><p><img src="/images/20180827/15.png"></p><p><img src="/images/20180827/16.png"></p><p><img src="/images/20180827/17.png"></p><p><img src="/images/20180827/18.png"></p><h2 id="10、数据仓库五大核心模块"><a href="#10、数据仓库五大核心模块" class="headerlink" title="10、数据仓库五大核心模块"></a>10、数据仓库五大核心模块</h2><p><img src="/images/20180827/19.png"></p><h2 id="11、实体建模和维度建模"><a href="#11、实体建模和维度建模" class="headerlink" title="11、实体建模和维度建模"></a>11、实体建模和维度建模</h2><h2 id="12、O2O业务建模案例"><a href="#12、O2O业务建模案例" class="headerlink" title="12、O2O业务建模案例"></a>12、O2O业务建模案例</h2><p><img src="/images/20180827/20.png"></p><p><img src="/images/20180827/21.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka学习二</title>
      <link href="/2018/08/23/kafka-xue-xi-er/"/>
      <url>/2018/08/23/kafka-xue-xi-er/</url>
      
        <content type="html"><![CDATA[<h1 id="kafka基础二"><a href="#kafka基础二" class="headerlink" title=" kafka基础二"></a><center> kafka基础二</center></h1><h2 id="1、Kafka整体结构图"><a href="#1、Kafka整体结构图" class="headerlink" title="1、Kafka整体结构图"></a>1、Kafka整体结构图</h2><pre class="language-none"><code class="language-none">Kafka名词解释和工作方式    • Producer ：消息生产者，就是向kafka broker发消息的客户端。    • Consumer ：消息消费者，向kafka broker取消息的客户端    • Topic ：咋们可以理解为一个队列。    • Consumer Group （CG）：这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。        一个topic可以有多个CG。topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个partion只会把消息发给该CG中的一个consumer。        如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。        用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。    • Broker ：一台kafka服务器就是一个broker。       一个集群由多个broker组成。一个broker可以容纳多个topic。    • Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，        每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。        kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序。    • Offset：kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。        例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka</code></pre><h2 id="2、Consumer与topic关系"><a href="#2、Consumer与topic关系" class="headerlink" title="2、Consumer与topic关系"></a>2、Consumer与topic关系</h2><pre class="language-none"><code class="language-none">本质上kafka只支持Topic；    • 每个group中可以有多个consumer，每个consumer属于一个consumer group；通常情况下，一个group中会包含多个consumer，这样不仅可以提高topic中消息的并发消费能力，而且还能提高"故障容错"性，如果group中的某个consumer失效那么其消费的partitions将会有其他consumer自动接管。    • 对于Topic中的一条特定的消息，只会被订阅此Topic的每个group中的其中一个consumer消费，此消息不会发送给一个group的多个consumer；那么一个group中所有的consumer将会交错的消费整个Topic，每个group中consumer消息消费互相独立，我们可以认为一个group是一个"订阅"者。    • 在kafka中,一个partition中的消息只会被group中的一个consumer消费(同一时刻)一个Topic中的每个partions，只会被一个"订阅者"中的一个consumer消费，不过一个consumer可以同时消费多个partitions中的消息。    • kafka的设计原理决定,对于一个topic，同一个group中不能有多于partitions个数的consumer同时消费，    否则将意味着某些consumer将无法得到消息。kafka只能保证一个partition中的消息被某个consumer消费时是顺序的；事实上，从Topic角度来说,当有多个partitions时,消息仍不是全局有序的。    </code></pre><h2 id="3、Kafka消息的分发"><a href="#3、Kafka消息的分发" class="headerlink" title="3、Kafka消息的分发"></a>3、Kafka消息的分发</h2><pre class="language-none"><code class="language-none">Producer客户端负责消息的分发:        ◦ kafka集群中的任何一个broker都可以向producer提供metadata信息,        这些metadata中包含"集群中存活的servers列表"/"partitions leader列表"等信息；        ◦ 当producer获取到metadata信息之后, producer将会和Topic下所有partition leader保持socket连接；        ◦ 消息由producer直接通过socket发送到broker，中间不会经过任何"路由层"，事实上，消息被路由到哪个partition上由producer客户端决定；比如可以采用"random""key-hash""轮询"等,如果一个topic中有多个partitions,那么在producer端实现"消息均衡分发"是必要的。    • 在producer端的配置文件中,开发者可以指定partition路由的方式。Producer消息发送的应答机制:    设置发送数据是否需要服务端的反馈,有三个值0,1,-1    0: producer不会等待broker发送ack     1: 当leader接收到消息之后发送ack     -1: 当所有的follower都同步消息成功后发送ack        request.required.acks=0</code></pre><h2 id="4、Consumer的负载均衡"><a href="#4、Consumer的负载均衡" class="headerlink" title="4、Consumer的负载均衡"></a>4、Consumer的负载均衡</h2><p>当一个group中,有consumer加入或者离开时,会触发partitions均衡.均衡的最终目的,是提升topic的并发消费能力，步骤如下：</p><pre class="language-none"><code class="language-none">1、 假如topic1,具有如下partitions: P0,P1,P2,P32、 加入group中,有如下consumer: C1,C23、 首先根据partition索引号对partitions排序: P0,P1,P2,P34、 根据consumer.id排序: C0,C15、 计算倍数: M = [P0,P1,P2,P3].size / [C0,C1].size,本例值M=2(向上取整)6、 然后依次分配partitions: C0 = [P0,P1],C1=[P2,P3],即Ci = [P(i * M),P((i + 1) * M -1)]</code></pre><h2 id="5、kafka文件存储机制"><a href="#5、kafka文件存储机制" class="headerlink" title="5、kafka文件存储机制"></a>5、kafka文件存储机制</h2><h3 id="5-1、Kafka文件存储基本结构"><a href="#5-1、Kafka文件存储基本结构" class="headerlink" title="5.1、Kafka文件存储基本结构"></a>5.1、Kafka文件存储基本结构</h3><pre class="language-none"><code class="language-none">    • 在Kafka文件存储中，同一个topic下有多个不同partition，    每个partition为一个目录，partiton命名规则为topic名称+有序序号，    第一个partiton序号从0开始，序号最大值为partitions数量减1。    • 每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。    但每个段segment file消息数量不一定相等，    这种特性方便old segment file快速被删除。默认保留7天的数据。    • 每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。    （什么时候创建，什么时候删除）数据有序的讨论？    一个partition的数据是否是有序的？    间隔性有序，不连续    针对一个topic里面的数据，只能做到partition内部有序，    不能做到全局有序。    特别加入消费者的场景后，如何保证消费者消费的数据全局有序的？伪命题。只有一种情况下才能保证全局有序？就是只有一个partition。    </code></pre><h3 id="5-2、Kafka-Partition-Segment"><a href="#5-2、Kafka-Partition-Segment" class="headerlink" title="5.2、Kafka Partition Segment"></a>5.2、Kafka Partition Segment</h3><pre><code>    • Segment file组成：由2大部分组成，分别为index file和data file，    此2个文件一一对应，成对出现，后缀".index"和“.log”    分别表示为segment索引文件、数据文件。    • Segment文件命名规则：partion全局的第一个segment从0开始，    后续每个segment文件名为上一个segment文件最后一条消息的offset值。    数值最大为64位long大小，19位数字字符长度，没有数字用0填充。    • 索引文件存储大量元数据，数据文件存储大量消息，    索引文件中元数据指向对应数据文件中message的物理偏移地址。3，497：当前log文件中的第几条信息，存放在磁盘上的那个地方上述图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton表示第368772个message)、以及该消息的物理偏移地址为497。    • segment data file由许多message组成， qq物理结构如下：关键字解释说明:    8 byte offset    在parition(分区)内的每条消息都有一个有序的id号，    这个id号被称为偏移(offset),它可以唯一确定每条消息在parition(分区)内的位置。    即offset表示partiion的第多少message    4 byte message size    message大小    4 byte CRC32    用crc32校验message    1 byte “magic"    表示本次发布Kafka服务程序协议版本号    1 byte “attributes"    表示为独立版本、或标识压缩类型、或编码类型。    4 byte key length    表示key的长度,当key为-1时，K byte key字段不填    K byte key    可选    value bytes payload    表示实际消息数据。</code></pre><h3 id="5-3、Kafka-查找message"><a href="#5-3、Kafka-查找message" class="headerlink" title="5.3、Kafka 查找message"></a>5.3、Kafka 查找message</h3><p>读取offset=368776的message，需要通过下面2个步骤查找。</p><h4 id="5-3-1、查找segment-file"><a href="#5-3-1、查找segment-file" class="headerlink" title="5.3.1、查找segment file"></a>5.3.1、查找segment file</h4><p>00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0</p><p>00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1</p><p>00000000000000737337.index的起始偏移量为737338=737337 + 1</p><p>其他后续文件依次类推。<br>以起始偏移量命名并排序这些文件，只要根据offset <strong>二分查找</strong>文件列表，</p><p>就可以快速定位到具体文件。当offset=368776时定位到00000000000000368769.index和对应log文件。</p><h4 id="5-3-2、通过segment-file查找message"><a href="#5-3-2、通过segment-file查找message" class="headerlink" title="5.3.2、通过segment file查找message"></a>5.3.2、通过segment file查找message</h4><p>当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址</p><p>然后再通过00000000000000368769.log顺序查找直到offset=368776为止。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>storm学习三</title>
      <link href="/2018/08/23/storm-xue-xi-san/"/>
      <url>/2018/08/23/storm-xue-xi-san/</url>
      
        <content type="html"><![CDATA[<h1 id="storm基础三"><a href="#storm基础三" class="headerlink" title="storm基础三"></a><center>storm基础三</center></h1><h2 id="1、Storm程序的并发机制"><a href="#1、Storm程序的并发机制" class="headerlink" title="1、Storm程序的并发机制"></a>1、Storm程序的并发机制</h2><h3 id="1-1、概念"><a href="#1-1、概念" class="headerlink" title="1.1、概念"></a>1.1、概念</h3><pre class="language-none"><code class="language-none">• Workers (JVMs): 在一个物理节点上可以运行一个或多个独立的JVM 进程。一个Topology可以包含一个或多个worker(并行的跑在不同的物理机上), 所以worker process就是执行一个topology的子集, 并且worker只能对应于一个topology&nbsp;• Executors (threads): 在一个worker JVM进程中运行着多个Java线程。一个executor线程可以执行一个或多个tasks。但一般默认每个executor只执行一个task。一个worker可以包含一个或多个executor, 每个component (spout或bolt)至少对应于一个executor, 所以可以说executor执行一个compenent的子集, 同时一个executor只能对应于一个component。&nbsp;• Tasks(bolt/spout instances)：Task就是具体的处理逻辑对象，每一个Spout和Bolt会被当作很多task在整个集群里面执行。每一个task对应到一个线程，而stream grouping则是定义怎么从一堆task发射tuple到另外一堆task。你可以调用TopologyBuilder.setSpout和TopBuilder.setBolt来设置并行度 — 也就是有多少个task。&nbsp;</code></pre><h3 id="1-2、配置并行度"><a href="#1-2、配置并行度" class="headerlink" title="1.2、配置并行度"></a>1.2、配置并行度</h3><pre class="language-none"><code class="language-none">    • 对于并发度的配置, 在storm里面可以在多个地方进行配置, 优先级为：defaults.yaml &lt; storm.yaml &lt; topology-specific configuration &lt; internal component-specific configuration &lt; external component-specific configuration&nbsp;    • worker processes的数目, 可以通过配置文件和代码中配置, worker就是执行进程, 所以考虑并发的效果, 数目至少应该大亍machines的数目&nbsp;    • executor的数目, component的并发线程数，只能在代码中配置(通过setBolt和setSpout的参数), 例如, setBolt("green-bolt", new GreenBolt(), 2)&nbsp;    • tasks的数目, 可以不配置, 默认和executor1:1, 也可以通过setNumTasks()配置&nbsp;Topology的worker数通过config设置，即执行该topology的worker（java）进程数。它可以通过 storm rebalance 命令任意调整。&nbsp;Config conf =&nbsp;newConfig();conf.setNumWorkers(2);&nbsp;//用2个workertopologyBuilder.setSpout("blue-spout",&nbsp;newBlueSpout(),&nbsp;2);&nbsp;//设置2个并发度topologyBuilder.setBolt("green-bolt",&nbsp;newGreenBolt(),&nbsp;2).setNumTasks(4).shuffleGrouping("blue-spout");&nbsp;//设置2个并发度，4个任务topologyBuilder.setBolt("yellow-bolt",&nbsp;newYellowBolt(),&nbsp;6).shuffleGrouping("green-bolt"); //设置6个并发度StormSubmitter.submitTopology("mytopology", conf, topologyBuilder.createTopology());3个组件的并发度加起来是10，就是说拓扑一共有10个executor，一共有2个worker，每个worker产生10 / 2 = 5条线程。绿色的bolt配置成2个executor和4个task。为此每个executor为这个bolt运行2个task。    • 动态的改变并行度Storm支持在不 restart topology 的情况下, 动态的改变(增减) worker processes 的数目和 executors 的数目, 称为rebalancing. 通过Storm web UI，或者通过storm rebalance命令实现        </code></pre><p><img src="/images/20180823/15.png"></p><p><code>storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10</code></p><h2 id="2、Storm通信机制"><a href="#2、Storm通信机制" class="headerlink" title="2、Storm通信机制"></a>2、Storm通信机制</h2><pre class="language-none"><code class="language-none">Worker间的通信经常需要通过网络跨节点进行，Storm使用ZeroMQ或Netty(0.9以后默认使用)作为进程间通信的消息框架。Worker进程内部通信：不同worker的thread通信使用LMAX Disruptor来完成。&nbsp;    不同topologey之间的通信，Storm不负责，需要自己想办法实现，例如使用kafka等；</code></pre><h3 id="2-1、Worker进程间通信"><a href="#2-1、Worker进程间通信" class="headerlink" title="2.1、Worker进程间通信"></a>2.1、Worker进程间通信</h3><p>worker进程间消息传递机制，消息的接收和处理的大概流程见下图</p><p><img src="/images/20180823/16.png"></p><pre class="language-none"><code class="language-none">        ◦ 对于worker进程来说，为了管理流入和传出的消息，每个worker进程有一个独立的接收线程(对配置的TCP端口supervisor.slots.ports进行监听);对应Worker接收线程，每个worker存在一个独立的发送线程，它负责从worker的transfer-queue中读取消息，并通过网络发送给其他worker        ◦ 每个executor有自己的incoming-queue和outgoing-queue。Worker接收线程将收到的消息通过task编号传递给对应的executor(一个或多个)的incoming-queues;每个executor有单独的线程分别来处理spout/bolt的业务逻辑，业务逻辑输出的中间数据会存放在outgoing-queue中，当executor的outgoing-queue中的tuple达到一定的阀值，executor的发送线程将批量获取outgoing-queue中的tuple,并发送到transfer-queue中。        ◦ 每个worker进程控制一个或多个executor线程，用户可在代码中进行配置。其实就是我们在代码中设置的并发度个数。</code></pre><h3 id="2-2、Worker进程间通信分析"><a href="#2-2、Worker进程间通信分析" class="headerlink" title="2.2、Worker进程间通信分析"></a>2.2、Worker进程间通信分析</h3><p><img src="/images/20180823/17.png"></p><pre class="language-none"><code class="language-none">1、 Worker接受线程通过网络接受数据，并根据Tuple中包含的taskId，匹配到对应的executor；然后根据executor找到对应的incoming-queue，将数据存发送到incoming-queue队列中。2、 业务逻辑执行现成消费incoming-queue的数据，通过调用Bolt的execute(xxxx)方法，将Tuple作为参数传输给用户自定义的方法3、 业务逻辑执行完毕之后，将计算的中间数据发送给outgoing-queue队列，当outgoing-queue中的tuple达到一定的阀值，executor的发送线程将批量获取outgoing-queue中的tuple,并发送到Worker的transfer-queue中4、 Worker发送线程消费transfer-queue中数据，计算Tuple的目的地，连接不同的node+port将数据通过网络传输的方式传送给另一个的Worker。5、 另一个worker执行以上步骤1的操作。</code></pre><h3 id="2-3、Worker进程间技术-Netty、ZeroMQ"><a href="#2-3、Worker进程间技术-Netty、ZeroMQ" class="headerlink" title="2.3、Worker进程间技术(Netty、ZeroMQ)"></a>2.3、Worker进程间技术(Netty、ZeroMQ)</h3><h4 id="2-3-1、Netty"><a href="#2-3-1、Netty" class="headerlink" title="2.3.1、Netty"></a>2.3.1、Netty</h4><p>Netty是一个NIO client-server(客户端服务器)框架，使用Netty可以快速开发网络应用，例如服务器和客户端协议。Netty提供了一种新的方式来使开发网络应用程序，这种新的方式使得它很容易使用和有很强的扩展性。Netty的内部实现时很复杂的，但是Netty提供了简单易用的api从网络处理代码中解耦业务逻辑。Netty是完全基于NIO实现的，所以整个Netty都是异步的。<br>书籍：Netty权威指南</p><h4 id="2-3-2、ZeroMQ"><a href="#2-3-2、ZeroMQ" class="headerlink" title="2.3.2、ZeroMQ"></a>2.3.2、ZeroMQ</h4><p>ZeroMQ是一种基于消息队列的多线程网络库，其对套接字类型、连接处理、帧、甚至路由的底层细节进行抽象，提供跨越多种传输协议的套接字。ZeroMQ是网络通信中新的一层，介于应用层和传输层之间（按照TCP/IP划分），其是一个可伸缩层，可并行运行，分散在分布式系统间。<br>ZeroMQ定位为：一个简单好用的传输层，像框架一样的一个socket library，他使得Socket编程更加简单、简洁和性能更高。是一个消息处理队列库，可在多个线程、内核和主机盒之间弹性伸缩。ZMQ的明确目标是“成为标准网络协议栈的一部分，之后进入Linux内核”。</p><h3 id="2-4、Worker-内部通信技术-Disruptor"><a href="#2-4、Worker-内部通信技术-Disruptor" class="headerlink" title="2.4、Worker 内部通信技术(Disruptor)"></a>2.4、Worker 内部通信技术(Disruptor)</h3><h4 id="2-4-1、-Disruptor的来历"><a href="#2-4-1、-Disruptor的来历" class="headerlink" title="2.4.1、 Disruptor的来历"></a>2.4.1、 Disruptor的来历</h4><pre><code>• 一个公司的业务与技术的关系，一般可以分为三个阶段。第一个阶段就是跟着业务跑。第二个阶段是经历了几年的时间，才达到的驱动业务阶段。第三个阶段，技术引领业务的发展乃至企业的发展。所以我们在学习Disruptor这个技术时，不得不提LMAX这个机构，因为Disruptor这门技术就是由LMAX公司开发并开源的。    ◦ LMAX是在英国注册并受到FSA监管（监管号码为509778）的外汇黄金交易所。LMAX也是欧洲第一家也是唯一一家采用多边交易设施Multilateral Trading Facility（MTF）拥有交易所牌照和经纪商牌照的欧洲顶级金融公司    ◦ LAMX拥有最迅捷的交易平台，顶级技术支持。LMAX交易所使用“（MTF）分裂器Disruptor”技术，可以在极短时间内（一般在3百万秒之一内）处理订单，在一个线程里每秒处理6百万订单。所有订单均为撮合成交形式，无一例外。多边交易设施（MTF）曾经用来设计伦敦证券交易 所（london Stock Exchange）、德国证券及衍生工具交易所（Deutsche Borse）和欧洲证券交易所（Euronext）。    ◦ 2011年LMAX凭借该技术获得了金融行业技术评选大赛的最佳交易系统奖和甲骨文“公爵杯”创新编程框架奖。</code></pre><h4 id="2-4-2、Disruptor是什么"><a href="#2-4-2、Disruptor是什么" class="headerlink" title="2.4.2、Disruptor是什么"></a>2.4.2、Disruptor是什么</h4><pre class="language-none"><code class="language-none">1、 简单理解：Disruptor是一个Queue。Disruptor是实现了“队列”的功能，而且是一个有界队列。而队列的应用场景自然就是“生产者-消费者”模型。2、 在JDK中Queue有很多实现类，包括不限于ArrayBlockingQueue、LinkBlockingQueue，这两个底层的数据结构分别是数组和链表。数组查询快，链表增删快，能够适应大多数应用场景。3、 但是ArrayBlockingQueue、LinkBlockingQueue都是线程安全的。涉及到线程安全，就会有synchronized、lock等关键字，这就意味着CPU会打架。 4、 Disruptor一种线程之间信息无锁的交换方式（使用CAS（Compare And Swap/Set）操作）。        </code></pre><h4 id="2-4-3、Disruptor主要特点"><a href="#2-4-3、Disruptor主要特点" class="headerlink" title="2.4.3、Disruptor主要特点"></a>2.4.3、Disruptor主要特点</h4><pre><code>1、 没有竞争=没有锁=非常快。2、 所有访问者都记录自己的序号的实现方式，允许多个生产者与多个消费者共享相同的数据结构。3、 在每个对象中都能跟踪序列号（ring buffer，claim Strategy，生产者和消费者），加上神奇的cache line padding，就意味着没有为伪共享和非预期的竞争。        </code></pre><h4 id="2-4-4、-Disruptor-核心技术点"><a href="#2-4-4、-Disruptor-核心技术点" class="headerlink" title="2.4.4、 Disruptor 核心技术点"></a>2.4.4、 Disruptor 核心技术点</h4><p>Disruptor可以看成一个事件监听或消息机制，在队列中一边生产者放入消息，另外一边消费者并行取出处理.<br>底层是单个数据结构：一个ring buffer。<br>每个生产者和消费者都有一个次序计算器，以显示当前缓冲工作方式。<br>每个生产者消费者能够操作自己的次序计数器的能够读取对方的计数器，生产者能够读取消费者的计算器确保其在没有锁的情况下是可写的。</p><p>核心组件<br>    • Ring Buffer 环形的缓冲区，负责对通过 Disruptor 进行交换的数据（事件）进行存储和更新。<br>    • Sequence 通过顺序递增的序号来编号管理通过其进行交换的数据（事件），对数据(事件)的处理过程总是沿着序号逐个递增处理。<br>    • RingBuffer底层是个数组，次序计算器是一个64bit long 整数型，平滑增长。    </p><h3 id="3、Storm组件本地目录树"><a href="#3、Storm组件本地目录树" class="headerlink" title="3、Storm组件本地目录树"></a>3、Storm组件本地目录树</h3><p><img src="/images/20180823/18.png"></p><h3 id="4、Storm-zookeeper目录树"><a href="#4、Storm-zookeeper目录树" class="headerlink" title="4、Storm zookeeper目录树"></a>4、Storm zookeeper目录树</h3><p><img src="/images/20180823/19.png">   </p><h3 id="5、Storm-任务提交的过程"><a href="#5、Storm-任务提交的过程" class="headerlink" title="5、Storm 任务提交的过程"></a>5、Storm 任务提交的过程</h3><p><img src="/images/20180823/20.png">   </p><p><img src="/images/20180823/21.png">   </p><h3 id="6、Storm-消息容错机制"><a href="#6、Storm-消息容错机制" class="headerlink" title="6、Storm 消息容错机制"></a>6、Storm 消息容错机制</h3><h4 id="6-1、总体介绍"><a href="#6-1、总体介绍" class="headerlink" title="6.1、总体介绍"></a>6.1、总体介绍</h4><pre class="language-none"><code class="language-none">    • 在storm中，可靠的信息处理机制是从spout开始的。    • 一个提供了可靠的处理机制的spout需要记录他发射出去的tuple，当下游bolt处理tuple或者子tuple失败时spout能够重新发射。     • Storm通过调用Spout的nextTuple()发送一个tuple。为实现可靠的消息处理，首先要给每个发出的tuple带上唯一的ID，并且将ID作为参数传递给SoputOutputCollector的emit()方法：collector.emit(new Values("value1","value2"), msgId); messageid就是用来标示唯一的tupke的，而rootid是随机生成的给每个tuple指定ID告诉Storm系统，无论处理成功还是失败，spout都要接收tuple树上所有节点返回的通知。如果处理成功，spout的ack()方法将会对编号是msgId的消息应答确认；如果处理失败或者超时，会调用fail()方法。 </code></pre><h4 id="6-2、基本实现"><a href="#6-2、基本实现" class="headerlink" title="6.2、基本实现"></a>6.2、基本实现</h4><pre class="language-none"><code class="language-none">Storm 系统中有一组叫做"acker"的特殊的任务，它们负责跟踪DAG（有向无环图）中的每个消息。acker任务保存了spout id到一对值的映射。第一个值就是spout的任务id，通过这个id，acker就知道消息处理完成时该通知哪个spout任务。第二个值是一个64bit的数字，我们称之为"ack val"， 它是树中所有消息的随机id的异或计算结果。ack val表示了整棵树的的状态，无论这棵树多大，只需要这个固定大小的数字就可以跟踪整棵树。当消息被创建和被应答的时候都会有相同的消息id发送过来做异或。&nbsp;每当acker发现一棵树的ack val值为0的时候，它就知道这棵树已经被完全处理了</code></pre><h4 id="6-3、可靠性配置"><a href="#6-3、可靠性配置" class="headerlink" title="6.3、可靠性配置"></a>6.3、可靠性配置</h4><pre class="language-none"><code class="language-none">有三种方法可以去掉消息的可靠性： 将参数Config.TOPOLOGY_ACKERS设置为0，通过此方法，当Spout发送一个消息的时候，它的ack方法将立刻被调用； Spout发送一个消息时，不指定此消息的messageID。当需要关闭特定消息可靠性的时候，可以使用此方法； 最后，如果你不在意某个消息派生出来的子孙消息的可靠性，则此消息派生出来的子消息在发送时不要做锚定，即在emit方法中不指定输入消息。因为这些子孙消息没有被锚定在任何tuple tree中，因此他们的失败不会引起任何spout重新发送消息。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> storm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka学习一</title>
      <link href="/2018/08/23/kafka-xue-xi-yi/"/>
      <url>/2018/08/23/kafka-xue-xi-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="kafka基础一"><a href="#kafka基础一" class="headerlink" title="kafka基础一"></a><center>kafka基础一</center></h1><h2 id="1、Kafka是什么"><a href="#1、Kafka是什么" class="headerlink" title="1、Kafka是什么"></a>1、Kafka是什么</h2><pre class="language-none"><code class="language-none">在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算。KAFKA + STORM +REDIS    • Apache Kafka是一个开源消息系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。    • Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。    该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。    • Kafka是一个分布式消息队列：生产者、消费者的功能。它提供了类似于JMS的特性，    但是在设计实现上完全不同，此外它并不是JMS规范的实现。    • Kafka对消息保存时根据Topic进行归类，    发送消息者称为Producer,消息接受者称为Consumer,    此外kafka集群有多个kafka实例组成，每个实例(server)成为broker。    • 无论是kafka集群，还是producer和consumer都依赖于zookeeper集群保存一些meta信息，来保证系统可用性</code></pre><h2 id="2、JMS是什么"><a href="#2、JMS是什么" class="headerlink" title="2、JMS是什么"></a>2、JMS是什么</h2><h3 id="2-1、JMS的基础"><a href="#2-1、JMS的基础" class="headerlink" title="2.1、JMS的基础"></a>2.1、JMS的基础</h3><pre><code>JMS是什么：JMS是Java提供的一套技术规范</code></pre><p>JMS干什么用：用来异构系统 集成通信，缓解系统瓶颈，提高系统的伸缩性增强系统用户体验，使得系统模块化和组件化变得可行并更加灵活<br>通过什么方式：生产消费者模式（生产者、服务器、消费者）</p><p><img src="/images/20180823/10.png"></p><h3 id="2-2、JMS消息传输模型"><a href="#2-2、JMS消息传输模型" class="headerlink" title="2.2、JMS消息传输模型"></a>2.2、JMS消息传输模型</h3><pre class="language-none"><code class="language-none">    • 点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）    点对点模型通常是一个基于拉取或者轮询的消息传送模型，    这种模型从队列中请求信息，而不是将消息推送到客户端。    这个模型的特点是发送到队列的消息被一个且只有一个接收者接收处理，    即使有多个消息监听者也是如此。    • 发布/订阅模式（一对多，数据生产后，推送给所有订阅者）    发布订阅模型则是一个基于推送的消息传送模型。    发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，    而持久订阅者则监听主题的所有消息，即时当前订阅者不可用，处于离线状态。queue.put（object）  数据生产queue.take(object)    数据消费    </code></pre><p><img src="/images/20180823/11.png"></p><h3 id="2-3、JMS核心组件"><a href="#2-3、JMS核心组件" class="headerlink" title="2.3、JMS核心组件"></a>2.3、JMS核心组件</h3><pre class="language-none"><code class="language-none">    • Destination：消息发送的目的地，也就是前面说的Queue和Topic。    • Message ：从字面上就可以看出是被发送的消息。    • Producer： 消息的生产者，要发送一个消息，必须通过这个生产者来发送。    • MessageConsumer： 与生产者相对应，这是消息的消费者或接收者，通过它来接收一个消息。通过与ConnectionFactory可以获得一个connection通过connection可以获得一个session会话。</code></pre><p><img src="/images/20180823/12.png"></p><h3 id="2-4、常见的类JMS消息服务器"><a href="#2-4、常见的类JMS消息服务器" class="headerlink" title="2.4、常见的类JMS消息服务器"></a>2.4、常见的类JMS消息服务器</h3><h4 id="2-4-1、JMS消息服务器-ActiveMQ"><a href="#2-4-1、JMS消息服务器-ActiveMQ" class="headerlink" title="2.4.1、JMS消息服务器 ActiveMQ"></a>2.4.1、JMS消息服务器 ActiveMQ</h4><pre class="language-none"><code class="language-none">ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的。主要特点：    • 多种语言和协议编写客户端。语言: Java, C, C++, C#, Ruby, Perl, Python, PHP。应用协议: OpenWire,Stomp REST,WS Notification,XMPP,AMQP    • 完全支持JMS1.1和J2EE 1.4规范 (持久化,XA消息,事务)    • 对Spring的支持,ActiveMQ可以很容易内嵌到使用Spring的系统里面去,而且也支持Spring2.0的特性    • 通过了常见J2EE服务器(如 Geronimo,JBoss 4, GlassFish,WebLogic)的测试,其中通过JCA 1.5 resource adaptors的配置,可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上    • 支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA    • 支持通过JDBC和journal提供高速的消息持久化    • 从设计上保证了高性能的集群,客户端-服务器,点对点    • 支持Ajax    • 支持与Axis的整合    • 可以很容易得调用内嵌JMS provider,进行测试</code></pre><h4 id="2-4-2、分布式消息中间件-Metamorphosis"><a href="#2-4-2、分布式消息中间件-Metamorphosis" class="headerlink" title="2.4.2、分布式消息中间件 Metamorphosis"></a>2.4.2、分布式消息中间件 Metamorphosis</h4><pre class="language-none"><code class="language-none">Metamorphosis (MetaQ) 是一个高性能、高可用、可扩展的分布式消息中间件，类似于LinkedIn的Kafka，具有消息存储顺序写、吞吐量大和支持本地和XA事务等特性，适用于大吞吐量、顺序消息、广播和日志数据传输等场景，在淘宝和支付宝有着广泛的应用，现已开源。主要特点：    • 生产者、服务器和消费者都可分布    • 消息存储顺序写    • 性能极高,吞吐量大    • 支持消息顺序    • 支持本地和XA事务    • 客户端pull，随机读,利用sendfile系统调用，zero-copy ,批量拉数据    • 支持消费端事务    • 支持消息广播模式    • 支持异步发送消息    • 支持http协议    • 支持消息重试和recover    • 数据迁移、扩容对用户透明    • 消费状态保存在客户端    • 支持同步和异步复制两种HA    • 支持group commit</code></pre><h4 id="2-4-3、分布式消息中间件-RocketMQ"><a href="#2-4-3、分布式消息中间件-RocketMQ" class="headerlink" title="2.4.3、分布式消息中间件 RocketMQ"></a>2.4.3、分布式消息中间件 RocketMQ</h4><pre class="language-none"><code class="language-none">RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点：    • 能够保证严格的消息顺序    • 提供丰富的消息拉取模式    • 高效的订阅者水平扩展能力    • 实时的消息订阅机制    • 亿级消息堆积能力    • Metaq3.0 版本改名，产品名称改为RocketMQ</code></pre><h4 id="2-4-4、其他MQ"><a href="#2-4-4、其他MQ" class="headerlink" title="2.4.4、其他MQ"></a>2.4.4、其他MQ</h4><pre class="language-none"><code class="language-none">• .NET消息中间件 DotNetMQ• 基于HBase的消息队列 HQueue• Go 的 MQ 框架 KiteQ• AMQP消息服务器 RabbitMQ• MemcacheQ 是一个基于 MemcacheDB 的消息队列服务器。</code></pre><h2 id="3、为什么需要消息队列（重要）"><a href="#3、为什么需要消息队列（重要）" class="headerlink" title="3、为什么需要消息队列（重要）"></a>3、为什么需要消息队列（重要）</h2><p>消息系统的核心作用就是三点：解耦，异步和并行<br>以用户注册的案列来说明消息系统的作用</p><pre><code>1、 保证主流程的正常执行、执行成功之后，发送MQ消息出去。2、 需要这个destination的其他系统通过消费数据再执行，最终一致。</code></pre><h2 id="4-Kafka核心组件"><a href="#4-Kafka核心组件" class="headerlink" title="4.Kafka核心组件"></a>4.Kafka核心组件</h2><pre class="language-none"><code class="language-none">• Topic ：消息根据Topic进行归类• Producer：发送消息者• Consumer：消息接受者• broker：每个kafka实例(server)• Zookeeper：依赖集群保存meta信息。</code></pre><h2 id="4-Kafka常用操作命令"><a href="#4-Kafka常用操作命令" class="headerlink" title="4.Kafka常用操作命令"></a>4.Kafka常用操作命令</h2><pre class="language-none"><code class="language-none">    • 查看当前服务器中的所有topicbin/kafka-topics.sh --list --zookeeper  zk01:2181    • 创建topic./kafka-topics.sh --create --zookeeper mini1:2181 --replication-factor 1 --partitions 3 --topic first    • 删除topicsh bin/kafka-topics.sh --delete --zookeeper zk01:2181 --topic test需要server.properties中设置delete.topic.enable=true否则只是标记删除或者直接重启。    • 通过shell命令发送消息kafka-console-producer.sh --broker-list kafka01:9092 --topic itheima    • 通过shell消费消息sh bin/kafka-console-consumer.sh --zookeeper zk01:2181 --from-beginning --topic test1    • 查看消费位置sh kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper zk01:2181 --group testGroup    • 查看某个Topic的详情sh kafka-topics.sh --topic test --describe --zookeeper zk01:2181</code></pre><h2 id="5、Kafka生产者Java-API"><a href="#5、Kafka生产者Java-API" class="headerlink" title="5、Kafka生产者Java API"></a>5、Kafka生产者Java API</h2><p><img src="/images/20180823/13.png"></p><h2 id="6、Kafka消费者Java-API"><a href="#6、Kafka消费者Java-API" class="headerlink" title="6、Kafka消费者Java API"></a>6、Kafka消费者Java API</h2><p><img src="/images/20180823/14.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>storm学习二</title>
      <link href="/2018/08/23/storm-xue-xi-er/"/>
      <url>/2018/08/23/storm-xue-xi-er/</url>
      
        <content type="html"><![CDATA[<h1 id="storm基础二"><a href="#storm基础二" class="headerlink" title=" storm基础二"></a><center> storm基础二</center></h1><h2 id="1-集群部署的基本流程"><a href="#1-集群部署的基本流程" class="headerlink" title="1.集群部署的基本流程"></a>1.集群部署的基本流程</h2><p>集群部署的流程：下载安装包、解压安装包、修改配置文件、分发安装包、启动集群<br>注意：<br>&nbsp; &nbsp; 所有的集群上都需要配置hosts<br>&nbsp; &nbsp;&nbsp;vi &nbsp;/etc/hosts<br>    192.168.239.128&nbsp;storm01&nbsp;zk01&nbsp;hadoop01<br>&nbsp; &nbsp; &nbsp; 192.168.239.129&nbsp;storm02&nbsp;zk02&nbsp;hadoop02<br>&nbsp;    192.168.239.130&nbsp;storm03&nbsp;zk03&nbsp;hadoop03&nbsp;    </p><h2 id="2-2、-集群部署的基础环境准备"><a href="#2-2、-集群部署的基础环境准备" class="headerlink" title="2.    2、 集群部署的基础环境准备"></a>2.    2、 集群部署的基础环境准备</h2><p>安装前的准备工作（zk集群已经部署完毕）<br>    • 关闭防火墙<br>chkconfig iptables off  &amp;&amp; setenforce 0<br>    • 创建用户<br>groupadd realtime &amp;&amp;　useradd realtime　&amp;&amp; usermod -a -G realtime realtime<br>    • 创建工作目录并赋权<br>mkdir /export<br>mkdir /export/servers<br>chmod 755 -R /export<br>    • 切换到realtime用户下<br>su realtime</p><h2 id="3-Storm集群部署"><a href="#3-Storm集群部署" class="headerlink" title="3.Storm集群部署"></a>3.Storm集群部署</h2><pre class="language-none"><code class="language-none">3.1、下载安装包    wget &nbsp; &nbsp;http://124.202.164.6/files/1139000006794ECA/apache.fayea.com/storm/apache-storm-0.9.5/apache-storm-0.9.5.tar.gz3.2、解压安装包tar -zxvf apache-storm-0.9.5.tar.gz -C /export/servers/cd /export/servers/ln -s apache-storm-0.9.5 storm3.3、修改配置文件    mv /export/servers/storm/conf/storm.yaml /export/servers/storm/conf/storm.yaml.bakvi /export/servers/storm/conf/storm.yaml输入以下内容：</code></pre><p><img src="/images/20180823/4.png"></p><pre class="language-none"><code class="language-none">3.4、分发安装包scp -r /export/servers/apache-storm-0.9.5 storm02:/export/servers然后分别在各机器上创建软连接cd /export/servers/ln -s apache-storm-0.9.5 storm3.5、启动集群    • 在nimbus.host所属的机器上启动 nimbus服务cd /export/servers/storm/bin/nohup ./storm nimbus &amp;    • 在nimbus.host所属的机器上启动ui服务cd /export/servers/storm/bin/nohup ./storm ui &amp;    • 在其它个点击上启动supervisor服务cd /export/servers/storm/bin/nohup ./storm supervisor &amp;3.6、查看集群访问nimbus.host:/8080，即可看到storm的ui界面。</code></pre><p><img src="/images/20180823/5.png"></p><pre class="language-none"><code class="language-none">##  4、Storm常用操作命令</code></pre><p>有许多简单且有用的命令可以用来管理拓扑，它们可以提交、杀死、禁用、再平衡拓扑。<br>    • 提交任务命令格式：storm jar 【jar路径】 【拓扑包名.拓扑类名】 【拓扑名称】<br>bin/storm jar examples/storm-starter/storm-starter-topologies-0.9.6.jar storm.starter.WordCountTopology wordcount</p><pre><code>• 杀死任务命令格式：storm kill 【拓扑名称】 -w 10（执行kill命令时可以通过-w [等待秒数]指定拓扑停用以后的等待时间）</code></pre><p>storm kill topology-name -w 10</p><pre><code>• 停用任务命令格式：storm deactivte  【拓扑名称】</code></pre><p>storm deactivte topology-name<br>我们能够挂起或停用运行中的拓扑。当停用拓扑时，所有已分发的元组都会得到处理，但是spouts的nextTuple方法不会被调用。销毁一个拓扑，可以使用kill命令。它会以一种安全的方式销毁一个拓扑，首先停用拓扑，在等待拓扑消息的时间段内允许拓扑完成当前的数据流。</p><pre><code>• 启用任务命令格式：storm activate【拓扑名称】    storm activate topology-name• 重新部署任务命令格式：storm rebalance  【拓扑名称】    storm rebalance topology-name    再平衡使你重分配集群任务。这是个很强大的命令。比如，你向一个运行中的集群增加了节点。再平衡命令将会停用拓扑，然后在相应超时时间之后重分配工人，并重启拓扑。</code></pre><pre class="language-none"><code class="language-none">## 5.5、Storm集群的进程及日志熟悉</code></pre><p>5.1、部署成功之后，启动storm集群。<br>    依次启动集群的各种角色</p><p>5.2、查看nimbus的日志信息<br>在nimbus的服务器上<br>cd /export/servers/storm/logs<br>tail -100f /export/servers/storm/logs/nimbus.log</p><p>5.3、查看ui运行日志信息<br>在ui的服务器上，一般和nimbus一个服务器<br>cd /export/servers/storm/logs<br>tail -100f /export/servers/storm/logs/ui.log</p><p>5.4、查看supervisor运行日志信息<br>在supervisor服务上<br>cd /export/servers/storm/logs<br>tail -100f /export/servers/storm/logs/supervisor.log</p><p>5.5、查看supervisor上worker运行日志信息<br>在supervisor服务上<br>cd /export/servers/storm/logs<br>tail -100f /export/servers/storm/logs/worker-6702.log</p><pre class="language-none"><code class="language-none">## 7、Storm单词技术案例### 7.1、功能说明</code></pre><p>设计一个topology，来实现对文档里面的单词出现的频率进行统计。<br>整个topology分为三个部分：<br>    • RandomSentenceSpout：数据源，在已知的英文句子中，随机发送一条句子出去。<br>    • SplitSentenceBolt：负责将单行文本记录（句子）切分成单词<br>    • WordCountBolt：负责对单词的频率进行累加</p><pre class="language-none"><code class="language-none">### 7.2、项目主要流程![](/images/20180823/6.png)### 7.3、RandomSentenceSpout的实现及生命周期![](/images/20180823/7.png)### 7.4、SplitSentenceBolt的实现及生命周期![](/images/20180823/8.png)### 7.5、WordCountBolt的实现及生命周期![](/images/20180823/9.png)### 7.6、Stream Grouping详解</code></pre><p>Storm里面有7种类型的stream grouping<br>    • Shuffle Grouping: 随机分组， 随机派发stream里面的tuple，保证每个bolt接收到的tuple数目大致相同。</p><pre><code>• Fields Grouping：按字段分组，比如按userid来分组，具有同样userid的tuple会被分到相同的Bolts里的一个task，而不同的userid则会被分配到不同的bolts里的task。• All Grouping：广播发送，对于每一个tuple，所有的bolts都会收到。• Global Grouping：全局分组， 这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task。• Non Grouping：不分组，这stream grouping个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果， 有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行。• Direct Grouping： 直接分组， 这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过TopologyContext来获取处理它的消息的task的id （OutputCollector.emit方法也会返回task的id）。• Local or shuffle grouping：如果目标bolt有一个或者多个task在同一个工作进程中，tuple将会被随机发生给这些tasks。否则，和普通的Shuffle Grouping行为一致。</code></pre><pre><code></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> storm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>storm学习一</title>
      <link href="/2018/08/23/storm-xue-xi-yi/"/>
      <url>/2018/08/23/storm-xue-xi-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="storm基础一"><a href="#storm基础一" class="headerlink" title="storm基础一"></a><center>storm基础一<center></center></center></h1><h2 id="1、离线计算是什么？"><a href="#1、离线计算是什么？" class="headerlink" title="1、离线计算是什么？"></a>1、离线计算是什么？</h2><pre class="language-none"><code class="language-none">离线计算：批量获取数据、批量传输数据、周期性批量计算数据、数据展示    代表技术：Sqoop批量导入数据、HDFS批量存储数据、MapReduce批量计算数据、Hive批量计算数据、***任务调度1，hivesql2、调度平台3、Hadoop集群运维4、数据清洗（脚本语言）5、元数据管理6、数据稽查7、数据仓库模型架构</code></pre><h2 id="2、流式计算是什么"><a href="#2、流式计算是什么" class="headerlink" title="2、流式计算是什么"></a>2、流式计算是什么</h2><pre class="language-none"><code class="language-none">流式计算：数据实时产生、数据实时传输、数据实时计算、实时展示    代表技术：Flume实时获取数据、Kafka/metaq实时数据存储、Storm/JStorm实时数据计算、Redis实时结果缓存、持久化存储(mysql)。    一句话总结：将源源不断产生的数据实时收集并实时计算，尽可能快的得到计算结果</code></pre><h2 id="3、离线计算与实时计算的区别"><a href="#3、离线计算与实时计算的区别" class="headerlink" title="3、离线计算与实时计算的区别"></a>3、离线计算与实时计算的区别</h2><p><code>最大的区别：实时收集、实时计算、实时展示</code></p><h2 id="4、Storm是什么？"><a href="#4、Storm是什么？" class="headerlink" title="4、Storm是什么？"></a>4、Storm是什么？</h2><pre><code>Flume实时采集，低延迟Kafka消息队列，低延迟Storm实时计算，低延迟Redis实时存储，低延迟Storm用来实时处理数据，特点：低延迟、高可用、分布式、可扩展、数据不丢失。提供简单容易理解的接口，便于开发。海量数据？数据类型很多，产生数据的终端很多，处理数据能力增强</code></pre><h2 id="5、Storm与Hadoop的区别"><a href="#5、Storm与Hadoop的区别" class="headerlink" title="5、Storm与Hadoop的区别"></a>5、Storm与Hadoop的区别</h2><pre class="language-none"><code class="language-none">    • Storm用于实时计算，Hadoop用于离线计算。    • Storm处理的数据保存在内存中，源源不断；Hadoop处理的数据保存在文件系统中，一批一批。    • Storm的数据通过网络传输进来；Hadoop的数据保存在磁盘中。    • Storm与Hadoop的编程模型相似Job：任务名称JobTracker：项目经理TaskTracker：开发组长、产品经理Child:负责开发的人员Mapper/Reduce:开发人员中的两种角色，一种是服务器开发、一种是客户端开发Topology:任务名称Nimbus:项目经理Supervisor:开组长、产品经理Worker:开人员Spout/Bolt：开人员中的两种角色，一种是服务器开发、一种是客户端开发</code></pre><h2 id="6、Storm应用场景及行业案例"><a href="#6、Storm应用场景及行业案例" class="headerlink" title="6、Storm应用场景及行业案例"></a>6、Storm应用场景及行业案例</h2><pre><code>    Storm用来实时计算源源不断产生的数据，如同流水线生产。</code></pre><h3 id="6-1、运用场景"><a href="#6-1、运用场景" class="headerlink" title="6.1、运用场景"></a>6.1、运用场景</h3><pre class="language-none"><code class="language-none">    • 日志分析从海量日志中分析出特定的数据，并将分析的结果存入外部存储器用来辅佐决策。    • 管道系统将一个数据从一个系统传输到另外一个系统，比如将数据库同步到Hadoop    • 消息转化器将接受到的消息按照某种格式进行转化，存储到另外一个系统如消息中间件        </code></pre><h3 id="6-2、典型案列"><a href="#6-2、典型案列" class="headerlink" title="6.2、典型案列"></a>6.2、典型案列</h3><pre class="language-none"><code class="language-none">    • 一淘-实时分析系统：实时分析用户的属性，并反馈给搜索引擎最初，用户属性分析是通过每天在云梯上定时运行的MR job来完成的。为了满足实时性的要求，希望能够实时分析用户的行为日志，将最新的用户属性反馈给搜索引擎，能够为用户展现最贴近其当前需求的结果。    • 携程-网站性能监控：实时分析系统监控携程网的网站性能利用HTML5提供的performance标准获得可用的指标，并记录日志。Storm集群实时分析日志和入库。使用DRPC聚合成报表，通过历史数据对比等判断规则，触发预警事件。    • 阿里妈妈-用户画像：实时计算用户的兴趣数据为了更加精准投放广告，阿里妈妈后台计算引擎需要维护每个用户的兴趣点（理想状态是，你对什么感兴趣，就向你投放哪类广告）。用户兴趣主要基于用户的历史行为、用户的实时查询、用户的实时点击、用户的地理信息而得，其中实时查询、实时点击等用户行为都是实时数据。考虑到系统的实时性，阿里妈妈使用Storm维护用户兴趣数据，并在此基础上进行受众定向的广告投放。</code></pre><h2 id="7、Storm核心组件（重要）"><a href="#7、Storm核心组件（重要）" class="headerlink" title="7、Storm核心组件（重要）"></a>7、Storm核心组件（重要）</h2><p><img src="/images/20180823/1.png"></p><pre class="language-none"><code class="language-none">• Nimbus：负责资源分配和任务调度。• Supervisor：负责接受nimbus分配的任务，启动和停止属于自己管理的worker进程。---通过配置文件设置当前supervisor上启动多少个worker。• Worker：运行具体处理组件逻辑的进程。Worker运行的任务类型只有两种，一种是Spout任务，一种是Bolt任务。• Task：worker中每一个spout/bolt的线程称为一个task. 在storm0.8之后，task不再与物理线程对应，不同spout/bolt的task可能会共享一个物理线程，该线程称为executor。</code></pre><h2 id="8、Storm编程模型（重要）"><a href="#8、Storm编程模型（重要）" class="headerlink" title="8、Storm编程模型（重要）"></a>8、Storm编程模型（重要）</h2><p><img src="/images/20180823/2.png"></p><pre><code>    • Topology：Storm中运行的一个实时应用程序的名称。（拓扑）    • Spout：在一个topology中获取源数据流的组件。通常情况下spout会从外部数据源中读取数据，然后转换为topology内部的源数据。    • Bolt：接受数据然后执行处理的组件,用户可以在其中执行自己想要的操作。    • Tuple：一次消息传递的基本单元，理解为一组消息就是一个Tuple。    • Stream：表示数据的流向。</code></pre><h2 id="9、流式计算一般架构图（重要）"><a href="#9、流式计算一般架构图（重要）" class="headerlink" title="9、流式计算一般架构图（重要）"></a>9、流式计算一般架构图（重要）</h2><p><img src="/images/20180823/3.png"></p><pre><code>• 其中flume用来获取数据。• Kafka用来临时保存数据。• Strom用来计算数据。• Redis是个内存数据库，用来保存数据。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> storm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> storm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hbase学习二</title>
      <link href="/2018/08/22/hbase-xue-xi-er/"/>
      <url>/2018/08/22/hbase-xue-xi-er/</url>
      
        <content type="html"><![CDATA[<h1 id="hbase基础二"><a href="#hbase基础二" class="headerlink" title=" hbase基础二"></a><center> hbase基础二</center></h1><h2 id="1-hbase原理"><a href="#1-hbase原理" class="headerlink" title="1. hbase原理"></a>1. hbase原理</h2><h3 id="1-1-hbase体系图"><a href="#1-1-hbase体系图" class="headerlink" title="1.1 hbase体系图"></a>1.1 hbase体系图</h3><p><img src="/images/20180822/2.png"></p><h4 id="1-1-1写流程"><a href="#1-1-1写流程" class="headerlink" title="1.1.1写流程"></a>1.1.1写流程</h4><pre class="language-none"><code class="language-none">1、 client向hregionserver发送写请求。2、 hregionserver将数据写到hlog（write ahead log）。为了数据的持久化和恢复。3、 hregionserver将数据写到内存（memstore）4、 反馈client写成功。</code></pre><h4 id="1-1-2-数据flush过程"><a href="#1-1-2-数据flush过程" class="headerlink" title="1.1.2  数据flush过程"></a>1.1.2  数据flush过程</h4><pre class="language-none"><code class="language-none">1、 当memstore数据达到阈值（默认是64M），将数据刷到硬盘，将内存中的数据删除，同时删除Hlog中的历史数据。2、 并将数据存储到hdfs中。3、 在hlog中做标记点。</code></pre><h4 id="1-1-3数据合并过程"><a href="#1-1-3数据合并过程" class="headerlink" title="1.1.3数据合并过程"></a>1.1.3数据合并过程</h4><pre class="language-none"><code class="language-none">1、 当数据块达到4块，hmaster将数据块加载到本地，进行合并2、 当合并的数据超过256M，进行拆分，将拆分后的region分配给不同的hregionserver管理3、 当hregionser宕机后，将hregionserver上的hlog拆分，然后分配给不同的hregionserver加载，修改.META.    4、 注意：hlog会同步到hdfs</code></pre><h4 id="1-1-4-hbase的读流程"><a href="#1-1-4-hbase的读流程" class="headerlink" title="1.1.4 hbase的读流程"></a>1.1.4 hbase的读流程</h4><pre class="language-none"><code class="language-none">1、 通过zookeeper和-ROOT- .META.表定位hregionserver。2、 数据从内存和硬盘合并后返回给client3、 数据块会缓存   </code></pre><h4 id="1-1-5hmaster的职责"><a href="#1-1-5hmaster的职责" class="headerlink" title="1.1.5hmaster的职责"></a>1.1.5hmaster的职责</h4><pre class="language-none"><code class="language-none">1、管理用户对Table的增、删、改、查操作； 2、记录region在哪台Hregion server上3、在Region Split后，负责新Region的分配； 4、新机器加入时，管理HRegion Server的负载均衡，调整Region分布5、在HRegion Server宕机后，负责失效HRegion Server 上的Regions迁移。     </code></pre><h4 id="1-1-6-hregionserver的职责"><a href="#1-1-6-hregionserver的职责" class="headerlink" title="1.1.6 hregionserver的职责"></a>1.1.6 hregionserver的职责</h4><pre class="language-none"><code class="language-none">HRegion Server主要负责响应用户I/O请求，向HDFS文件系统中读写数据，是HBASE中最核心的模块。HRegion Server管理了很多table的分区，也就是region。</code></pre><h4 id="1-1-7-client职责"><a href="#1-1-7-client职责" class="headerlink" title="1.1.7 client职责"></a>1.1.7 client职责</h4><pre class="language-none"><code class="language-none">ClientHBASE Client使用HBASE的RPC机制与HMaster和RegionServer进行通信管理类操作：Client与HMaster进行RPC；数据读写类操作：Client与HRegionServer进行RPC。</code></pre><h3 id="1-2MapReduce操作Hbase"><a href="#1-2MapReduce操作Hbase" class="headerlink" title="1.2MapReduce操作Hbase"></a>1.2MapReduce操作Hbase</h3><h4 id="1-2-1-实现方法"><a href="#1-2-1-实现方法" class="headerlink" title="1.2.1 实现方法"></a>1.2.1 实现方法</h4><pre class="language-none"><code class="language-none">Hbase对MapReduce提供支持，它实现了TableMapper类和TableReducer类，我们只需要继承这两个类即可。1、写个mapper继承TableMapper&lt;Text, IntWritable&gt;    参数：Text：mapper的输出key类型； IntWritable：mapper的输出value类型。      其中的map方法如下：    map(ImmutableBytesWritable key, Result value,Context context)     参数：key：rowKey；value： Result ，一行数据； context上下文2、写个reduce继承TableReducer&lt;Text, IntWritable, ImmutableBytesWritable&gt;    参数：Text:reducer的输入key； IntWritable：reduce的输入value；     ImmutableBytesWritable：reduce输出到hbase中的rowKey类型。      其中的reduce方法如下：    reduce(Text key, Iterable&lt;IntWritable&gt; values,Context context)    参数： key：reduce的输入key；values：reduce的输入value；</code></pre><h4 id="1-2-2-准备表"><a href="#1-2-2-准备表" class="headerlink" title="1.2.2 准备表"></a>1.2.2 准备表</h4><pre class="language-none"><code class="language-none">1、建立数据来源表‘word’，包含一个列族‘content’向表中添加数据，在列族中放入列‘info’，并将短文数据放入该列中，如此插入多行，行键为不同的数据即可2、建立输出表‘stat’，包含一个列族‘content’3、通过Mr操作Hbase的‘word’表，对‘content：info’中的短文做词频统计，并将统计结果写入‘stat’表的‘content：info中’，行键为单词</code></pre><h4 id="1-2-3实现"><a href="#1-2-3实现" class="headerlink" title="1.2.3实现"></a>1.2.3实现</h4><pre class="language-none"><code class="language-none">package com.itcast.hbase;import java.io.IOException;import java.util.ArrayList;import java.util.List;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.HColumnDescriptor;import org.apache.hadoop.hbase.HTableDescriptor;import org.apache.hadoop.hbase.client.HBaseAdmin;import org.apache.hadoop.hbase.client.HTable;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.client.Scan;import org.apache.hadoop.hbase.io.ImmutableBytesWritable;import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;import org.apache.hadoop.hbase.mapreduce.TableMapper;import org.apache.hadoop.hbase.mapreduce.TableReducer;import org.apache.hadoop.hbase.util.Bytes;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;/** * mapreduce操作hbase * @author wilson * */public class HBaseMr {    /**     * 创建hbase配置     */    static Configuration config = null;    static {        config = HBaseConfiguration.create();        config.set("hbase.zookeeper.quorum", "slave1,slave2,slave3");        config.set("hbase.zookeeper.property.clientPort", "2181");    }    /**     * 表信息     */    public static final String tableName = "word";//表名1    public static final String colf = "content";//列族    public static final String col = "info";//列    public static final String tableName2 = "stat";//表名2    /**     * 初始化表结构，及其数据     */    public static void initTB() {        HTable table=null;        HBaseAdmin admin=null;        try {            admin = new HBaseAdmin(config);//创建表管理            /*删除表*/            if (admin.tableExists(tableName)||admin.tableExists(tableName2)) {                System.out.println("table is already exists!");                admin.disableTable(tableName);                admin.deleteTable(tableName);                admin.disableTable(tableName2);                admin.deleteTable(tableName2);            }            /*创建表*/                HTableDescriptor desc = new HTableDescriptor(tableName);                HColumnDescriptor family = new HColumnDescriptor(colf);                desc.addFamily(family);                admin.createTable(desc);                HTableDescriptor desc2 = new HTableDescriptor(tableName2);                HColumnDescriptor family2 = new HColumnDescriptor(colf);                desc2.addFamily(family2);                admin.createTable(desc2);            /*插入数据*/                table = new HTable(config,tableName);                table.setAutoFlush(false);                table.setWriteBufferSize(5);                List&lt;Put&gt; lp = new ArrayList&lt;Put&gt;();                Put p1 = new Put(Bytes.toBytes("1"));                p1.add(colf.getBytes(), col.getBytes(),    ("The Apache Hadoop software library is a framework").getBytes());                lp.add(p1);                Put p2 = new Put(Bytes.toBytes("2"));p2.add(colf.getBytes(),col.getBytes(),("The common utilities that support the other Hadoop modules").getBytes());                lp.add(p2);                Put p3 = new Put(Bytes.toBytes("3"));                p3.add(colf.getBytes(), col.getBytes(),("Hadoop by reading the documentation").getBytes());                lp.add(p3);                Put p4 = new Put(Bytes.toBytes("4"));                p4.add(colf.getBytes(), col.getBytes(),("Hadoop from the release page").getBytes());                lp.add(p4);                Put p5 = new Put(Bytes.toBytes("5"));                p5.add(colf.getBytes(), col.getBytes(),("Hadoop on the mailing list").getBytes());                lp.add(p5);                table.put(lp);                table.flushCommits();                lp.clear();        } catch (Exception e) {            e.printStackTrace();        } finally {            try {                if(table!=null){                    table.close();                }            } catch (IOException e) {                e.printStackTrace();            }        }    }    /**     * MyMapper 继承 TableMapper     * TableMapper&lt;Text,IntWritable&gt;      * Text:输出的key类型，     * IntWritable：输出的value类型     */    public static class MyMapper extends TableMapper&lt;Text, IntWritable&gt; {        private static IntWritable one = new IntWritable(1);        private static Text word = new Text();        @Override        //输入的类型为：key：rowKey； value：一行数据的结果集Result        protected void map(ImmutableBytesWritable key, Result value,                Context context) throws IOException, InterruptedException {            //获取一行数据中的colf：col            String words = Bytes.toString(value.getValue(Bytes.toBytes(colf), Bytes.toBytes(col)));// 表里面只有一个列族，所以我就直接获取每一行的值            //按空格分割            String itr[] = words.toString().split(" ");            //循环输出word和1            for (int i = 0; i &lt; itr.length; i++) {                word.set(itr[i]);                context.write(word, one);            }        }    }    /**     * MyReducer 继承 TableReducer     * TableReducer&lt;Text,IntWritable&gt;      * Text:输入的key类型，     * IntWritable：输入的value类型，     * ImmutableBytesWritable：输出类型，表示rowkey的类型     */    public static class MyReducer extends            TableReducer&lt;Text, IntWritable, ImmutableBytesWritable&gt; {        @Override        protected void reduce(Text key, Iterable&lt;IntWritable&gt; values,                Context context) throws IOException, InterruptedException {            //对mapper的数据求和            int sum = 0;            for (IntWritable val : values) {//叠加                sum += val.get();            }            // 创建put，设置rowkey为单词            Put put = new Put(Bytes.toBytes(key.toString()));            // 封装数据            put.add(Bytes.toBytes(colf), Bytes.toBytes(col),Bytes.toBytes(String.valueOf(sum)));            //写到hbase,需要指定rowkey、put            context.write(new ImmutableBytesWritable(Bytes.toBytes(key.toString())),put);        }    }    public static void main(String[] args) throws IOException,            ClassNotFoundException, InterruptedException {        config.set("df.default.name", "hdfs://master:9000/");//设置hdfs的默认路径        config.set("hadoop.job.ugi", "hadoop,hadoop");//用户名，组        config.set("mapred.job.tracker", "master:9001");//设置jobtracker在哪        //初始化表        initTB();//初始化表        //创建job        Job job = new Job(config, "HBaseMr");//job        job.setJarByClass(HBaseMr.class);//主类        //创建scan        Scan scan = new Scan();        //可以指定查询某一列        scan.addColumn(Bytes.toBytes(colf), Bytes.toBytes(col));        //创建查询hbase的mapper，设置表名、scan、mapper类、mapper的输出key、mapper的输出value        TableMapReduceUtil.initTableMapperJob(tableName, scan, MyMapper.class,Text.class, IntWritable.class, job);        //创建写入hbase的reducer，指定表名、reducer类、job        TableMapReduceUtil.initTableReducerJob(tableName2, MyReducer.class, job);        System.exit(job.waitForCompletion(true) ? 0 : 1);    }}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hbase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hbase学习一</title>
      <link href="/2018/08/22/hbase-xue-xi-yi/"/>
      <url>/2018/08/22/hbase-xue-xi-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="HBASE"><a href="#HBASE" class="headerlink" title="HBASE"></a><center>HBASE</center></h1><h2 id="1-hbase简介"><a href="#1-hbase简介" class="headerlink" title="1. hbase简介"></a>1. hbase简介</h2><h3 id="1-1-什么是hbase"><a href="#1-1-什么是hbase" class="headerlink" title="1.1 什么是hbase"></a>1.1 什么是hbase</h3><pre class="language-none"><code class="language-none">HBASE是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBASE技术可在廉价PC Server上搭建起大规模结构化存储集群。HBASE的目标是存储并处理大型的数据，更具体来说是仅需使用普通的硬件配置，就能够处理由成千上万的行和列所组成的大型数据。HBASE是Google Bigtable的开源实现，但是也有很多不同之处。比如：Google Bigtable利用GFS作为其文件存储系统，HBASE利用Hadoop HDFS作为其文件存储系统；Google运行MAPREDUCE来处理Bigtable中的海量数据，HBASE同样利用Hadoop MapReduce来处理HBASE中的海量数据；Google Bigtable利用Chubby作为协同服务，HBASE利用Zookeeper作为对应。</code></pre><h3 id="1-2-与传统数据库的对比"><a href="#1-2-与传统数据库的对比" class="headerlink" title="1.2 与传统数据库的对比"></a>1.2 与传统数据库的对比</h3><pre class="language-none"><code class="language-none">1、传统数据库遇到的问题：1）数据量很大的时候无法存储2）没有很好的备份机制3）数据达到一定数量开始缓慢，很大的话基本无法支撑2、HBASE优势：1）线性扩展，随着数据量增多可以通过节点扩展进行支撑2）数据存储在hdfs上，备份机制健全3）通过zookeeper协调查找数据，访问速度块。</code></pre><h3 id="1-3hbase集群中的角色"><a href="#1-3hbase集群中的角色" class="headerlink" title="1.3hbase集群中的角色"></a>1.3hbase集群中的角色</h3><pre class="language-none"><code class="language-none">1、一个或者多个主节点，Hmaster2、多个从节点，HregionServer</code></pre><h2 id="2-habse安装"><a href="#2-habse安装" class="headerlink" title="2.habse安装"></a>2.habse安装</h2><pre class="language-none"><code class="language-none">2.1. hbase安装2.1.1. 上传用工具上传 2.1.2. 解压su – hadooptar -zxvf hbase-0.94.6.tar.gz2.1.3. 重命名mv hbase-0.94.6 hbase2.1.4. 修改环境变量(每台机器都要执行)su – rootvi /etc/profile添加内容：export HBASE_HOME=/home/hadoop/hbaseexport PATH=$PATH:$HBASE_HOME/binsource /etc/profliesu - hadoop2.1.5. 修改配置文件上传配置文件 2.1.6. 分发到其他节点scp -r /home/hadoop/hbase hadoop@slave1:/home/hadoop/scp -r /home/hadoop/hbase hadoop@slave2:/home/hadoop/scp -r /home/hadoop/hbase hadoop@slave3:/home/hadoop/2.1.7. 启动注意：启动hbase之前，必须保证hadoop集群和zookeeper集群是可用的。start-hbase.sh2.1.8. 监控    1、 进入命令行hbase shell    2、 页面监控http://master:60010/</code></pre><h2 id="3-hbase数据模型"><a href="#3-hbase数据模型" class="headerlink" title="3.hbase数据模型"></a>3.hbase数据模型</h2><h3 id="3-1hbase数据模型"><a href="#3-1hbase数据模型" class="headerlink" title="3.1hbase数据模型"></a>3.1hbase数据模型</h3><p><img src="/images/20180822/1.png"></p><h4 id="3-1-1-Row-Key"><a href="#3-1-1-Row-Key" class="headerlink" title="3.1.1 Row Key"></a>3.1.1 Row Key</h4><pre class="language-none"><code class="language-none">与nosql数据库们一样,row key是用来检索记录的主键。访问HBASE table中的行，只有三种方式：1.通过单个row key访问2.通过row key的range（正则）3.全表扫描Row key行键 (Row key)可以是任意字符串(最大长度 是 64KB，实际应用中长度一般为 10-100bytes)，在HBASE内部，row key保存为字节数组。存储时，数据按照Row key的字典序(byte order)排序存储。设计key时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。(位置相关性)</code></pre><h4 id="3-1-2-Columns-Family"><a href="#3-1-2-Columns-Family" class="headerlink" title="3.1.2 Columns Family"></a>3.1.2 Columns Family</h4><pre class="language-none"><code class="language-none">列簇 ：HBASE表中的每个列，都归属于某个列族。列族是表的schema的一部 分(而列不是)，必须在使用表之前定义。列名都以列族作为前缀。例如 courses:history，courses:math都属于courses 这个列族。</code></pre><h4 id="3-1-3-Cell"><a href="#3-1-3-Cell" class="headerlink" title="3.1.3 Cell"></a>3.1.3 Cell</h4><pre class="language-none"><code class="language-none">由{row key, columnFamily, version} 唯一确定的单元。cell中 的数据是没有类型的，全部是字节码形式存贮。关键字：无类型、字节码</code></pre><h4 id="3-1-4-Time-Stamp"><a href="#3-1-4-Time-Stamp" class="headerlink" title="3.1.4 Time Stamp"></a>3.1.4 Time Stamp</h4><pre class="language-none"><code class="language-none">HBASE 中通过rowkey和columns确定的为一个存贮单元称为cell。每个 cell都保存 着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是 64位整型。时间戳可以由HBASE(在数据写入时自动 )赋值，此时时间戳是精确到毫秒 的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版 本冲突，就必须自己生成具有唯一性的时间戳。每个 cell中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。为了避免数据存在过多版本造成的的管理 (包括存贮和索引)负担，HBASE提供 了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段 时间内的版本（比如最近七天）。用户可以针对每个列族进行设置。</code></pre><h2 id="4-hbase命令"><a href="#4-hbase命令" class="headerlink" title="4.hbase命令"></a>4.hbase命令</h2><h3 id="4-1命令的进退"><a href="#4-1命令的进退" class="headerlink" title="4.1命令的进退"></a>4.1命令的进退</h3><pre class="language-none"><code class="language-none">1、hbase提供了一个shell的终端给用户交互#$HBASE_HOME/bin/hbase shell 2、如果退出执行quit命令#$HBASE_HOME/bin/hbase shell…… &gt;quit</code></pre><h3 id="4-2-hbase命令"><a href="#4-2-hbase命令" class="headerlink" title="4.2 hbase命令"></a>4.2 hbase命令</h3><pre class="language-none"><code class="language-none">名称   命令表达式创建表  create '表名', '列族名1','列族名2','列族名N'查看所有表  list描述表     describe  ‘表名’判断表存在    exists  '表名'判断是否禁用启用表   is_enabled '表名'    is_disabled ‘表名’添加记录   put  ‘表名’, ‘rowKey’, ‘列族 : 列‘  ,  '值'查看记录rowkey下的所有数据     get  '表名' , 'rowKey'查看表中的记录总数   count  '表名'获取某个列族   get '表名','rowkey','列族'获取某个列族的某个列   get '表名','rowkey','列族：列’删除记录   delete  ‘表名’ ,‘行名’ , ‘列族：列'删除整行  deleteall '表名','rowkey'删除一张表   先要屏蔽该表，才能对该表进行删除   第一步 disable ‘表名’ ，第二步  drop '表名'清空表    truncate '表名'查看所有记录  scan "表名"  查看某个表某个列中所有数据   scan "表名" , {COLUMNS=&gt;'列族名:列名'}更新记录   就是重写一遍，进行覆盖，hbase没有修改，都是追加</code></pre><h2 id="5-hbase依赖zookeeper"><a href="#5-hbase依赖zookeeper" class="headerlink" title="5.hbase依赖zookeeper"></a>5.hbase依赖zookeeper</h2><pre class="language-none"><code class="language-none">    1、 保存Hmaster的地址和backup-master地址hmaster：    a) 管理HregionServer    b) 做增删改查表的节点    c) 管理HregionServer中的表分配    2、 保存表-ROOT-的地址hbase默认的根表，检索表。    3、 HRegionServer列表表的增删改查数据。和hdfs交互，存取数据。</code></pre><h2 id="6-hbase开发"><a href="#6-hbase开发" class="headerlink" title="6.hbase开发"></a>6.hbase开发</h2><h3 id="6-1-配置"><a href="#6-1-配置" class="headerlink" title="6.1 配置"></a>6.1 配置</h3><pre class="language-none"><code class="language-none">HBaseConfiguration包：org.apache.hadoop.hbase.HBaseConfiguration作用：通过此类可以对HBase进行配置用法实例： Configuration config = HBaseConfiguration.create();说明： HBaseConfiguration.create() 默认会从classpath 中查找 hbase-site.xml 中的配置信息，初始化 Configuration。使用方法:static Configuration config = null;static {     config = HBaseConfiguration.create();     config.set("hbase.zookeeper.quorum", "slave1,slave2,slave3");     config.set("hbase.zookeeper.property.clientPort", "2181");}</code></pre><h3 id="6-2-表管理类"><a href="#6-2-表管理类" class="headerlink" title="6.2 表管理类"></a>6.2 表管理类</h3><pre class="language-none"><code class="language-none">HBaseAdmin包：org.apache.hadoop.hbase.client.HBaseAdmin作用：提供接口关系HBase 数据库中的表信息用法：HBaseAdmin admin = new HBaseAdmin(config);</code></pre><h3 id="6-2表描述类"><a href="#6-2表描述类" class="headerlink" title="6.2表描述类"></a>6.2表描述类</h3><pre class="language-none"><code class="language-none">HTableDescriptor包：org.apache.hadoop.hbase.HTableDescriptor作用：HTableDescriptor 类包含了表的名字以及表的列族信息          表的schema（设计）用法：HTableDescriptor htd =new HTableDescriptor(tablename);htd.addFamily(new HColumnDescriptor(“myFamily”));</code></pre><h3 id="6-3列族的描述类"><a href="#6-3列族的描述类" class="headerlink" title="6.3列族的描述类"></a>6.3列族的描述类</h3><pre class="language-none"><code class="language-none">HColumnDescriptor包：org.apache.hadoop.hbase.HColumnDescriptor作用：HColumnDescriptor 维护列族的信息用法：htd.addFamily(new HColumnDescriptor(“myFamily”));</code></pre><h3 id="6-4-创建表的操作"><a href="#6-4-创建表的操作" class="headerlink" title="6.4 创建表的操作"></a>6.4 创建表的操作</h3><pre class="language-none"><code class="language-none">CreateTable（一般我们用shell创建表）static Configuration config = null;static {     config = HBaseConfiguration.create();     config.set("hbase.zookeeper.quorum", "slave1,slave2,slave3");     config.set("hbase.zookeeper.property.clientPort", "2181");}HBaseAdmin admin = new HBaseAdmin(config);HTableDescriptor desc = new HTableDescriptor(tableName);HColumnDescriptor family1 = new HColumnDescriptor(“f1”);HColumnDescriptor family2 = new HColumnDescriptor(“f2”);desc.addFamily(family1);desc.addFamily(family2);admin.createTable(desc);</code></pre><h3 id="6-5删除表"><a href="#6-5删除表" class="headerlink" title="6.5删除表"></a>6.5删除表</h3><pre class="language-none"><code class="language-none">HBaseAdmin admin = new HBaseAdmin(config);admin.disableTable(tableName);admin.deleteTable(tableName);</code></pre><h3 id="6-6创建一个表的类"><a href="#6-6创建一个表的类" class="headerlink" title="6.6创建一个表的类"></a>6.6创建一个表的类</h3><pre class="language-none"><code class="language-none">HTable包：org.apache.hadoop.hbase.client.HTable作用：HTable 和 HBase 的表通信用法：// 普通获取表 HTable table = new HTable(config,Bytes.toBytes(tablename);// 通过连接池获取表Connection connection = ConnectionFactory.createConnection(config);HTableInterface table = connection.getTable(TableName.valueOf("user"));</code></pre><h3 id="6-7插入单条数据"><a href="#6-7插入单条数据" class="headerlink" title="6.7插入单条数据"></a>6.7插入单条数据</h3><pre class="language-none"><code class="language-none">Put包：org.apache.hadoop.hbase.client.Put作用：插入数据用法：Put put = new Put(row);p.add(family,qualifier,value);说明：向表 tablename 添加 “family,qualifier,value”指定的值。示例代码：Connection connection = ConnectionFactory.createConnection(config);HTableInterface table = connection.getTable(TableName.valueOf("user"));Put put = new Put(Bytes.toBytes(rowKey));put.add(Bytes.toBytes(family), Bytes.toBytes(qualifier),Bytes.toBytes(value));table.put(put);</code></pre><h3 id="6-8批量插入数据"><a href="#6-8批量插入数据" class="headerlink" title="6.8批量插入数据"></a>6.8批量插入数据</h3><pre class="language-none"><code class="language-none">批量插入List&lt;Put&gt; list = new ArrayList&lt;Put&gt;();Put put = new Put(Bytes.toBytes(rowKey));//获取put，用于插入put.add(Bytes.toBytes(family), Bytes.toBytes(qualifier),Bytes.toBytes(value));//封装信息list.add(put);table.put(list);//添加记录</code></pre><h3 id="6-9-删除数据"><a href="#6-9-删除数据" class="headerlink" title="6.9 删除数据"></a>6.9 删除数据</h3><pre class="language-none"><code class="language-none">Delete包：org.apache.hadoop.hbase.client.Delete作用：删除给定rowkey的数据用法：Delete del= new Delete(Bytes.toBytes(rowKey));table.delete(del);代码实例Connection connection = ConnectionFactory.createConnection(config);HTableInterface table = connection.getTable(TableName.valueOf("user"));Delete del= new Delete(Bytes.toBytes(rowKey));table.delete(del);</code></pre><h3 id="6-10-单条查询"><a href="#6-10-单条查询" class="headerlink" title="6.10 单条查询"></a>6.10 单条查询</h3><pre class="language-none"><code class="language-none">Get包：org.apache.hadoop.hbase.client.Get作用：获取单个行的数据用法：HTable table = new HTable(config,Bytes.toBytes(tablename));Get get = new Get(Bytes.toBytes(row));Result result = table.get(get);说明：获取 tablename 表中 row 行的对应数据代码示例：Connection connection = ConnectionFactory.createConnection(config);HTableInterface table = connection.getTable(TableName.valueOf("user"));Get get = new Get(rowKey.getBytes());Result row = table.get(get);for (KeyValue kv : row.raw()) {    System.out.print(new String(kv.getRow()) + " ");    System.out.print(new String(kv.getFamily()) + ":");    System.out.print(new String(kv.getQualifier()) + " = ");    System.out.print(new String(kv.getValue()));    System.out.print(" timestamp = " + kv.getTimestamp() + "\n");}</code></pre><h3 id="6-11-批量查询"><a href="#6-11-批量查询" class="headerlink" title="6.11 批量查询"></a>6.11 批量查询</h3><pre class="language-none"><code class="language-none">ResultScanner包：org.apache.hadoop.hbase.client.ResultScanner作用：获取值的接口用法：ResultScanner scanner = table.getScanner(scan);For(Result rowResult : scanner){       &nbsp;Bytes[] str = rowResult.getValue(family,column);}说明：循环获取行中列值。代码示例：Connection connection = ConnectionFactory.createConnection(config);HTableInterface table = connection.getTable(TableName.valueOf("user"));Scan scan = new Scan();scan.setStartRow("a1".getBytes());scan.setStopRow("a20".getBytes());ResultScanner scanner = table.getScanner(scan);for (Result row : scanner) {    System.out.println("\nRowkey: " + new String(row.getRow()));    for (KeyValue kv : row.raw()) {         System.out.print(new String(kv.getRow()) + " ");         System.out.print(new String(kv.getFamily()) + ":");         System.out.print(new String(kv.getQualifier()) + " = ");         System.out.print(new String(kv.getValue()));         System.out.print(" timestamp = " + kv.getTimestamp() + "\n");    }}</code></pre><h3 id="6-3-hbase过滤器"><a href="#6-3-hbase过滤器" class="headerlink" title="6.3  hbase过滤器"></a>6.3  hbase过滤器</h3><h4 id="6-3-1-FilterList"><a href="#6-3-1-FilterList" class="headerlink" title="6.3.1  FilterList"></a>6.3.1  FilterList</h4><pre class="language-none"><code class="language-none">FilterList 代表一个过滤器列表，可以添加多个过滤器进行查询，多个过滤器之间的关系有：与关系（符合所有）：FilterList.Operator.MUST_PASS_ALL  或关系（符合任一）：FilterList.Operator.MUST_PASS_ONE    使用方法：FilterList&nbsp;filterList&nbsp;=&nbsp;new&nbsp;FilterList(FilterList.Operator.MUST_PASS_ONE);&nbsp;&nbsp;&nbsp;Scan&nbsp;s1&nbsp;=&nbsp;new&nbsp;Scan();&nbsp;&nbsp;&nbsp;filterList.addFilter(new&nbsp;SingleColumnValueFilter(Bytes.toBytes(“f1”),&nbsp;&nbsp;Bytes.toBytes(“c1”),&nbsp;&nbsp;CompareOp.EQUAL,Bytes.toBytes(“v1”)&nbsp;)&nbsp;&nbsp;);&nbsp;&nbsp;filterList.addFilter(new&nbsp;SingleColumnValueFilter(Bytes.toBytes(“f1”),&nbsp;&nbsp;Bytes.toBytes(“c2”),&nbsp;&nbsp;CompareOp.EQUAL,Bytes.toBytes(“v2”)&nbsp;)&nbsp;&nbsp;);&nbsp;&nbsp;&nbsp;//&nbsp;添加下面这一行后，则只返回指定的cell，同一行中的其他cell不返回&nbsp;&nbsp; s1.addColumn(Bytes.toBytes(“f1”),&nbsp;Bytes.toBytes(“c1”));&nbsp;&nbsp;&nbsp;s1.setFilter(filterList);&nbsp;&nbsp;//设置filter&nbsp;ResultScanner&nbsp;ResultScannerFilterList&nbsp;=&nbsp;table.getScanner(s1);&nbsp;&nbsp;//返回结果列表</code></pre><h4 id="6-3-2过滤器的种类"><a href="#6-3-2过滤器的种类" class="headerlink" title="6.3.2过滤器的种类"></a>6.3.2过滤器的种类</h4><pre class="language-none"><code class="language-none">过滤器的种类：列植过滤器—SingleColumnValueFilter       过滤列植的相等、不等、范围等列名前缀过滤器—ColumnPrefixFilter       过滤指定前缀的列名多个列名前缀过滤器—MultipleColumnPrefixFilter       过滤多个指定前缀的列名rowKey过滤器—RowFilter      通过正则，过滤rowKey值。</code></pre><h4 id="6-3-3列植过滤器—SingleColumnValueFilter"><a href="#6-3-3列植过滤器—SingleColumnValueFilter" class="headerlink" title="6.3.3列植过滤器—SingleColumnValueFilter"></a>6.3.3列植过滤器—SingleColumnValueFilter</h4><pre class="language-none"><code class="language-none">SingleColumnValueFilter 列值判断相等 (CompareOp.EQUAL ), 不等(CompareOp.NOT_EQUAL),范围 (e.g., CompareOp.GREATER)…………下面示例检查列值和字符串'values' 相等...SingleColumnValueFilter f = new  SingleColumnValueFilter(            Bytes.toBytes("cFamily")                              Bytes.toBytes("column"),             CompareFilter.CompareOp.EQUAL,        Bytes.toBytes("values"));s1.setFilter(f);注意：如果过滤器过滤的列在数据表中有的行中不存在，那么这个过滤器对此行无法过滤。</code></pre><h4 id="6-3-4-列名前缀过滤器—ColumnPrefixFilter"><a href="#6-3-4-列名前缀过滤器—ColumnPrefixFilter" class="headerlink" title="6.3.4 列名前缀过滤器—ColumnPrefixFilter"></a>6.3.4 列名前缀过滤器—ColumnPrefixFilter</h4><pre class="language-none"><code class="language-none">过滤器—ColumnPrefixFilter ColumnPrefixFilter 用于指定列名前缀值相等ColumnPrefixFilter f = new ColumnPrefixFilter(Bytes.toBytes("values"));s1.setFilter(f);</code></pre><h4 id="6-3-5-多个列值前缀过滤器—MultipleColumnPrefixFilter"><a href="#6-3-5-多个列值前缀过滤器—MultipleColumnPrefixFilter" class="headerlink" title="6.3.5 多个列值前缀过滤器—MultipleColumnPrefixFilter"></a>6.3.5 多个列值前缀过滤器—MultipleColumnPrefixFilter</h4><pre class="language-none"><code class="language-none">MultipleColumnPrefixFilter 和 ColumnPrefixFilter 行为差不多，但可以指定多个前缀byte[][] prefixes = new byte[][] {Bytes.toBytes("value1"),Bytes.toBytes("value2")};Filter f = new MultipleColumnPrefixFilter(prefixes);s1.setFilter(f);</code></pre><h4 id="6-3-6rowKey过滤器—RowFilter"><a href="#6-3-6rowKey过滤器—RowFilter" class="headerlink" title="6.3.6rowKey过滤器—RowFilter"></a>6.3.6rowKey过滤器—RowFilter</h4><pre class="language-none"><code class="language-none">RowFilter 是rowkey过滤器通常根据rowkey来指定范围时，使用scan扫描器的StartRow和StopRow方法比较好。Filter f = new RowFilter(CompareFilter.CompareOp.EQUAL, new RegexStringComparator("^1234")); //匹配以1234开头的rowkeys1.setFilter(f);</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hbase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sqoop学习</title>
      <link href="/2018/08/21/sqoop-xue-xi/"/>
      <url>/2018/08/21/sqoop-xue-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="sqoop教程"><a href="#sqoop教程" class="headerlink" title=" sqoop教程"></a><center> sqoop教程</center></h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h2><p>sqoop是apache旗下一款“Hadoop和关系数据库服务器之间传送数据”的工具。<br>导入数据：MySQL，Oracle导入数据到Hadoop的HDFS、HIVE、HBASE等数据存储系统；<br>导出数据：从Hadoop的文件系统中导出数据到关系数据库</p><p><img src="/images/20180821/12.png"></p><h2 id="2-工作机制"><a href="#2-工作机制" class="headerlink" title="2. 工作机制"></a>2. 工作机制</h2><p>将导入或导出命令翻译成mapreduce程序来实现<br>在翻译出的mapreduce中主要是对inputformat和outputformat进行定制</p><h2 id="3-sqoop安装"><a href="#3-sqoop安装" class="headerlink" title="3.sqoop安装"></a>3.sqoop安装</h2><pre class="language-none"><code class="language-none">安装sqoop的前提是已经具备java和hadoop的环境1、下载并解压最新版下载地址http://ftp.wayne.edu/apache/sqoop/1.4.6/2、修改配置文件$ cd $SQOOP_HOME/conf$ mv sqoop-env-template.sh sqoop-env.sh打开sqoop-env.sh并编辑下面几行：export HADOOP_COMMON_HOME=/home/hadoop/apps/hadoop-2.6.1/ export HADOOP_MAPRED_HOME=/home/hadoop/apps/hadoop-2.6.1/export HIVE_HOME=/home/hadoop/apps/hive-1.2.1    3、 加入mysql的jdbc驱动包cp  ~/app/hive/lib/mysql-connector-java-5.1.28.jar   $SQOOP_HOME/lib/4、验证启动$ cd $SQOOP_HOME/bin$ sqoop-version预期的输出：15/12/17 14:52:32 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6Sqoop 1.4.6 git commit id 5b34accaca7de251fc91161733f906af2eddbe83Compiled by abe on Fri Aug 1 11:19:26 PDT 2015到这里，整个Sqoop安装工作完成。</code></pre><h3 id="4-Sqoop的数据导入"><a href="#4-Sqoop的数据导入" class="headerlink" title="4.Sqoop的数据导入"></a>4.Sqoop的数据导入</h3><p>“导入工具”导入单个表从RDBMS到HDFS。表中的每一行被视为HDFS的记录。所有记录都存储为文本文件的文本数据（或者Avro、sequence文件等二进制数据）&nbsp;</p><pre class="language-none"><code class="language-none">下面的语法用于将数据导入HDFS。$ sqoop import (generic-args) (import-args) 导入表表数据到HDFS下面的命令用于从MySQL数据库服务器中的emp表导入HDFS。$bin/sqoop import \--connect jdbc:mysql://hdp-node-01:3306/test \--username root \--password root \--table emp --m 1为了验证在HDFS导入的数据，请使用以下命令查看导入的数据$ $HADOOP_HOME/bin/hadoop fs -cat /user/hadoop/emp/part-m-00000</code></pre><p>导入关系表到HIVE</p><pre class="language-none"><code class="language-none">bin/sqoop import --connect jdbc:mysql://hdp-node-01:3306/test --username root --password root --table emp --hive-import --m 1</code></pre><p>导入到HDFS指定目录</p><pre class="language-none"><code class="language-none">在导入表数据到HDFS使用Sqoop导入工具，我们可以指定目标目录。以下是指定目标目录选项的Sqoop导入命令的语法。--target-dir &lt;new or exist directory in HDFS&gt;下面的命令是用来导入emp_add表数据到'/queryresult'目录。bin/sqoop import \--connect jdbc:mysql://hdp-node-01:3306/test \--username root \--password root \--target-dir /queryresult \--table emp --m 1下面的命令是用来验证 /queryresult&nbsp;目录中 emp_add表导入的数据形式。 $HADOOP_HOME/bin/hadoop fs -cat /queryresult/part-m-*它会用逗号（，）分隔emp_add表的数据和字段。1201, 288A, vgiri,   jublee1202, 108I, aoc,     sec-bad1203, 144Z, pgutta,  hyd1204, 78B,  oldcity, sec-bad1205, 720C, hitech,  sec-bad</code></pre><p>导入表数据子集</p><pre class="language-none"><code class="language-none">我们可以导入表的使用Sqoop导入工具，"where"子句的一个子集。它执行在各自的数据库服务器相应的SQL查询，并将结果存储在HDFS的目标目录。where子句的语法如下。--where &lt;condition&gt;下面的命令用来导入emp_add表数据的子集。子集查询检索员工ID和地址，居住城市为：Secunderabadbin/sqoop import \--connect jdbc:mysql://hdp-node-01:3306/test \--username root \--password root \--where "city ='sec-bad'" \--target-dir /wherequery \--table emp_add --m 1下面的命令用来验证数据从emp_add表导入/wherequery目录$HADOOP_HOME/bin/hadoop fs -cat /wherequery/part-m-*它用逗号（，）分隔 emp_add表数据和字段。1202, 108I, aoc, sec-bad1204, 78B, oldcity, sec-bad1205, 720C, hitech, sec-bad</code></pre><p>增量导入</p><pre class="language-none"><code class="language-none">增量导入是仅导入新添加的表中的行的技术。它需要添加‘incremental’, ‘check-column’, 和 ‘last-value’选项来执行增量导入。下面的语法用于Sqoop导入命令增量选项。--incremental &lt;mode&gt;--check-column &lt;column name&gt;--last value &lt;last check column value&gt;假设新添加的数据转换成emp表如下：1206, satish p, grp des, 20000, GR下面的命令用于在EMP表执行增量导入。bin/sqoop import \--connect jdbc:mysql://hdp-node-01:3306/test \--username root \--password root \--table emp --m 1 \--incremental append \--check-column id \--last-value 1205以下命令用于从emp表导入HDFS&nbsp;emp/&nbsp;目录的数据验证。$ $HADOOP_HOME/bin/hadoop fs -cat /user/hadoop/emp/part-m-*它用逗号（，）分隔 emp_add表数据和字段。1201, gopal,    manager, 50000, TP1202, manisha,  preader, 50000, TP1203, kalil,    php dev, 30000, AC1204, prasanth, php dev, 30000, AC1205, kranthi,  admin,   20000, TP1206, satish p, grp des, 20000, GR下面的命令是从表emp 用来查看修改或新添加的行$ $HADOOP_HOME/bin/hadoop fs -cat /emp/part-m-*1这表示新添加的行用逗号（，）分隔emp表的字段。 1206, satish p, grp des, 20000, GR</code></pre><h3 id="5-Sqoop的数据导出"><a href="#5-Sqoop的数据导出" class="headerlink" title="5.Sqoop的数据导出"></a>5.Sqoop的数据导出</h3><p>将数据从HDFS导出到RDBMS数据库<br>导出前，目标表必须存在于目标数据库中。<br>    • 默认操作是从将文件中的数据使用INSERT语句插入到表中<br>    • 更新模式下，是生成UPDATE语句更新表数据</p><p>语法</p><pre class="language-none"><code class="language-none">以下是export命令语法。$ sqoop export (generic-args) (export-args) </code></pre><p>示例</p><pre class="language-none"><code class="language-none">数据是在HDFS 中“EMP/”目录的emp_data文件中。所述emp_data如下：1201, gopal,     manager, 50000, TP1202, manisha,   preader, 50000, TP1203, kalil,     php dev, 30000, AC1204, prasanth,  php dev, 30000, AC1205, kranthi,   admin,   20000, TP1206, satish p,  grp des, 20000, GR1、首先需要手动创建mysql中的目标表$ mysqlmysql&gt; USE db;mysql&gt; CREATE TABLE employee (    id INT NOT NULL PRIMARY KEY,    name VARCHAR(20),    deg VARCHAR(20),   salary INT,   dept VARCHAR(10));2、然后执行导出命令bin/sqoop export \--connect jdbc:mysql://hdp-node-01:3306/test \--username root \--password root \--table emp2 \--export-dir /user/hadoop/emp/3、验证表mysql命令行。mysql&gt;select * from employee;如果给定的数据存储成功，那么可以找到数据在如下的employee表。+------+--------------+-------------+-------------------+--------+| Id   | Name         | Designation | Salary            | Dept   |+------+--------------+-------------+-------------------+--------+| 1201 | gopal        | manager     | 50000             | TP     || 1202 | manisha      | preader     | 50000             | TP     || 1203 | kalil        | php dev     | 30000             | AC     || 1204 | prasanth     | php dev     | 30000             | AC     || 1205 | kranthi      | admin       | 20000             | TP     || 1206 | satish p     | grp des     | 20000             | GR     |+------+--------------+-------------+-------------------+--------+</code></pre><h3 id="6-Sqoop的原理"><a href="#6-Sqoop的原理" class="headerlink" title="6.Sqoop的原理"></a>6.Sqoop的原理</h3><pre class="language-none"><code class="language-none">Sqoop的原理其实就是将导入导出命令转化为mapreduce程序来执行，sqoop在接收到命令后，都要生成mapreduce程序使用sqoop的代码生成工具可以方便查看到sqoop所生成的java代码，并可在此基础之上进行深入定制开发</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> sqoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> sqoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark Streaming基础四</title>
      <link href="/2018/08/21/spark-streaming-ji-chu-si/"/>
      <url>/2018/08/21/spark-streaming-ji-chu-si/</url>
      
        <content type="html"><![CDATA[<p>#</p><center>  spark Streaming基础四</center><p></p><h2 id="1-目标"><a href="#1-目标" class="headerlink" title="1 目标"></a>1 目标</h2><pre class="language-none"><code class="language-none">1.1. 掌握Spark Streaming的原理1.2. 熟练使用Spark Streaming完成流式计算任务</code></pre><h2 id="2-Spark-Streaming介绍"><a href="#2-Spark-Streaming介绍" class="headerlink" title="2. Spark Streaming介绍"></a>2. Spark Streaming介绍</h2><h3 id="2-1-Spark-Streaming概述"><a href="#2-1-Spark-Streaming概述" class="headerlink" title="2.1. Spark Streaming概述"></a>2.1. Spark Streaming概述</h3><h4 id="2-1-1-什么是Spark-Streaming"><a href="#2-1-1-什么是Spark-Streaming" class="headerlink" title="2.1.1. 什么是Spark Streaming"></a>2.1.1. 什么是Spark Streaming</h4><p><img src="/images/20180828/23.png"></p><p>Spark Streaming类似于Apache Storm，用于流式数据的处理。根据其官方文档介绍，Spark Streaming有高吞吐量和容错能力强等特点。Spark Streaming支持的数据输入源很多，例如：Kafka、Flume、Twitter、ZeroMQ和简单的TCP套接字等等。数据输入后可以用Spark的高度抽象原语如：map、reduce、join、window等进行运算。而结果也能保存在很多地方，如HDFS，数据库等。另外Spark Streaming也能和MLlib（机器学习）以及Graphx完美融合。</p><p><img src="/images/20180828/24.png"></p><h4 id="2-1-2-为什么要学习Spark-Streaming"><a href="#2-1-2-为什么要学习Spark-Streaming" class="headerlink" title="2.1.2. 为什么要学习Spark Streaming"></a>2.1.2. 为什么要学习Spark Streaming</h4><p>1.易用</p><p><img src="/images/20180828/25.png">    </p><p>2.容错</p><p><img src="/images/20180828/26.png">  </p><p>3.易整合到Spark体系</p><p><img src="/images/20180828/27.png">  </p><h4 id="2-1-3Spark与Storm的对比"><a href="#2-1-3Spark与Storm的对比" class="headerlink" title="2.1.3Spark与Storm的对比"></a>2.1.3Spark与Storm的对比</h4><p>spark</p><p><img src="/images/20180828/28.png">  </p><p>storm</p><p><img src="/images/20180828/29.png">  </p><p>编程模型:DStream</p><p><img src="/images/20180828/30.png">  </p><p>编程模型：Spout/Bolt</p><p><img src="/images/20180828/31.png">  </p><h2 id="3-DStream"><a href="#3-DStream" class="headerlink" title="3.DStream"></a>3.DStream</h2><h3 id="3-1-什么是DStream"><a href="#3-1-什么是DStream" class="headerlink" title="3.1. 什么是DStream"></a>3.1. 什么是DStream</h3><p>Discretized Stream是Spark Streaming的基础抽象，代表持续性的数据流和经过各种Spark原语操作后的结果数据流。在内部实现上，DStream是一系列连续的RDD来表示。每个RDD含有一段时间间隔内的数据，如下图：</p><p><img src="/images/20180828/32.png">  </p><p>对数据的操作也是按照RDD为单位来进行的</p><p><img src="/images/20180828/33.png">  </p><p>计算过程由Spark engine来完成</p><p><img src="/images/20180828/34.png">  </p><h3 id="3-2-DStream相关操作"><a href="#3-2-DStream相关操作" class="headerlink" title="3.2. DStream相关操作"></a>3.2. DStream相关操作</h3><p>DStream上的原语与RDD的类似，分为Transformations（转换）和Output Operations（输出）两种，此外转换操作中还有一些比较特殊的原语，如：updateStateByKey()、transform()以及各种Window相关的原语。</p><h4 id="3-2-1Transformations-on-DStreams"><a href="#3-2-1Transformations-on-DStreams" class="headerlink" title="3.2.1Transformations on DStreams"></a>3.2.1Transformations on DStreams</h4><pre class="language-none"><code class="language-none">Transformation        Meaningmap(func)        Return a new DStream by passing each element of the source DStream through a function func.flatMap(func)        Similar to map, but each input item can be mapped to 0 or more output items.filter(func)        Return a new DStream by selecting only the records of the source DStream on which func returns true.repartition(numPartitions)        Changes the level of parallelism in this DStream by creating more or fewer partitions.union(otherStream)        Return a new DStream that contains the union of the elements in the source DStream and otherDStream.count()        Return a new DStream of single-element RDDs by counting the number of elements in each RDD of the source DStream.reduce(func)        Return a new DStream of single-element RDDs by aggregating the elements in each RDD of the source DStream using a function func (which takes two arguments and returns one). The function should be associative so that it can be computed in parallel.countByValue()        When called on a DStream of elements of type K, return a new DStream of (K, Long) pairs where the value of each key is its frequency in each RDD of the source DStream.reduceByKey(func, [numTasks])            When called on a DStream of (K, V) pairs, return a new DStream of (K, V) pairs where the values for each key are aggregated using the given reduce function. Note: By default, this uses Spark's default number of parallel tasks (2 for local mode, and in cluster mode the number is determined by the config property spark.default.parallelism) to do the grouping. You can pass an optional numTasks argument to set a different number of tasks.join(otherStream, [numTasks])        When called on two DStreams of (K, V) and (K, W) pairs, return a new DStream of (K, (V, W)) pairs with all pairs of elements for each key.cogroup(otherStream, [numTasks])        When called on a DStream of (K, V) and (K, W) pairs, return a new DStream of (K, Seq[V], Seq[W]) tuples.transform(func)            Return a new DStream by applying a RDD-to-RDD function to every RDD of the source DStream. This can be used to do arbitrary RDD operations on the DStream.updateStateByKey(func)        Return a new "state" DStream where the state for each key is updated by applying the given function on the previous state of the key and the new values for the key. This can be used to maintain arbitrary state data for each key.</code></pre><p>特殊的Transformations</p><pre><code>1. UpdateStateByKey Operation</code></pre><p>UpdateStateByKey原语用于记录历史记录，上文中Word Count示例中就用到了该特性。若不用UpdateStateByKey来更新状态，那么每次数据进来后分析完成后，结果输出后将不在保存</p><pre><code>2. Transform Operation</code></pre><p>Transform原语允许DStream上执行任意的RDD-to-RDD函数。通过该函数可以方便的扩展Spark API。此外，MLlib（机器学习）以及Graphx也是通过本函数来进行结合的。</p><pre><code>3. Window Operations</code></pre><p>Window Operations有点类似于Storm中的State，可以设置窗口的大小和滑动窗口的间隔来动态的获取当前Steaming的允许状态</p><p><img src="/images/20180828/35.png">  </p><h3 id="3-2-2-Output-Operations-on-DStreams"><a href="#3-2-2-Output-Operations-on-DStreams" class="headerlink" title="3.2.2. Output Operations on DStreams"></a>3.2.2. Output Operations on DStreams</h3><p>Output Operations可以将DStream的数据输出到外部的数据库或文件系统，当某个Output Operations原语被调用时（与RDD的Action相同），streaming程序才会开始真正的计算过程。</p><pre class="language-none"><code class="language-none">Output Operation        Meaningprint()        Prints the first ten elements of every batch of data in a DStream on the driver node running the streaming application. This is useful for development and debugging. saveAsTextFiles(prefix, [suffix])        Save this DStream's contents as text files. The file name at each batch interval is generated based on prefix and suffix: "prefix-TIME_IN_MS[.suffix]".saveAsObjectFiles(prefix, [suffix])        Save this DStream's contents as SequenceFiles of serialized Java objects. The file name at each batch interval is generated based on prefix and suffix: "prefix-TIME_IN_MS[.suffix]". saveAsHadoopFiles(prefix, [suffix])        Save this DStream's contents as Hadoop files. The file name at each batch interval is generated based on prefix and suffix: "prefix-TIME_IN_MS[.suffix]". foreachRDD(func)        The most generic output operator that applies a function, func, to each RDD generated from the stream. This function should push the data in each RDD to an external system, such as saving the RDD to files, or writing it over the network to a database. Note that the function func is executed in the driver process running the streaming application, and will usually have RDD actions in it that will force the computation of the streaming RDDs.</code></pre><h2 id="4-实战"><a href="#4-实战" class="headerlink" title="4. 实战"></a>4. 实战</h2><h3 id="4-1-用Spark-Streaming实现实时WordCount"><a href="#4-1-用Spark-Streaming实现实时WordCount" class="headerlink" title="4.1. 用Spark Streaming实现实时WordCount"></a>4.1. 用Spark Streaming实现实时WordCount</h3><p>架构图：</p><p><img src="/images/20180828/36.png">  </p><p>1.安装并启动生成者<br>首先在一台Linux（ip：192.168.10.101）上用YUM安装nc工具<br>yum install -y nc</p><p>启动一个服务端并监听9999端口<br>nc -lk 9999</p><p>2.编写Spark Streaming程序</p><pre class="language-none"><code class="language-none">package cn.itcast.spark.streamingimport cn.itcast.spark.util.LoggerLevelimport org.apache.spark.SparkConfimport org.apache.spark.streaming.{Seconds, StreamingContext}object NetworkWordCount {  def main(args: Array[String]) {    //设置日志级别    LoggerLevel.setStreamingLogLevels()    //创建SparkConf并设置为本地模式运行    //注意local[2]代表开两个线程    val conf = new SparkConf().setMaster("local[2]").setAppName("NetworkWordCount")    //设置DStream批次时间间隔为2秒    val ssc = new StreamingContext(conf, Seconds(2))    //通过网络读取数据    val lines = ssc.socketTextStream("192.168.10.101", 9999)    //将读到的数据用空格切成单词    val words = lines.flatMap(_.split(" "))    //将单词和1组成一个pair    val pairs = words.map(word =&gt; (word, 1))    //按单词进行分组求相同单词出现的次数    val wordCounts = pairs.reduceByKey(_ + _)    //打印结果到控制台    wordCounts.print()    //开始计算    ssc.start()    //等待停止    ssc.awaitTermination()  }}</code></pre><p>3.启动Spark Streaming程序：由于使用的是本地模式”local[2]”所以可以直接在本地运行该程序<br>注意：要指定并行度，如在本地运行设置setMaster(“local[2]”)，相当于启动两个线程，一个给receiver，一个给computer。如果是在集群中运行，必须要求集群中可用core数大于1</p><p><img src="/images/20180828/37.png"> </p><p>4.在Linux端命令行中输入单词</p><p><img src="/images/20180828/38.png"> </p><p>5.在IDEA控制台中查看结果</p><p><img src="/images/20180828/39.png"> </p><p>问题：结果每次在Linux段输入的单词次数都被正确的统计出来，但是结果不能累加！如果需要累加需要使用updateStateByKey(func)来更新状态，下面给出一个例子：</p><pre class="language-none"><code class="language-none">package cn.itcast.spark.streamingimport cn.itcast.spark.util.LoggerLevelimport org.apache.spark.{HashPartitioner, SparkConf}import org.apache.spark.streaming.{StreamingContext, Seconds}object NetworkUpdateStateWordCount {  /**    * String : 单词 hello    * Seq[Int] ：单词在当前批次出现的次数    * Option[Int] ： 历史结果    */  val updateFunc = (iter: Iterator[(String, Seq[Int], Option[Int])]) =&gt; {    //iter.flatMap(it=&gt;Some(it._2.sum + it._3.getOrElse(0)).map(x=&gt;(it._1,x)))    iter.flatMap{case(x,y,z)=&gt;Some(y.sum + z.getOrElse(0)).map(m=&gt;(x, m))}  }  def main(args: Array[String]) {    LoggerLevel.setStreamingLogLevels()    val conf = new SparkConf().setMaster("local[2]").setAppName("NetworkUpdateStateWordCount")    val ssc = new StreamingContext(conf, Seconds(5))    //做checkpoint 写入共享存储中    ssc.checkpoint("c://aaa")    val lines = ssc.socketTextStream("192.168.10.100", 9999)    //reduceByKey 结果不累加    //val result = lines.flatMap(_.split(" ")).map((_, 1)).reduceByKey(_+_)    //updateStateByKey结果可以累加但是需要传入一个自定义的累加函数：updateFunc    val results = lines.flatMap(_.split(" ")).map((_,1)).updateStateByKey(updateFunc, new HashPartitioner(ssc.sparkContext.defaultParallelism), true)    results.print()    ssc.start()    ssc.awaitTermination()  }</code></pre><h3 id="4-2Spark-Streaming整合Kafka完成网站点击流实时统计"><a href="#4-2Spark-Streaming整合Kafka完成网站点击流实时统计" class="headerlink" title="4.2Spark Streaming整合Kafka完成网站点击流实时统计"></a>4.2Spark Streaming整合Kafka完成网站点击流实时统计</h3><p><img src="/images/20180828/40.png">  </p><pre class="language-none"><code class="language-none">    1. 安装并配置zk    2. 安装并配置Kafka    3. 启动zk    4. 启动Kafka    5. 创建topicbin/kafka-topics.sh --create --zookeeper node1.itcast.cn:2181,node2.itcast.cn:2181 \--replication-factor 3 --partitions 3 --topic urlcount    6. 编写Spark Streaming应用程序</code></pre><pre class="language-none"><code class="language-none">package cn.itcast.spark.streamingpackage cn.itcast.sparkimport org.apache.spark.{HashPartitioner, SparkConf}import org.apache.spark.storage.StorageLevelimport org.apache.spark.streaming.kafka.KafkaUtilsimport org.apache.spark.streaming.{Seconds, StreamingContext}object UrlCount {  val updateFunc = (iterator: Iterator[(String, Seq[Int], Option[Int])]) =&gt; {    iterator.flatMap{case(x,y,z)=&gt; Some(y.sum + z.getOrElse(0)).map(n=&gt;(x, n))}  }  def main(args: Array[String]) {    //接收命令行中的参数    val Array(zkQuorum, groupId, topics, numThreads, hdfs) = args    //创建SparkConf并设置AppName    val conf = new SparkConf().setAppName("UrlCount")    //创建StreamingContext    val ssc = new StreamingContext(conf, Seconds(2))    //设置检查点    ssc.checkpoint(hdfs)    //设置topic信息    val topicMap = topics.split(",").map((_, numThreads.toInt)).toMap    //重Kafka中拉取数据创建DStream    val lines = KafkaUtils.createStream(ssc, zkQuorum ,groupId, topicMap, StorageLevel.MEMORY_AND_DISK).map(_._2)    //切分数据，截取用户点击的url    val urls = lines.map(x=&gt;(x.split(" ")(6), 1))    //统计URL点击量    val result = urls.updateStateByKey(updateFunc, new HashPartitioner(ssc.sparkContext.defaultParallelism), true)    //将结果打印到控制台    result.print()    ssc.start()    ssc.awaitTermination()  }}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>azkaban学习</title>
      <link href="/2018/08/21/azkaban-xue-xi/"/>
      <url>/2018/08/21/azkaban-xue-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="azkaban教程"><a href="#azkaban教程" class="headerlink" title="azkaban教程"></a><center>azkaban教程</center></h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h2><h3 id="1-1-为什么需要工作流调度系统"><a href="#1-1-为什么需要工作流调度系统" class="headerlink" title="1.1 为什么需要工作流调度系统"></a>1.1 为什么需要工作流调度系统</h3><pre class="language-none"><code class="language-none">    • 一个完整的数据分析系统通常都是由大量任务单元组成：shell脚本程序，java程序，mapreduce程序、hive脚本等    • 各任务单元之间存在时间先后及前后依赖关系    • 为了很好地组织起这样的复杂执行计划，需要一个工作流调度系统来调度执行；例如，我们可能有这样一个需求，某个业务系统每天产生20G原始数据，我们每天都要对其进行处理，处理步骤如下所示：    1、 通过Hadoop先将原始数据同步到HDFS上；    2、 借助MapReduce计算框架对原始数据进行转换，生成的数据以分区表的形式存储到多张Hive表中；    3、 需要对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表；    4、 将明细数据进行复杂的统计分析，得到结果报表信息；    5、 需要将统计分析得到的结果数据同步到业务系统中，供业务调用使用。</code></pre><h3 id="1-2-工作流调度实现方式"><a href="#1-2-工作流调度实现方式" class="headerlink" title="1.2 工作流调度实现方式"></a>1.2 工作流调度实现方式</h3><pre class="language-none"><code class="language-none">简单的任务调度：直接使用linux的crontab来定义；复杂的任务调度：开发调度平台或使用现成的开源调度系统，比如ooize、azkaban等</code></pre><h3 id="1-3-常见工作流调度系统"><a href="#1-3-常见工作流调度系统" class="headerlink" title="1.3 常见工作流调度系统"></a>1.3 常见工作流调度系统</h3><pre class="language-none"><code class="language-none">市面上目前有许多工作流调度器在hadoop领域，常见的工作流调度器有Oozie, Azkaban,Cascading,Hamake等</code></pre><h3 id="1-4-Azkaban与Oozie对比"><a href="#1-4-Azkaban与Oozie对比" class="headerlink" title="1.4 Azkaban与Oozie对比"></a>1.4 Azkaban与Oozie对比</h3><pre class="language-none"><code class="language-none">对市面上最流行的两种调度器，给出以下详细对比，以供技术选型参考。总体来说，ooize相比azkaban是一个重量级的任务调度系统，功能全面，但配置使用也更复杂。如果可以不在意某些功能的缺失，轻量级调度器azkaban是很不错的候选对象。详情如下：    • 功能两者均可以调度mapreduce,pig,java,脚本工作流任务两者均可以定时执行工作流任务    • 工作流定义Azkaban使用Properties文件定义工作流Oozie使用XML文件定义工作流    • 工作流传参Azkaban支持直接传参，例如${input}Oozie支持参数和EL表达式，例如${fs:dirSize(myInputDir)}    • 定时执行Azkaban的定时执行任务是基于时间的Oozie的定时执行任务基于时间和输入数据    • 资源管理Azkaban有较严格的权限控制，如用户对工作流进行读/写/执行等操作Oozie暂无严格的权限控制    • 工作流执行Azkaban有两种运行模式，分别是solo server mode(executor server和web server部署在同一台节点)和multi server mode(executor server和web server可以部署在不同节点)Oozie作为工作流服务器运行，支持多用户和多工作流    • 工作流管理Azkaban支持浏览器以及ajax方式操作工作流Oozie支持命令行、HTTP REST、Java API、浏览器操作工作流</code></pre><h2 id="2-Azkaban介绍"><a href="#2-Azkaban介绍" class="headerlink" title="2.Azkaban介绍"></a>2.Azkaban介绍</h2><pre class="language-none"><code class="language-none">Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。它有如下功能特点：    • Web用户界面    • 方便上传工作流    • 方便设置任务之间的关系    • 调度工作流    • 认证/授权(权限的工作)    • 能够杀死并重新启动工作流    • 模块化和可插拔的插件机制    • 项目工作区    • 工作流和任务的日志记录和审计</code></pre><h2 id="3-Azkaban安装部署"><a href="#3-Azkaban安装部署" class="headerlink" title="3.Azkaban安装部署"></a>3.Azkaban安装部署</h2><pre class="language-none"><code class="language-none">准备工作Azkaban Web服务器azkaban-web-server-2.5.0.tar.gzAzkaban执行服务器&nbsp;azkaban-executor-server-2.5.0.tar.gzMySQL目前azkaban只支持&nbsp;mysql,需安装mysql服务器,本文档中默认已安装好mysql服务器,并建立了&nbsp;root用户,密码&nbsp;root.&nbsp;下载地址:http://azkaban.github.io/downloads.html安装将安装文件上传到集群,最好上传到安装&nbsp;hive、sqoop的机器上,方便命令的执行在当前用户目录下新建&nbsp;azkabantools目录,用于存放源安装文件.新建azkaban目录,用于存放azkaban运行程序azkaban web服务器安装解压azkaban-web-server-2.5.0.tar.gz命令: tar –zxvf azkaban-web-server-2.5.0.tar.gz将解压后的azkaban-web-server-2.5.0&nbsp;移动到&nbsp;azkaban目录中,并重新命名&nbsp;webserver命令: mv azkaban-web-server-2.5.0 ../azkaban&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;cd ../azkaban&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;mv azkaban-web-server-2.5.0  serverazkaban&nbsp;执行服器安装解压azkaban-executor-server-2.5.0.tar.gz命令:tar –zxvf azkaban-executor-server-2.5.0.tar.gz将解压后的azkaban-executor-server-2.5.0&nbsp;移动到&nbsp;azkaban目录中,并重新命名&nbsp;executor命令:mv azkaban-executor-server-2.5.0 &nbsp;../azkabancd ../azkabanmv azkaban-executor-server-2.5.0 &nbsp;executorazkaban脚本导入解压:&nbsp;azkaban-sql-script-2.5.0.tar.gz命令:tar –zxvf&nbsp;azkaban-sql-script-2.5.0.tar.gz将解压后的mysql&nbsp;脚本,导入到mysql中:进入mysqlmysql&gt; create database azkaban;mysql&gt; use azkaban;Database changedmysql&gt; source /home/hadoop/azkaban-2.5.0/create-all-sql-2.5.0.sql;创建SSL配置参考地址: http://docs.codehaus.org/display/JETTY/How+to+configure+SSL命令:&nbsp;keytool -keystore keystore -alias jetty -genkey -keyalg RSA运行此命令后,会提示输入当前生成&nbsp;keystor的密码及相应信息,输入的密码请劳记,信息如下:&nbsp;输入keystore密码：&nbsp;再次输入新密码:您的名字与姓氏是什么？&nbsp; [Unknown]：&nbsp;您的组织单位名称是什么？&nbsp; [Unknown]：&nbsp;您的组织名称是什么？&nbsp; [Unknown]：&nbsp;您所在的城市或区域名称是什么？&nbsp; [Unknown]：&nbsp;您所在的州或省份名称是什么？&nbsp; [Unknown]：&nbsp;该单位的两字母国家代码是什么&nbsp; [Unknown]：&nbsp; CNCN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=CN&nbsp;正确吗？&nbsp; [否]：&nbsp; y&nbsp;输入&lt;jetty&gt;的主密码&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（如果和&nbsp;keystore&nbsp;密码相同，按回车）：&nbsp;再次输入新密码:完成上述工作后,将在当前目录生成&nbsp;keystore&nbsp;证书文件,将keystore&nbsp;考贝到&nbsp;azkaban web服务器根目录中.如:cp keystore azkaban/webserver配置文件注：先配置好服务器节点上的时区    1、 先生成时区配置文件Asia/Shanghai，用交互式命令 tzselect 即可    2、 拷贝该时区文件，覆盖系统本地时区配置cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime  azkaban web服务器配置进入azkaban web服务器安装目录&nbsp;conf目录    • 修改azkaban.properties文件命令vi azkaban.properties内容说明如下:#Azkaban Personalization Settingsazkaban.name=Test&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #服务器UI名称,用于服务器上方显示的名字azkaban.label=My Local Azkaban&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #描述azkaban.color=#FF3601&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #UI颜色azkaban.default.servlet.path=/index&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #web.resource.dir=web/&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #默认根web目录default.timezone.id=Asia/Shanghai&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #默认时区,已改为亚洲/上海&nbsp;默认为美国&nbsp;#Azkaban UserManager classuser.manager.class=azkaban.user.XmlUserManager&nbsp;&nbsp; #用户权限管理默认类user.manager.xml.file=conf/azkaban-users.xml&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #用户配置,具体配置参加下文&nbsp;#Loader for projectsexecutor.global.properties=conf/global.properties&nbsp;&nbsp;&nbsp; # global配置文件所在位置azkaban.project.dir=projects&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #&nbsp;database.type=mysql&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库类型mysql.port=3306&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #端口号mysql.host=hadoop03    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库连接IPmysql.database=azkaban&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库实例名mysql.user=root &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库用户名mysql.password=root&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库密码mysql.numconnections=100&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #最大连接数&nbsp;# Velocity dev modevelocity.dev.mode=false# Jetty服务器属性.jetty.maxThreads=25&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #最大线程数jetty.ssl.port=8443&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #Jetty SSL端口jetty.port=8081&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #Jetty端口jetty.keystore=keystore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #SSL文件名jetty.password=123456&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #SSL文件密码jetty.keypassword=123456&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #Jetty主密码&nbsp;与&nbsp;keystore文件相同jetty.truststore=keystore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #SSL文件名jetty.trustpassword=123456&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # SSL文件密码&nbsp;#&nbsp;执行服务器属性executor.port=12321&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #执行服务器端口&nbsp;#&nbsp;邮件设置mail.sender=xxxxxxxx@163.com&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #发送邮箱mail.host=smtp.163.com&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #发送邮箱smtp地址mail.user=xxxxxxxx &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #发送邮件时显示的名称mail.password=**********&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #邮箱密码job.failure.email=xxxxxxxx@163.com&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #任务失败时发送邮件的地址job.success.email=xxxxxxxx@163.com&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #任务成功时发送邮件的地址lockdown.create.projects=false&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #cache.directory=cache&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #缓存目录&nbsp;    • azkaban&nbsp;执行服务器配置进入执行服务器安装目录conf,修改azkaban.propertiesvi azkaban.properties#Azkabandefault.timezone.id=Asia/Shanghai&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #时区&nbsp;# Azkaban JobTypes&nbsp;插件配置azkaban.jobtype.plugin.dir=plugins/jobtypes&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #jobtype&nbsp;插件所在位置&nbsp;#Loader for projectsexecutor.global.properties=conf/global.propertiesazkaban.project.dir=projects&nbsp;#数据库设置database.type=mysql&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库类型(目前只支持mysql)mysql.port=3306&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库端口号mysql.host=192.168.20.200&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库IP地址mysql.database=azkaban&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库实例名mysql.user=azkaban&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库用户名mysql.password=oracle&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #数据库密码mysql.numconnections=100&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #最大连接数&nbsp;#&nbsp;执行服务器配置executor.maxThreads=50&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #最大线程数executor.port=12321&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #端口号(如修改,请与web服务中一致)executor.flow.threads=30&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #线程数    • 用户配置进入azkaban web服务器conf目录,修改azkaban-users.xmlvi azkaban-users.xml&nbsp;增加&nbsp;管理员用户&lt;azkaban-users&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;user username="azkaban" password="azkaban" roles="admin" groups="azkaban" /&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;user username="metrics" password="metrics" roles="metrics"/&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;user username="admin" password="admin" roles="admin,metrics" /&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;role name="admin" permissions="ADMIN" /&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;role name="metrics" permissions="METRICS"/&gt;&lt;/azkaban-users&gt;启动web服务器在azkaban web服务器目录下执行启动命令bin/azkaban-web-start.sh注:在web服务器根目录运行执行服务器在执行服务器目录下执行启动命令bin/azkaban-executor-start.sh ./注:只能要执行服务器根目录运行&nbsp;启动完成后,在浏览器(建议使用谷歌浏览器)中输入https://服务器IP地址:8443 ,即可访问azkaban服务了.在登录中输入刚才新的户用名及密码,点击&nbsp;login.</code></pre><h2 id="4-Azkaban实战"><a href="#4-Azkaban实战" class="headerlink" title="4. Azkaban实战"></a>4. Azkaban实战</h2><p><code>Azkaba内置的任务类型支持command、java</code></p><p>Command类型单一job示例</p><pre class="language-none"><code class="language-none">    1、 创建job描述文件vi command.job#command.jobtype=command                                                    command=echo 'hello'    2、 将job资源文件打包成zip文件zip command.job    3、 通过azkaban的web管理平台创建project并上传job压缩包首先创建project</code></pre><p>Command类型多job工作流flow</p><pre class="language-none"><code class="language-none">    1、 创建有依赖关系的多个job描述第一个job：foo.job# foo.jobtype=commandcommand=echo foo第二个job：bar.job依赖foo.job# bar.jobtype=commanddependencies=foocommand=echo bar    2、 将所有job资源文件打到一个zip包中    3、 在azkaban的web管理界面创建工程并上传zip包    4、 启动工作流flow</code></pre><p>HDFS操作任务</p><pre class="language-none"><code class="language-none">    1、 创建job描述文件# fs.jobtype=commandcommand=/home/hadoop/apps/hadoop-2.6.1/bin/hadoop fs -mkdir /azaz    2、 将job资源文件打包成zip文件3、通过azkaban的web管理平台创建project并上传job压缩包4、启动执行该job</code></pre><p>MAPREDUCE任务</p><pre class="language-none"><code class="language-none">Mr任务依然可以使用command的job类型来执行    1、 创建job描述文件，及mr程序jar包（示例中直接使用hadoop自带的example jar）# mrwc.jobtype=commandcommand=/home/hadoop/apps/hadoop-2.6.1/bin/hadoop  jar hadoop-mapreduce-examples-2.6.1.jar wordcount /wordcount/input /wordcount/azout    2、 将所有job资源文件打到一个zip包中3、在azkaban的web管理界面创建工程并上传zip包4、启动job</code></pre><p>HIVE脚本任务</p><pre class="language-none"><code class="language-none">    • 创建job描述文件和hive脚本Hive脚本： test.sqluse default;drop table aztest;create table aztest(id int,name string) row format delimited fields terminated by ',';load data inpath '/aztest/hiveinput' into table aztest;create table azres as select * from aztest;insert overwrite directory '/aztest/hiveoutput' select count(1) from aztest; Job描述文件：hivef.job# hivef.jobtype=commandcommand=/home/hadoop/apps/hive/bin/hive -f 'test.sql'2、将所有job资源文件打到一个zip包中3、在azkaban的web管理界面创建工程并上传zip包4、启动job</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> azkaban </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flume学习</title>
      <link href="/2018/08/21/flume-xue-xi/"/>
      <url>/2018/08/21/flume-xue-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="日志采集框架Flume"><a href="#日志采集框架Flume" class="headerlink" title="日志采集框架Flume"></a><center>日志采集框架Flume</center></h1><h3 id="1-Flume介绍"><a href="#1-Flume介绍" class="headerlink" title="1.Flume介绍"></a>1.Flume介绍</h3><h4 id="1-1概述"><a href="#1-1概述" class="headerlink" title="1.1概述"></a>1.1概述</h4><pre class="language-none"><code class="language-none">• Flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。• Flume可以采集文件，socket数据包等各种形式源数据，又可以将采集到的数据输出到HDFS、hbase、hive、kafka等众多外部存储系统中• 一般的采集需求，通过对flume的简单配置即可实现• Flume针对特殊场景也具备良好的自定义扩展能力，因此，flume可以适用于大部分的日常数据采集场景</code></pre><h4 id="1-1-2-运行机制"><a href="#1-1-2-运行机制" class="headerlink" title="1.1.2 运行机制"></a>1.1.2 运行机制</h4><pre class="language-none"><code class="language-none">1、 Flume分布式系统中最核心的角色是agent，flume采集系统就是由一个个agent所连接起来形成2、 每一个agent相当于一个数据传递员，内部有三个组件：        a) Source：采集源，用于跟数据源对接，以获取数据        b) Sink：下沉地，采集数据的传送目的，用于往下一级agent传递数据或者往最终存储系统传递数据        c) Channel：angent内部的数据传输通道，用于从source将数据传递到sink</code></pre><p><img src="/images/20180821/9.png"></p><h4 id="1-1-3-Flume采集系统结构图"><a href="#1-1-3-Flume采集系统结构图" class="headerlink" title="1.1.3 Flume采集系统结构图"></a>1.1.3 Flume采集系统结构图</h4><ul><li>简单结构</li></ul><p>单个agent采集数据</p><p><img src="/images/20180821/10.png"></p><ul><li>复杂结构</li></ul><p><img src="/images/20180821/11.png"></p><h3 id="1-2-Flume实战案例"><a href="#1-2-Flume实战案例" class="headerlink" title="1.2 Flume实战案例"></a>1.2 Flume实战案例</h3><h4 id="1-2-1-Flume的安装部署"><a href="#1-2-1-Flume的安装部署" class="headerlink" title="1.2.1 Flume的安装部署"></a>1.2.1 Flume的安装部署</h4><pre class="language-none"><code class="language-none">    1、 Flume的安装非常简单，只需要解压即可，当然，前提是已有hadoop环境上传安装包到数据源所在节点上然后解压  tar -zxvf apache-flume-1.6.0-bin.tar.gz然后进入flume的目录，修改conf下的flume-env.sh，在里面配置JAVA_HOME2、根据数据采集的需求配置采集方案，描述在配置文件中(文件名可任意自定义)3、指定采集方案配置文件，在相应的节点上启动flume agent先用一个最简单的例子来测试一下程序环境是否正常    1、 先在flume的conf目录下新建一个文件vi   netcat-logger.conf# 定义这个agent中各组件的名字a1.sources = r1a1.sinks = k1a1.channels = c1# 描述和配置source组件：r1a1.sources.r1.type = netcata1.sources.r1.bind = localhosta1.sources.r1.port = 44444# 描述和配置sink组件：k1a1.sinks.k1.type = logger# 描述和配置channel组件，此处使用是内存缓存的方式a1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# 描述和配置source  channel   sink之间的连接关系a1.sources.r1.channels = c1a1.sinks.k1.channel = c1    2、 启动agent去采集数据bin/flume-ng agent -c conf -f conf/netcat-logger.conf -n a1  -Dflume.root.logger=INFO,console-c conf   指定flume自身的配置文件所在目录-f conf/netcat-logger.con  指定我们所描述的采集方案-n a1  指定我们这个agent的名字    3、 测试先要往agent采集监听的端口上发送数据，让agent有数据可采随便在一个能跟agent节点联网的机器上telnet anget-hostname  port   （telnet localhost 44444）</code></pre><h3 id="1-3-采集案例"><a href="#1-3-采集案例" class="headerlink" title="1.3 采集案例"></a>1.3 采集案例</h3><p>1、采集目录到HDFS</p><pre class="language-none"><code class="language-none">采集需求：某服务器的某特定目录下，会不断产生新的文件，每当有新文件出现，就需要把文件采集到HDFS中去根据需求，首先定义以下3大要素    • 采集源，即source——监控文件目录 :  spooldir    • 下沉目标，即sink——HDFS文件系统  :  hdfs sink    • source和sink之间的传递通道——channel，可用file channel 也可以用内存channel配置文件编写：#定义三大组件的名称agent1.sources = source1agent1.sinks = sink1agent1.channels = channel1# 配置source组件agent1.sources.source1.type = spooldiragent1.sources.source1.spoolDir = /home/hadoop/logs/agent1.sources.source1.fileHeader = false#配置拦截器agent1.sources.source1.interceptors = i1agent1.sources.source1.interceptors.i1.type = hostagent1.sources.source1.interceptors.i1.hostHeader = hostname# 配置sink组件agent1.sinks.sink1.type = hdfsagent1.sinks.sink1.hdfs.path =hdfs://hdp-node-01:9000/weblog/flume-collection/%y-%m-%d/%H-%Magent1.sinks.sink1.hdfs.filePrefix = access_logagent1.sinks.sink1.hdfs.maxOpenFiles = 5000agent1.sinks.sink1.hdfs.batchSize= 100agent1.sinks.sink1.hdfs.fileType = DataStreamagent1.sinks.sink1.hdfs.writeFormat =Textagent1.sinks.sink1.hdfs.rollSize = 102400agent1.sinks.sink1.hdfs.rollCount = 1000000agent1.sinks.sink1.hdfs.rollInterval = 60#agent1.sinks.sink1.hdfs.round = true#agent1.sinks.sink1.hdfs.roundValue = 10#agent1.sinks.sink1.hdfs.roundUnit = minuteagent1.sinks.sink1.hdfs.useLocalTimeStamp = true# Use a channel which buffers events in memoryagent1.channels.channel1.type = memoryagent1.channels.channel1.keep-alive = 120agent1.channels.channel1.capacity = 500000agent1.channels.channel1.transactionCapacity = 600# Bind the source and sink to the channelagent1.sources.source1.channels = channel1agent1.sinks.sink1.channel = channel1Channel参数解释：capacity：默认该通道中最大的可以存储的event数量trasactionCapacity：每次最大可以从source中拿到或者送到sink中的event数量keep-alive：event添加到通道中或者移出的允许时间</code></pre><p>2、采集文件到HDFS</p><pre class="language-none"><code class="language-none">采集需求：比如业务系统使用log4j生成的日志，日志内容不断增加，需要把追加到日志文件中的数据实时采集到hdfs根据需求，首先定义以下3大要素    • 采集源，即source——监控文件内容更新 :  exec  ‘tail -F file’    • 下沉目标，即sink——HDFS文件系统  :  hdfs sink    • Source和sink之间的传递通道——channel，可用file channel 也可以用 内存channel配置文件编写：agent1.sources = source1agent1.sinks = sink1agent1.channels = channel1# Describe/configure tail -F source1agent1.sources.source1.type = execagent1.sources.source1.command = tail -F /home/hadoop/logs/access_logagent1.sources.source1.channels = channel1#configure host for sourceagent1.sources.source1.interceptors = i1agent1.sources.source1.interceptors.i1.type = hostagent1.sources.source1.interceptors.i1.hostHeader = hostname# Describe sink1agent1.sinks.sink1.type = hdfs#a1.sinks.k1.channel = c1agent1.sinks.sink1.hdfs.path =hdfs://hdp-node-01:9000/weblog/flume-collection/%y-%m-%d/%H-%Magent1.sinks.sink1.hdfs.filePrefix = access_logagent1.sinks.sink1.hdfs.maxOpenFiles = 5000agent1.sinks.sink1.hdfs.batchSize= 100agent1.sinks.sink1.hdfs.fileType = DataStreamagent1.sinks.sink1.hdfs.writeFormat =Textagent1.sinks.sink1.hdfs.rollSize = 102400agent1.sinks.sink1.hdfs.rollCount = 1000000agent1.sinks.sink1.hdfs.rollInterval = 60agent1.sinks.sink1.hdfs.round = trueagent1.sinks.sink1.hdfs.roundValue = 10agent1.sinks.sink1.hdfs.roundUnit = minuteagent1.sinks.sink1.hdfs.useLocalTimeStamp = true# Use a channel which buffers events in memoryagent1.channels.channel1.type = memoryagent1.channels.channel1.keep-alive = 120agent1.channels.channel1.capacity = 500000agent1.channels.channel1.transactionCapacity = 600# Bind the source and sink to the channelagent1.sources.source1.channels = channel1agent1.sinks.sink1.channel = channel1</code></pre><h4 id="1-4更多source和sink组件"><a href="#1-4更多source和sink组件" class="headerlink" title="1.4更多source和sink组件"></a>1.4更多source和sink组件</h4><pre class="language-none"><code class="language-none">Flume支持众多的source和sink类型，详细手册可参考官方文档http://flume.apache.org/FlumeUserGuide.html</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> flume </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> flume </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hive学习二</title>
      <link href="/2018/08/21/hive-xue-xi-er/"/>
      <url>/2018/08/21/hive-xue-xi-er/</url>
      
        <content type="html"><![CDATA[<h1 id="hive-系列教程二"><a href="#hive-系列教程二" class="headerlink" title="hive 系列教程二"></a><center>hive 系列教程二</center></h1><pre class="language-none"><code class="language-none">包含如下部分:一  hive实战</code></pre><p>１　Hive 实战案例1——数据ETL</p><p>需求：</p><pre class="language-none"><code class="language-none">    • 对web点击流日志基础数据表进行etl（按照仓库模型设计）    • 按各时间维度统计来源域名top10已有数据表 “t_orgin_weblog” ：+------------------+------------+----------+--+|     col_name     | data_type  | comment  |+------------------+------------+----------+--+| valid            | string     |          || remote_addr      | string     |          || remote_user      | string     |          || time_local       | string     |          || request          | string     |          || status           | string     |          || body_bytes_sent  | string     |          || http_referer     | string     |          || http_user_agent  | string     |          |+------------------+------------+----------+--+</code></pre><p>数据示例：</p><pre class="language-none"><code class="language-none">| true|1.162.203.134| - | 18/Sep/2013:13:47:35| /images/my.jpg                        | 200| 19939 | "http://www.angularjs.cn/A0d9"                      | "Mozilla/5.0 (Windows   || true|1.202.186.37 | - | 18/Sep/2013:15:39:11| /wp-content/uploads/2013/08/windjs.png| 200| 34613 | "http://cnodejs.org/topic/521a30d4bee8d3cb1272ac0f" | "Mozilla/5.0 (Macintosh;|</code></pre><p>实现步骤：</p><pre class="language-none"><code class="language-none">1、对原始数据进行抽取转换--将来访url分离出host  path  query  query iddrop table if exists t_etl_referurl;create table t_etl_referurl asSELECT a.*,b.*FROM t_orgin_weblog a LATERAL VIEW parse_url_tuple(regexp_replace(http_referer, "\"", ""), 'HOST', 'PATH','QUERY', 'QUERY:id') b as host, path, query, query_id 2、从前述步骤进一步分离出日期时间形成ETL明细表“t_etl_detail”    day tm   drop table if exists t_etl_detail;create table t_etl_detail as select b.*,substring(time_local,0,11) as daystr,substring(time_local,13) as tmstr,substring(time_local,4,3) as month,substring(time_local,0,2) as day,substring(time_local,13,2) as hourfrom t_etl_referurl b;3、对etl数据进行分区(包含所有数据的结构化信息)drop table t_etl_detail_prt;create table t_etl_detail_prt(valid                   string,remote_addr            string,remote_user            string,time_local               string,request                 string,status                  string,body_bytes_sent         string,http_referer             string,http_user_agent         string,host                   string,path                   string,query                  string,query_id               string,daystr                 string,tmstr                  string,month                  string,day                    string,hour                   string) partitioned by (mm string,dd string);4.导入数据insert into table t_etl_detail_prt partition(mm='Sep',dd='18')select * from t_etl_detail where daystr='18/Sep/2013';insert into table t_etl_detail_prt partition(mm='Sep',dd='19')select * from t_etl_detail where daystr='19/Sep/2013';分个时间维度统计各referer_host的访问次数并排序create table t_refer_host_visit_top_tmp asselect referer_host,count(*) as counts,mm,dd,hh from t_display_referer_counts group by hh,dd,mm,referer_host order by hh asc,dd asc,mm asc,counts desc;5、来源访问次数topn各时间维度URL取各时间维度的referer_host访问次数topnselect * from (select referer_host,counts,concat(hh,dd),row_number() over (partition by concat(hh,dd) order by concat(hh,dd) asc) as od from t_refer_host_visit_top_tmp) t where od&lt;=3;</code></pre><p>Hive 实战案例2——访问时长统计</p><p>需求：</p><p><code>从web日志中统计每日访客平均停留时间</code></p><p>实现步骤：</p><pre class="language-none"><code class="language-none">    1、 由于要从大量请求中分辨出用户的各次访问，逻辑相对复杂，通过hive直接实现有困难，因此编写一个mr程序来求出访客访问信息（详见代码）启动mr程序获取结果：[hadoop@hdp-node-01 ~]$ hadoop jar weblog.jar cn.itcast.bigdata.hive.mr.UserStayTime /weblog/input /weblog/stayout    2、 将mr的处理结果导入hive表drop table t_display_access_info_tmp;create table t_display_access_info_tmp(remote_addr string,firt_req_time string,last_req_time string,stay_long bigint)row format delimited fields terminated by '\t';load data inpath '/weblog/stayout4' into table t_display_access_info_tmp;3、得出访客访问信息表 "t_display_access_info"由于有一些访问记录是单条记录，mr程序处理处的结果给的时长是0，所以考虑给单次请求的停留时间一个默认市场30秒drop table t_display_access_info;create table t_display_access_info asselect remote_addr,firt_req_time,last_req_time,case stay_longwhen 0 then 30000else stay_longend as stay_longfrom t_display_access_info_tmp;4、统计所有用户停留时间平均值select avg(stay_long) from t_display_access_info;</code></pre><p>Hive实战案例3——级联求和</p><p>需求：</p><pre class="language-none"><code class="language-none">有如下访客访问次数统计表 t_access_times访客月份访问次数A2015-01-025A2015-01-0315B2015-01-015A2015-01-048B2015-01-0525A2015-01-065A2015-02-024A2015-02-066B2015-02-0610B2015-02-075需要输出报表：t_access_times_accumulate访客月份月访问总计累计访问总计A2015-013333A2015-021043…….…….…….…….B2015-013030B2015-021545</code></pre><p>实现步骤</p><pre class="language-none"><code class="language-none">可以用一个hql语句即可实现：select A.username,A.month,max(A.salary) as salary,sum(B.salary) as accumulatefrom (select username,month,sum(salary) as salary from t_access_times group by username,month) A inner join (select username,month,sum(salary) as salary from t_access_times group by username,month) BonA.username=B.usernamewhere B.month &lt;= A.monthgroup by A.username,A.monthorder by A.username,A.month;</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hive学习一</title>
      <link href="/2018/08/21/hive-xue-xi-yi/"/>
      <url>/2018/08/21/hive-xue-xi-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="hive-系列教程一"><a href="#hive-系列教程一" class="headerlink" title="hive 系列教程一"></a><center>hive 系列教程一</center></h1><pre class="language-none"><code class="language-none">包含如下三个部分:一  hive基本概念二  hive基本操作三  hive函数</code></pre><h2 id="１．hive基本概念"><a href="#１．hive基本概念" class="headerlink" title="１．hive基本概念"></a>１．hive基本概念</h2><h3 id="1-1-hive基本简介"><a href="#1-1-hive基本简介" class="headerlink" title="1.1 hive基本简介"></a>1.1 hive基本简介</h3><h4 id="1-1-1-什么是Hive"><a href="#1-1-1-什么是Hive" class="headerlink" title="1.1.1 什么是Hive"></a>1.1.1 什么是Hive</h4><pre class="language-none"><code class="language-none">Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。</code></pre><h4 id="1-1-2-为什么使用Hive"><a href="#1-1-2-为什么使用Hive" class="headerlink" title="1.1.2 为什么使用Hive"></a>1.1.2 为什么使用Hive</h4><pre class="language-none"><code class="language-none">    • 直接使用hadoop所面临的问题 人员学习成本太高 项目周期要求太短 MapReduce实现复杂查询逻辑开发难度太大     • 为什么要使用Hive 操作接口采用类SQL语法，提供快速开发的能力。 避免了去写MapRedu</code></pre><h4 id="1-1-3-Hive的特点"><a href="#1-1-3-Hive的特点" class="headerlink" title="1.1.3 Hive的特点"></a>1.1.3 Hive的特点</h4><pre class="language-none"><code class="language-none">    • 可扩展 Hive可以自由的扩展集群的规模，一般情况下不需要重启服务。    • 延展性 Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。    • 容错 良好的容错性，节点出现问题SQL仍可完成执行。</code></pre><h3 id="1-2-Hive架构"><a href="#1-2-Hive架构" class="headerlink" title="1.2  Hive架构"></a>1.2  Hive架构</h3><h4 id="1-2-1-架构图"><a href="#1-2-1-架构图" class="headerlink" title="1.2.1 架构图"></a>1.2.1 架构图</h4><p><img src="/images/20180821/2.png"></p><p>Jobtracker是hadoop1.x中的组件，它的功能相当于： Resourcemanager+AppMaster</p><p>TaskTracker 相当于：  Nodemanager  +  yarnchild</p><h4 id="1-2-2-基本组成"><a href="#1-2-2-基本组成" class="headerlink" title="1.2.2 基本组成"></a>1.2.2 基本组成</h4><pre class="language-none"><code class="language-none">• 用户接口：包括 CLI、JDBC/ODBC、WebGUI。• 元数据存储：通常是存储在关系数据库如 mysql , derby中。• 解释器、编译器、优化器、执行器。</code></pre><h4 id="1-2-3-各组件的基本功能"><a href="#1-2-3-各组件的基本功能" class="headerlink" title="1.2.3 各组件的基本功能"></a>1.2.3 各组件的基本功能</h4><pre class="language-none"><code class="language-none">• 用户接口主要由三个：CLI、JDBC/ODBC和WebGUI。其中，CLI为shell命令行；JDBC/ODBC是Hive的JAVA实现，与传统数据库JDBC类似；WebGUI是通过浏览器访问Hive。• 元数据存储：Hive 将元数据存储在数据库中。Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。• 解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后有 MapReduce 调用执行。</code></pre><h3 id="1-3-Hive与Hadoop的关系"><a href="#1-3-Hive与Hadoop的关系" class="headerlink" title="1.3 Hive与Hadoop的关系"></a>1.3 Hive与Hadoop的关系</h3><p>Hive利用HDFS存储数据，利用MapReduce查询数据</p><p><img src="/images/20180821/3.png"></p><h3 id="1-4-Hive与传统数据库对比"><a href="#1-4-Hive与传统数据库对比" class="headerlink" title="1.4 Hive与传统数据库对比"></a>1.4 Hive与传统数据库对比</h3><p><img src="/images/20180821/4.png"></p><p>总结：hive具有sql数据库的外表，但应用场景完全不同，hive只适合用来做批量数据统计分析</p><h3 id="1-5-Hive的数据存储"><a href="#1-5-Hive的数据存储" class="headerlink" title="1.5 Hive的数据存储"></a>1.5 Hive的数据存储</h3><pre class="language-none"><code class="language-none">1、Hive中所有的数据都存储在 HDFS 中，没有专门的数据存储格式（可支持Text，SequenceFile，ParquetFile，RCFILE等）2、只需要在创建表的时候告诉 Hive 数据中的列分隔符和行分隔符，Hive 就可以解析数据。3、Hive 中包含以下数据模型：DB、Table，External Table，Partition，Bucket。    • db：在hdfs中表现为${hive.metastore.warehouse.dir}目录下一个文件夹    • table：在hdfs中表现所属db目录下一个文件夹    • external table：外部表, 与table类似，不过其数据存放位置可以在任意指定路径普通表: 删除表后, hdfs上的文件都删了External外部表删除后, hdfs上的文件没有删除, 只是把文件删除了    • partition：在hdfs中表现为table目录下的子目录    • bucket：桶, 在hdfs中表现为同一个表目录下根据hash散列之后的多个文件, 会根据不同的文件把数据放到不同的文件中 </code></pre><h3 id="1-6-HIVE的安装部署"><a href="#1-6-HIVE的安装部署" class="headerlink" title="1.6 HIVE的安装部署"></a>1.6 HIVE的安装部署</h3><p>见我大数据软件安装教程</p><h4 id="1-6-1-Hive-thrift服务"><a href="#1-6-1-Hive-thrift服务" class="headerlink" title="1.6.1 Hive thrift服务"></a>1.6.1 Hive thrift服务</h4><pre class="language-none"><code class="language-none">启动方式，（假如是在hadoop01上）：启动为前台：bin/hiveserver2启动为后台：nohup bin/hiveserver2 1&gt;/var/log/hiveserver.log 2&gt;/var/log/hiveserver.err &amp;启动成功后，可以在别的节点上用beeline去连接    • 方式（1）hive/bin/beeline  回车，进入beeline的命令界面输入命令连接hiveserver2beeline&gt; !connect jdbc:hive2//mini1:10000（hadoop01是hiveserver2所启动的那台主机名，端口默认是10000）    • 方式（2）或者启动就连接：bin/beeline -u jdbc:hive2://mini1:10000 -n hadoop接下来就可以做正常sql查询了</code></pre><h4 id="1-6-2-Hive命令"><a href="#1-6-2-Hive命令" class="headerlink" title="1.6.2 Hive命令"></a>1.6.2 Hive命令</h4><pre class="language-none"><code class="language-none">[hadoop@hdp-node-02 ~]$ hive  -e  ‘sql’</code></pre><h2 id="2-Hive基本操作"><a href="#2-Hive基本操作" class="headerlink" title="2 Hive基本操作"></a>2 Hive基本操作</h2><h3 id="2-1-DDL操作"><a href="#2-1-DDL操作" class="headerlink" title="2.1 DDL操作"></a>2.1 DDL操作</h3><h4 id="2-1-1-创建表"><a href="#2-1-1-创建表" class="headerlink" title="2.1.1 创建表"></a>2.1.1 创建表</h4><p>建表语法</p><pre class="language-none"><code class="language-none">CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name    [(col_name data_type [COMMENT col_comment], ...)]    [COMMENT table_comment]    [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]    [CLUSTERED BY (col_name, col_name, ...)    [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]    [ROW FORMAT row_format]    [STORED AS file_format]    [LOCATION hdfs_path]</code></pre><p>说明：</p><pre class="language-none"><code class="language-none">    1、 CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。    2、 EXTERNAL关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION），Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。    3、 LIKE 允许用户复制现有的表结构，但是不复制数据。    4、 ROW FORMAT DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char]         [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]    | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用自带的 SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive通过 SerDe 确定表的具体的列的数据。    5、 STORED AS SEQUENCEFILE|TEXTFILE|RCFILE如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。6、CLUSTERED BY对于每一个表（table）或者分区， Hive可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive也是 针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中。 把表（或者分区）组织成桶（Bucket）有两个理由：（1）获得更高的查询处理效率。桶为表加上了额外的结构，Hive 在处理有些查询时能利用这个结构。具体而言，连接两个在（包含连接列的）相同列上划分了桶的表，可以使用 Map 端连接 （Map-side join）高效的实现。比如JOIN操作。对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了桶操作。那么将保存相同列值的桶进行JOIN操作就可以，可以大大较少JOIN的数据量。（2）使取样（sampling）更高效。在处理大规模数据集时，在开发和修改查询的阶段，如果能在数据集的一小部分数据上试运行查询，会带来很多方便。</code></pre><p>具体实例:<br>1.创建内部表mytable。</p><p><img src="/images/20180821/5.png"></p><p>2.创建外部表pageview。</p><p><img src="/images/20180821/6.png"></p><p>3.创建分区表invites。</p><pre class="language-none"><code class="language-none">create table student_p(Sno int,Sname string,Sex string,Sage int,Sdept string) partitioned by(part string) row format delimited fields terminated by ','stored as textfile;</code></pre><p><img src="/images/20180821/7.png"></p><p>4.创建带桶的表student。</p><p><img src="/images/20180821/8.png"></p><h4 id="2-1-2-修改表"><a href="#2-1-2-修改表" class="headerlink" title="2.1.2 修改表"></a>2.1.2 修改表</h4><p>增加/删除分区:</p><pre class="language-none"><code class="language-none">    • 语法结构ALTER TABLE table_name ADD [IF NOT EXISTS] partition_spec [ LOCATION 'location1' ] partition_spec [ LOCATION 'location2' ] ...partition_spec:: PARTITION (partition_col = partition_col_value, partition_col = partiton_col_value, ...)ALTER TABLE table_name DROP partition_spec, partition_spec,...    • 具体实例alter table student_p add partition(part='a') partition(part='b');</code></pre><p>重命名表:</p><pre class="language-none"><code class="language-none">    • 语法结构ALTER TABLE table_name RENAME TO new_table_name</code></pre><p>增加/更新列:</p><pre class="language-none"><code class="language-none">    • 语法结构ALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...) 注：ADD是代表新增一字段，字段位置在所有列后面(partition列前)，REPLACE则是表示替换表中所有字段。ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]</code></pre><h4 id="2-1-3-显示命令"><a href="#2-1-3-显示命令" class="headerlink" title="2.1.3 显示命令"></a>2.1.3 显示命令</h4><pre class="language-none"><code class="language-none">show tablesshow databasesshow partitionsshow functionsdesc extended t_name;desc formatted table_name;</code></pre><h3 id="2-2-DML操作"><a href="#2-2-DML操作" class="headerlink" title="2.2  DML操作"></a>2.2  DML操作</h3><h4 id="2-2-1-Load"><a href="#2-2-1-Load" class="headerlink" title="2.2.1 Load"></a>2.2.1 Load</h4><pre class="language-none"><code class="language-none">• 语法结构LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]说明：    1、 Load 操作只是单纯的复制/移动操作，将数据文件移动到 Hive 表对应的位置。    2、 filepath：相对路径，例如：project/data1 绝对路径，例如：/user/hive/project/data1 包含模式的完整 URI，列如：hdfs://namenode:9000/user/hive/project/data1    3、 LOCAL关键字如果指定了 LOCAL， load 命令会去查找本地文件系统中的 filepath。如果没有指定 LOCAL 关键字，则根据inpath中的uri查找文件    4、 OVERWRITE 关键字如果使用了 OVERWRITE 关键字，则目标表（或者分区）中的内容会被删除，然后再将 filepath 指向的文件/目录中的内容添加到表/分区中。 如果目标表（分区）已经有一个文件，并且文件名和 filepath 中的文件名冲突，那么现有的文件会被新文件所替代。 </code></pre><h4 id="2-2-2-Insert"><a href="#2-2-2-Insert" class="headerlink" title="2.2.2 Insert"></a>2.2.2 Insert</h4><pre class="language-none"><code class="language-none">    1. 将查询结果插入Hive表    • 语法结构INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1 FROM from_statementMultiple inserts:FROM from_statement INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1 [INSERT OVERWRITE TABLE tablename2 [PARTITION ...] select_statement2] ...Dynamic partition inserts:INSERT OVERWRITE TABLE tablename PARTITION (partcol1[=val1], partcol2[=val2] ...) select_statement FROM from_statement     2.  导出表数据    • 语法结构INSERT OVERWRITE [LOCAL] DIRECTORY directory1 SELECT ... FROM ...multiple inserts:FROM from_statementINSERT OVERWRITE [LOCAL] DIRECTORY directory1 select_statement1[INSERT OVERWRITE [LOCAL] DIRECTORY directory2 select_statement2] ...</code></pre><h4 id="2-2-3-SELECT"><a href="#2-2-3-SELECT" class="headerlink" title="2.2.3 SELECT"></a>2.2.3 SELECT</h4><pre class="language-none"><code class="language-none">1. 基本的Select操作    • 语法结构SELECT [ALL | DISTINCT] select_expr, select_expr, ... FROM table_reference[WHERE where_condition] [GROUP BY col_list [HAVING condition]] [CLUSTER BY col_list   | [DISTRIBUTE BY col_list] [SORT BY| ORDER BY col_list] ] [LIMIT number]注：1、order by 会对输入做全局排序，因此只有一个reducer，会导致当输入规模较大时，需要较长的计算时间。2、sort by不是全局排序，其在数据进入reducer前完成排序。因此，如果用sort by进行排序，并且设置mapred.reduce.tasks&gt;1，则sort by只保证每个reducer的输出有序，不保证全局有序。3、distribute by根据distribute by指定的内容将数据分到同一个reducer。4、Cluster by 除了具有Distribute by的功能外，还会对该字段进行排序。因此，常常认为cluster by = distribute by + sort by</code></pre><h3 id="2-3Hive-Join"><a href="#2-3Hive-Join" class="headerlink" title="2.3Hive Join"></a>2.3Hive Join</h3><h4 id="2-3-1-语法结构"><a href="#2-3-1-语法结构" class="headerlink" title="2.3.1  语法结构"></a>2.3.1  语法结构</h4><pre class="language-none"><code class="language-none">join_table:  table_reference JOIN table_factor [join_condition]  | table_reference {LEFT|RIGHT|FULL} [OUTER] JOIN table_reference join_condition  | table_reference LEFT SEMI JOIN table_reference join_conditionHive 支持等值连接（equality joins）、外连接（outer joins）和（left/right joins）。Hive 不支持非等值的连接，因为非等值连接非常难转化到 map/reduce 任务。另外，Hive 支持多于 2 个表的连接。</code></pre><p>写 join 查询时，需要注意几个关键点：</p><ol><li><p>只支持等值join</p><pre class="language-none"><code class="language-none">例如： SELECT a.* FROM a JOIN b ON (a.id = b.id)SELECT a.* FROM a JOIN b ON (a.id = b.id AND a.department = b.department)是正确的，然而:SELECT a.* FROM a JOIN b ON (a.id&gt;b.id)是错误的。</code></pre></li><li><p>可以 join 多于 2 个表。</p><pre class="language-none"><code class="language-none">例如SELECT a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key2)如果join中多个表的 join key 是同一个，则 join 会被转化为单个 map/reduce 任务，例如：SELECT a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key1)被转化为单个 map/reduce 任务，因为 join 中只使用了 b.key1 作为 join key。SELECT a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1)JOIN c ON (c.key = b.key2)而这一 join 被转化为 2 个 map/reduce 任务。因为 b.key1 用于第一次 join 条件，而 b.key2 用于第二次 join。</code></pre></li></ol><p>3．join 时，每次 map/reduce 任务的逻辑：</p><pre class="language-none"><code class="language-none">reducer 会缓存 join 序列中除了最后一个表的所有表的记录，再通过最后一个表将结果序列化到文件系统。这一实现有助于在 reduce 端减少内存的使用量。实践中，应该把最大的那个表写在最后（否则会因为缓存浪费大量内存）。例如： SELECT a.val, b.val, c.val FROM a    JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key1)所有表都使用同一个 join key（使用 1 次 map/reduce 任务计算）。Reduce 端会缓存 a 表和 b 表的记录，然后每次取得一个 c 表的记录就计算一次 join 结果，类似的还有：  SELECT a.val, b.val, c.val FROM a    JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key2)这里用了 2 次 map/reduce 任务。第一次缓存 a 表，用 b 表序列化；第二次缓存第一次 map/reduce 任务的结果，然后用 c 表序列化。</code></pre><p>4．LEFT，RIGHT 和 FULL OUTER 关键字用于处理 join 中空记录的情况</p><pre class="language-none"><code class="language-none">例如：  SELECT a.val, b.val FROM a LEFT OUTER  JOIN b ON (a.key=b.key)对应所有 a 表中的记录都有一条记录输出。输出的结果应该是 a.val, b.val，当 a.key=b.key 时，而当 b.key 中找不到等值的 a.key 记录时也会输出:a.val, NULL所以 a 表中的所有记录都被保留了；“a RIGHT OUTER JOIN b”会保留所有 b 表的记录。Join 发生在 WHERE 子句之前。如果你想限制 join 的输出，应该在 WHERE 子句中写过滤条件——或是在 join 子句中写。这里面一个容易混淆的问题是表分区的情况：  SELECT a.val, b.val FROM a  LEFT OUTER JOIN b ON (a.key=b.key)  WHERE a.ds='2009-07-07' AND b.ds='2009-07-07'会 join a 表到 b 表（OUTER JOIN），列出 a.val 和 b.val 的记录。WHERE 从句中可以使用其他列作为过滤条件。但是，如前所述，如果 b 表中找不到对应 a 表的记录，b 表的所有列都会列出 NULL，包括 ds 列。也就是说，join 会过滤 b 表中不能找到匹配 a 表 join key 的所有记录。这样的话，LEFT OUTER 就使得查询结果与 WHERE 子句无关了。解决的办法是在 OUTER JOIN 时使用以下语法：  SELECT a.val, b.val FROM a LEFT OUTER JOIN b  ON (a.key=b.key AND      b.ds='2009-07-07' AND      a.ds='2009-07-07')这一查询的结果是预先在 join 阶段过滤过的，所以不会存在上述问题。这一逻辑也可以应用于 RIGHT 和 FULL 类型的 join 中。Join 是不能交换位置的。无论是 LEFT 还是 RIGHT join，都是左连接的。  SELECT a.val1, a.val2, b.val, c.val  FROM a  JOIN b ON (a.key = b.key)  LEFT OUTER JOIN c ON (a.key = c.key)先 join a 表到 b 表，丢弃掉所有 join key 中不匹配的记录，然后用这一中间结果和 c 表做 join。这一表述有一个不太明显的问题，就是当一个 key 在 a 表和 c 表都存在，但是 b 表中不存在的时候：整个记录在第一次 join，即 a JOIN b 的时候都被丢掉了（包括a.val1，a.val2和a.key），然后我们再和 c 表 join 的时候，如果 c.key 与 a.key 或 b.key 相等，就会得到这样的结果：NULL, NULL, NULL, c.val</code></pre><h2 id="3-Hive-Shell参数"><a href="#3-Hive-Shell参数" class="headerlink" title="3.Hive Shell参数"></a>3.Hive Shell参数</h2><h3 id="3-1-Hive命令行"><a href="#3-1-Hive命令行" class="headerlink" title="3.1 Hive命令行"></a>3.1 Hive命令行</h3><pre class="language-none"><code class="language-none">    • 语法结构hive [-hiveconf x=y]* [&lt;-i filename&gt;]* [&lt;-f filename&gt;|&lt;-e query-string&gt;] [-S]说明：    1、 -i&nbsp;从文件初始化HQL。    2、 -e从命令行执行指定的HQL     3、 -f 执行HQL脚本     4、 -v 输出执行的HQL语句到控制台     5、 -p &lt;port&gt; connect to Hive Server on port number     6、 -hiveconf x=y Use this to set hive/hadoop configuration variables.</code></pre><h3 id="3-2-Hive参数配置方式"><a href="#3-2-Hive参数配置方式" class="headerlink" title="3.2 Hive参数配置方式"></a>3.2 Hive参数配置方式</h3><pre class="language-none"><code class="language-none">Hive参数大全：https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties开发Hive应用时，不可避免地需要设定Hive的参数。设定Hive的参数可以调优HQL代码的执行效率，或帮助定位问题。然而实践中经常遇到的一个问题是，为什么设定的参数没有起作用？这通常是错误的设定方式导致的。对于一般参数，有以下三种设定方式：    • 配置文件     • 命令行参数     • 参数声明 配置文件：Hive的配置文件包括    • 用户自定义配置文件：$HIVE_CONF_DIR/hive-site.xml     • 默认配置文件：$HIVE_CONF_DIR/hive-default.xml 用户自定义配置会覆盖默认配置。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop的配置。配置文件的设定对本机启动的所有Hive进程都有效。命令行参数：启动Hive（客户端或Server方式）时，可以在命令行添加-hiveconf param=value来设定参数，例如：bin/hive -hiveconf hive.root.logger=INFO,console这一设定对本次启动的Session（对于Server方式启动，则是所有请求的Sessions）有效。参数声明：可以在HQL中使用SET关键字设定参数，例如：set mapred.reduce.tasks=100;这一设定的作用域也是session级的。上述三种设定方式的优先级依次递增。即参数声明覆盖命令行参数，命令行参数覆盖配置文件设定。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在Session建立以前已经完成了。    </code></pre><h2 id="4-HIVE函数"><a href="#4-HIVE函数" class="headerlink" title="4.HIVE函数"></a>4.HIVE函数</h2><h3 id="4-1-内置运算符"><a href="#4-1-内置运算符" class="headerlink" title="4.1 内置运算符"></a>4.1 内置运算符</h3><p>内容较多，见《Hive官方文档》</p><h3 id="4-2-内置函数"><a href="#4-2-内置函数" class="headerlink" title="4.2 内置函数"></a>4.2 内置函数</h3><p>内容较多，见《Hive官方文档》</p><h3 id="4-3-Hive自定义函数和Transform"><a href="#4-3-Hive自定义函数和Transform" class="headerlink" title="4.3 Hive自定义函数和Transform"></a>4.3 Hive自定义函数和Transform</h3><p>当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。</p><h4 id="4-3-1-自定义函数类别"><a href="#4-3-1-自定义函数类别" class="headerlink" title="4.3.1 自定义函数类别"></a>4.3.1 自定义函数类别</h4><p>UDF  作用于单个数据行，产生一个数据行作为输出。（数学函数，字符串函数）<br>UDAF（用户定义聚集函数）：接收多个输入数据行，并产生一个输出数据行。（count，max）</p><h4 id="4-3-2-UDF开发实例"><a href="#4-3-2-UDF开发实例" class="headerlink" title="4.3.2 UDF开发实例"></a>4.3.2 UDF开发实例</h4><pre class="language-none"><code class="language-none">1、先开发一个java类，继承UDF，并重载evaluate方法package cn.itcast.bigdata.udfimport org.apache.hadoop.hive.ql.exec.UDF;import org.apache.hadoop.io.Text;public final class Lower extends UDF{    public Text evaluate(final Text s){        if(s==null){return null;}        return new Text(s.toString().toLowerCase());    }}2、打成jar包上传到服务器3、将jar包添加到hive的classpathhive&gt;add JAR /home/hadoop/udf.jar;4、 创建临时函数与开发好的java class关联Hive&gt;create temporary function toprovince as 'cn.itcast.bigdata.udf.ToProvince';5、 即可在hql中使用自定义的函数strip&nbsp;Select strip(name),age from t_test;</code></pre><h4 id="4-3-3-Transform实现"><a href="#4-3-3-Transform实现" class="headerlink" title="4.3.3 Transform实现"></a>4.3.3 Transform实现</h4><pre class="language-none"><code class="language-none">Hive的 TRANSFORM 关键字提供了在SQL中调用自写脚本的功能适合实现Hive中没有的功能又不想写UDF的情况使用示例1：下面这句sql就是借用了weekday_mapper.py对数据进行了处理.CREATE TABLE u_data_new (  movieid INT,  rating INT,  weekday INT,  userid INT)ROW FORMAT DELIMITEDFIELDS TERMINATED BY '\t';add FILE weekday_mapper.py;INSERT OVERWRITE TABLE u_data_newSELECT  TRANSFORM (movieid, rating, unixtime,userid)  USING 'python weekday_mapper.py'  AS (movieid, rating, weekday,userid)FROM u_data;其中weekday_mapper.py内容如下#!/bin/pythonimport sysimport datetimefor line in sys.stdin:  line = line.strip()  movieid, rating, unixtime,userid = line.split('\t')  weekday = datetime.datetime.fromtimestamp(float(unixtime)).isoweekday()  print '\t'.join([movieid, rating, str(weekday),userid])使用示例2：下面的例子则是使用了shell的cat命令来处理数据FROM invites a INSERT OVERWRITE TABLE events SELECT TRANSFORM(a.foo, a.bar) AS (oof, rab) USING '/bin/cat' WHERE a.ds &gt; '2008-08-09';</code></pre><p><code>注：　教程二主要为hive实战</code></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop HA高可用</title>
      <link href="/2018/08/21/hadoop-ha-gao-ke-yong/"/>
      <url>/2018/08/21/hadoop-ha-gao-ke-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="hadoop-HA-学习"><a href="#hadoop-HA-学习" class="headerlink" title="hadoop HA 学习"></a><center>hadoop HA 学习</center></h1><pre class="language-none"><code class="language-none">HA运作机制        什么是HA        HADOOP如何实现HA        HDFS-HA详解        HA集群搭建目标：        掌握分布式系统中HA机制的思想        掌握HADOOP内置HA的运作机制        掌握HADOOP2.x的HA集群机制配置</code></pre><h2 id="1-hadoop-HA-机制"><a href="#1-hadoop-HA-机制" class="headerlink" title="1.hadoop HA 机制"></a>1.hadoop HA 机制</h2><p>前言：正式引入HA机制是从hadoop2.0开始，之前的版本中没有HA机制</p><h3 id="1-1-HA-运行机制"><a href="#1-1-HA-运行机制" class="headerlink" title="1.1 HA 运行机制"></a>1.1 HA 运行机制</h3><pre class="language-none"><code class="language-none">（1）hadoop-HA集群运作机制介绍所谓HA，即高可用（7*24小时不中断服务）实现高可用最关键的是消除单点故障hadoop-ha严格来说应该分成各个组件的HA机制——HDFS的HA、YARN的HA（2）HDFS的HA机制详解通过双namenode消除单点故障双namenode协调工作的要点：    A、元数据管理方式需要改变：    内存中各自保存一份元数据    Edits日志只能有一份，只有Active状态的namenode节点可以做写操作    两个namenode都可以读取edits    共享的edits放在一个共享存储中管理（qjournal和NFS两个主流实现）    B、需要一个状态管理功能模块    实现了一个zkfailover，常驻在每一个namenode所在的节点    每一个zkfailover负责监控自己所在namenode节点，利用zk进行状态标识    当需要进行状态切换时，由zkfailover来负责切换    切换时需要防止brain split现象的发生</code></pre><h3 id="1-2-HDFS-HA图解："><a href="#1-2-HDFS-HA图解：" class="headerlink" title="1.2 HDFS-HA图解："></a>1.2 HDFS-HA图解：</h3><p><img src="/images/20180821/1.png"></p><h3 id="1-3-HA集群的安装部署"><a href="#1-3-HA集群的安装部署" class="headerlink" title="1.3 HA集群的安装部署"></a>1.3 HA集群的安装部署</h3><h4 id="1-3-1-集群节点规划"><a href="#1-3-1-集群节点规划" class="headerlink" title="1.3.1 集群节点规划"></a>1.3.1 集群节点规划</h4><p>(1) 集群部署节点角色的规划（10节点）：</p><pre class="language-none"><code class="language-none">server01   namenode   zkfc    &gt; start-dfs.shserver02   namenode   zkfcserver03   resourcemanager    &gt; start-yarn.shserver04   resourcemanagerserver05   datanode   nodemanager     server06   datanode   nodemanager     server07   datanode   nodemanager     server08   journal node    zookeeperserver09   journal node    zookeeperserver10   journal node    zookeeper</code></pre><p>(2) 集群部署节点角色的规划（3节点）</p><pre class="language-none"><code class="language-none">server01   namenode    resourcemanager  zkfc   nodemanager  datanode   zookeeper   journal nodeserver02   namenode    resourcemanager  zkfc   nodemanager  datanode   zookeeper   journal nodeserver05   datanode    nodemanager     zookeeper    journal node</code></pre><h4 id="1-3-2-环境准备"><a href="#1-3-2-环境准备" class="headerlink" title="1.3.2 环境准备"></a>1.3.2 环境准备</h4><pre class="language-none"><code class="language-none">1、环境准备linux系统准备    ip地址配置    hostname配置    hosts映射配置    防火墙关闭init启动级别修改sudoers加入hadoop用户ssh免密登陆配置b/java环境的配置    上传jdk，解压，修改/etc/profile c/zookeeper集群的部署</code></pre><h4 id="1-3-3-配置文件"><a href="#1-3-3-配置文件" class="headerlink" title="1.3.3 配置文件"></a>1.3.3 配置文件</h4><p>(1 )core-site.xml</p><pre class="language-none"><code class="language-none">&lt;configuration&gt;                    &lt;!-- 指定hdfs的nameservice为ns1 --&gt;                    &lt;property&gt;                        &lt;name&gt;fs.defaultFS&lt;/name&gt;                        &lt;value&gt;hdfs://ns1/&lt;/value&gt;                    &lt;/property&gt;                    &lt;!-- 指定hadoop临时目录 --&gt;                    &lt;property&gt;                        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;                        &lt;value&gt;/home/hadoop/app/hadoop-2.4.1/tmp&lt;/value&gt;                    &lt;/property&gt;                    &lt;!-- 指定zookeeper地址 --&gt;                    &lt;property&gt;                        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;                        &lt;value&gt;weekend05:2181,weekend06:2181,weekend07:2181&lt;/value&gt;                    &lt;/property&gt;                &lt;/configuration&gt;</code></pre><p>(2) hdfs-site.xml</p><pre class="language-none"><code class="language-none">configuration&gt;&lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;&lt;property&gt;    &lt;name&gt;dfs.nameservices&lt;/name&gt;    &lt;value&gt;ns1&lt;/value&gt;&lt;/property&gt;&lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;    &lt;value&gt;nn1,nn2&lt;/value&gt;&lt;/property&gt;&lt;!-- nn1的RPC通信地址 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;    &lt;value&gt;weekend01:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- nn1的http通信地址 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;    &lt;value&gt;weekend01:50070&lt;/value&gt;&lt;/property&gt;&lt;!-- nn2的RPC通信地址 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;    &lt;value&gt;weekend02:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- nn2的http通信地址 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;    &lt;value&gt;weekend02:50070&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定NameNode的edits元数据在JournalNode上的存放位置 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;    &lt;value&gt;qjournal://weekend05:8485;weekend06:8485;weekend07:8485/ns1&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;&lt;property&gt;    &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;    &lt;value&gt;/home/hadoop/app/hadoop-2.4.1/journaldata&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启NameNode失败自动切换 --&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置失败自动切换实现方式 --&gt;&lt;property&gt;    &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;    &lt;value&gt;        sshfence        shell(/bin/true)    &lt;/value&gt;&lt;/property&gt;&lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;    &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置sshfence隔离机制超时时间 --&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;    &lt;value&gt;30000&lt;/value&gt;&lt;/property&gt;/configuration&gt;</code></pre><h4 id="1-2-4-集群运维测试"><a href="#1-2-4-集群运维测试" class="headerlink" title="1.2.4 集群运维测试"></a>1.2.4 集群运维测试</h4><p>1、Datanode动态上下线</p><pre class="language-none"><code class="language-none">Datanode动态上下线很简单，步骤如下：    a) 准备一台服务器，设置好环境    b) 部署hadoop的安装包，并同步集群配置    c) 联网上线，新datanode会自动加入集群    d) 如果是一次增加大批datanode，还应该做集群负载重均衡</code></pre><p>2、Namenode状态切换管理</p><pre class="language-none"><code class="language-none">使用的命令上hdfs  haadmin可用 hdfs  haadmin –help查看所有帮助信息可以看到，状态操作的命令示例：查看namenode工作状态   hdfs haadmin -getServiceState nn1将standby状态namenode切换到activehdfs haadmin –transitionToActive nn1将active状态namenode切换到standbyhdfs haadmin –transitionToStandby nn2</code></pre><p>3、数据块的balance</p><pre class="language-none"><code class="language-none">启动balancer的命令：start-balancer.sh -threshold 8运行之后，会有Balancer进程出现：上述命令设置了Threshold为8%，那么执行balancer命令的时候，首先统计所有DataNode的磁盘利用率的均值，然后判断如果某一个DataNode的磁盘利用率超过这个均值Threshold，那么将会把这个DataNode的block转移到磁盘利用率低的DataNode，这对于新节点的加入来说十分有用。Threshold的值为1到100之间，不显示的进行参数设置的话，默认是10。</code></pre><h4 id="1-3-5-HA下hdfs-api变化"><a href="#1-3-5-HA下hdfs-api变化" class="headerlink" title="1.3.5 HA下hdfs-api变化"></a>1.3.5 HA下hdfs-api变化</h4><p>注: 客户端需要nameservice的配置信息，其他不变</p><pre class="language-none"><code class="language-none">/** * 如果访问的是一个ha机制的集群 * 则一定要把core-site.xml和hdfs-site.xml配置文件放在客户端程序的classpath下 * 以让客户端能够理解hdfs://ns1/中  “ns1”是一个ha机制中的namenode对——nameservice * 以及知道ns1下具体的namenode通信地址 * @author * */public class UploadFile {    public static void main(String[] args) throws Exception  {        Configuration conf = new Configuration();        conf.set("fs.defaultFS", "hdfs://ns1/");        FileSystem fs = FileSystem.get(new URI("hdfs://ns1/"),conf,"hadoop");        fs.copyFromLocalFile(new Path("g:/eclipse-jee-luna-SR1-linux-gtk.tar.gz"), new Path("hdfs://ns1/"));        fs.close();    }}</code></pre><h3 id="1-4-Federation下-mr程序运行的staging提交目录问题"><a href="#1-4-Federation下-mr程序运行的staging提交目录问题" class="headerlink" title="1.4 Federation下 mr程序运行的staging提交目录问题"></a>1.4 Federation下 mr程序运行的staging提交目录问题</h3><pre class="language-none"><code class="language-none">&lt;property&gt;  &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt;  &lt;value&gt;/bi/tmp/hadoop-yarn/staging&lt;/value&gt;  &lt;description&gt;The staging dir used while submitting jobs.  &lt;/description&gt;&lt;/property&gt;</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop学习三之mapreduce加强</title>
      <link href="/2018/04/27/hadoop-xue-xi-san-zhi-mapreduce-jia-qiang/"/>
      <url>/2018/04/27/hadoop-xue-xi-san-zhi-mapreduce-jia-qiang/</url>
      
        <content type="html"><![CDATA[<h3 id="流量统计相关需求"><a href="#流量统计相关需求" class="headerlink" title="流量统计相关需求"></a>流量统计相关需求</h3><p>1、对流量日志中的用户统计总上、下行流量<br>技术点： 自定义javaBean用来在mapreduce中充当value<br>注意： javaBean要实现Writable接口，实现两个方法</p><pre class="language-none"><code class="language-none">//序列化，将对象的字段信息写入输出流    @Override    public void write(DataOutput out) throws IOException {        out.writeLong(upflow);        out.writeLong(downflow);        out.writeLong(sumflow);    }    //反序列化，从输入流中读取各个字段信息    @Override    public void readFields(DataInput in) throws IOException {        upflow = in.readLong();        downflow = in.readLong();        sumflow = in.readLong();    }</code></pre><p>2、统计流量且按照流量大小倒序排序</p><p>技术点：这种需求，用一个mapreduce -job 不好实现，需要两个mapreduce -job<br>第一个job负责流量统计，跟上题相同<br>第二个job读入第一个job的输出，然后做排序<br>要将flowBean作为map的key输出，这样mapreduce就会自动排序<br>     此时，flowBean要实现接口WritableComparable<br>     要实现其中的compareTo()方法，方法中，我们可以定义倒序比较的逻辑</p><p>3、统计流量且按照手机号的归属地，将结果数据输出到不同的省份文件中<br>技术点：自定义Partitioner</p><pre class="language-none"><code class="language-none">    @Override    public int getPartition(Text key, FlowBean value, int numPartitions) {        String prefix = key.toString().substring(0,3);        Integer partNum = pmap.get(prefix);        return (partNum==null?4:partNum);    }自定义partition后，要根据自定义partitioner的逻辑设置相应数量的reduce taskjob.setNumReduceTasks(5);注意：如果reduceTask的数量&gt;= getPartition的结果数  ，则会多产生几个空的输出文件part-r-000xx如果     1&lt;reduceTask的数量&lt;getPartition的结果数 ，则有一部分分区数据无处安放，会Exception！！！如果 reduceTask的数量=1，则不管mapTask端输出多少个分区文件，最终结果都交给这一个reduceTask，最终也就只会产生一个结果文件 part-r-00000</code></pre><h3 id="社交粉丝数据分析"><a href="#社交粉丝数据分析" class="headerlink" title="社交粉丝数据分析"></a>社交粉丝数据分析</h3><p>以下是qq的好友列表数据，冒号前是一个用，冒号后是该用户的所有好友（数据中的好友关系是单向的）<br>A:B,C,D,F,E,O<br>B:A,C,E,K<br>C:F,A,D,I<br>D:A,E,F,L<br>E:B,C,D,M,L<br>F:A,B,C,D,E,O,M<br>G:A,C,D,E,F<br>H:A,C,D,E,O<br>I:A,O<br>J:B,O<br>K:A,C,D<br>L:D,E,F<br>M:E,F,G<br>O:A,H,I,J</p><p>求出哪些人两两之间有共同好友，及他俩的共同好友都有谁？<br>解题思路：</p><pre class="language-none"><code class="language-none">第一步  map读一行   A:B,C,D,F,E,O输出    &lt;B,A&gt;&lt;C,A&gt;&lt;D,A&gt;&lt;F,A&gt;&lt;E,A&gt;&lt;O,A&gt;在读一行   B:A,C,E,K输出   &lt;A,B&gt;&lt;C,B&gt;&lt;E,B&gt;&lt;K,B&gt;REDUCE拿到的数据比如&lt;C,A&gt;&lt;C,B&gt;&lt;C,E&gt;&lt;C,F&gt;&lt;C,G&gt;......输出：  &lt;A-B,C&gt;&lt;A-E,C&gt;&lt;A-F,C&gt;&lt;A-G,C&gt;&lt;B-E,C&gt;&lt;B-F,C&gt;.....第二步map读入一行&lt;A-B,C&gt;直接输出&lt;A-B,C&gt;reduce读入数据  &lt;A-B,C&gt;&lt;A-B,F&gt;&lt;A-B,G&gt;.......输出： A-B  C,F,G,.....</code></pre><h3 id="倒排索引建立"><a href="#倒排索引建立" class="headerlink" title="倒排索引建立"></a>倒排索引建立</h3><p>需求：有大量的文本（文档、网页），需要建立搜索索引</p><h4 id="1-自定义inputFormat"><a href="#1-自定义inputFormat" class="headerlink" title="1.    自定义inputFormat"></a>1.    自定义inputFormat</h4><p>1.1 需求</p><p>无论hdfs还是mapreduce，对于小文件都有损效率，实践中，又难免面临处理大量小文件的场景，此时，就需要有相应解决方案</p><p>1.2 分析</p><p>小文件的优化无非以下几种方式：<br>1、    在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS<br>2、    在业务处理之前，在HDFS上使用mapreduce程序对小文件进行合并<br>3、    在mapreduce处理时，可采用combineInputFormat提高效率</p><p>1.3 实现<br>本节实现的是上述第二种方式<br>程序的核心机制：<br>自定义一个InputFormat<br>改写RecordReader，实现一次读取一个完整文件封装为KV<br>在输出时使用SequenceFileOutPutFormat输出合并文件</p><p>代码如下：<br>自定义InputFromat</p><pre class="language-none"><code class="language-none">public class WholeFileInputFormat extends        FileInputFormat&lt;NullWritable, BytesWritable&gt; {    //设置每个小文件不可分片,保证一个小文件生成一个key-value键值对    @Override    protected boolean isSplitable(JobContext context, Path file) {        return false;    }    @Override    public RecordReader&lt;NullWritable, BytesWritable&gt; createRecordReader(            InputSplit split, TaskAttemptContext context) throws IOException,            InterruptedException {        WholeFileRecordReader reader = new WholeFileRecordReader();        reader.initialize(split, context);        return reader;    }}自定义RecordReaderclass WholeFileRecordReader extends RecordReader&lt;NullWritable, BytesWritable&gt; {    private FileSplit fileSplit;    private Configuration conf;    private BytesWritable value = new BytesWritable();    private boolean processed = false;    @Override    public void initialize(InputSplit split, TaskAttemptContext context)            throws IOException, InterruptedException {        this.fileSplit = (FileSplit) split;        this.conf = context.getConfiguration();    }    @Override    public boolean nextKeyValue() throws IOException, InterruptedException {        if (!processed) {            byte[] contents = new byte[(int) fileSplit.getLength()];            Path file = fileSplit.getPath();            FileSystem fs = file.getFileSystem(conf);            FSDataInputStream in = null;            try {                in = fs.open(file);                IOUtils.readFully(in, contents, 0, contents.length);                value.set(contents, 0, contents.length);            } finally {                IOUtils.closeStream(in);            }            processed = true;            return true;        }        return false;    }    @Override    public NullWritable getCurrentKey() throws IOException,            InterruptedException {        return NullWritable.get();    }    @Override    public BytesWritable getCurrentValue() throws IOException,            InterruptedException {        return value;    }    @Override    public float getProgress() throws IOException {        return processed ? 1.0f : 0.0f;    }    @Override    public void close() throws IOException {        // do nothing    }}定义mapreduce处理流程public class SmallFilesToSequenceFileConverter extends Configured implements        Tool {    static class SequenceFileMapper extends            Mapper&lt;NullWritable, BytesWritable, Text, BytesWritable&gt; {        private Text filenameKey;        @Override        protected void setup(Context context) throws IOException,                InterruptedException {            InputSplit split = context.getInputSplit();            Path path = ((FileSplit) split).getPath();            filenameKey = new Text(path.toString());        }        @Override        protected void map(NullWritable key, BytesWritable value,                Context context) throws IOException, InterruptedException {            context.write(filenameKey, value);        }    }    @Override    public int run(String[] args) throws Exception {        Configuration conf = new Configuration();        System.setProperty("HADOOP_USER_NAME", "hdfs");        String[] otherArgs = new GenericOptionsParser(conf, args)                .getRemainingArgs();        if (otherArgs.length != 2) {            System.err.println("Usage: combinefiles &lt;in&gt; &lt;out&gt;");            System.exit(2);        }        Job job = Job.getInstance(conf,"combine small files to sequencefile");//        job.setInputFormatClass(WholeFileInputFormat.class);        job.setOutputFormatClass(SequenceFileOutputFormat.class);        job.setOutputKeyClass(Text.class);        job.setOutputValueClass(BytesWritable.class);        job.setMapperClass(SequenceFileMapper.class);        return job.waitForCompletion(true) ? 0 : 1;    }    public static void main(String[] args) throws Exception {        int exitCode = ToolRunner.run(new SmallFilesToSequenceFileConverter(),                args);        System.exit(exitCode);    }}</code></pre><p>2    自定义outputFormat</p><p>2.1 需求<br>现有一些原始日志需要做增强解析处理，流程：<br>1、    从原始日志文件中读取数据<br>2、    根据日志中的一个URL字段到外部知识库中获取信息增强到原始日志<br>3、    如果成功增强，则输出到增强结果目录；如果增强失败，则抽取原始数据中URL字段输出到待爬清单目录</p><p>2.2 分析<br>程序的关键点是要在一个mapreduce程序中根据数据的不同输出两类结果到不同目录，这类灵活的输出需求可以通过自定义outputformat来实现</p><p>2.3 实现<br>实现要点：<br>1、    在mapreduce中访问外部资源<br>2、    自定义outputformat，改写其中的recordwriter，改写具体输出数据的方法write()</p><p>代码实现如下：<br>数据库获取数据的工具</p><pre class="language-none"><code class="language-none">public class DBLoader {    public static void dbLoader(HashMap&lt;String, String&gt; ruleMap) {        Connection conn = null;        Statement st = null;        ResultSet res = null;        try {            Class.forName("com.mysql.jdbc.Driver");            conn = DriverManager.getConnection("jdbc:mysql://hdp-node01:3306/urlknowledge", "root", "root");            st = conn.createStatement();            res = st.executeQuery("select url,content from urlcontent");            while (res.next()) {                ruleMap.put(res.getString(1), res.getString(2));            }        } catch (Exception e) {            e.printStackTrace();        } finally {            try{                if(res!=null){                    res.close();                }                if(st!=null){                    st.close();                }                if(conn!=null){                    conn.close();                }            }catch(Exception e){                e.printStackTrace();            }        }    }    public static void main(String[] args) {        DBLoader db = new DBLoader();        HashMap&lt;String, String&gt; map = new HashMap&lt;String,String&gt;();        db.dbLoader(map);        System.out.println(map.size());    }}自定义一个outputformatpublic class LogEnhancerOutputFormat extends FileOutputFormat&lt;Text, NullWritable&gt;{    @Override    public RecordWriter&lt;Text, NullWritable&gt; getRecordWriter(TaskAttemptContext context) throws IOException, InterruptedException {        FileSystem fs = FileSystem.get(context.getConfiguration());        Path enhancePath = new Path("hdfs://hdp-node01:9000/flow/enhancelog/enhanced.log");        Path toCrawlPath = new Path("hdfs://hdp-node01:9000/flow/tocrawl/tocrawl.log");        FSDataOutputStream enhanceOut = fs.create(enhancePath);        FSDataOutputStream toCrawlOut = fs.create(toCrawlPath);        return new MyRecordWriter(enhanceOut,toCrawlOut);    }    static class MyRecordWriter extends RecordWriter&lt;Text, NullWritable&gt;{        FSDataOutputStream enhanceOut = null;        FSDataOutputStream toCrawlOut = null;        public MyRecordWriter(FSDataOutputStream enhanceOut, FSDataOutputStream toCrawlOut) {            this.enhanceOut = enhanceOut;            this.toCrawlOut = toCrawlOut;        }        @Override        public void write(Text key, NullWritable value) throws IOException, InterruptedException {            //有了数据，你来负责写到目的地  —— hdfs            //判断，进来内容如果是带tocrawl的，就往待爬清单输出流中写 toCrawlOut            if(key.toString().contains("tocrawl")){                toCrawlOut.write(key.toString().getBytes());            }else{                enhanceOut.write(key.toString().getBytes());            }        }        @Override        public void close(TaskAttemptContext context) throws IOException, InterruptedException {            if(toCrawlOut!=null){                toCrawlOut.close();            }            if(enhanceOut!=null){                enhanceOut.close();            }        }    }}开发mapreduce处理流程/** * 这个程序是对每个小时不断产生的用户上网记录日志进行增强(将日志中的url所指向的网页内容分析结果信息追加到每一行原始日志后面) *  * @author *  */public class LogEnhancer {    static class LogEnhancerMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt; {        HashMap&lt;String, String&gt; knowledgeMap = new HashMap&lt;String, String&gt;();        /**         * maptask在初始化时会先调用setup方法一次 利用这个机制，将外部的知识库加载到maptask执行的机器内存中         */        @Override        protected void setup(org.apache.hadoop.mapreduce.Mapper.Context context) throws IOException, InterruptedException {            DBLoader.dbLoader(knowledgeMap);        }        @Override        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {            String line = value.toString();            String[] fields = StringUtils.split(line, "\t");            try {                String url = fields[26];                // 对这一行日志中的url去知识库中查找内容分析信息                String content = knowledgeMap.get(url);                // 根据内容信息匹配的结果，来构造两种输出结果                String result = "";                if (null == content) {                    // 输往待爬清单的内容                    result = url + "\t" + "tocrawl\n";                } else {                    // 输往增强日志的内容                    result = line + "\t" + content + "\n";                }                context.write(new Text(result), NullWritable.get());            } catch (Exception e) {            }        }    }    public static void main(String[] args) throws Exception {        Configuration conf = new Configuration();        Job job = Job.getInstance(conf);        job.setJarByClass(LogEnhancer.class);        job.setMapperClass(LogEnhancerMapper.class);        job.setOutputKeyClass(Text.class);        job.setOutputValueClass(NullWritable.class);        // 要将自定义的输出格式组件设置到job中        job.setOutputFormatClass(LogEnhancerOutputFormat.class);        FileInputFormat.setInputPaths(job, new Path(args[0]));        // 虽然我们自定义了outputformat，但是因为我们的outputformat继承自fileoutputformat        // 而fileoutputformat要输出一个_SUCCESS文件，所以，在这还得指定一个输出目录        FileOutputFormat.setOutputPath(job, new Path(args[1]));        job.waitForCompletion(true);        System.exit(0);    }}</code></pre><h3 id="3-自定义GroupingComparator"><a href="#3-自定义GroupingComparator" class="headerlink" title="3.    自定义GroupingComparator"></a>3.    自定义GroupingComparator</h3><p>3.1 需求</p><pre class="language-none"><code class="language-none">有如下订单数据订单id    商品id    成交金额Order_0000001    Pdt_01    222.8Order_0000001    Pdt_05    25.8Order_0000002    Pdt_03    522.8Order_0000002    Pdt_04    122.4Order_0000003    Pdt_01    222.8现在需要求出每一个订单中成交金额最大的一笔交易</code></pre><p>3.1 需求<br>有如下订单数据<br>订单id    商品id    成交金额<br>Order_0000001    Pdt_01    222.8<br>Order_0000001    Pdt_05    25.8<br>Order_0000002    Pdt_03    522.8<br>Order_0000002    Pdt_04    122.4<br>Order_0000003    Pdt_01    222.8</p><p>现在需要求出每一个订单中成交金额最大的一笔交易</p><p>3.2 分析</p><p>1、利用“订单id和成交金额”作为key，可以将map阶段读取到的所有订单数据按照id分区，按照金额排序，发送到reduce<br>2、在reduce端利用groupingcomparator将订单id相同的kv聚合成组，然后取第一个即是最大值</p><p>3.3 实现<br>自定义groupingcomparator</p><pre class="language-none"><code class="language-none">/** * 用于控制shuffle过程中reduce端对kv对的聚合逻辑 * @author duanhaitao@itcast.cn * */public class ItemidGroupingComparator extends WritableComparator {    protected ItemidGroupingComparator() {        super(OrderBean.class, true);    }    @Override    public int compare(WritableComparable a, WritableComparable b) {        OrderBean abean = (OrderBean) a;        OrderBean bbean = (OrderBean) b;        //将item_id相同的bean都视为相同，从而聚合为一组        return abean.getItemid().compareTo(bbean.getItemid());    }}定义订单信息bean/** * 订单信息bean，实现hadoop的序列化机制 * @author duanhaitao@itcast.cn * */public class OrderBean implements WritableComparable&lt;OrderBean&gt;{    private Text itemid;    private DoubleWritable amount;    public OrderBean() {    }    public OrderBean(Text itemid, DoubleWritable amount) {        set(itemid, amount);    }    public void set(Text itemid, DoubleWritable amount) {        this.itemid = itemid;        this.amount = amount;    }    public Text getItemid() {        return itemid;    }    public DoubleWritable getAmount() {        return amount;    }    @Override    public int compareTo(OrderBean o) {        int cmp = this.itemid.compareTo(o.getItemid());        if (cmp == 0) {            cmp = -this.amount.compareTo(o.getAmount());        }        return cmp;    }    @Override    public void write(DataOutput out) throws IOException {        out.writeUTF(itemid.toString());        out.writeDouble(amount.get());    }    @Override    public void readFields(DataInput in) throws IOException {        String readUTF = in.readUTF();        double readDouble = in.readDouble();        this.itemid = new Text(readUTF);        this.amount= new DoubleWritable(readDouble);    }    @Override    public String toString() {        return itemid.toString() + "\t" + amount.get();    }}编写mapreduce处理流程/** * 利用secondarysort机制输出每种item订单金额最大的记录 * @author duanhaitao@itcast.cn * */public class SecondarySort {    static class SecondarySortMapper extends Mapper&lt;LongWritable, Text, OrderBean, NullWritable&gt;{        OrderBean bean = new OrderBean();        @Override        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {            String line = value.toString();            String[] fields = StringUtils.split(line, "\t");            bean.set(new Text(fields[0]), new DoubleWritable(Double.parseDouble(fields[1])));            context.write(bean, NullWritable.get());        }    }    static class SecondarySortReducer extends Reducer&lt;OrderBean, NullWritable, OrderBean, NullWritable&gt;{        //在设置了groupingcomparator以后，这里收到的kv数据 就是：  &lt;1001 87.6&gt;,null  &lt;1001 76.5&gt;,null  ....         //此时，reduce方法中的参数key就是上述kv组中的第一个kv的key：&lt;1001 87.6&gt;        //要输出同一个item的所有订单中最大金额的那一个，就只要输出这个key        @Override        protected void reduce(OrderBean key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException {            context.write(key, NullWritable.get());        }    }    public static void main(String[] args) throws Exception {        Configuration conf = new Configuration();        Job job = Job.getInstance(conf);        job.setJarByClass(SecondarySort.class);        job.setMapperClass(SecondarySortMapper.class);        job.setReducerClass(SecondarySortReducer.class);        job.setOutputKeyClass(OrderBean.class);        job.setOutputValueClass(NullWritable.class);        FileInputFormat.setInputPaths(job, new Path(args[0]));        FileOutputFormat.setOutputPath(job, new Path(args[1]));        //指定shuffle所使用的GroupingComparator类        job.setGroupingComparatorClass(ItemidGroupingComparator.class);        //指定shuffle所使用的partitioner类        job.setPartitionerClass(ItemIdPartitioner.class);        job.setNumReduceTasks(3);        job.waitForCompletion(true);    }}</code></pre><h3 id="4-Mapreduce中的DistributedCache应用"><a href="#4-Mapreduce中的DistributedCache应用" class="headerlink" title="4.    Mapreduce中的DistributedCache应用"></a>4.    Mapreduce中的DistributedCache应用</h3><p>4.1 需求</p><p>实现两个“表”的join操作，其中一个表数据量小，一个表很大，这种场景在实际中非常常见，比如“订单日志” join “产品信息”</p><p>4.1.2 分析</p><p>–原理阐述<br>适用于关联表中有小表的情形；<br>可以将小表分发到所有的map节点，这样，map节点就可以在本地对自己所读到的大表数据进行join并输出最终结果<br>可以大大提高join操作的并发度，加快处理速度</p><p>–示例：先在mapper类中预先定义好小表，进行join<br>–并用distributedcache机制将小表的数据分发到每一个maptask执行节点，从而每一个maptask节点可以从本地加载到小表的数据，进而在本地即可实现join</p><p>4.1.3 实现</p><pre class="language-none"><code class="language-none">public class TestDistributedCache {    static class TestDistributedCacheMapper extends Mapper&lt;LongWritable, Text, Text, Text&gt;{        FileReader in = null;        BufferedReader reader = null;        HashMap&lt;String,String&gt; b_tab = new HashMap&lt;String, String&gt;();        String localpath =null;        String uirpath = null;        //是在map任务初始化的时候调用一次        @Override        protected void setup(Context context) throws IOException, InterruptedException {            //通过这几句代码可以获取到cache file的本地绝对路径，测试验证用            Path[] files = context.getLocalCacheFiles();            localpath = files[0].toString();            URI[] cacheFiles = context.getCacheFiles();            //缓存文件的用法——直接用本地IO来读取            //这里读的数据是map task所在机器本地工作目录中的一个小文件            in = new FileReader("b.txt");            reader =new BufferedReader(in);            String line =null;            while(null!=(line=reader.readLine())){                String[] fields = line.split(",");                b_tab.put(fields[0],fields[1]);            }            IOUtils.closeStream(reader);            IOUtils.closeStream(in);        }        @Override        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {            //这里读的是这个map task所负责的那一个切片数据（在hdfs上）             String[] fields = value.toString().split("\t");             String a_itemid = fields[0];             String a_amount = fields[1];             String b_name = b_tab.get(a_itemid);             // 输出结果  1001    98.9    banan             context.write(new Text(a_itemid), new Text(a_amount + "\t" + ":" + localpath + "\t" +b_name ));        }    }    public static void main(String[] args) throws Exception {        Configuration conf = new Configuration();        Job job = Job.getInstance(conf);        job.setJarByClass(TestDistributedCache.class);        job.setMapperClass(TestDistributedCacheMapper.class);        job.setOutputKeyClass(Text.class);        job.setOutputValueClass(LongWritable.class);        //这里是我们正常的需要处理的数据所在路径        FileInputFormat.setInputPaths(job, new Path(args[0]));        FileOutputFormat.setOutputPath(job, new Path(args[1]));        //不需要reducer        job.setNumReduceTasks(0);        //分发一个文件到task进程的工作目录        job.addCacheFile(new URI("hdfs://hadoop-server01:9000/cachefile/b.txt"));        //分发一个归档文件到task进程的工作目录//        job.addArchiveToClassPath(archive);        //分发jar包到task节点的classpath下//        job.addFileToClassPath(jarfile);        job.waitForCompletion(true);    }}</code></pre><h3 id="5-Mapreduce的其他补充"><a href="#5-Mapreduce的其他补充" class="headerlink" title="5.    Mapreduce的其他补充"></a>5.    Mapreduce的其他补充</h3><p>5.1 计数器应用<br>在实际生产代码中，常常需要将数据处理过程中遇到的不合规数据行进行全局计数，类似这种需求可以借助mapreduce框架中提供的全局计数器来实现<br>示例代码如下：</p><pre class="language-none"><code class="language-none">public class MultiOutputs {    //通过枚举形式定义自定义计数器    enum MyCounter{MALFORORMED,NORMAL}    static class CommaMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; {        @Override        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {            String[] words = value.toString().split(",");            for (String word : words) {                context.write(new Text(word), new LongWritable(1));            }            //对枚举定义的自定义计数器加1            context.getCounter(MyCounter.MALFORORMED).increment(1);            //通过动态设置自定义计数器加1            context.getCounter("counterGroupa", "countera").increment(1);        }    }</code></pre><p>5.2 多job串联<br>一个稍复杂点的处理逻辑往往需要多个mapreduce程序串联处理，多job的串联可以借助mapreduce框架的JobControl实现</p><p>示例代码：</p><pre class="language-none"><code class="language-none">ControlledJob cJob1 = new ControlledJob(job1.getConfiguration());        ControlledJob cJob2 = new ControlledJob(job2.getConfiguration());        ControlledJob cJob3 = new ControlledJob(job3.getConfiguration());        // 设置作业依赖关系        cJob2.addDependingJob(cJob1);        cJob3.addDependingJob(cJob2);        JobControl jobControl = new JobControl("RecommendationJob");        jobControl.addJob(cJob1);        jobControl.addJob(cJob2);        jobControl.addJob(cJob3);        cJob1.setJob(job1);        cJob2.setJob(job2);        cJob3.setJob(job3);        // 新建一个线程来运行已加入JobControl中的作业，开始进程并等待结束        Thread jobControlThread = new Thread(jobControl);        jobControlThread.start();        while (!jobControl.allFinished()) {            Thread.sleep(500);        }        jobControl.stop();        return 0;</code></pre><h3 id="6-mapreduce参数优化"><a href="#6-mapreduce参数优化" class="headerlink" title="6.    mapreduce参数优化"></a>6.    mapreduce参数优化</h3><pre class="language-none"><code class="language-none">资源相关参数(1) mapreduce.map.memory.mb: 一个Map Task可使用的资源上限（单位:MB），默认为1024。如果Map Task实际使用的资源量超过该值，则会被强制杀死。(2) mapreduce.reduce.memory.mb: 一个Reduce Task可使用的资源上限（单位:MB），默认为1024。如果Reduce Task实际使用的资源量超过该值，则会被强制杀死。(3) mapreduce.map.java.opts: Map Task的JVM参数，你可以在此配置默认的java heap size等参数, e.g.“-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc” （@taskid@会被Hadoop框架自动换为相应的taskid）, 默认值: “”(4) mapreduce.reduce.java.opts: Reduce Task的JVM参数，你可以在此配置默认的java heap size等参数, e.g.“-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc”, 默认值: “”(5) mapreduce.map.cpu.vcores: 每个Map task可使用的最多cpu core数目, 默认值: 1(6) mapreduce.map.cpu.vcores: 每个Reduce task可使用的最多cpu core数目, 默认值: 1</code></pre><pre class="language-none"><code class="language-none">容错相关参数(1) mapreduce.map.maxattempts: 每个Map Task最大重试次数，一旦重试参数超过该值，则认为Map Task运行失败，默认值：4。(2) mapreduce.reduce.maxattempts: 每个Reduce Task最大重试次数，一旦重试参数超过该值，则认为Map Task运行失败，默认值：4。(3) mapreduce.map.failures.maxpercent: 当失败的Map Task失败比例超过该值为，整个作业则失败，默认值为0. 如果你的应用程序允许丢弃部分输入数据，则该该值设为一个大于0的值，比如5，表示如果有低于5%的Map Task失败（如果一个Map Task重试次数超过mapreduce.map.maxattempts，则认为这个Map Task失败，其对应的输入数据将不会产生任何结果），整个作业扔认为成功。(4) mapreduce.reduce.failures.maxpercent: 当失败的Reduce Task失败比例超过该值为，整个作业则失败，默认值为0.(5) mapreduce.task.timeout: Task超时时间，经常需要设置的一个参数，该参数表达的意思为：如果一个task在一定时间内没有任何进入，即不会读取新的数据，也没有输出数据，则认为该task处于block状态，可能是卡住了，也许永远会卡主，为了防止因为用户程序永远block住不退出，则强制设置了一个该超时时间（单位毫秒），默认是300000。如果你的程序对每条输入数据的处理时间过长（比如会访问数据库，通过网络拉取数据等），建议将该参数调大，该参数过小常出现的错误提示是“AttemptID:attempt_14267829456721_123456_m_000224_0 Timed out after 300 secsContainer killed by the ApplicationMaster.”。</code></pre><pre class="language-none"><code class="language-none">本地运行mapreduce 作业设置以下几个参数:mapreduce.framework.name=localmapreduce.jobtracker.addre</code></pre><pre class="language-none"><code class="language-none">效率和稳定性相关参数(1) mapreduce.map.speculative: 是否为Map Task打开推测执行机制，默认为false(2) mapreduce.reduce.speculative: 是否为Reduce Task打开推测执行机制，默认为false(3) mapreduce.job.user.classpath.first &amp; mapreduce.task.classpath.user.precedence：当同一个class同时出现在用户jar包和hadoop jar中时，优先使用哪个jar包中的class，默认为false，表示优先使用hadoop jar中的class。(4) mapreduce.input.fileinputformat.split.minsize: 每个Map Task处理的数据量（仅针对基于文件的Inputformat有效，比如TextInputFormat，SequenceFileInputFormat），默认为一个block大小，即 134217728。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop学习三之mapreduce</title>
      <link href="/2018/04/27/hadoop-xue-xi-san-zhi-mapreduce/"/>
      <url>/2018/04/27/hadoop-xue-xi-san-zhi-mapreduce/</url>
      
        <content type="html"><![CDATA[<h3 id="1-MAPREDUCE原理篇（1）"><a href="#1-MAPREDUCE原理篇（1）" class="headerlink" title="1. MAPREDUCE原理篇（1）"></a>1. MAPREDUCE原理篇（1）</h3><p>Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架；<br>Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上；</p><h4 id="1-1-为什么要MAPREDUCE"><a href="#1-1-为什么要MAPREDUCE" class="headerlink" title="1.1 为什么要MAPREDUCE"></a>1.1 为什么要MAPREDUCE</h4><p>（1）海量数据在单机上处理因为硬件资源限制，无法胜任<br>（2）而一旦将单机版程序扩展到集群来分布式运行，将极大增加程序的复杂度和开发难度<br>（3）引入mapreduce框架后，开发人员可以将绝大部分工作集中在业务逻辑的开发上，而将分布式计算中的复杂性交由框架来处理</p><p>设想一个海量数据场景下的wordcount需求：<br>单机版：内存受限，磁盘受限，运算能力受限<br>分布式：<br>1、文件分布式存储（HDFS）<br>2、运算逻辑需要至少分成2个阶段（一个阶段独立并发，一个阶段汇聚）<br>3、运算程序如何分发<br>4、程序如何分配运算任务（切片）<br>5、两阶段的程序如何启动？如何协调？<br>6、整个程序运行过程中的监控？容错？重试？</p><p>可见在程序由单机版扩成分布式时，会引入大量的复杂工作。为了提高开发效率，可以将分布式程序中的公共功能封装成框架，让开发人员可以将精力集中于业务逻辑。</p><p>而mapreduce就是这样一个分布式程序的通用框架，其应对以上问题的整体结构如下：<br>1、MRAppMaster(mapreduce application master)<br>2、MapTask<br>3、ReduceTask</p><h4 id="1-2-MAPREDUCE框架结构及核心运行机制"><a href="#1-2-MAPREDUCE框架结构及核心运行机制" class="headerlink" title="1.2 MAPREDUCE框架结构及核心运行机制"></a>1.2 MAPREDUCE框架结构及核心运行机制</h4><pre class="language-none"><code class="language-none">1.2.1 结构一个完整的mapreduce程序在分布式运行时有三类实例进程：1、MRAppMaster：负责整个程序的过程调度及状态协调2、mapTask：负责map阶段的整个数据处理流程3、ReduceTask：负责reduce阶段的整个数据处理流程</code></pre><pre class="language-none"><code class="language-none">流程解析1、    一个mr程序启动的时候，最先启动的是MRAppMaster，MRAppMaster启动后根据本次job的描述信息，计算出需要的maptask实例数量，然后向集群申请机器启动相应数量的maptask进程2、    maptask进程启动之后，根据给定的数据切片范围进行数据处理，主体流程为：a)    利用客户指定的inputformat来获取RecordReader读取数据，形成输入KV对b)    将输入KV对传递给客户定义的map()方法，做逻辑运算，并将map()方法输出的KV对收集到缓存c)    将缓存中的KV对按照K分区排序后不断溢写到磁盘文件3、    MRAppMaster监控到所有maptask进程任务完成之后，会根据客户指定的参数启动相应数量的reducetask进程，并告知reducetask进程要处理的数据范围（数据分区）4、    Reducetask进程启动之后，根据MRAppMaster告知的待处理数据所在位置，从若干台maptask运行所在机器上获取到若干个maptask输出结果文件，并在本地进行重新归并排序，然后按照相同key的KV为一个组，调用客户定义的reduce()方法进行逻辑运算，并收集运算输出的结果KV，然后调用客户指定的outputformat将结果数据输出到外部存储</code></pre><h4 id="1-3-MapTask并行度决定机制"><a href="#1-3-MapTask并行度决定机制" class="headerlink" title="1.3 MapTask并行度决定机制"></a>1.3 MapTask并行度决定机制</h4><p>maptask的并行度决定map阶段的任务处理并发度，进而影响到整个job的处理速度<br>那么，mapTask并行实例是否越多越好呢？其并行度又是如何决定呢？</p><pre class="language-none"><code class="language-none">1.3.1 mapTask并行度的决定机制一个job的map阶段并行度由客户端在提交job时决定而客户端对map阶段并行度的规划的基本逻辑为：将待处理数据执行逻辑切片（即按照一个特定切片大小，将待处理数据划分成逻辑上的多个split），然后每一个split分配一个mapTask并行实例处理这段逻辑及形成的切片规划描述文件，由FileInputFormat实现类的getSplits()方法完成</code></pre><pre class="language-none"><code class="language-none">1.3.2 FileInputFormat切片机制、切片定义在InputFormat类中的getSplit()方法2、FileInputFormat中默认的切片机制：a)    简单地按照文件的内容长度进行切片b)    切片大小，默认等于block大小c)    切片时不考虑数据集整体，而是逐个针对每一个文件单独切片比如待处理数据有两个文件：file1.txt    320Mfile2.txt    10M经过FileInputFormat的切片机制运算后，形成的切片信息如下：  file1.txt.split1--  0~128file1.txt.split2--  128~256file1.txt.split3--  256~320file2.txt.split1--  0~10M3、FileInputFormat中切片的大小的参数配置通过分析源码，在FileInputFormat中，计算切片大小的逻辑：Math.max(minSize, Math.min(maxSize, blockSize));  切片主要由这几个值来运算决定minsize：默认值：1        配置参数： mapreduce.input.fileinputformat.split.minsize    maxsize：默认值：Long.MAXValue      配置参数：mapreduce.input.fileinputformat.split.maxsizeblocksize因此，默认情况下，切片大小=blocksizemaxsize（切片最大值）：参数如果调得比blocksize小，则会让切片变小，而且就等于配置的这个参数的值minsize （切片最小值）：参数调的比blockSize大，则可以让切片变得比blocksize还大选择并发数的影响因素：1、运算节点的硬件配置2、运算任务的类型：CPU密集型还是IO密集型3、运算任务的数据量</code></pre><pre class="language-none"><code class="language-none">1.4 map并行度的经验之谈如果硬件配置为2*12core + 64G，恰当的map并行度是大约每个节点20-100个map，最好每个map的执行时间至少一分钟。    如果job的每个map或者 reduce task的运行时间都只有30-40秒钟，那么就减少该job的map或者reduce数，每一个task(map|reduce)的setup和加入到调度器中进行调度，这个中间的过程可能都要花费几秒钟，所以如果每个task都非常快就跑完了，就会在task的开始和结束的时候浪费太多的时间。配置task的JVM重用 可以改善该问题：（mapred.job.reuse.jvm.num.tasks，默认是1，表示一个JVM上最多可以顺序执行的task数目（属于同一个Job）是1。也就是说一个task启一个JVM）    如果input的文件非常的大，比如1TB，可以考虑将hdfs上的每个block size设大，比如设成256MB或者512MB</code></pre><pre class="language-none"><code class="language-none">1.5 ReduceTask并行度的决定reducetask的并行度同样影响整个job的执行并发度和执行效率，但与maptask的并发数由切片数决定不同，Reducetask数量的决定是可以直接手动设置：//默认值是1，手动设置为4job.setNumReduceTasks(4);如果数据分布不均匀，就有可能在reduce阶段产生数据倾斜注意： reducetask数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1个reducetask尽量不要运行太多的reduce task。对大多数job来说，最好rduce的个数最多和集群中的reduce持平，或者比集群的 reduce slots小。这个对于小集群而言，尤其重要。</code></pre><pre class="language-none"><code class="language-none">1.6 MAPREDUCE程序运行演示Hadoop的发布包中内置了一个hadoop-mapreduce-example-2.4.1.jar，这个jar包中有各种MR示例程序，可以通过以下步骤运行：启动hdfs，yarn然后在集群中的任意一台服务器上启动执行程序（比如运行wordcount）：hadoop jar hadoop-mapreduce-example-2.4.1.jar wordcount  /wordcount/data /wordcount/out</code></pre><h3 id="2-MAPREDUCE实践篇（1）"><a href="#2-MAPREDUCE实践篇（1）" class="headerlink" title="2. MAPREDUCE实践篇（1）"></a>2. MAPREDUCE实践篇（1）</h3><h4 id="2-1-1-编程规范"><a href="#2-1-1-编程规范" class="headerlink" title="2.1.1 编程规范"></a>2.1.1 编程规范</h4><p>（1）用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行mr程序的客户端)<br>（2）Mapper的输入数据是KV对的形式（KV的类型可自定义）<br>（3）Mapper的输出数据是KV对的形式（KV的类型可自定义）<br>（4）Mapper中的业务逻辑写在map()方法中<br>（5）map()方法（maptask进程）对每一个&lt;K,V&gt;调用一次<br>（6）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV<br>（7）Reducer的业务逻辑写在reduce()方法中<br>（8）Reducetask进程对每一组相同k的&lt;k,v&gt;组调用一次reduce()方法<br>（9）用户自定义的Mapper和Reducer都要继承各自的父类<br>（10）整个程序需要一个Drvier来进行提交，提交的是一个描述了各种必要信息的job对象</p><h4 id="2-1-2-wordcount示例编写"><a href="#2-1-2-wordcount示例编写" class="headerlink" title="2.1.2 wordcount示例编写"></a>2.1.2 wordcount示例编写</h4><p>需求：在一堆给定的文本文件中统计输出每一个单词出现的总次数<br>(1)定义一个mapper类</p><pre class="language-none"><code class="language-none">//首先要定义四个泛型的类型//keyin:  LongWritable    valuein: Text//keyout: Text            valueout:IntWritablepublic class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt;{    //map方法的生命周期：  框架每传一行数据就被调用一次    //key :  这一行的起始点在文件中的偏移量    //value: 这一行的内容    @Override    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {        //拿到一行数据转换为string        String line = value.toString();        //将这一行切分出各个单词        String[] words = line.split(" ");        //遍历数组，输出&lt;单词，1&gt;        for(String word:words){            context.write(new Text(word), new IntWritable(1));        }    }}</code></pre><p>(2)定义一个reducer类</p><pre class="language-none"><code class="language-none">    //生命周期：框架每传递进来一个kv 组，reduce方法被调用一次    @Override    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {        //定义一个计数器        int count = 0;        //遍历这一组kv的所有v，累加到count中        for(IntWritable value:values){            count += value.get();        }        context.write(key, new IntWritable(count));    }}</code></pre><p>(3)定义一个主类，用来描述job并提交job</p><pre class="language-none"><code class="language-none">public class WordCountRunner {    //把业务逻辑相关的信息（哪个是mapper，哪个是reducer，要处理的数据在哪里，输出的结果放哪里……）描述成一个job对象    //把这个描述好的job提交给集群去运行    public static void main(String[] args) throws Exception {        Configuration conf = new Configuration();        Job wcjob = Job.getInstance(conf);        //指定我这个job所在的jar包//        wcjob.setJar("/home/hadoop/wordcount.jar");        wcjob.setJarByClass(WordCountRunner.class);        wcjob.setMapperClass(WordCountMapper.class);        wcjob.setReducerClass(WordCountReducer.class);        //设置我们的业务逻辑Mapper类的输出key和value的数据类型        wcjob.setMapOutputKeyClass(Text.class);        wcjob.setMapOutputValueClass(IntWritable.class);        //设置我们的业务逻辑Reducer类的输出key和value的数据类型        wcjob.setOutputKeyClass(Text.class);        wcjob.setOutputValueClass(IntWritable.class);        //指定要处理的数据所在的位置        FileInputFormat.setInputPaths(wcjob, "hdfs://hdp-server01:9000/wordcount/data/big.txt");        //指定处理完成之后的结果所保存的位置        FileOutputFormat.setOutputPath(wcjob, new Path("hdfs://hdp-server01:9000/wordcount/output/"));        //向yarn集群提交这个job        boolean res = wcjob.waitForCompletion(true);        System.exit(res?0:1);    }</code></pre><p>####2.2MAPREDUCE程序运行模式</p><ul><li>本地运行模式</li></ul><p>（1）mapreduce程序是被提交给LocalJobRunner在本地以单进程的形式运行<br>（2）而处理的数据及输出结果可以在本地文件系统，也可以在hdfs上<br>（3）怎样实现本地运行？写一个程序，不要带集群的配置文件（本质是你的mr程序的conf中是否有mapreduce.framework.name=local以及yarn.resourcemanager.hostname参数）<br>（4）本地模式非常便于进行业务逻辑的debug，只要在eclipse中打断点即可</p><p>如果在windows下想运行本地模式来测试程序逻辑，需要在windows中配置环境变量：<br>％HADOOP_HOME％  =  d:/hadoop-2.6.1<br>%PATH% =  ％HADOOP_HOME％\bin<br>并且要将d:/hadoop-2.6.1的lib和bin目录替换成windows平台编译的版本</p><ul><li>集群运行模式<br>（1）将mapreduce程序提交给yarn集群resourcemanager，分发到很多的节点上并发执行<br>（2）处理的数据和输出结果应该位于hdfs文件系统<br>（3）提交集群的实现步骤：<br>A、将程序打成JAR包，然后在集群的任意一个节点上用hadoop命令启动<br>   $ hadoop jar wordcount.jar cn.itcast.bigdata.mrsimple.WordCountDriver inputpath outputpath<br>B、直接在linux的eclipse中运行main方法<br>（项目中要带参数：mapreduce.framework.name=yarn以及yarn的两个基本配置）<br>C、如果要在windows的eclipse中提交job给集群，则要修改YarnRunner类</li></ul><h4 id="2-3-MAPREDUCE中的Combiner"><a href="#2-3-MAPREDUCE中的Combiner" class="headerlink" title="2.3 MAPREDUCE中的Combiner"></a>2.3 MAPREDUCE中的Combiner</h4><p>（1）combiner是MR程序中Mapper和Reducer之外的一种组件<br>（2）combiner组件的父类就是Reducer<br>（3）combiner和reducer的区别在于运行的位置：<br>Combiner是在每一个maptask所在的节点运行<br>Reducer是接收全局所有Mapper的输出结果；<br>(4) combiner的意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量<br>具体实现步骤：<br>1、    自定义一个combiner继承Reducer，重写reduce方法<br>2、    在job中设置：  job.setCombinerClass(CustomCombiner.class)<br>(5) combiner能够应用的前提是不能影响最终的业务逻辑<br>而且，combiner的输出kv应该跟reducer的输入kv类型要对应起来</p><h3 id="3-MAPREDUCE原理篇（2）"><a href="#3-MAPREDUCE原理篇（2）" class="headerlink" title="3. MAPREDUCE原理篇（2）"></a>3. MAPREDUCE原理篇（2）</h3><h4 id="3-1-mapreduce的shuffle机制"><a href="#3-1-mapreduce的shuffle机制" class="headerlink" title="3.1 mapreduce的shuffle机制"></a>3.1 mapreduce的shuffle机制</h4><p>3.1.1 概述：</p><pre class="language-none"><code class="language-none">mapreduce中，map阶段处理的数据如何传递给reduce阶段，是mapreduce框架中最关键的一个流程，这个流程就叫shuffle；shuffle: 洗牌、发牌——（核心机制：数据分区，排序，缓存）；具体来说：就是将maptask输出的处理结果数据，分发给reducetask，并在分发的过程中，对数据按key进行了分区和排序；</code></pre><p>3.1.2 主要流程： Shuffle缓存流程：</p><p>shuffle是MR处理流程中的一个过程，它的每一个处理步骤是分散在各个map task和reduce task节点上完成的，整体来看，分为3个操作：<br>1、分区partition<br>2、Sort根据key排序<br>3、Combiner进行局部value的合并</p><p>3.1.3 详细流程<br>1、    maptask收集我们的map()方法输出的kv对，放到内存缓冲区中<br>2、    从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件<br>3、    多个溢出文件会被合并成大的溢出文件<br>4、    在溢出过程中，及合并的过程中，都要调用partitoner进行分组和针对key进行排序<br>5、    reducetask根据自己的分区号，去各个maptask机器上取相应的结果分区数据<br>6、    reducetask会取到同一个分区的来自不同maptask的结果文件，reducetask会将这些文件再进行合并（归并排序）<br>7、    合并成大文件后，shuffle的过程也就结束了，后面进入reducetask的逻辑运算过程（从文件中取出一个一个的键值对group，调用用户自定义的reduce()方法）</p><p>Shuffle中的缓冲区大小会影响到mapreduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快<br>缓冲区的大小可以通过参数调整,  参数：io.sort.mb  默认100M</p><h4 id="3-2-MAPREDUCE中的序列化"><a href="#3-2-MAPREDUCE中的序列化" class="headerlink" title="3.2. MAPREDUCE中的序列化"></a>3.2. MAPREDUCE中的序列化</h4><p>3.2.1 概述</p><p>Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，header，继承体系。。。。），不便于在网络中高效传输；<br>所以，hadoop自己开发了一套序列化机制（Writable），精简，高效</p><p>3.2.2 自定义对象实现MR中的序列化接口<br>如果需要将自定义的bean放在key中传输，则还需要实现comparable接口，因为mapreduce框中的shuffle过程一定会对key进行排序,此时，自定义的bean实现的接口应该是：<br>public  class  FlowBean  implements  WritableComparable<flowbean><br>需要自己实现的方法是：</flowbean></p><pre class="language-none"><code class="language-none">/**     * 反序列化的方法，反序列化时，从流中读取到的各个字段的顺序应该与序列化时写出去的顺序保持一致     */    @Override    public void readFields(DataInput in) throws IOException {        upflow = in.readLong();        dflow = in.readLong();        sumflow = in.readLong();    }    /**     * 序列化的方法     */    @Override    public void write(DataOutput out) throws IOException {        out.writeLong(upflow);        out.writeLong(dflow);        //可以考虑不序列化总流量，因为总流量是可以通过上行流量和下行流量计算出来的        out.writeLong(sumflow);    }    @Override    public int compareTo(FlowBean o) {        //实现按照sumflow的大小倒序排序        return sumflow&gt;o.getSumflow()?-1:1;    }</code></pre><h3 id="3-3-MapReduce与YARN"><a href="#3-3-MapReduce与YARN" class="headerlink" title="3.3. MapReduce与YARN"></a>3.3. MapReduce与YARN</h3><p>3.3.1 YARN概述</p><pre><code>Yarn是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而mapreduce等运算程序则相当于运行于操作系统之上的应用程序</code></pre><p>3.3.2 YARN的重要概念</p><pre><code>1、    yarn并不清楚用户提交的程序的运行机制2、    yarn只提供运算资源的调度（用户程序向yarn申请资源，yarn就负责分配资源）3、    yarn中的主管角色叫ResourceManager4、    yarn中具体提供运算资源的角色叫NodeManager5、    这样一来，yarn其实就与运行的用户程序完全解耦，就意味着yarn上可以运行各种类型的分布式运算程序（mapreduce只是其中的一种），比如mapreduce、storm程序，spark程序，tez ……6、    所以，spark、storm等运算框架都可以整合在yarn上运行，只要他们各自的框架中有符合yarn规范的资源请求机制即可7、    Yarn就成为一个通用的资源调度平台，从此，企业中以前存在的各种运算集群都可以整合在一个物理集群上，提高资源利用率，方便数据共享</code></pre><h3 id="4-MAPREDUCE实践篇（2）"><a href="#4-MAPREDUCE实践篇（2）" class="headerlink" title="4. MAPREDUCE实践篇（2）"></a>4. MAPREDUCE实践篇（2）</h3><h4 id="4-1-Mapreduce中的排序初步"><a href="#4-1-Mapreduce中的排序初步" class="headerlink" title="4.1. Mapreduce中的排序初步"></a>4.1. Mapreduce中的排序初步</h4><p>4.1.1 需求</p><pre><code>对日志数据中的上下行流量信息汇总，并输出按照总流量倒序排序的结果数据如下：1363157985066     13726230503    00-FD-07-A4-72-B8:CMCC    120.196.100.82             24    27    2481    24681    2001363157995052     13826544101    5C-0E-8B-C7-F1-E0:CMCC    120.197.40.4            4    0    264    0    2001363157991076     13926435656    20-10-7A-28-CC-0A:CMCC    120.196.100.99            2    4    132    1512    2001363154400022     13926251106    5C-0E-8B-8B-B1-50:CMCC    120.197.40.4            4    0    240    0    200</code></pre><p>4.1.2 分析</p><p>基本思路：实现自定义的bean来封装流量信息，并将bean作为map输出的key来传输</p><p>MR程序在处理数据的过程中会对数据排序(map输出的kv对传输到reduce之前，会排序)，排序的依据是map输出的key<br>所以，我们如果要实现自己需要的排序规则，则可以考虑将排序因素放到key中，让key实现接口：WritableComparable<br>然后重写key的compareTo方法</p><p>4.1.3 实现</p><pre class="language-none"><code class="language-none">1、    自定义的beanpublic class FlowBean implements WritableComparable&lt;FlowBean&gt;{    long upflow;    long downflow;    long sumflow;    //如果空参构造函数被覆盖，一定要显示定义一下，否则在反序列时会抛异常    public FlowBean(){}    public FlowBean(long upflow, long downflow) {        super();        this.upflow = upflow;        this.downflow = downflow;        this.sumflow = upflow + downflow;    }    public long getSumflow() {        return sumflow;    }    public void setSumflow(long sumflow) {        this.sumflow = sumflow;    }    public long getUpflow() {        return upflow;    }    public void setUpflow(long upflow) {        this.upflow = upflow;    }    public long getDownflow() {        return downflow;    }    public void setDownflow(long downflow) {        this.downflow = downflow;    }    //序列化，将对象的字段信息写入输出流    @Override    public void write(DataOutput out) throws IOException {        out.writeLong(upflow);        out.writeLong(downflow);        out.writeLong(sumflow);    }    //反序列化，从输入流中读取各个字段信息    @Override    public void readFields(DataInput in) throws IOException {        upflow = in.readLong();        downflow = in.readLong();        sumflow = in.readLong();    }    @Override    public String toString() {        return upflow + "\t" + downflow + "\t" + sumflow;    }    @Override    public int compareTo(FlowBean o) {        //自定义倒序比较规则        return sumflow &gt; o.getSumflow() ? -1:1;    }}2、    mapper 和 reducerpublic class FlowCount {    static class FlowCountMapper extends Mapper&lt;LongWritable, Text, FlowBean,Text &gt; {        @Override        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {            String line = value.toString();            String[] fields = line.split("\t");            try {                String phonenbr = fields[0];                long upflow = Long.parseLong(fields[1]);                long dflow = Long.parseLong(fields[2]);                FlowBean flowBean = new FlowBean(upflow, dflow);                context.write(flowBean,new Text(phonenbr));            } catch (Exception e) {                e.printStackTrace();            }        }    }    static class FlowCountReducer extends Reducer&lt;FlowBean,Text,Text, FlowBean&gt; {        @Override        protected void reduce(FlowBean bean, Iterable&lt;Text&gt; phonenbr, Context context) throws IOException, InterruptedException {            Text phoneNbr = phonenbr.iterator().next();            context.write(phoneNbr, bean);        }    }    public static void main(String[] args) throws Exception {        Configuration conf = new Configuration();        Job job = Job.getInstance(conf);        job.setJarByClass(FlowCount.class);        job.setMapperClass(FlowCountMapper.class);        job.setReducerClass(FlowCountReducer.class);         job.setMapOutputKeyClass(FlowBean.class);         job.setMapOutputValueClass(Text.class);        job.setOutputKeyClass(Text.class);        job.setOutputValueClass(FlowBean.class);        // job.setInputFormatClass(TextInputFormat.class);        FileInputFormat.setInputPaths(job, new Path(args[0]));        FileOutputFormat.setOutputPath(job, new Path(args[1]));        job.waitForCompletion(true);    }}</code></pre><h4 id="4-2-Mapreduce中的分区Partitioner"><a href="#4-2-Mapreduce中的分区Partitioner" class="headerlink" title="4.2. Mapreduce中的分区Partitioner"></a>4.2. Mapreduce中的分区Partitioner</h4><p>4.2.1 需求</p><p>根据归属地输出流量统计数据结果到不同文件，以便于在查询统计结果时可以定位到省级范围进行</p><p>4.2.2 分析</p><p>Mapreduce中会将map输出的kv对，按照相同key分组，然后分发给不同的reducetask<br>默认的分发规则为：根据key的hashcode%reducetask数来分发<br>所以：如果要按照我们自己的需求进行分组，则需要改写数据分发（分组）组件Partitioner<br>自定义一个CustomPartitioner继承抽象类：Partitioner<br>然后在job对象中，设置自定义partitioner： job.setPartitionerClass(CustomPartitioner.class)</p><p>4.2.3 实现</p><pre class="language-none"><code class="language-none">/** * 定义自己的从map到reduce之间的数据（分组）分发规则 按照手机号所属的省份来分发（分组）ProvincePartitioner * 默认的分组组件是HashPartitioner *  * @author *  */public class ProvincePartitioner extends Partitioner&lt;Text, FlowBean&gt; {    static HashMap&lt;String, Integer&gt; provinceMap = new HashMap&lt;String, Integer&gt;();    static {        provinceMap.put("135", 0);        provinceMap.put("136", 1);        provinceMap.put("137", 2);        provinceMap.put("138", 3);        provinceMap.put("139", 4);    }    @Override    public int getPartition(Text key, FlowBean value, int numPartitions) {        Integer code = provinceMap.get(key.toString().substring(0, 3));        return code == null ? 5 : code;    }}</code></pre><h4 id="4-3-mapreduce数据压缩"><a href="#4-3-mapreduce数据压缩" class="headerlink" title="4.3. mapreduce数据压缩"></a>4.3. mapreduce数据压缩</h4><p>4.3.1 概述</p><p>这是mapreduce的一种优化策略：通过压缩编码对mapper或者reducer的输出进行压缩，以减少磁盘IO，提高MR程序运行速度（但相应增加了cpu运算负担）</p><p>1、    Mapreduce支持将map输出的结果或者reduce输出的结果进行压缩，以减少网络IO或最终输出数据的体积</p><p>2、    压缩特性运用得当能提高性能，但运用不当也可能降低性能</p><p>3、    基本原则：<br>运算密集型的job，少用压缩<br>IO密集型的job，多用压缩</p><p>4.3.3 Reducer输出压缩</p><pre><code>在配置参数或在代码中都可以设置reduce的输出压缩1、在配置参数中设置 mapreduce.output.fileoutputformat.compress=falsemapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodecmapreduce.output.fileoutputformat.compress.type=RECORD2、在代码中设置        Job job = Job.getInstance(conf);        FileOutputFormat.setCompressOutput(job, true);        FileOutputFormat.setOutputCompressorClass(job, (Class&lt;? extends CompressionCodec&gt;) Class.forName(""));</code></pre><p>4.3.4 Mapper输出压缩</p><pre><code>在配置参数或在代码中都可以设置reduce的输出压缩1、在配置参数中设置 mapreduce.map.output.compress=falsemapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.DefaultCodec2、在代码中设置：conf.setBoolean(Job.MAP_OUTPUT_COMPRESS, true);conf.setClass(Job.MAP_OUTPUT_COMPRESS_CODEC, GzipCodec.class, CompressionCodec.class);</code></pre><p>4.3.5 压缩文件的读取</p><pre><code>Hadoop自带的InputFormat类内置支持压缩文件的读取，比如TextInputformat类，在其initialize方法中：  public void initialize(InputSplit genericSplit,                     TaskAttemptContext context) throws IOException {    FileSplit split = (FileSplit) genericSplit;    Configuration job = context.getConfiguration();    this.maxLineLength = job.getInt(MAX_LINE_LENGTH, Integer.MAX_VALUE);    start = split.getStart();    end = start + split.getLength();    final Path file = split.getPath();    // open the file and seek to the start of the split    final FileSystem fs = file.getFileSystem(job);    fileIn = fs.open(file);    //根据文件后缀名创建相应压缩编码的codec    CompressionCodec codec = new CompressionCodecFactory(job).getCodec(file);    if (null!=codec) {      isCompressedInput = true;          decompressor = CodecPool.getDecompressor(codec);      //判断是否属于可切片压缩编码类型      if (codec instanceof SplittableCompressionCodec) {    final SplitCompressionInputStream cIn =      ((SplittableCompressionCodec)codec).createInputStream(        fileIn, decompressor, start, end,        SplittableCompressionCodec.READ_MODE.BYBLOCK);         //如果是可切片压缩编码，则创建一个CompressedSplitLineReader读取压缩数据    in = new CompressedSplitLineReader(cIn, job,        this.recordDelimiterBytes);    start = cIn.getAdjustedStart();    end = cIn.getAdjustedEnd();    filePosition = cIn;      } else {        //如果是不可切片压缩编码，则创建一个SplitLineReader读取压缩数据，并将文件输入流转换成解压数据流传递给普通SplitLineReader读取    in = new SplitLineReader(codec.createInputStream(fileIn,        decompressor), job, this.recordDelimiterBytes);    filePosition = fileIn;      }    } else {      fileIn.seek(start);       //如果不是压缩文件，则创建普通SplitLineReader读取数据      in = new SplitLineReader(fileIn, job, this.recordDelimiterBytes);      filePosition = fileIn;    }</code></pre><h4 id="4-4reduce端join算法实现"><a href="#4-4reduce端join算法实现" class="headerlink" title="4.4reduce端join算法实现"></a>4.4reduce端join算法实现</h4><pre class="language-none"><code class="language-none">1、需求：订单数据表t_order：id    date    pid    amount1001    20150710    P0001    21002    20150710    P0001    31002    20150710    P0002    3商品信息表t_productid    name    category_id    priceP0001    小米5    C01    2P0002    锤子T1    C01    3假如数据量巨大，两表的数据是以文件的形式存储在HDFS中，需要用mapreduce程序来实现一下SQL查询运算： select  a.id,a.date,b.name,b.category_id,b.price from t_order a join t_product b on a.pid = b.id</code></pre><pre class="language-none"><code class="language-none">2、实现机制：通过将关联的条件作为map输出的key，将两表满足join条件的数据并携带数据所来源的文件信息，发往同一个reduce task，在reduce中进行数据的串联public class OrderJoin {    static class OrderJoinMapper extends Mapper&lt;LongWritable, Text, Text, OrderJoinBean&gt; {        @Override        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {            // 拿到一行数据，并且要分辨出这行数据所属的文件            String line = value.toString();            String[] fields = line.split("\t");            // 拿到itemid            String itemid = fields[0];            // 获取到这一行所在的文件名（通过inpusplit）            String name = "你拿到的文件名";            // 根据文件名，切分出各字段（如果是a，切分出两个字段，如果是b，切分出3个字段）            OrderJoinBean bean = new OrderJoinBean();            bean.set(null, null, null, null, null);            context.write(new Text(itemid), bean);        }    }    static class OrderJoinReducer extends Reducer&lt;Text, OrderJoinBean, OrderJoinBean, NullWritable&gt; {        @Override        protected void reduce(Text key, Iterable&lt;OrderJoinBean&gt; beans, Context context) throws IOException, InterruptedException {             //拿到的key是某一个itemid,比如1000            //拿到的beans是来自于两类文件的bean            //  {1000,amount} {1000,amount} {1000,amount}   ---   {1000,price,name}            //将来自于b文件的bean里面的字段，跟来自于a的所有bean进行字段拼接并输出        }    }}缺点：这种方式中，join的操作是在reduce阶段完成，reduce端的处理压力太大，map节点的运算负载则很低，资源利用率不高，且在reduce阶段极易产生数据倾斜解决方案： map端join实现方式</code></pre><p>####　4.4.2 map端join算法实现</p><pre class="language-none"><code class="language-none">1、原理阐述适用于关联表中有小表的情形；可以将小表分发到所有的map节点，这样，map节点就可以在本地对自己所读到的大表数据进行join并输出最终结果，可以大大提高join操作的并发度，加快处理速度</code></pre><pre class="language-none"><code class="language-none">2、实现示例--先在mapper类中预先定义好小表，进行join--引入实际场景中的解决方案：一次加载数据库或者用distributedcachepublic class TestDistributedCache {    static class TestDistributedCacheMapper extends Mapper&lt;LongWritable, Text, Text, Text&gt;{        FileReader in = null;        BufferedReader reader = null;        HashMap&lt;String,String&gt; b_tab = new HashMap&lt;String, String&gt;();        String localpath =null;        String uirpath = null;        //是在map任务初始化的时候调用一次        @Override        protected void setup(Context context) throws IOException, InterruptedException {            //通过这几句代码可以获取到cache file的本地绝对路径，测试验证用            Path[] files = context.getLocalCacheFiles();            localpath = files[0].toString();            URI[] cacheFiles = context.getCacheFiles();            //缓存文件的用法——直接用本地IO来读取            //这里读的数据是map task所在机器本地工作目录中的一个小文件            in = new FileReader("b.txt");            reader =new BufferedReader(in);            String line =null;            while(null!=(line=reader.readLine())){                String[] fields = line.split(",");                b_tab.put(fields[0],fields[1]);            }            IOUtils.closeStream(reader);            IOUtils.closeStream(in);        }        @Override        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {            //这里读的是这个map task所负责的那一个切片数据（在hdfs上）             String[] fields = value.toString().split("\t");             String a_itemid = fields[0];             String a_amount = fields[1];             String b_name = b_tab.get(a_itemid);             // 输出结果  1001    98.9    banan             context.write(new Text(a_itemid), new Text(a_amount + "\t" + ":" + localpath + "\t" +b_name ));        }    }    public static void main(String[] args) throws Exception {        Configuration conf = new Configuration();        Job job = Job.getInstance(conf);        job.setJarByClass(TestDistributedCache.class);        job.setMapperClass(TestDistributedCacheMapper.class);        job.setOutputKeyClass(Text.class);        job.setOutputValueClass(LongWritable.class);        //这里是我们正常的需要处理的数据所在路径        FileInputFormat.setInputPaths(job, new Path(args[0]));        FileOutputFormat.setOutputPath(job, new Path(args[1]));        //不需要reducer        job.setNumReduceTasks(0);        //分发一个文件到task进程的工作目录        job.addCacheFile(new URI("hdfs://hadoop-server01:9000/cachefile/b.txt"));        //分发一个归档文件到task进程的工作目录//        job.addArchiveToClassPath(archive);        //分发jar包到task节点的classpath下//        job.addFileToClassPath(jarfile);        job.waitForCompletion(true);    }}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop学习二之hdfs</title>
      <link href="/2018/04/27/hadoop-xue-xi-er-zhi-hdfs/"/>
      <url>/2018/04/27/hadoop-xue-xi-er-zhi-hdfs/</url>
      
        <content type="html"><![CDATA[<p><strong>**</strong>HDFS基本概念篇******</p><h3 id="1-HDFS前言"><a href="#1-HDFS前言" class="headerlink" title="1. HDFS前言"></a>1. HDFS前言</h3><ul><li><p>设计思想<br>分而治之：将大文件、大批量文件，分布式存放在大量服务器上，以便于采取分而治之的方式对海量数据进行运算分析；</p></li><li><p>在大数据系统中作用：<br>为各类分布式运算框架（如：mapreduce，spark，tez，……）提供数据存储服务</p></li><li><p>重点概念：文件切块，副本存放，元数据</p></li></ul><h3 id="2-HDFS的概念和特性"><a href="#2-HDFS的概念和特性" class="headerlink" title="2. HDFS的概念和特性"></a>2. HDFS的概念和特性</h3><p>首先，它是一个文件系统，用于存储文件，通过统一的命名空间——目录树来定位文件</p><p>其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色；</p><p>重要特性如下：</p><p>（1）HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M</p><p>（2）HDFS文件系统会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data</p><p>（3）目录结构及文件分块信息(元数据)的管理由namenode节点承担<br>——namenode是HDFS集群主节点，负责维护整个hdfs文件系统的目录树，以及每一个路径（文件）所对应的block块信息（block的id，及所在的datanode服务器）</p><p>（4）文件的各个block的存储管理由datanode节点承担<br>—- datanode是HDFS集群从节点，每一个block都可以在多个datanode上存储多个副本（副本数量也可以通过参数设置dfs.replication）</p><p>（5）HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改</p><p>(注：适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太高)</p><p><strong>**</strong>HDFS基本操作篇******</p><h3 id="3-HDFS的shell-命令行客户端-操作"><a href="#3-HDFS的shell-命令行客户端-操作" class="headerlink" title="3. HDFS的shell(命令行客户端)操作"></a>3. HDFS的shell(命令行客户端)操作</h3><h4 id="3-1-HDFS命令行客户端使用"><a href="#3-1-HDFS命令行客户端使用" class="headerlink" title="3.1 HDFS命令行客户端使用"></a>3.1 HDFS命令行客户端使用</h4><p>hadoop fs 参数 </p><h4 id="3-2-命令行客户端支持的命令参数"><a href="#3-2-命令行客户端支持的命令参数" class="headerlink" title="3.2 命令行客户端支持的命令参数"></a>3.2 命令行客户端支持的命令参数</h4><p>[-appendToFile <localsrc> … <dst>]<br>        [-cat [-ignoreCrc] <src> …]<br>        [-checksum <src> …]<br>        [-chgrp [-R] GROUP PATH…]<br>        [-chmod [-R] &lt;MODE[,MODE]… | OCTALMODE&gt; PATH…]<br>        [-chown [-R] [OWNER][:[GROUP]] PATH…]<br>        [-copyFromLocal [-f] [-p] <localsrc> … <dst>]<br>        [-copyToLocal [-p] [-ignoreCrc] [-crc] <src> … <localdst>]<br>        [-count [-q] <path> …]<br>        [-cp [-f] [-p] <src> … <dst>]<br>        [-createSnapshot <snapshotdir> [<snapshotname>]]<br>        [-deleteSnapshot <snapshotdir> <snapshotname>]<br>        [-df [-h] [<path> …]]<br>        [-du [-s] [-h] <path> …]<br>        [-expunge]<br>        [-get [-p] [-ignoreCrc] [-crc] <src> … <localdst>]<br>        [-getfacl [-R] <path>]<br>        [-getmerge [-nl] <src> <localdst>]<br>        [-help [cmd …]]<br>        [-ls [-d] [-h] [-R] [<path> …]]<br>        [-mkdir [-p] <path> …]<br>        [-moveFromLocal <localsrc> … <dst>]<br>        [-moveToLocal <src> <localdst>]</localdst></src></dst></localsrc></path></path></localdst></src></path></localdst></src></path></path></snapshotname></snapshotdir></snapshotname></snapshotdir></dst></src></path></localdst></src></dst></localsrc></src></src></dst></localsrc></p><h3 id="3-3-常用命令参数介绍"><a href="#3-3-常用命令参数介绍" class="headerlink" title="3.3 常用命令参数介绍"></a>3.3 常用命令参数介绍</h3><pre class="language-none"><code class="language-none">-help             功能：输出这个命令参数手册-ls                  功能：显示目录信息示例： hadoop fs -ls hdfs://hadoop-server01:9000/备注：这些参数中，所有的hdfs路径都可以简写--&gt;hadoop fs -ls /   等同于上一条命令的效果-mkdir              功能：在hdfs上创建目录示例：hadoop fs  -mkdir  -p  /aaa/bbb/cc/dd-moveFromLocal            功能：从本地剪切粘贴到hdfs示例：hadoop  fs  - moveFromLocal  /home/hadoop/a.txt  /aaa/bbb/cc/dd-moveToLocal              功能：从hdfs剪切粘贴到本地示例：hadoop  fs  - moveToLocal   /aaa/bbb/cc/dd  /home/hadoop/a.txt --appendToFile  功能：追加一个文件到已经存在的文件末尾示例：hadoop  fs  -appendToFile  ./hello.txt  hdfs://hadoop-server01:9000/hello.txt可以简写为：Hadoop  fs  -appendToFile  ./hello.txt  /hello.txt-cat  功能：显示文件内容  示例：hadoop fs -cat  /hello.txt-tail                 功能：显示一个文件的末尾示例：hadoop  fs  -tail  /weblog/access_log.1-text                  功能：以字符形式打印一个文件的内容示例：hadoop  fs  -text  /weblog/access_log.1-chgrp -chmod-chown功能：linux文件系统中的用法一样，对文件所属权限示例：hadoop  fs  -chmod  666  /hello.txthadoop  fs  -chown  someuser:somegrp   /hello.txt-copyFromLocal    功能：从本地文件系统中拷贝文件到hdfs路径去示例：hadoop  fs  -copyFromLocal  ./jdk.tar.gz  /aaa/-copyToLocal      功能：从hdfs拷贝到本地示例：hadoop fs -copyToLocal /aaa/jdk.tar.gz-cp              功能：从hdfs的一个路径拷贝hdfs的另一个路径示例： hadoop  fs  -cp  /aaa/jdk.tar.gz  /bbb/jdk.tar.gz.2-mv                     功能：在hdfs目录中移动文件示例： hadoop  fs  -mv  /aaa/jdk.tar.gz  /-get              功能：等同于copyToLocal，就是从hdfs下载文件到本地示例：hadoop fs -get  /aaa/jdk.tar.gz-getmerge             功能：合并下载多个文件示例：比如hdfs的目录 /aaa/下有多个文件:log.1, log.2,log.3,...hadoop fs -getmerge /aaa/log.* ./log.sum-put                功能：等同于copyFromLocal示例：hadoop  fs  -put  /aaa/jdk.tar.gz  /bbb/jdk.tar.gz.2-rm                功能：删除文件或文件夹示例：hadoop fs -rm -r /aaa/bbb/-rmdir                 功能：删除空目录示例：hadoop  fs  -rmdir   /aaa/bbb/ccc-df               功能：统计文件系统的可用空间信息示例：hadoop  fs  -df  -h  /-du 功能：统计文件夹的大小信息示例：hadoop  fs  -du  -s  -h /aaa/*-count         功能：统计一个指定目录下的文件节点数量示例：hadoop fs -count /aaa/-setrep                功能：设置hdfs中文件的副本数量示例：hadoop fs -setrep 3 /aaa/jdk.tar.gz&lt;这里设置的副本数只是记录在namenode的元数据中，是否真的会有这么多副本，还得看datanode的数量&gt;</code></pre><p><strong>**</strong>HDFS原理篇******</p><h3 id="4-hdfs的工作机制"><a href="#4-hdfs的工作机制" class="headerlink" title="4. hdfs的工作机制"></a>4. hdfs的工作机制</h3><p>（工作机制的学习主要是为加深对分布式系统的理解，以及增强遇到各种问题时的分析解决能力，形成一定的集群运维能力）</p><p>很多不是真正理解hadoop技术体系的人会常常觉得HDFS可用于网盘类应用，但实际并非如此。要想将技术准确用在恰当的地方，必须对技术有深刻的理解</p><p>####4.1 概述</p><ol><li>HDFS集群分为两大角色：NameNode、DataNode</li><li>NameNode负责管理整个文件系统的元数据</li><li>DataNode 负责管理用户的文件数据块</li><li>文件会按照固定的大小（blocksize）切成若干块后分布式存储在若干台datanode上</li><li>每一个文件块可以有多个副本，并存放在不同的datanode上</li><li>Datanode会定期向Namenode汇报自身所保存的文件block信息，而namenode则会负责保持文件的副本数量</li><li>HDFS的内部工作机制对客户端保持透明，客户端请求访问HDFS都是通过向namenode申请来进行</li></ol><h4 id="4-2HDFS写数据流程"><a href="#4-2HDFS写数据流程" class="headerlink" title="4.2HDFS写数据流程"></a>4.2HDFS写数据流程</h4><p>4.2.1 概述:</p><p>客户端要向HDFS写数据，首先要跟namenode通信以确认可以写文件并获得接收文件block的datanode，然后，客户端按顺序将文件逐个block传递给相应datanode，并由接收到block的datanode负责向其他datanode复制block的副本</p><p>4.2.3 详细步骤解析</p><pre class="language-none"><code class="language-none">1、根namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在2、namenode返回是否可以上传3、client请求第一个 block该传输到哪些datanode服务器上4、namenode返回3个datanode服务器ABC5、client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline），A收到请求会继续调用B，然后B调用C，将真个pipeline建立完成，逐级返回客户端6、client开始往A上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，A收到一个packet就会传给B，B传给C；A每传一个packet会放入一个应答队列等待应答7、当一个block传输完成之后，client再次请求namenode上传第二个block的服务器。</code></pre><h4 id="4-3-HDFS读数据流程"><a href="#4-3-HDFS读数据流程" class="headerlink" title="4.3. HDFS读数据流程"></a>4.3. HDFS读数据流程</h4><p>4.3.1 概述</p><p>客户端将要读取的文件路径发送给namenode，namenode获取文件的元信息（主要是block的存放位置信息）返回给客户端，客户端根据返回的信息找到相应datanode逐个获取文件的block并在客户端本地进行数据追加合并从而获得整个文件</p><p>4.3.3 详细步骤解析</p><pre class="language-none"><code class="language-none">1、跟namenode通信查询元数据，找到文件块所在的datanode服务器2、挑选一台datanode（就近原则，然后随机）服务器，请求建立socket流3、datanode开始发送数据（从磁盘里面读取数据放入流，以packet为单位来做校验）4、客户端以packet为单位接收，现在本地缓存，然后写入目标文件</code></pre><h3 id="5-NAMENODE工作机制"><a href="#5-NAMENODE工作机制" class="headerlink" title="5. NAMENODE工作机制"></a>5. NAMENODE工作机制</h3><p>学习目标：理解namenode的工作机制尤其是元数据管理机制，以增强对HDFS工作原理的理解，及培养hadoop集群运营中“性能调优”、“namenode”故障问题的分析解决能力</p><p>问题场景：<br>1、集群启动后，可以查看文件，但是上传文件时报错，打开web页面可看到namenode正处于safemode状态，怎么处理？<br>2、Namenode服务器的磁盘故障导致namenode宕机，如何挽救集群及数据？<br>3、Namenode是否可以有多个？namenode内存要配置多大？namenode跟集群数据存储能力有关系吗？<br>4、文件的blocksize究竟调大好还是调小好？<br>……</p><p>诸如此类问题的回答，都需要基于对namenode自身的工作原理的深刻理解</p><p>5.1 NAMENODE职责:</p><pre><code>NAMENODE职责：    负责客户端请求的响应    元数据的管理（查询，修改）</code></pre><p>5.2 元数据管理</p><pre><code>    namenode对数据的管理采用了三种存储形式：    内存元数据(NameSystem)    磁盘元数据镜像文件    数据操作日志文件（可通过日志运算出元数据）</code></pre><pre class="language-none"><code class="language-none">5.2.1 元数据存储机制A、内存中有一份完整的元数据(内存meta data)B、磁盘有一个“准完整”的元数据镜像（fsimage）文件(在namenode的工作目录中)C、用于衔接内存metadata和持久化元数据镜像fsimage之间的操作日志（edits文件）注：当客户端对hdfs中的文件进行新增或者修改操作，操作记录首先被记入edits日志文件中，当客户端操作成功后，相应的元数据会更新到内存meta.data中</code></pre><pre class="language-none"><code class="language-none">5.2.2 元数据手动查看可以通过hdfs的一个工具来查看edits中的信息bin/hdfs oev -i edits -o edits.xmlbin/hdfs oiv -i fsimage_0000000000000000087 -p XML -o fsimage.xml</code></pre><pre class="language-none"><code class="language-none">5.2.3 元数据的checkpoint每隔一段时间，会由secondary namenode将namenode上积累的所有edits和一个最新的fsimage下载到本地，并加载到内存进行merge（这个过程称为checkpoint）checkpoint操作的触发条件配置参数dfs.namenode.checkpoint.check.period=60  #检查触发条件是否满足的频率，60秒dfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary#以上两个参数做checkpoint操作时，secondary namenode的本地工作目录dfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir}dfs.namenode.checkpoint.max-retries=3  #最大重试次数dfs.namenode.checkpoint.period=3600  #两次checkpoint之间的时间间隔3600秒dfs.namenode.checkpoint.txns=1000000 #两次checkpoint之间最大的操作记录checkpoint的附带作用namenode和secondary namenode的工作目录存储结构完全相同，所以，当namenode故障退出需要重新恢复时，可以从secondary namenode的工作目录中将fsimage拷贝到namenode的工作目录，以恢复namenode的元数据</code></pre><h3 id="6-DATANODE的工作机制"><a href="#6-DATANODE的工作机制" class="headerlink" title="6. DATANODE的工作机制"></a>6. DATANODE的工作机制</h3><p>问题场景：<br>1、集群容量不够，怎么扩容？<br>2、如果有一些datanode宕机，该怎么办？<br>3、datanode明明已启动，但是集群中的可用datanode列表中就是没有，怎么办？</p><p>以上这类问题的解答，有赖于对datanode工作机制的深刻理解</p><h4 id="6-1-概述"><a href="#6-1-概述" class="headerlink" title="6.1 概述"></a>6.1 概述</h4><ul><li><p>Datanode工作职责：</p><pre><code>  存储管理用户的文件块数据  定期向namenode汇报自身所持有的block信息（通过心跳信息上报）  （这点很重要，因为，当集群中发生某些block副本失效时，集群如何恢复block初始副本数量的问题）  &lt;property&gt;      &lt;name&gt;dfs.blockreport.intervalMsec&lt;/name&gt;      &lt;value&gt;3600000&lt;/value&gt;      &lt;description&gt;Determines block reporting interval in milliseconds.&lt;/description&gt;  &lt;/property&gt;</code></pre></li><li><p>2、Datanode掉线判断时限参数</p><pre><code>  datanode进程死亡或者网络故障造成datanode无法与namenode通信，namenode不会立即把该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。HDFS默认的超时时长为10分钟+30秒。如果定义超时时间为timeout，则超时时长的计算公式为：      timeout  = 2 * heartbeat.recheck.interval + 10 * dfs.heartbeat.interval。      而默认的heartbeat.recheck.interval 大小为5分钟，dfs.heartbeat.interval默认为3秒。      需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。所以，举个例子，如果heartbeat.recheck.interval设置为5000（毫秒），dfs.heartbeat.interval设置为3（秒，默认），则总的超时时间为40秒。</code></pre></li></ul><pre><code>    &lt;property&gt;        &lt;name&gt;heartbeat.recheck.interval&lt;/name&gt;        &lt;value&gt;2000&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.heartbeat.interval&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;    &lt;/property&gt;</code></pre><h4 id="6-2-观察验证DATANODE功能"><a href="#6-2-观察验证DATANODE功能" class="headerlink" title="6.2 观察验证DATANODE功能"></a>6.2 观察验证DATANODE功能</h4><p>上传一个文件，观察文件的block具体的物理存放情况：</p><p>在每一台datanode机器上的这个目录中能找到文件的切块：<br>/home/hadoop/app/hadoop-2.4.1/tmp/dfs/data/current/BP-193442119-192.168.2.120-1432457733977/current/finalized</p><p><strong>**</strong>HDFS应用开发篇******</p><h3 id="7-HDFS的java操作"><a href="#7-HDFS的java操作" class="headerlink" title="7. HDFS的java操作"></a>7. HDFS的java操作</h3><p>hdfs在生产应用中主要是客户端的开发，其核心步骤是从hdfs提供的api中构造一个HDFS的访问客户端对象，然后通过该客户端对象操作（增删改查）HDFS上的文件</p><h4 id="7-1-搭建开发环境"><a href="#7-1-搭建开发环境" class="headerlink" title="7.1 搭建开发环境"></a>7.1 搭建开发环境</h4><p>1、引入依赖</p><pre><code>    &lt;dependency&gt;        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;        &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;        &lt;version&gt;2.6.1&lt;/version&gt;    &lt;/dependency&gt;    注：如需手动引入jar包，hdfs的jar包----hadoop的安装目录的share下    2、window下开发的说明    建议在linux下进行hadoop应用的开发，不会存在兼容性问题。如在window上做客户端应用开发，需要设置以下环境：    A、在windows的某个目录下解压一个hadoop的安装包    B、将安装包下的lib和bin目录用对应windows版本平台编译的本地库替换    C、在window系统中配置HADOOP_HOME指向你解压的安装包    D、在windows系统的path变量中加入hadoop的bin目录</code></pre><h4 id="7-2-获取api中的客户端对象"><a href="#7-2-获取api中的客户端对象" class="headerlink" title="7.2 获取api中的客户端对象"></a>7.2 获取api中的客户端对象</h4><pre><code>    在java中操作hdfs，首先要获得一个客户端实例    Configuration conf = new Configuration()    FileSystem fs = FileSystem.get(conf)    而我们的操作目标是HDFS，所以获取到的fs对象应该是DistributedFileSystem的实例；    get方法是从何处判断具体实例化那种客户端类呢？    ——从conf中的一个参数 fs.defaultFS的配置值判断；    如果我们的代码中没有指定fs.defaultFS，并且工程classpath下也没有给定相应的配置，conf中的默认值就来自于hadoop的jar包中的core-default.xml，默认值为： file:///，则获取的将不是一个DistributedFileSystem的实例，而是一个本地文件系统的客户端对象</code></pre><h4 id="7-3HDFS客户端操作数据代码示例"><a href="#7-3HDFS客户端操作数据代码示例" class="headerlink" title="7.3HDFS客户端操作数据代码示例"></a>7.3HDFS客户端操作数据代码示例</h4><pre class="language-none"><code class="language-none">package com.bigdata.day06_hadoop.hdfs;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.*;import org.junit.Before;import org.junit.Test;import java.net.URI;import java.util.Iterator;import java.util.Map.Entry;/** * 客户端去操作hdfs时，是有一个用户身份的 * 默认情况下，hdfs客户端api会从jvm中获取一个参数来作为自己的用户身份：-DHADOOP_USER_NAME=hadoop * 也可以在构造客户端fs对象时，通过参数传递进去 * @author */public class HdfsClientDemo {    FileSystem fs = null;    Configuration conf = null;    @Before    public void init() throws Exception{        conf = new Configuration();        conf.set("fs.defaultFS", "hdfs://hadoop-master:9000");        //拿到一个文件系统操作的客户端实例对象        /*fs = FileSystem.get(conf);*/        //可以直接传入 uri和用户身份        fs = FileSystem.get(new URI("hdfs://hadoop-master:9000"),conf,"hadoop"); //最后一个参数为用户名    }    //上传文件    @Test    public void testUpload() throws Exception {        Thread.sleep(2000);        fs.copyFromLocalFile(new Path("G:/access.log"), new Path("/access.log.copy"));        fs.close();    }    //下载文件    @Test    public void testDownload() throws Exception {        fs.copyToLocalFile(new Path("/access.log.copy"), new Path("d:/"));        fs.close();    }    //测试配置文件    @Test    public void testConf(){        Iterator&lt;Entry&lt;String, String&gt;&gt; iterator = conf.iterator();        while (iterator.hasNext()) {            Entry&lt;String, String&gt; entry = iterator.next();            System.out.println(entry.getValue() + "--" + entry.getValue());//conf加载的内容        }    }    //创建目录    @Test    public void makdirTest() throws Exception {        boolean mkdirs = fs.mkdirs(new Path("/aaa/bbb"));        System.out.println(mkdirs);    }    //删除    @Test    public void deleteTest() throws Exception{        boolean delete = fs.delete(new Path("/aaa"), true);//true， 递归删除        System.out.println(delete);    }    //递归找到所有的文件    @Test    public void listTest() throws Exception{        FileStatus[] listStatus = fs.listStatus(new Path("/"));        for (FileStatus fileStatus : listStatus) {            System.err.println(fileStatus.getPath()+"================="+fileStatus.toString());        }        //会递归找到所有的文件        RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(new Path("/"), true);        while(listFiles.hasNext()){            LocatedFileStatus next = listFiles.next();            String name = next.getPath().getName();            Path path = next.getPath();            System.out.println(name + "---" + path.toString());        }    }}</code></pre><h3 id="8-案例1：开发shell采集脚本"><a href="#8-案例1：开发shell采集脚本" class="headerlink" title="8. 案例1：开发shell采集脚本"></a>8. 案例1：开发shell采集脚本</h3><h4 id="8-1需求说明"><a href="#8-1需求说明" class="headerlink" title="8.1需求说明"></a>8.1需求说明</h4><p>点击流日志每天都10T，在业务应用服务器上，需要准实时上传至数据仓库（Hadoop HDFS）上</p><h4 id="8-2需求分析"><a href="#8-2需求分析" class="headerlink" title="8.2需求分析"></a>8.2需求分析</h4><p>一般上传文件都是在凌晨24点操作，由于很多种类的业务数据都要在晚上进行传输，为了减轻服务器的压力，避开高峰期。<br>如果需要伪实时的上传，则采用定时上传的方式</p><h4 id="8-3技术分析"><a href="#8-3技术分析" class="headerlink" title="8.3技术分析"></a>8.3技术分析</h4><pre><code> HDFS SHELL:  hadoop fs  –put   xxxx.tar  /data    还可以使用 Java Api         满足上传一个文件，不能满足定时、周期性传入。 定时调度器：    Linux crontab    crontab -e*/5 * * * * $home/bin/command.sh   //五分钟执行一次系统会自动执行脚本，每5分钟一次，执行时判断文件是否符合上传规则，符合则上传</code></pre><h4 id="8-4实现流程"><a href="#8-4实现流程" class="headerlink" title="8.4实现流程"></a>8.4实现流程</h4><pre class="language-none"><code class="language-none">8.4.1日志产生程序日志产生程序将日志生成后，产生一个一个的文件，使用滚动模式创建文件名。日志生成的逻辑由业务系统决定，比如在log4j配置文件中配置生成规则，如：当xxxx.log 等于10G时，滚动生成新日志    log4j.logger.msg=info,msglog4j.appender.msg=cn.maoxiangyi.MyRollingFileAppenderlog4j.appender.msg.layout=org.apache.log4j.PatternLayoutlog4j.appender.msg.layout.ConversionPattern=%m%nlog4j.appender.msg.datePattern='.'yyyy-MM-ddlog4j.appender.msg.Threshold=infolog4j.appender.msg.append=truelog4j.appender.msg.encoding=UTF-8log4j.appender.msg.MaxBackupIndex=100log4j.appender.msg.MaxFileSize=10GBlog4j.appender.msg.File=/home/hadoop/logs/log/access.log细节：1、    如果日志文件后缀是1\2\3等数字，该文件满足需求可以上传的话。把该文件移动到准备上传的工作区间。2、    工作区间有文件之后，可以使用hadoop put命令将文件上传。阶段问题：1、    待上传文件的工作区间的文件，在上传完成之后，是否需要删除掉</code></pre><pre class="language-none"><code class="language-none">8.4.2伪代码    使用ls命令读取指定路径下的所有文件信息，    ls  | while read  line     //判断line这个文件名称是否符合规则if     line=access.log.* (        将文件移动到待上传的工作区间    )//批量上传工作区间的文件hadoop fs  –put   xxx脚本写完之后，配置linux定时任务，每5分钟运行一次。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>轻量级RPC框架开发</title>
      <link href="/2018/04/26/qing-liang-ji-rpc-kuang-jia-kai-fa/"/>
      <url>/2018/04/26/qing-liang-ji-rpc-kuang-jia-kai-fa/</url>
      
        <content type="html"><![CDATA[<h3 id="1-RPC原理学习"><a href="#1-RPC原理学习" class="headerlink" title="1.    RPC原理学习"></a>1.    RPC原理学习</h3><h4 id="1-1-什么是RPC"><a href="#1-1-什么是RPC" class="headerlink" title="1.1.    什么是RPC"></a>1.1.    什么是RPC</h4><p>RPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP或UDP，为通信程序之间携带信息数据。在OSI网络通信模型中，RPC跨越了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易。<br>    RPC采用客户机/服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。</p><h4 id="1-2-RPC原理"><a href="#1-2-RPC原理" class="headerlink" title="1.2.    RPC原理"></a>1.2.    RPC原理</h4><p>运行时,一次客户机对服务器的RPC调用,其内部操作大致有如下十步：<br>1.调用客户端句柄；执行传送参数<br>2.调用本地系统内核发送网络消息<br>3.消息传送到远程主机<br>4.服务器句柄得到消息并取得参数<br>5.执行远程过程<br>6.执行的过程将结果返回服务器句柄<br>7.服务器句柄返回结果，调用远程系统内核<br>8.消息传回本地主机<br>9.客户句柄由内核接收消息<br>10.客户接收句柄返回的数据</p><h3 id="2-nio原理学习-nio的优势不在于数据传送的速度"><a href="#2-nio原理学习-nio的优势不在于数据传送的速度" class="headerlink" title="2.    nio原理学习(nio的优势不在于数据传送的速度)"></a>2.    nio原理学习(nio的优势不在于数据传送的速度)</h3><h4 id="2-1-简介"><a href="#2-1-简介" class="headerlink" title="2.1.    简介"></a>2.1.    简介</h4><p>nio 是New IO 的简称，在jdk1.4 里提供的新api 。Sun 官方标榜的特性如下： 为所有的原始类型提供(Buffer)缓存支持。字符集编码解码解决方案。 Channel ：一个新的原始I/O 抽象。 支持锁和内存映射文件的文件访问接口。 提供多路(non-bloking) 非阻塞式的高伸缩性网络I/O 。</p><h4 id="2-3-socket-nio原理"><a href="#2-3-socket-nio原理" class="headerlink" title="2.3.    socket nio原理"></a>2.3.    socket nio原理</h4><ul><li>传统的I/O<br>  使用传统的I/O程序读取文件内容, 并写入到另一个文件(或Socket), 如下程序:<br>  File.read(fileDesc, buf, len);<br>  Socket.send(socket, buf, len);<br>  会有较大的性能开销, 主要表现在一下两方面:<ol><li>上下文切换(context switch), 此处有4次用户态和内核态的切换</li><li>Buffer内存开销, 一个是应用程序buffer, 另一个是系统读取buffer以及socket buffer</li></ol><ol><li>先将文件内容从磁盘中拷贝到操作系统buffer</li><li>再从操作系统buffer拷贝到程序应用buffer</li><li>从程序buffer拷贝到socket buffer</li><li>从socket buffer拷贝到协议引擎.</li></ol></li><li>NIO<br>NIO技术省去了将操作系统的read buffer拷贝到程序的buffer, 以及从程序buffer拷贝到socket buffer的步骤, 直接将 read buffer 拷贝到 socket buffer. java 的 FileChannel.transferTo() 方法就是这样的实现, 这个实现是依赖于操作系统底层的sendFile()实现的.<br>publicvoid transferTo(long position, long count, WritableByteChannel target);<br>他的底层调用的是系统调用sendFile()方法<br>sendfile(int out_fd, int in_fd, off_t *offset, size_t count);</li></ul><h3 id="3-netty常用API学习"><a href="#3-netty常用API学习" class="headerlink" title="3.    netty常用API学习"></a>3.    netty常用API学习</h3><h4 id="3-1-netty简介"><a href="#3-1-netty简介" class="headerlink" title="3.1.    netty简介"></a>3.1.    netty简介</h4><pre><code>Netty是基于Java NIO的网络应用框架.Netty是一个NIO client-server(客户端服务器)框架，使用Netty可以快速开发网络应用，例如服务器和客户端协议。Netty提供了一种新的方式来使开发网络应用程序，这种新的方式使得它很容易使用和有很强的扩展性。Netty的内部实现时很复杂的，但是Netty提供了简单易用的api从网络处理代码中解耦业务逻辑。Netty是完全基于NIO实现的，所以整个Netty都是异步的。    网络应用程序通常需要有较高的可扩展性，无论是Netty还是其他的基于Java NIO的框架，都会提供可扩展性的解决方案。Netty中一个关键组成部分是它的异步特性.</code></pre><h4 id="3-2-netty的helloworld"><a href="#3-2-netty的helloworld" class="headerlink" title="3.2.    netty的helloworld"></a>3.2.    netty的helloworld</h4><p>服务端启动类</p><pre class="language-none"><code class="language-none">package com.netty.demo.server;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.Channel;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioServerSocketChannel;/** * • 配置服务器功能，如线程、端口 • 实现服务器处理程序，它包含业务逻辑，决定当有一个请求连接或接收数据时该做什么 *  * @author wilson * */public class EchoServer {    private final int port;    public EchoServer(int port) {        this.port = port;    }    public void start() throws Exception {        EventLoopGroup eventLoopGroup = null;        try {            //创建ServerBootstrap实例来引导绑定和启动服务器            ServerBootstrap serverBootstrap = new ServerBootstrap();            //创建NioEventLoopGroup对象来处理事件，如接受新连接、接收数据、写数据等等            eventLoopGroup = new NioEventLoopGroup();            //指定通道类型为NioServerSocketChannel，设置InetSocketAddress让服务器监听某个端口已等待客户端连接。            serverBootstrap.group(eventLoopGroup).channel(NioServerSocketChannel.class).localAddress("localhost",port).childHandler(new ChannelInitializer&lt;Channel&gt;() {                //设置childHandler执行所有的连接请求                @Override                protected void initChannel(Channel ch) throws Exception {                    ch.pipeline().addLast(new EchoServerHandler());                }                    });            // 最后绑定服务器等待直到绑定完成，调用sync()方法会阻塞直到服务器完成绑定,然后服务器等待通道关闭，因为使用sync()，所以关闭操作也会被阻塞。            ChannelFuture channelFuture = serverBootstrap.bind().sync();            System.out.println("开始监听，端口为：" + channelFuture.channel().localAddress());            channelFuture.channel().closeFuture().sync();        } finally {            eventLoopGroup.shutdownGracefully().sync();        }    }    public static void main(String[] args) throws Exception {        new EchoServer(20000).start();    }}</code></pre><p>服务端回调方法</p><pre class="language-none"><code class="language-none">package com.netty.demo.server;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFutureListener;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import java.util.Date;public class EchoServerHandler extends ChannelInboundHandlerAdapter {    @Override    public void channelRead(ChannelHandlerContext ctx, Object msg)            throws Exception {        System.out.println("server 读取数据……");        //读取数据        ByteBuf buf = (ByteBuf) msg;        byte[] req = new byte[buf.readableBytes()];        buf.readBytes(req);        String body = new String(req, "UTF-8");        System.out.println("接收客户端数据:" + body);        //向客户端写数据        System.out.println("server向client发送数据");        String currentTime = new Date(System.currentTimeMillis()).toString();        ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes());        ctx.write(resp);    }    @Override    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {        System.out.println("server 读取数据完毕..");        ctx.flush();//刷新后才将数据发出到SocketChannel    }    @Override    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause)            throws Exception {        cause.printStackTrace();        ctx.close();    }}</code></pre><p>客户端启动类</p><pre class="language-none"><code class="language-none">package com.netty.demo.client;import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import java.net.InetSocketAddress;/** * • 连接服务器 • 写数据到服务器 • 等待接受服务器返回相同的数据 • 关闭连接 *  * @author wilson * */public class EchoClient {    private final String host;    private final int port;    public EchoClient(String host, int port) {        this.host = host;        this.port = port;    }    public void start() throws Exception {        EventLoopGroup nioEventLoopGroup = null;        try {            //创建Bootstrap对象用来引导启动客户端            Bootstrap bootstrap = new Bootstrap();            //创建EventLoopGroup对象并设置到Bootstrap中，EventLoopGroup可以理解为是一个线程池，这个线程池用来处理连接、接受数据、发送数据            nioEventLoopGroup = new NioEventLoopGroup();            //创建InetSocketAddress并设置到Bootstrap中，InetSocketAddress是指定连接的服务器地址            bootstrap.group(nioEventLoopGroup).channel(NioSocketChannel.class).remoteAddress(new InetSocketAddress(host, port))                    .handler(new ChannelInitializer&lt;SocketChannel&gt;() {                        //添加一个ChannelHandler，客户端成功连接服务器后就会被执行                        @Override                        protected void initChannel(SocketChannel ch)                                throws Exception {                            ch.pipeline().addLast(new EchoClientHandler());                        }                    });            // • 调用Bootstrap.connect()来连接服务器            ChannelFuture f = bootstrap.connect().sync();            // • 最后关闭EventLoopGroup来释放资源            f.channel().closeFuture().sync();        } finally {            nioEventLoopGroup.shutdownGracefully().sync();        }    }    public static void main(String[] args) throws Exception {        new EchoClient("localhost", 20000).start();    }}</code></pre><p>客户端回调方法</p><pre class="language-none"><code class="language-none">package com.netty.demo.client;    import io.netty.buffer.ByteBuf;import io.netty.buffer.ByteBufUtil;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;    public class EchoClientHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; {            //客户端连接服务器后被调用        @Override          public void channelActive(ChannelHandlerContext ctx) throws Exception {              System.out.println("客户端连接服务器，开始发送数据……");            byte[] req = "QUERY TIME ORDER".getBytes();            ByteBuf  firstMessage = Unpooled.buffer(req.length);            firstMessage.writeBytes(req);            ctx.writeAndFlush(firstMessage);          }        //•    从服务器接收到数据后调用        @Override          protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception {               System.out.println("client 读取server数据..");             //服务端返回消息后             ByteBuf buf = (ByteBuf) msg;             byte[] req = new byte[buf.readableBytes()];             buf.readBytes(req);             String body = new String(req, "UTF-8");             System.out.println("服务端数据为 :" + body);}        //•    发生异常时被调用        @Override          public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {               System.out.println("client exceptionCaught..");             // 释放资源             ctx.close();         }      }  </code></pre><p>####3.3.    netty中handler的执行顺序<br>Handler在netty中，无疑占据着非常重要的地位。Handler与Servlet中的filter很像，通过Handler可以完成通讯报文的解码编码、拦截指定的报文、统一对日志错误进行处理、统一对请求进行计数、控制Handler执行与否。一句话，没有它做不到的只有你想不到的。</p><p>Netty中的所有handler都实现自ChannelHandler接口。按照输出输出来分，分为ChannelInboundHandler、ChannelOutboundHandler两大类。ChannelInboundHandler对从客户端发往服务器的报文进行处理，一般用来执行解码、读取客户端数据、进行业务处理等；ChannelOutboundHandler对从服务器发往客户端的报文进行处理，一般用来进行编码、发送报文到客户端。</p><p>Netty中，可以注册多个handler。ChannelInboundHandler按照注册的先后顺序执行；ChannelOutboundHandler按照注册的先后顺序逆序执行，如下图所示，按照注册的先后顺序对Handler进行排序，request进入Netty后的执行顺序为：</p><p>在使用Handler的过程中，需要注意：<br>1、ChannelInboundHandler之间的传递，通过调用 ctx.fireChannelRead(msg) 实现；调用ctx.write(msg) 将传递到ChannelOutboundHandler。<br>2、ctx.write()方法执行后，需要调用flush()方法才能令它立即执行。<br>3、流水线pipeline中outhandler不能放在最后，否则不生效<br>4、Handler的消费处理放在最后一个处理。<br>3.4.    netty发送对象<br>3.4.1.    简介<br>Netty中，通讯的双方建立连接后，会把数据按照ByteBuf的方式进行传输，例如http协议中，就是通过HttpRequestDecoder对ByteBuf数据流进行处理，转换成http的对象。基于这个思路，我自定义一种通讯协议：Server和客户端直接传输java对象。</p><p>实现的原理是通过Encoder把java对象转换成ByteBuf流进行传输，通过Decoder把ByteBuf转换成java对象进行处理，处理逻辑如下图所示：</p><h3 id="5-轻量级RPC框架开发"><a href="#5-轻量级RPC框架开发" class="headerlink" title="5.    轻量级RPC框架开发"></a>5.    轻量级RPC框架开发</h3><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java高级特性增强</title>
      <link href="/2018/04/26/java-gao-ji-te-xing-zeng-qiang/"/>
      <url>/2018/04/26/java-gao-ji-te-xing-zeng-qiang/</url>
      
        <content type="html"><![CDATA[<h2 id="1-多线程增强"><a href="#1-多线程增强" class="headerlink" title="1.多线程增强"></a>1.多线程增强</h2><h3 id="1-1-java多线程基本知识"><a href="#1-1-java多线程基本知识" class="headerlink" title="1.1 java多线程基本知识"></a>1.1 java多线程基本知识</h3><h4 id="1-1-1-进程介绍"><a href="#1-1-1-进程介绍" class="headerlink" title="1.1.1    进程介绍"></a>1.1.1    进程介绍</h4><p>不管是我们开发的应用程序，还是我们运行的其他的应用程序，都需要先把程序安装在本地的硬盘上。然后找到这个程序的启动文件，启动程序的时候，其实是电脑把当前的这个程序加载到内存中，在内存中需要给当前的程序分配一段独立的运行空间。这片空间就专门负责当前这个程序的运行。<br>    不同的应用程序运行的过程中都需要在内存中分配自己独立的运行空间，彼此之间不会相互的影响。我们把每个独立应用程序在内存的独立空间称为当前应用程序运行的一个进程。<br>进程：它是内存中的一段独立的空间，可以负责当前应用程序的运行。当前这个进程负责调度当前程序中的所有运行细节。</p><h4 id="1-1-2-线程介绍"><a href="#1-1-2-线程介绍" class="headerlink" title="1.1.2 线程介绍"></a>1.1.2 线程介绍</h4><p>启动的QQ聊天软件，需要和多个人进行聊天。这时多个人之间是不能相互影响，但是它们都位于当前QQ这个软件运行时所分配的内容的独立空间中。<br>    在一个进程中，每个独立的功能都需要独立的去运行，这时又需要把当前这个进程划分成多个运行区域，每个独立的小区域（小单元）称为一个线程。<br>线程：它是位于进程中，负责当前进程中的某个具备独立运行资格的空间。<br>进程是负责整个程序的运行，而线程是程序中具体的某个独立功能的运行。一个进程中至少应该有一个线程。</p><h4 id="1-1-3-多线程介绍"><a href="#1-1-3-多线程介绍" class="headerlink" title="1.1.3 多线程介绍"></a>1.1.3 多线程介绍</h4><p>现在的操作系统基本都是多用户，多任务的操作系统。每个任务就是一个进程。而在这个进程中就会有线程。<br>    真正可以完成程序运行和功能的实现靠的是进程中的线程。<br>多线程：在一个进程中，我们同时开启多个线程，让多个线程同时去完成某些任务（功能）。<br>多线程的目的：提高程序的运行效率。</p><h4 id="1-1-4-多线程运行的原理"><a href="#1-1-4-多线程运行的原理" class="headerlink" title="1.1.4 多线程运行的原理"></a>1.1.4 多线程运行的原理</h4><p>cpu在线程中做时间片的切换。</p><pre><code>其实真正电脑中的程序的运行不是同时在运行的。CPU负责程序的运行，而CPU在运行程序的过程中某个时刻点上，它其实只能运行一个程序。而不是多个程序。而CPU它可以在多个程序之间进行高速的切换。而切换频率和速度太快，导致人的肉看看不到。</code></pre><p>每个程序就是进程， 而每个进程中会有多个线程，而CPU是在这些线程之间进行切换。<br>了解了CPU对一个任务的执行过程，我们就必须知道，多线程可以提高程序的运行效率，但不能无限制的开线程。</p><h4 id="1-1-5-实现线程的两种方式"><a href="#1-1-5-实现线程的两种方式" class="headerlink" title="1.1.5 实现线程的两种方式"></a>1.1.5 实现线程的两种方式</h4><ol><li>继承Thread</li><li>实现Runabbe</li></ol><h3 id="1-2-java同步关键词解释"><a href="#1-2-java同步关键词解释" class="headerlink" title="1.2 java同步关键词解释"></a>1.2 java同步关键词解释</h3><p>synchronized<br>加同步格式：<br>synchronized( 需要一个任意的对象（锁） ){<br>    代码块中放操作共享数据的代码。<br>}</p><pre class="language-none"><code class="language-none">synchronized的缺陷：    synchronized是java中的一个关键字，也就是说是Java语言内置的特性。如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况：1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有；2）线程执行发生异常，此时JVM会让线程自动释放锁。</code></pre><p> lock</p><ul><li>lock和synchronized的区别<pre><code> 1）Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问；　2）Lock和synchronized有一点非常大的不同，采用synchronized不需要用户去手动释放锁，当synchronized方法或者synchronized代码块执行完之后，系统会自动让线程释放对锁的占用；而Lock则必须要用户去手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象　</code></pre><ul><li>java.util.concurrent.locks包下常用的类</li></ul></li></ul><p>首先要说明的就是Lock，通过查看Lock的源码可知，Lock是一个接口</p><pre class="language-none"><code class="language-none">public interface Lock {    void lock();    void lockInterruptibly() throws InterruptedException;    boolean tryLock();    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;    void unlock();    }</code></pre><p>Lock接口中每个方法的使用：<br>lock()、tryLock()、tryLock(long time, TimeUnit unit)、lockInterruptibly()是用来获取锁的。    unLock()方法是用来释放锁的</p><p>ReentrantLock<br>直接使用lock接口的话，我们需要实现很多方法，不太方便，ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法，ReentrantLock，意思是“可重入锁”。</p><p>ReadWriteLock<br>一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作。下面的ReentrantReadWriteLock实现了ReadWriteLock接口。</p><p>ReentrantReadWriteLock<br>ReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。</p><p>Lock和synchronized的选择</p><pre class="language-none"><code class="language-none">1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。5）Lock可以提高多个线程进行读操作的效率。在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。</code></pre><h3 id="2、java并发包"><a href="#2、java并发包" class="headerlink" title="2、java并发包"></a>2、java并发包</h3><h4 id="2-1java并发包介绍"><a href="#2-1java并发包介绍" class="headerlink" title="2.1java并发包介绍"></a>2.1java并发包介绍</h4><p>JDK5.0 以后的版本都引入了高级并发特性，大多数的特性在java.util.concurrent 包中，是专门用于多线程发编程的，充分利用了现代多处理器和多核心系统的功能以编写大规模并发应用程序。主要包含原子量、并发集合、同步器、可重入锁，并对线程池的构造提供<br>了强力的支持。</p><ul><li>线程池:    线程池的5中创建方式<br>&lt;!–hexoPostRenderEscape:<pre class="language-none"><code class="language-none">1、    Single Thread Executor : 只有一个线程的线程池，因此所有提交的任务是顺序执行，<br>代码： Executors.newSingleThreadExecutor()</code></pre></li><code class="language-none"></code></ul><code class="language-none"><p>2、    Cached Thread Pool : 线程池里有很多线程需要同时执行，老的可用线程将被新的任务触发重新执行，如果线程超过60秒内没执行，那么将被终止并从池中删除，<br>代码：Executors.newCachedThreadPool()</p><p>3、    Fixed Thread Pool : 拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待，<br>代码： Executors.newFixedThreadPool(4)<br>在构造函数中的参数4是线程池的大小，你可以随意设置，也可以和cpu的数量保持一致，获取cpu的数量int cpuNums = Runtime.getRuntime().availableProcessors();</p><p>4、    Scheduled Thread Pool : 用来调度即将执行的任务的线程池，<br>代码：Executors.newScheduledThreadPool()</p></code><p><code class="language-none">5、    Single Thread Scheduled Pool : 只有一个线程，用来调度执行将来的任务，代码：Executors.newSingleThreadScheduledExecutor()</code>:hexoPostRenderEscape–&gt;</p><ul><li>线程池的使用<br>提交 Runnable ，任务完成后 Future 对象返回 null<br>提交 Callable，该方法返回一个 Future 实例表示任务的状态</li></ul><h4 id="2-2-java并发包消息队列及在开源软件中的应用"><a href="#2-2-java并发包消息队列及在开源软件中的应用" class="headerlink" title="2.2.java并发包消息队列及在开源软件中的应用"></a>2.2.java并发包消息队列及在开源软件中的应用</h4><p>BlockingQueue也是java.util.concurrent下的主要用来控制线程同步的工具。<br>主要的方法是：put、take一对阻塞存取；add、poll一对非阻塞存取。</p><pre class="language-none"><code class="language-none">插入:        1)add(anObject):把anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则抛出        2)offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false.        3)put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续.读取：        4)poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间,取不到时返回null        5)take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到Blocking有新的对象被加入为止其他:    int remainingCapacity();返回队列剩余的容量，在队列插入和获取的时候，不要瞎搞，数    据可能不准    boolean remove(Object o); 从队列移除元素，如果存在，即移除一个或者更多，队列改    变了返回true    public boolean contains(Object o); 查看队列是否存在这个元素，存在返回true    int drainTo(Collection&lt;? super E&gt; c); 传入的集合中的元素，如果在队列中存在，那么将    队列中的元素移动到集合中    int drainTo(Collection&lt;? super E&gt; c, int maxElements); 和上面方法的区别在于，制定了移    动的数量</code></pre><p>BlockingQueue有四个具体的实现类,常用的两种实现类为：</p><pre class="language-none"><code class="language-none">1、ArrayBlockingQueue：一个由数组支持的有界阻塞队列，规定大小的BlockingQueue,其构造函数必须带一个int参数来指明其大小.其所含的对象是以FIFO(先入先出)顺序排序的。2、LinkedBlockingQueue：大小不定的BlockingQueue,若其构造函数带一个规定大小的参数,生成的BlockingQueue有大小限制,若不带大小参数,所生成的BlockingQueue的大小由Integer.MAX_VALUE来决定.其所含的对象是以FIFO(先入先出)顺序排序的。     LinkedBlockingQueue 可以指定容量，也可以不指定，不指定的话，默认最大是Integer.MAX_VALUE,其中主要用到put和take方法，put方法在队列满的时候会阻塞直到有队列成员被消费，take方法在队列空的时候会阻塞，直到有队列成员被放进来。</code></pre><p>LinkedBlockingQueue和ArrayBlockingQueue区别：</p><p>LinkedBlockingQueue和ArrayBlockingQueue比较起来,它们背后所用的数据结构不一样,导致LinkedBlockingQueue的数据吞吐量要大于ArrayBlockingQueue,但在线程数量很大时其性能的可预见性低于ArrayBlockingQueue.</p><h3 id="3-java-JMS技术"><a href="#3-java-JMS技术" class="headerlink" title="3.java JMS技术"></a>3.java JMS技术</h3><h4 id="3-1-什么是JMS"><a href="#3-1-什么是JMS" class="headerlink" title="3.1 什么是JMS"></a>3.1 什么是JMS</h4><pre class="language-none"><code class="language-none">JMS即Java消息服务（Java Message Service）应用程序接口是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。    JMS是一种与厂商无关的 API，用来访问消息收发系统消息。它类似于JDBC(Java Database Connectivity)：这里，JDBC 是可以用来访问许多不同关系数据库的 API，而 JMS 则提供同样与厂商无关的访问方法，以访问消息收发服务。许多厂商都支持 JMS，包括 IBM 的 MQSeries、BEA的 Weblogic JMS service和 Progress 的 SonicMQ，这只是几个例子。 JMS 使您能够通过消息收发服务（有时称为消息中介程序或路由器）从一个 JMS 客户机向另一个 JMS客户机发送消息。消息是 JMS 中的一种类型对象，由两部分组成：报头和消息主体。报头由路由信息以及有关该消息的元数据组成。消息主体则携带着应用程序的数据或有效负载。根据有效负载的类型来划分，可以将消息分为几种类型，它们分别携带：简单文本(TextMessage)、可序列化的对象 (ObjectMessage)、属性集合 (MapMessage)、字节流 (BytesMessage)、原始值流 (StreamMessage)，还有无有效负载的消息 (Message)。</code></pre><h4 id="3-2-专业技术规范"><a href="#3-2-专业技术规范" class="headerlink" title="3.2.专业技术规范"></a>3.2.专业技术规范</h4><p>JMS（Java Messaging Service）是Java平台上有关面向消息中间件(MOM)的技术规范，它便于消息系统中的Java应用程序进行消息交换,并且通过提供标准的产生、发送、接收消息的接口简化企业应用的开发，翻译为Java消息服务。</p><h4 id="3-3体系架构"><a href="#3-3体系架构" class="headerlink" title="3.3体系架构"></a>3.3体系架构</h4><pre class="language-none"><code class="language-none">JMS由以下元素组成。JMS提供者：连接面向消息中间件的，JMS接口的一个实现。提供者可以是Java平台的JMS实现，也可以是非Java平台的面向消息中间件的适配器。JMS客户：生产或消费基于消息的Java的应用程序或对象。JMS生产者：创建并发送消息的JMS客户。JMS消费者：接收消息的JMS客户。JMS消息：包括可以在JMS客户之间传递的数据的对象JMS队列：一个容纳那些被发送的等待阅读的消息的区域。与队列名字所暗示的意思不同，消息的接受顺序并不一定要与消息的发送顺序相同。一旦一个消息被阅读，该消息将被从队列中移走。JMS主题：一种支持发送消息给多个订阅者的机制。</code></pre><h4 id="3-4Java消息服务应用程序结构支持两种模型"><a href="#3-4Java消息服务应用程序结构支持两种模型" class="headerlink" title="3.4Java消息服务应用程序结构支持两种模型"></a>3.4Java消息服务应用程序结构支持两种模型</h4><pre class="language-none"><code class="language-none">1、    点对点或队列模型在点对点或队列模型下，一个生产者向一个特定的队列发布消息，一个消费者从该队列中读取消息。这里，生产者知道消费者的队列，并直接将消息发送到消费者的队列。这种模式被概括为：只有一个消费者将获得消息生产者不需要在接收者消费该消息期间处于运行状态，接收者也同样不需要在消息发送时处于运行状态。每一个成功处理的消息都由接收者签收2、发布者/订阅者模型发布者/订阅者模型支持向一个特定的消息主题发布消息。0或多个订阅者可能对接收来自特定消息主题的消息感兴趣。在这种模型下，发布者和订阅者彼此不知道对方。这种模式好比是匿名公告板。这种模式被概括为：多个消费者可以获得消息在发布者和订阅者之间存在时间依赖性。发布者需要建立一个订阅（subscription），以便客户能够订阅。订阅者必须保持持续的活动状态以接收消息，除非订阅者建立了持久的订阅。在那种情况下，在订阅者未连接时发布的消息将在订阅者重新连接时重新发布。使用Java语言，JMS提供了将应用与提供数据的传输层相分离的方式。同一组Java类可以通过JNDI中关于提供者的信息，连接不同的JMS提供者。这一组类首先使用一个连接工厂以连接到队列或主题，然后发送或发布消息。在接收端，客户接收或订阅这些消息。</code></pre><h4 id="3-5常用的JMS实现"><a href="#3-5常用的JMS实现" class="headerlink" title="3.5常用的JMS实现"></a>3.5常用的JMS实现</h4><p>要使用Java消息服务，你必须要有一个JMS提供者，管理会话和队列。既有开源的提供者也有专有的提供者。<br>开源的提供者包括：<br>Apache ActiveMQ<br>JBoss 社区所研发的 HornetQ<br>Joram<br>Coridan的MantaRay<br>The OpenJMS Group的OpenJMS<br>专有的提供者包括：<br>BEA的BEA WebLogic Server JMS<br>TIBCO Software的EMS<br>GigaSpaces Technologies的GigaSpaces<br>Softwired 2006的iBus<br>IONA Technologies的IONA JMS<br>SeeBeyond的IQManager（2005年8月被Sun Microsystems并购）<br>webMethods的JMS+ -<br>my-channels的Nirvana<br>Sonic Software的SonicMQ<br>SwiftMQ的SwiftMQ<br>IBM的WebSphere MQ</p><h4 id="3-6java监控工具使用"><a href="#3-6java监控工具使用" class="headerlink" title="3.6java监控工具使用"></a>3.6java监控工具使用</h4><ul><li><p>console<br>  jconsole是一种集成了上面所有命令功能的可视化工具，可以分析jvm的内存使用情况和线程等信息。</p></li><li><p>jvisualvm<br>  提供了和jconsole的功能类似，提供了一大堆的插件。<br>插件中，Visual GC（可视化GC）还是比较好用的，可视化GC可以看到内存的具体使用情况</p></li></ul><h4 id="3-7java内存模型"><a href="#3-7java内存模型" class="headerlink" title="3.7java内存模型"></a>3.7java内存模型</h4><p>Java虚拟机在执行Java程序的过程中，会把它所管理的内存划分为若干个不同的数据区。这些区域有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有的区域则依赖用户线程的启动和结束而建立和销毁，我们可以将这些区域统称为Java运行时数据区域。</p><p>Java虚拟机运行时数据区域被分为五个区域：堆(Heap)、栈(Stack)、本地方法栈(Native Stack)、方法区(Method Area)、程序计数器(Program Count Register)。</p><ul><li><p>堆（Heap）</p><pre class="language-none"><code class="language-none">对于大多数应用来说，Java Heap是Java虚拟机管理的内存的最大一块，这块区域随着虚拟机的启动而创建。在实际的运用中，我们创建的对象和数组就是存放在堆里面。如果你听说线程安全的问题，就会很明确的知道Java Heap是一块共享的区域，操作共享区域的成员就有了锁和同步。  与Java Heap相关的还有Java的垃圾回收机制（GC）,Java Heap是垃圾回收器管理的主要区域。程序猿所熟悉的新生代、老生代、永久代的概念就是在堆里面，现在大多数的GC基本都采用了分代收集算法。如果再细致一点，Java Heap还有Eden空间，From Survivor空间,To Survivor空间等。  Java Heap可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。</code></pre></li><li><p>栈（Stack）</p><pre class="language-none"><code class="language-none">相对于Java Heap来讲，Java Stack是线程私有的，她的生命周期与线程相同。Java Stack描述的是Java方法执行时的内存模型，每个方法执行时都会创建一个栈帧（Stack Frame）用语存储局部变量表、操作数栈、动态链接、方法出口等信息。从下图从可以看到，每个线程在执行一个方法时，都意味着有一个栈帧在当前线程对应的栈帧中入栈和出栈每一个栈帧中都有局部变量表。局部变量表存放了编译期间的各种基本数据类型，对象引用等信息。</code></pre></li><li><p>本地方法栈（Native Stack）<br>本地方法栈（Native Stack）与Java虚拟机站（Java Stack）所发挥的作用非常相似，他们之间的区别在于虚拟机栈为虚拟机栈执行java方法（也就是字节码）服务，而本地方法栈则为使用到Native方法服务。</p></li><li><p>方法区（Method Area）</p><pre class="language-none"><code class="language-none">方法区（Method Area）与堆（Java Heap）一样，是各个线程共享的内存区域，它用于存储虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是她却有一个别名叫做非堆（Non-Heap）。分析下Java虚拟机规范，之所以把方法区描述为堆的一个逻辑部分，应该觉得她们都是存储数据的角度出发的。一个存储对象数据（堆），一个存储静态信息(方法区)。  在上文中，我们看到堆中有新生代、老生代、永久代的描述。为什么我们将新生代、老生代、永久代三个概念一起说，那是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。这样HotSpot的垃圾收集器就能想管理Java堆一样管理这部分内存。简单点说就是HotSpot虚拟机中内存模型的分代，其中新生代和老生代在堆中，永久代使用方法区实现。根据官方发布的路线图信息，现在也有放弃永久代并逐步采用Native Memory来实现方法区的规划，在JDK1.7的HotSpot中，已经把原本放在永久代的字符串常量池移出。</code></pre><h4 id="3-8总结"><a href="#3-8总结" class="headerlink" title="3.8总结"></a>3.8总结</h4><p>1、    线程私有的数据区域有：<br>Java虚拟机栈（Java Stack）<br>本地方法栈（Native Stack）</p></li></ul><p>2、    线程共有的数据区域有：<br>堆（Java Heap）<br>方法区</p><h3 id="4、GC算法"><a href="#4、GC算法" class="headerlink" title="4、GC算法"></a>4、GC算法</h3><h4 id="4-1-标记-清除算法（Mark-Sweep）"><a href="#4-1-标记-清除算法（Mark-Sweep）" class="headerlink" title="4.1 标记-清除算法（Mark-Sweep）"></a>4.1 标记-清除算法（Mark-Sweep）</h4><pre class="language-none"><code class="language-none">1、标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象2、在标记完成后统一回收所有被标记的对象缺点：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</code></pre><h4 id="4-2复制算法（Copying）"><a href="#4-2复制算法（Copying）" class="headerlink" title="4.2复制算法（Copying）"></a>4.2复制算法（Copying）</h4><pre class="language-none"><code class="language-none">1、将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。2、当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。优点：这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。缺点：复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低</code></pre><h4 id="4-3-标记-整理算法（Mark-Compact）"><a href="#4-3-标记-整理算法（Mark-Compact）" class="headerlink" title="4.3     标记-整理算法（Mark-Compact）"></a>4.3     标记-整理算法（Mark-Compact）</h4><pre class="language-none"><code class="language-none">1、标记2、让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存</code></pre><h4 id="4-4分代收集算法（Generational-Collection）"><a href="#4-4分代收集算法（Generational-Collection）" class="headerlink" title="4.4分代收集算法（Generational Collection）"></a>4.4分代收集算法（Generational Collection）</h4><pre class="language-none"><code class="language-none">1、根据对象存活周期的不同将内存划分为几块。2、一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。3、在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。4、老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。</code></pre><h3 id="5-垃圾回收器"><a href="#5-垃圾回收器" class="headerlink" title="5.垃圾回收器"></a>5.垃圾回收器</h3><h4 id="5-1-Serial收集器："><a href="#5-1-Serial收集器：" class="headerlink" title="5.1    Serial收集器："></a>5.1    Serial收集器：</h4><p>1、是一个单线程的收集器，“Stop The World”<br>2、对于运行在Client模式下的虚拟机来说是一个很好的选择<br>4、简单而高效</p><h4 id="5-2-Serial-Old收集器"><a href="#5-2-Serial-Old收集器" class="headerlink" title="5.2 Serial Old收集器"></a>5.2 Serial Old收集器</h4><p>1、Serial收集器的老年代版本，它同样是一个单线程收集器，使用“标记-整理”算法。<br>2、主要意义也是在于给Client模式下的虚拟机使用。<br>3、如果在Server模式下，那么它主要还有两大用途：<br>    一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用<br>    另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。</p><h4 id="5-3ParNew收集器"><a href="#5-3ParNew收集器" class="headerlink" title="5.3ParNew收集器"></a>5.3ParNew收集器</h4><p>1、Serial收集器的多线程版本<br>2、单CPU不如Serial<br>3、Server模式下新生代首选,目前只有它能与CMS收集器配合工作<br>4、使用-XX：+UseConcMarkSweepGC选项后的默认新生代收集器，也可以使用-XX：+UseParNewGC选项来强制指定它。<br>5、-XX：ParallelGCThreads：限制垃圾收集的线程数。</p><h4 id="5-4-Parallel-Scavenge收集器"><a href="#5-4-Parallel-Scavenge收集器" class="headerlink" title="5.4 Parallel Scavenge收集器"></a>5.4 Parallel Scavenge收集器</h4><p>1、吞吐量优先”收集器<br>2、新生代收集器，复制算法，并行的多线程收集器<br>3、目标是达到一个可控制的吞吐量（Throughput）。<br>4、吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。<br>5、两个参数用于精确控制吞吐量:<br>-XX：MaxGCPauseMillis是控制最大垃圾收集停顿时间<br>-XX：GCTimeRatio直接设置吞吐量大小<br>-XX：+UseAdaptiveSizePolicy:动态设置新生代大小、Eden与Survivor区的比例、晋升老年代对象年龄<br>6、并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。<br>7、并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户<br>程序在继续运行，而垃圾收集程序运行于另一个CPU上。</p><h4 id="5-5Parallel-Old收集器"><a href="#5-5Parallel-Old收集器" class="headerlink" title="5.5Parallel Old收集器"></a>5.5Parallel Old收集器</h4><p>1、Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。<br>2、在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。</p><h4 id="5-6CMS收集器一款优秀的收集器"><a href="#5-6CMS收集器一款优秀的收集器" class="headerlink" title="5.6CMS收集器一款优秀的收集器"></a>5.6CMS收集器一款优秀的收集器</h4><p>1、以获取最短回收停顿时间为目标的收集器。<br>2、非常符合互联网站或者B/S系统的服务端上，重视服务的响应速度，希望系统停顿时间最短的应用<br>3、基于“标记—清除”算法实现的<br>4、CMS收集器的内存回收过程是与用户线程一起并发执行的<br>5、它的运作过程分为4个步骤，包括：<br>        初始标记，“Stop The World”，只是标记一下GC Roots能直接关联到的对象，速度很快<br>        并发标记，并发标记阶段就是进行GC RootsTracing的过程<br>        重新标记，Stop The World”，是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，但远比并发标记的时间短<br>        并发清除（CMS concurrent sweep）<br>6、优点：并发收集、低停顿<br>7、缺点：<br>            对CPU资源非常敏感。<br>            无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。<br>            一款基于“标记—清除”算法实现的收集器</p><h4 id="5-7G1（Garbage-First）收集器"><a href="#5-7G1（Garbage-First）收集器" class="headerlink" title="5.7G1（Garbage-First）收集器"></a>5.7G1（Garbage-First）收集器</h4><p>1、当今收集器技术发展的最前沿成果之一<br>2、G1是一款面向服务端应用的垃圾收集器。<br>3、优点：<br>        并行与并发：充分利用多CPU、多核环境下的硬件优势<br>        分代收集：不需要其他收集器配合就能独立管理整个GC堆<br>        空间整合：“标记—整理”算法实现的收集器，局部上基于“复制”算法不会产生内存空间碎片<br>        可预测的停顿：能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒<br>4、G1收集器的运作大致可划分为以下几个步骤：<br>        初始标记：标记一下GC Roots能直接关联到的对象，需要停顿线程，但耗时很短<br>        并发标记：是从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行<br>        最终标记：修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录<br>        筛选回收：对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划</p><h3 id="6-java动态代理、反射"><a href="#6-java动态代理、反射" class="headerlink" title="6.java动态代理、反射"></a>6.java动态代理、反射</h3><h4 id="6-1反射"><a href="#6-1反射" class="headerlink" title="6.1反射"></a>6.1反射</h4><p>通过反射的方式可以获取class对象中的属性、方法、构造函数等，一下是实例：</p><pre class="language-none"><code class="language-none">package cn.java.reflect;import java.lang.reflect.Constructor;import java.lang.reflect.Field;import java.lang.reflect.Method;import java.util.ArrayList;import java.util.List;import org.junit.Before;import org.junit.Test;public class MyReflect {    public String className = null;    @SuppressWarnings("rawtypes")    public Class personClass = null;    /**     * 反射Person类     * @throws Exception      */    @Before    public void init() throws Exception {        className = "cn.java.reflect.Person";        personClass = Class.forName(className);    }    /**     *获取某个class文件对象     */    @Test    public void getClassName() throws Exception {        System.out.println(personClass);    }    /**     *获取某个class文件对象的另一种方式     */    @Test    public void getClassName2() throws Exception {        System.out.println(Person.class);    }    /**     *创建一个class文件表示的真实对象，底层会调用空参数的构造方法     */    @Test    public void getNewInstance() throws Exception {        System.out.println(personClass.newInstance());    }    /**     *获取非私有的构造函数     */    @SuppressWarnings({ "rawtypes", "unchecked" })    @Test    public void getPublicConstructor() throws Exception {        Constructor  constructor  = personClass.getConstructor(Long.class,String.class);        Person person = (Person)constructor.newInstance(100L,"zhangsan");        System.out.println(person.getId());        System.out.println(person.getName());    }    /**     *获得私有的构造函数     */    @SuppressWarnings({ "rawtypes", "unchecked" })    @Test    public void getPrivateConstructor() throws Exception {        Constructor con = personClass.getDeclaredConstructor(String.class);        con.setAccessible(true);//强制取消Java的权限检测        Person person2 = (Person)con.newInstance("zhangsan");        System.out.println(person2.getName());    }    /**     *获取非私有的成员变量     */    @SuppressWarnings({ "rawtypes", "unchecked" })    @Test    public void getNotPrivateField() throws Exception {        Constructor  constructor  = personClass.getConstructor(Long.class,String.class);        Object obj = constructor.newInstance(100L,"zhangsan");        Field field = personClass.getField("name");        field.set(obj, "lisi");        System.out.println(field.get(obj));    }    /**     *获取私有的成员变量     */    @SuppressWarnings({ "rawtypes", "unchecked" })    @Test    public void getPrivateField() throws Exception {        Constructor  constructor  = personClass.getConstructor(Long.class);        Object obj = constructor.newInstance(100L);        Field field2 = personClass.getDeclaredField("id");        field2.setAccessible(true);//强制取消Java的权限检测        field2.set(obj,10000L);        System.out.println(field2.get(obj));    }    /**     *获取非私有的成员函数     */    @SuppressWarnings({ "unchecked" })    @Test    public void getNotPrivateMethod() throws Exception {        System.out.println(personClass.getMethod("toString"));        Object obj = personClass.newInstance();//获取空参的构造函数        Object object = personClass.getMethod("toString").invoke(obj);        System.out.println(object);    }    /**     *获取私有的成员函数     */    @SuppressWarnings("unchecked")    @Test    public void getPrivateMethod() throws Exception {        Object obj = personClass.newInstance();//获取空参的构造函数        Method method = personClass.getDeclaredMethod("getSomeThing");        method.setAccessible(true);        Object value = method.invoke(obj);        System.out.println(value);    }    /**     *     */    @Test    public void otherMethod() throws Exception {        //当前加载这个class文件的那个类加载器对象        System.out.println(personClass.getClassLoader());        //获取某个类实现的所有接口        Class[] interfaces = personClass.getInterfaces();        for (Class class1 : interfaces) {            System.out.println(class1);        }        //反射当前这个类的直接父类        System.out.println(personClass.getGenericSuperclass());        /**         * getResourceAsStream这个方法可以获取到一个输入流，这个输入流会关联到name所表示的那个文件上。         */        //path 不以’/'开头时默认是从此类所在的包下取资源，以’/'开头则是从ClassPath根下获取。其只是通过path构造一个绝对路径，最终还是由ClassLoader获取资源。        System.out.println(personClass.getResourceAsStream("/log4j.properties"));        //默认则是从ClassPath根下获取，path不能以’/'开头，最终是由ClassLoader获取资源。        System.out.println(personClass.getResourceAsStream("/log4j.properties"));        //判断当前的Class对象表示是否是数组        System.out.println(personClass.isArray());        System.out.println(new String[3].getClass().isArray());        //判断当前的Class对象表示是否是枚举类        System.out.println(personClass.isEnum());        System.out.println(Class.forName("cn.java.reflect.City").isEnum());        //判断当前的Class对象表示是否是接口        System.out.println(personClass.isInterface());        System.out.println(Class.forName("cn.java.reflect.TestInterface").isInterface());    }}</code></pre><h4 id="6-2动态代理"><a href="#6-2动态代理" class="headerlink" title="6.2动态代理"></a>6.2动态代理</h4><ul><li><p>在之前的代码调用阶段，我们用action调用service的方法实现业务即可。<br>  由于之前在service中实现的业务可能不能够满足当先客户的要求，需要我们重新修改service中的方法，但是service的方法不只在我们这个模块使用，在其他模块也在调用，其他模块调用的时候，现有的service方法已经能够满足业务需求，所以我们不能只为了我们的业务而修改service，导致其他模块授影响。<br>  那怎么办呢？<br>  可以通过动态代理的方式，扩展我们的service中的方法实现，使得在原油的方法中增加更多的业务，而不是实际修改service中的方法，这种实现技术就叫做动态代理。<br>  动态代理：在不修改原业务的基础上，基于原业务方法，进行重新的扩展，实现新的业务。</p></li><li><p>代理实现流程：<br>1、    书写代理类和代理方法，在代理方法中实现代理Proxy.newProxyInstance<br>2、    代理中需要的参数分别为：被代理的类的类加载器soneObjectclass.getClassLoader()，被代理类的所有实现接口new Class[] { Interface.class }，句柄方法new InvocationHandler()<br>3、    在句柄方法中复写invoke方法，invoke方法的输入有3个参数Object proxy（代理类对象）, Method method（被代理类的方法）,Object[] args（被代理类方法的传入参数），在这个方法中，我们可以定制化的开发新的业务。<br>4、    获取代理类，强转成被代理的接口<br>5、    最后，我们可以像没被代理一样，调用接口的认可方法，方法被调用后，方法名和参数列表将被传入代理类的invoke方法中，进行新业务的逻辑流程。</p><pre><code>  原业务接口IBoss</code></pre></li></ul><pre class="language-none"><code class="language-none">原业务接口IBosspublic interface IBoss {//接口    int yifu(String size);}原业务实现类public class Boss implements IBoss{    public int yifu(String size){        System.err.println("天猫小强旗舰店，老板给客户发快递----衣服型号："+size);        //这件衣服的价钱，从数据库读取        return 50;    }    public void kuzi(){        System.err.println("天猫小强旗舰店，老板给客户发快递----裤子");    }}原业务调用public class SaleAction {        @Test    public void saleByBossSelf() throws Exception {        IBoss boss = new Boss();        System.out.println("老板自营！");        int money = boss.yifu("xxl");        System.out.println("衣服成交价：" + money);    }}代理类public static IBoss getProxyBoss(final int discountCoupon) throws Exception {    Object proxedObj = Proxy.newProxyInstance(Boss.class.getClassLoader(),            new Class[] { IBoss.class }, new InvocationHandler() {                public Object invoke(Object proxy, Method method,                        Object[] args) throws Throwable {                        Integer returnValue = (Integer) method.invoke(new Boss(),                                args);// 调用原始对象以后返回的值                        return returnValue - discountCoupon;                }            });    return (IBoss)proxedObj;}}新业务调用public class ProxySaleAction {        @Test    public void saleByProxy() throws Exception {        IBoss boss = ProxyBoss.getProxyBoss(20);// 将代理的方法实例化成接口        System.out.println("代理经营！");        int money = boss.yifu("xxl");// 调用接口的方法，实际上调用方式没有变        System.out.println("衣服成交价：" + money);    }}</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zookeeper学习</title>
      <link href="/2018/04/26/zookeeper-xue-xi/"/>
      <url>/2018/04/26/zookeeper-xue-xi/</url>
      
        <content type="html"><![CDATA[<h4 id="1、Zookeeper概念简介"><a href="#1、Zookeeper概念简介" class="headerlink" title="1、Zookeeper概念简介"></a>1、Zookeeper概念简介</h4><p>Zookeeper是一个分布式协调服务；就是为用户的分布式应用程序提供协调服务</p><ul><li><p>A、zookeeper是为别的分布式程序服务的</p></li><li><p>B、Zookeeper本身就是一个分布式程序（只要有半数以上节点存活，zk就能正常服务）</p></li><li><p>C、Zookeeper所提供的服务涵盖：主从协调、服务器节点动态上下线、统一配置管理、分布式共享锁、统一名称服务……</p></li><li><p>D、虽然说可以提供各种服务，但是zookeeper在底层其实只提供了两个功能：</p><pre><code>  1.管理(存储，读取)用户程序提交的数据；  2.并为用户程序提供数据节点监听服务；</code></pre></li></ul><h4 id="2、Zookeeper常用应用场景："><a href="#2、Zookeeper常用应用场景：" class="headerlink" title="2、Zookeeper常用应用场景："></a>2、Zookeeper常用应用场景：</h4><ul><li>服务器状态的动态感知</li><li>配置文件的管理</li><li>分布式共享锁</li></ul><p>Zookeeper集群的角色：  Leader 和  follower  （Observer）<br>只要集群中有半数以上节点存活，集群就能提供服务</p><h4 id="3、zookeeper集群机制"><a href="#3、zookeeper集群机制" class="headerlink" title="3、zookeeper集群机制"></a>3、zookeeper集群机制</h4><p>半数机制：集群中半数以上机器存活，集群可用。<br>zookeeper适合装在奇数台机器上！！！<br>投票选举leader 使用了算法PAXOS  简化后的算法Zab</p><h4 id="4、zookeeper集群的安装请参考我的另一片文章"><a href="#4、zookeeper集群的安装请参考我的另一片文章" class="headerlink" title="4、zookeeper集群的安装请参考我的另一片文章"></a>4、zookeeper集群的安装请参考我的另一片文章</h4><h3 id="5、zookeeper结构和命令"><a href="#5、zookeeper结构和命令" class="headerlink" title="5、zookeeper结构和命令"></a>5、zookeeper结构和命令</h3><h4 id="5-1-zookeeper特性"><a href="#5-1-zookeeper特性" class="headerlink" title="5.1 zookeeper特性"></a>5.1 zookeeper特性</h4><pre class="language-none"><code class="language-none">1、Zookeeper：一个leader，多个follower组成的集群2、全局数据一致：每个server保存一份相同的数据副本，client无论连接到哪个server，数据都是一致的3、分布式读写，更新请求转发，由leader实施4、更新请求顺序进行，来自同一个client的更新请求按其发送顺序依次执行5、数据更新原子性，一次数据更新要么成功，要么失败6、实时性，在一定时间范围内，client能读到最新数据</code></pre><h4 id="５-2-zookeeper数据结构"><a href="#５-2-zookeeper数据结构" class="headerlink" title="５.2 zookeeper数据结构"></a>５.2 zookeeper数据结构</h4><pre class="language-none"><code class="language-none">1、层次化的目录结构，命名符合常规文件系统规范(见下图)2、每个节点在zookeeper中叫做znode,并且其有一个唯一的路径标识3、节点Znode可以包含数据和子节点（但是EPHEMERAL类型的节点不能有子节点，下一页详细讲解）4、客户端应用可以在节点上设置监视器（后续详细讲解）</code></pre><h4 id="5-3-zookeeper节点类型"><a href="#5-3-zookeeper节点类型" class="headerlink" title="5.3 zookeeper节点类型"></a>5.3 zookeeper节点类型</h4><pre class="language-none"><code class="language-none">1、Znode有两种类型：    短暂（ephemeral）（断开连接自己删除）    持久（persistent）（断开连接不删除）2、Znode有四种形式的目录节点（默认是persistent ）    PERSISTENT    PERSISTENT_SEQUENTIAL（持久序列/test0000000019 ）    EPHEMERAL    EPHEMERAL_SEQUENTIAL （短暂带序号的）3、创建znode时设置顺序标识，znode名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护4、在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序</code></pre><h4 id="5-4-zookeeper命令行操作"><a href="#5-4-zookeeper命令行操作" class="headerlink" title="5.4 zookeeper命令行操作"></a>5.4 zookeeper命令行操作</h4><p>运行 zkCli.sh  -server  ip:port 进入命令行工具</p><p>1、使用 ls 命令来查看当前 ZooKeeper 中所包含的内容：<br>[zk: 202.115.36.251:2181(CONNECTED) 1] ls  /</p><p>2、创建一个新的 znode ，使用 create /zk myData 。这个命令创建了一个新的 znode 节点“ zk ”以及与它关联的字符串：<br>[zk: 202.115.36.251:2181(CONNECTED) 2] create  /zk  “myData</p><p>3、我们运行 get 命令来确认 znode 是否包含我们所创建的字符串：<br>[zk: 202.115.36.251:2181(CONNECTED) 3] get  /zk<br>监听这个节点的变化,当另外一个客户端改变/zk时,它会打出下面的<br>WATCHER::<br>WatchedEvent state:SyncConnected type:NodeDataChanged path:/zk<br>[zk: localhost:2181(CONNECTED) 4] get  /zk  watch</p><p>4、下面我们通过 set 命令来对 zk 所关联的字符串进行设置：<br>[zk: 202.115.36.251:2181(CONNECTED) 4] set  /zk  “zsl“</p><p>5、下面我们将刚才创建的 znode 删除：<br>[zk: 202.115.36.251:2181(CONNECTED) 5] delete  /zk</p><p>6、删除节点：rmr<br>[zk: 202.115.36.251:2181(CONNECTED) 5] rmr  /zk</p><h4 id="5-5-zookeeper-java-api应用"><a href="#5-5-zookeeper-java-api应用" class="headerlink" title="5.5 zookeeper  java  api应用"></a>5.5 zookeeper  java  api应用</h4><h5 id="5-5-1-基本使用"><a href="#5-5-1-基本使用" class="headerlink" title="5.5.1 基本使用"></a>5.5.1 基本使用</h5><p>org.apache.zookeeper.Zookeeper是客户端入口主类，负责建立与server的会话<br>它提供了表 1 所示几类主要方法  ：</p><pre class="language-none"><code class="language-none">create        在本地目录树中创建一个节点delete        删除一个节点exists        测试本地是否存在目标节点get/set data        从目标节点上读取 / 写数据get/set ACL        获取 / 设置目标节点访问控制列表信息get children        检索一个子节点上的列表sync        等待要被传送的数据</code></pre><h5 id="5-5-2-demo增删改查"><a href="#5-5-2-demo增删改查" class="headerlink" title="5.5.2 demo增删改查"></a>5.5.2 demo增删改查</h5><pre class="language-none"><code class="language-none">我创建的是maven工程pom依赖为：    &lt;dependency&gt;            &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt;            &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;            &lt;version&gt;3.3.6&lt;/version&gt;        &lt;/dependency&gt;package com.bigdata.day03.zookeeper;import org.apache.zookeeper.*;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.util.List;public class zookeeperClient {    private static final String connectString = "114.55.253.31:2181";    private static final int sessionTimeout = 2000;    public ZooKeeper zkClient;    @Before    public void init() throws IOException {        zkClient = new ZooKeeper(connectString, sessionTimeout, new Watcher() {            @Override            public void process(WatchedEvent watchedEvent) {                //收到事件通知后的回调函数                System.out.println(watchedEvent.getType() + "--"+ watchedEvent.getPath());                try {                    zkClient.getChildren("/", true);                } catch (Exception e) {                    e.printStackTrace();                }            }        });        //拿到zooKeeperClient就可以做数据的crud    }    //增加节点    @Test    public void createZonde() throws KeeperException, InterruptedException {        String createZnode = zkClient.create("/zk",                "hello zk".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);        System.out.println(createZnode);    }    //获取子节点    @Test    public void getZonde() throws KeeperException, InterruptedException {        List&lt;String&gt; children = zkClient.getChildren("/", true);        for (String zonde: children){            System.out.println(zonde);        }        //这是测试用 阻塞程序 可以监听zk的节点的数据变化        Thread.sleep(Long.MAX_VALUE);    }    //判断znode是否存在    @Test    public void isZonde() throws KeeperException, InterruptedException {        Stat exists = zkClient.exists("/zk", false);        System.out.println(exists == null ? "not exists": "exists");    }    //获取znode的数据        @Test        public void getZondeData() throws KeeperException, InterruptedException {        byte[] data = zkClient.getData("/zk", false, new Stat());        System.out.println(new String(data));        }        //删除znode的数据    @Test    public void deleteZonde() throws KeeperException, InterruptedException {        //-1表示删除所有版本        zkClient.delete("/zk", -1);    }    //修改znode的数据    @Test    public void updateZonde() throws KeeperException, InterruptedException {        Stat stat = zkClient.setData("/zk", "hello znode".getBytes(), -1);        System.out.println(stat.getDataLength());        byte[] data = zkClient.getData("/zk", false, null);        System.out.println(new String(data));    }}</code></pre><h3 id="6-zookeeper应用案例"><a href="#6-zookeeper应用案例" class="headerlink" title="6. zookeeper应用案例"></a>6. zookeeper应用案例</h3><h4 id="6-1-实现分布式应用的-主节点HA-及客户端动态更新主节点状态"><a href="#6-1-实现分布式应用的-主节点HA-及客户端动态更新主节点状态" class="headerlink" title="6.1 实现分布式应用的(主节点HA)及客户端动态更新主节点状态"></a>6.1 实现分布式应用的(主节点HA)及客户端动态更新主节点状态</h4><p>某分布式系统中，主节点可以有多台，可以动态上下线<br>任意一台客户端都能实时感知到主节点服务器的上下线</p><p>A、服务端实现</p><pre class="language-none"><code class="language-none">package com.bigdata.day03.app;import org.apache.zookeeper.*;import java.io.IOException;import static org.apache.zookeeper.CreateMode.EPHEMERAL_SEQUENTIAL;public class DistubutServer {    private static final String groupNode = "/servers";    private static final String connectString = "114.55.253.31:2181";    private static final int sessionTimeout = 2000;    public ZooKeeper zkClient;    public  void conect() throws IOException {        zkClient = new ZooKeeper(connectString, sessionTimeout, new Watcher() {            @Override            public void process(WatchedEvent watchedEvent) {                //收到事件通知后的回调函数                System.out.println(watchedEvent.getType() + "--"+ watchedEvent.getPath());                try {                    zkClient.getChildren("/", true);                } catch (Exception e) {                    e.printStackTrace();                }            }        });    }    public void resgisterServer(String hostname) throws KeeperException, InterruptedException {        String create = zkClient.create(groupNode + "server", hostname.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, EPHEMERAL_SEQUENTIAL);        System.out.println(hostname + "is on line"+ create);    }    public void handlerBussiness() throws InterruptedException {        System.out.println("say hello");        Thread.sleep(Long.MAX_VALUE);    }    public static void main(String[] args) throws IOException, KeeperException, InterruptedException {        //获取zk连接        DistubutServer distubutServer = new DistubutServer();        distubutServer.conect();        //使用zk连接注册服务器        distubutServer.resgisterServer(args[0]);        //启动业务功能        distubutServer.handlerBussiness();    }}</code></pre><p>B、客服端实现</p><pre class="language-none"><code class="language-none">package com.bigdata.day03.app;import org.apache.zookeeper.KeeperException;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooKeeper;import org.apache.zookeeper.data.Stat;import java.io.IOException;import java.util.ArrayList;import java.util.List;public class DistubutClient {    private static final String groupNode = "/servers";    private static final String connectString = "114.55.253.31:2181";    private static final int sessionTimeout = 2000;    private volatile ArrayList&lt;String&gt; serverList;    public ZooKeeper zkClient;    public  void conect() throws IOException {        zkClient = new ZooKeeper(connectString, sessionTimeout, new Watcher() {            @Override            public void process(WatchedEvent watchedEvent) {                //收到事件通知后的回调函数                try {                    getServerList();                } catch (Exception e) {                    e.printStackTrace();                }            }        });    }    public void getServerList() throws KeeperException, InterruptedException {        List&lt;String&gt; children = zkClient.getChildren(groupNode, true);  //监听父节点        ArrayList&lt;String&gt; servers = new ArrayList&lt;String&gt;();        for (String child: children){            byte[] data = zkClient.getData(groupNode + "/" + child, false, new Stat());            servers.add(new String(data));        }        serverList = servers;    }    public void handlerBussiness() throws InterruptedException {        System.out.println("start working............");        Thread.sleep(Long.MAX_VALUE);    }    public static void main(String[] args) throws IOException, KeeperException, InterruptedException {        //获取zk连接        DistubutClient distubutClient = new DistubutClient();        distubutClient.conect();        //获取servers的子节点信息，获取服务器信息列表        distubutClient.getServerList();        //业务线程启动        distubutClient.handlerBussiness();    }}</code></pre><h4 id="6-2-分布式共享锁的简单实现"><a href="#6-2-分布式共享锁的简单实现" class="headerlink" title="6.2 分布式共享锁的简单实现"></a>6.2 分布式共享锁的简单实现</h4><pre class="language-none"><code class="language-none">public class DistributedClientLock {    // 超时时间    private static final int SESSION_TIMEOUT = 5000;    // zookeeper server列表    private String hosts = "114.55.253.31:2181";    private String groupNode = "locks";    private String subNode = "sub";    private ZooKeeper zk;    // 当前client创建的子节点    private String thisPath;    // 当前client等待的子节点    private String waitPath;    private CountDownLatch latch = new CountDownLatch(1);    /**     * 连接zookeeper     */    public void connectZookeeper() throws Exception {        zk = new ZooKeeper(hosts, SESSION_TIMEOUT, new Watcher() {            public void process(WatchedEvent event) {                try {                    // 连接建立时, 打开latch, 唤醒wait在该latch上的线程                    if (event.getState() == KeeperState.SyncConnected) {                        latch.countDown();                    }                    // 发生了waitPath的删除事件                    if (event.getType() == EventType.NodeDeleted &amp;&amp; event.getPath().equals(waitPath)) {                        doSomething();                    }                } catch (Exception e) {                    e.printStackTrace();                }            }        });        // 等待连接建立        latch.await();        // 创建子节点        thisPath = zk.create("/" + groupNode + "/" + subNode, null, Ids.OPEN_ACL_UNSAFE,                CreateMode.EPHEMERAL_SEQUENTIAL);        // wait一小会, 让结果更清晰一些        Thread.sleep(10);        // 注意, 没有必要监听"/locks"的子节点的变化情况        List&lt;String&gt; childrenNodes = zk.getChildren("/" + groupNode, false);        // 列表中只有一个子节点, 那肯定就是thisPath, 说明client获得锁        if (childrenNodes.size() == 1) {            doSomething();        } else {            String thisNode = thisPath.substring(("/" + groupNode + "/").length());            // 排序            Collections.sort(childrenNodes);            int index = childrenNodes.indexOf(thisNode);            if (index == -1) {                // never happened            } else if (index == 0) {                // inddx == 0, 说明thisNode在列表中最小, 当前client获得锁                doSomething();            } else {                // 获得排名比thisPath前1位的节点                this.waitPath = "/" + groupNode + "/" + childrenNodes.get(index - 1);                // 在waitPath上注册监听器, 当waitPath被删除时, zookeeper会回调监听器的process方法                zk.getData(waitPath, true, new Stat());            }        }    }    private void doSomething() throws Exception {        try {            System.out.println("gain lock: " + thisPath);            Thread.sleep(2000);            // do something        } finally {            System.out.println("finished: " + thisPath);            // 将thisPath删除, 监听thisPath的client将获得通知            // 相当于释放锁            zk.delete(this.thisPath, -1);        }    }    public static void main(String[] args) throws Exception {        for (int i = 0; i &lt; 10; i++) {            new Thread() {                public void run() {                    try {                        DistributedClient dl = new DistributedClient();                        dl.connectZookeeper();                    } catch (Exception e) {                        e.printStackTrace();                    }                }            }.start();        }        Thread.sleep(Long.MAX_VALUE);    }}</code></pre><h3 id="7-zookeeper原理"><a href="#7-zookeeper原理" class="headerlink" title="7.zookeeper原理"></a>7.zookeeper原理</h3><p>Zookeeper虽然在配置文件中并没有指定master和slave<br>但是，zookeeper工作时，是有一个节点为leader，其他则为follower<br>Leader是通过内部的选举机制临时产生的</p><h4 id="7-1-zookeeper的选举机制（全新集群paxos）"><a href="#7-1-zookeeper的选举机制（全新集群paxos）" class="headerlink" title="7.1 zookeeper的选举机制（全新集群paxos）"></a>7.1 zookeeper的选举机制（全新集群paxos）</h4><p>以一个简单的例子来说明整个选举的过程.<br>假设有五台服务器组成的zookeeper集群,它们的id从1-5,同时它们都是最新启动的,也就是没有历史数据,在存放数据量这一点上,都是一样的.假设这些服务器依序启动,来看看会发生什么.</p><pre class="language-none"><code class="language-none">1) 服务器1启动,此时只有它一台服务器启动了,它发出去的报没有任何响应,所以它的选举状态一直是LOOKING状态2) 服务器2启动,它与最开始启动的服务器1进行通信,互相交换自己的选举结果,由于两者都没有历史数据,所以id值较大的服务器2胜出,但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是3),所以服务器1,2还是继续保持LOOKING状态.3) 服务器3启动,根据前面的理论分析,服务器3成为服务器1,2,3中的老大,而与上面不同的是,此时有三台服务器选举了它,所以它成为了这次选举的leader.4) 服务器4启动,根据前面的分析,理论上服务器4应该是服务器1,2,3,4中最大的,但是由于前面已经有半数以上的服务器选举了服务器3,所以它只能接收当小弟的命了.5) 服务器5启动,同4一样,当小弟.</code></pre><h4 id="7-2非全新集群的选举机制-数据恢复"><a href="#7-2非全新集群的选举机制-数据恢复" class="headerlink" title="7.2非全新集群的选举机制(数据恢复)"></a>7.2非全新集群的选举机制(数据恢复)</h4><pre class="language-none"><code class="language-none">那么，初始化的时候，是按照上述的说明进行选举的，但是当zookeeper运行了一段时间之后，有机器down掉，重新选举时，选举过程就相对复杂了。需要加入数据id、leader id和逻辑时钟。数据id：数据新的id就大，数据每次更新都会更新id。Leader id：就是我们配置的myid中的值，每个机器一个。逻辑时钟：这个值从0开始递增,每次选举对应一个值,也就是说:  如果在同一次选举中,那么这个值应该是一致的 ;  逻辑时钟值越大,说明这一次选举leader的进程更新.选举的标准就变成：        1、逻辑时钟小的选举结果被忽略，重新投票        2、统一逻辑时钟后，数据id大的胜出        3、数据id相同的情况下，leader id大的胜出根据这个规则选出leader。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> zookeeper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> 大数据学习 </tag>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据学习软件的安装</title>
      <link href="/2018/04/25/da-shu-ju-xue-xi-ruan-jian-de-an-zhuang/"/>
      <url>/2018/04/25/da-shu-ju-xue-xi-ruan-jian-de-an-zhuang/</url>
      
        <content type="html"><![CDATA[<h3 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h3><p>先说一下我的配置 ：我是在virturbox上进行安装的、只用了3台centos7 mini版本的虚拟机进行搭建的。操作系统的光盘在网上下吧。</p><pre><code>这是我hostname以及IP，我的每台虚拟机使用了2个网络、分别是NAT和host-only网络、NAT主要是和外网相连、要下载一些辅助软件、host-only网络主要是在hadoop集群之间进行通信使用！具体怎么设置网络、百度吧！这些都是基础技能、我也不想写！当然了在安装操作系统是3台虚拟机的时区都选择上海、这也是为避免以后的不必要的麻烦1     hadoop-master    192.168.56.101 2    hadoop-node1     192.168.56.1023    hadoop-node2     192.168.56.103</code></pre><h3 id="2、配置服务器-以下3个动作需要在3个虚拟机上都要修改"><a href="#2、配置服务器-以下3个动作需要在3个虚拟机上都要修改" class="headerlink" title="2、配置服务器 (以下3个动作需要在3个虚拟机上都要修改)"></a>2、配置服务器 (以下3个动作需要在3个虚拟机上都要修改)</h3><h4 id="2-1"><a href="#2-1" class="headerlink" title="2.1"></a>2.1</h4><pre class="language-none"><code class="language-none">关闭防火墙：    centos7：//临时关闭            service iptables stop            //禁止开机启动            chkconfig iptables off    ubuntu16.04:            //临时关闭            sudo ufw disable</code></pre><h4 id="2-2-设置主机名称"><a href="#2-2-设置主机名称" class="headerlink" title="2.2 设置主机名称"></a>2.2 设置主机名称</h4><pre class="language-none"><code class="language-none">查看现在的主机名称$ hostname  abls234243 永久修改主机名称vim /etc/sysconfig/networkHOSTNAME=hadoop-master# ip 与 hostname 绑定vim /etc/hosts192.168.56.101  hadoop-master</code></pre><h4 id="2-3-免密码登录"><a href="#2-3-免密码登录" class="headerlink" title="2.3 免密码登录"></a>2.3 免密码登录</h4><pre class="language-none"><code class="language-none">在每台虚拟机上创建hadoop用户：useradd hadoop设置密码：passwd hadoop切换到root用户vi /etc/sudoers在其中添加  hadoop    ALL=(ALL)     ALLHadoop用户就有了root权限 也就可以使用sudo命令了切换到hadoop用户、在家目录下、以下操作都子家目录下进行# 设置 ssh 免密码登录（在三个节点分别执行以下命令）ssh-keygen -t rsa# ~/.ssh/id_rsa.pub就是生成的公钥，把三个id_rsa.pub的内容合并，写入以下文件cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys# 3台虚拟机互相复制到其他节点scp ~/.ssh/authorized_keys zkpk@hss01:~/.ssh/scp ~/.ssh/authorized_keys zkpk@hss02:~/.ssh/# CentOS7中还需要设置权限chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys#修改/etc/hosts文件vi  /etc/hosts添加如下： 每台都要添加    192.168.56.101    hadoop-master    192.168.56.102    hadoop-node1    192.168.56.103    hadoop-node2# 每台都要安装sshsudo yum install openssh-server# 3台虚拟机之间分别用ssh命令试一试能不能连接ssh  hadoop-masterssh  hadoop-node1ssh  hadoop-node2第一次可能需要填写密码、后面ssh连接就不会再要密码了如果都能连接那都没问题了 服务器的配置完成！ ok#如果没连接成功 后面的就不要做了</code></pre><h4 id="3、Java环境安装"><a href="#3、Java环境安装" class="headerlink" title="3、Java环境安装"></a>3、Java环境安装</h4><pre class="language-none"><code class="language-none">#  3台虚拟机都都要安装    我的所有安装包都是放在家目录下的、好管理    jdk版本：jdk-8u144-linux-x64.tar.gz 自行下载    tar zxvf jdk-8u144-linux-x64.tar.gz    cd  jdk1.8.0_144     ls    配置jdk环境变量    sudo vim /etc/profile    在最后面添加        export JAVA_HOME="/home/hadoop/jdk1.8.0_144"        export PATH=$JAVA_HOME/bin:$PATH    source /etc/profile    测试是否成功    输入java     javac等命令  如果什么都没有那就报错了    以下的操作不要做了</code></pre><h4 id="4、zookeeper集群安装"><a href="#4、zookeeper集群安装" class="headerlink" title="4、zookeeper集群安装"></a>4、zookeeper集群安装</h4><pre class="language-none"><code class="language-none">1、    我使用的版本是：zookeeper-3.4.10.tar.gz    tar zxvf zookeeper-3.4.10.tar.gz    cd zookeeper-3.4.10/conf    cp zoo_sample.cfg zoo.cfg2、    vim zoo.cfg     添加如下：                 dataDir=/home/hadoop/zookeeper-3.4.10/data                dataLogDir=/home/hadoop/zookeeper-3.4.10/logs                server.1=hadoop-master:2888:3888                server.2=hadoop-node1:2888:3888                server.3=hadoop-node2:2888:38883、    zookeeper根目录执行， 也就是/home/hadoop/zookeeper-3.4.10下    mkdir data    mkdir logs    # 在dataDir目录下创建myid文件写入1    vim data/myid4、     复制ZooKeeper到其他节点        scp -r zookeeper-3.4.10  hadoop@hadoop-node1:~/        scp -r zookeeper-3.4.10  hadoop@hadoop-node2:~/        # 将hadoop-node1中的myid改为2，hadoop-node2中的myid改为3        vim  ~/zookeeper-3.4.10/data/myid5、    配置环境变量、3台虚拟机都要执行    sudo vim /etc/profile    在最后面添加        export ZOOKEEPER_HOME="/home/hadoop/zookeeper-3.4.10"        export PATH=$ZOOKEEPER_HOME/bin:$PATH    source /etc/profile    测试        zkServer.sh  zkCli.sh等命令就有了6、     开启zookeeper集群：        在每台虚拟机上执行命令：zkServer.sh start        执行完了以后查看状态：zkServer.sh status        显示为：        ZooKeeper JMX enabled by default        Using config: /home/hadoop/zookeeper-3.4.10/bin/../conf/zoo.cfg        Mode: follower        集群启动成功！        也可以用jps命令查看        也可以用zkClis.sh  默认连接本机的zk  他是zk集群的客户段        出现这种提示：[zk: localhost:2181(CONNECTED) 0]        也说明集群启动成功          输入zk命令   ls  /        退出客户端用 quit        如果失败或者报异常：        查看日志在/home/hadoop/zookeeper-3.4.10/logs目录下        失败了找百度吧！ 你会发生什么问题我也不清楚7、     关闭集群        在每台虚拟机上执行 zkServer.sh stop    如果没成功、后面的先不要做了</code></pre><h4 id="5、hadoop的HA集群安装"><a href="#5、hadoop的HA集群安装" class="headerlink" title="5、hadoop的HA集群安装"></a>5、hadoop的HA集群安装</h4><pre class="language-none"><code class="language-none">hadoop集群有2中模式：    1：普通的集群模式    2：基于zookeeper的HA高可靠性的模式这里我直接使用第2中模式搭建Hadoop集群、至于第一种很简单、百度上有很多资料可以查看1、    上传tar包、我使用的是hadoop-2.7.5.tar.gz    tar -xf hadoop-2.7.5.tar.gz    cd hadoop-2.7.5    # namenode信息存放目录    mkdir name    # datanode信息存放目录    mkdir data    cd etc/hadoop    vim core-site.xml    &lt;configuration&gt;                &lt;!-- 指定hdfs的nameservice为ns1 --&gt;                &lt;property&gt;                    &lt;name&gt;fs.defaultFS&lt;/name&gt;                    &lt;value&gt;hdfs://ns1/&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定hadoop临时目录 --&gt;                &lt;property&gt;                    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;                    &lt;value&gt;/home/hadoop/hadoop-2.7.5/tmp&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定zookeeper地址 --&gt;                &lt;property&gt;                    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;                    &lt;value&gt;hadoop-master:2181,hadoop-node1:2181,hadoop-node2:2181&lt;/value&gt;                &lt;/property&gt;        &lt;property&gt;           &lt;name&gt;ipc.client.connect.max.retries&lt;/name&gt;            &lt;value&gt;30&lt;/value&gt;          &lt;/property&gt;        &lt;property&gt;           &lt;name&gt;ipc.client.connect.retry.interval&lt;/name&gt;            &lt;value&gt;5000&lt;/value&gt;          &lt;/property&gt;       &lt;/configuration&gt;       注：不要忘了创建tmp目录        vim hdfs-site.xml       &lt;configuration&gt;        &lt;property&gt;            &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;            &lt;value&gt;/home/hadoop/data/name&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;            &lt;value&gt;/home/hadoop/data/data&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;name&gt;dfs.replication&lt;/name&gt;            &lt;value&gt;3&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;name&gt;dfs.secondary.http.address&lt;/name&gt;            &lt;value&gt;hadoop-node1:50090&lt;/value&gt;        &lt;/property&gt;        &lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.nameservices&lt;/name&gt;                    &lt;value&gt;ns1&lt;/value&gt;               &lt;/property&gt;               &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;                    &lt;value&gt;nn1,nn2&lt;/value&gt;                &lt;/property&gt;        &lt;!-- nn1的RPC通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;                    &lt;value&gt;hadoop-master:9000&lt;/value&gt;                &lt;/propert                &lt;!-- nn1的http通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;                    &lt;value&gt;hadoop-master:50070&lt;/value&gt;                &lt;/property&gt;                &lt;!-- nn2的RPC通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;                    &lt;value&gt;hadoop-node1:9000&lt;/value&gt;                &lt;/property&gt;        &lt;!-- nn2的http通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;                    &lt;value&gt;hadoop-node1:50070&lt;/value&gt;                &lt;/property&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;                    &lt;value&gt;qjournal://hadoop-master:8485;hadoop-node1:8485;hadoop-node2:8485/ns1&lt;/value&gt;                &lt;/property&gt;                &lt;property&gt;                &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;                &lt;value&gt;/home/hadoop/hadoop-2.7.5/journaldata&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 开启NameNode失败自动切换 --&gt;        &lt;property&gt;            &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;            &lt;value&gt;true&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 配置失败自动切换实现方式 --&gt;        &lt;property&gt;            &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;        &lt;property&gt;            &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;            &lt;value&gt;                sshfence                shell(/bin/true)            &lt;/value&gt;        &lt;/property&gt;        &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;        &lt;property&gt;            &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;            &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 配置sshfence隔离机制超时时间 --&gt;        &lt;property&gt;            &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;            &lt;value&gt;30000&lt;/value&gt;        &lt;/property&gt;    vim  mapred-site.xml    &lt;configuration&gt;        &lt;property&gt;            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;            &lt;value&gt;yarn&lt;/value&gt;        &lt;/property&gt;    &lt;/configuration&gt;    vim yarn-site.xml    &lt;configuration&gt;        &lt;property&gt;            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 开启RM高可用 --&gt;        &lt;property&gt;            &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;            &lt;value&gt;true&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 指定RM的cluster id   我这里随便叫一个  yrc--&gt;        &lt;property&gt;            &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;            &lt;value&gt;yrc&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 指定RM的名字 --&gt;        &lt;property&gt;            &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;            &lt;value&gt;hadoop-node1,hadoop-master&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 分别指定RM的地址 --&gt;        &lt;property&gt;            &lt;name&gt;yarn.resourcemanager.hostname.hadoop-node1&lt;/name&gt;            &lt;value&gt;hadoop-node1&lt;/value&gt;        &lt;/property&gt;        &lt;property&gt;            &lt;name&gt;yarn.resourcemanager.hostname.hadoop-master&lt;/name&gt;            &lt;value&gt;hadoop-master&lt;/value&gt;        &lt;/property&gt;        &lt;!-- 指定zk集群地址 --&gt;        &lt;property&gt;            &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;            &lt;value&gt;hadoop-master:2181,hadoop-node1:2181,hadoop-node2:2181&lt;/value&gt;        &lt;/property&gt;    &lt;/configuration&gt;    vi hadoop-env.sh    修改export JAVA_HOME=/home/hadoop/jdk1.8.0_144    vim slaves    添加：            hadoop-master            hadoop-node1            hadoop-node2    复制到其他节点：        scp -r ~/hadoop-2.7.5 hadoop@hadoop-node1:~/        scp -r ~/hadoop-2.7.5 hadoop@hadoop-node2:~/    同样在每台机器上设置hadoop的环境变量：    sudo vi /etc/profile    添加：        export HADOOP_HOME="/home/hadoop/hadoop-2.7.5"        export PATH=$HADOOP_HOME/bin:$PATH        export PATH=$HADOOP_HOME/sbin:$PATH    source /etc/profile    在命令行确认是否配置成功:  输入start-hdfs.sh  看是否有这个命令  这个时候不要回车执行    ***** 启动集群 严格按照下面的步骤    在家目录下执行命令    1、启动zookeeper集群， 分别在3台机器上执行        zkServer.sh start        # 查看状态：一个leader，两个follower        zkServer.sh status    2、同样在3台机器上执行：        hadoop-daemon.sh start journalnode    3、以下命令只在hadoop-master机器上执行        hdfs namenode -format    4、执行复制命令        scp -r hadoop-2.7.5/tmp/ hadoop@hadoop-node1:/home/hadoop/hadoop-2.7.5        scp -r hadoop-2.7.5/tmp/ hadoop@hadoop-node2:/home/hadoop/hadoop-2.7.5    5、hdfs zkfc -formatZK     6、start-dfs.sh    7、start-yarn.sh    验证是否成功：        # 通过以下IP用浏览器访问，一个处于active,一个处于standby，说明集群启动成功。            http://192.168.56.101:50070            NameNode 'hadoop-master:9000' (active)            http://192.168.56.101:50070            NameNode 'hadoop-node1:9000' (standby)        # 验证HDFS HA（向hdfs上传一个文件）            hadoop fs -put /etc/profile /profile            hadoop fs -ls /        #kill掉active的NameNode            kill -9 &lt;pid of NN&gt;            访问：http://192.168.56.101:50070 无法打开            访问:http://192.168.56.102:50070            NameNode 'hadoop-node1:9000' (active)            执行： hadoop fs -ls /    也可以看到有profile文件        #手动启动挂掉的那个NameNode，在hadoop-master上执行            hadoop-daemon.sh start namenode            访问：http://192.168.56.101:50070            显示：NameNode 'hadoop-master:9000' (standby)        # 验证Yarn HA            http://192.168.56.101:8088/            正常显示内容。        至此hadoop的ha集群模式搭建完毕！        在hadoop-master上执行jps命令：  会有如下进程            1841 DFSZKFailoverController            1222 QuorumPeerMain            2008 ResourceManager            1497 DataNode            1387 NameNode            2124 NodeManager            8429 Jps            1695 JournalNode        在hadoop-node1上执行jps命令：            3905 Jps            1763 DataNode            2117 NodeManager            1882 JournalNode            1533 QuorumPeerMain            1982 DFSZKFailoverController        在hadoop-node2上执行jps命令：            1376 JournalNode            1220 QuorumPeerMain            1476 NodeManager            4648 Jps            1278 DataNode        如果在启动的过程中，出现问题，可以查看日志文件：        /home/hadoop/hadoop-2.7.5/logs  有些复杂！         集群的启动和关闭：            # 启动                zkServer.sh start  此命令在每台机器上都要执行，下面2个在hadoop-master机器上执行                start-dfs.sh                start-yarn.sh            # 关闭                stop-yarn.sh                stop-dfs.sh                zkServer.sh stop  此命令在每台机器上都要执行</code></pre><h4 id="6、HIVE安装"><a href="#6、HIVE安装" class="headerlink" title="6、HIVE安装"></a>6、HIVE安装</h4><pre class="language-none"><code class="language-none">    hive只安装在hadoop-master节点上就可以了    1、 先安装MySQL5.7    sudo yum remove mysql    wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm    sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm    sudo yum install mysql-server    sudo chown -R hadoop:hadoop /var/lib/mysql    mysql -u root    第一次不用密码    use mysql;    开启远程访问权限：grant all privileges  on *.* to root@'%' identified by "root";    FLUSH PRIVILEGES ;    create database hivedb;    exit;    上传hive的tar包：    tar -xf apache-hive-1.2.2-bin.tar.gz    cd    hive-1.2.2/conf    mv hive-env.sh.template hive-env.sh    vim hive-env.sh    添加下面3条数据：        export HADOOP_HOME=/home/hadoop/hadoop-2.7.5        export HIVE_CONF_DIR=home/hadoop/hive-1.2.2/conf        export JAVA_HOME=/home/hadoop/jdk1.8.0_144    mv hive-log4j.properties.template hive-log4j.properties    vim  hive-log4j.properties    hive.log.dir=/home/zkpk/hive-1.2.2/logs    # 创建日志目录    mkdir /home/zkpk/hive-1.2.2/logs    vim hive-site.xml    删除所有内容，添加如下内容：    &lt;configuration&gt;      &lt;property&gt;        &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;        &lt;value&gt;hdfs://ns1/hive/warehouse&lt;/value&gt;      &lt;/property&gt;      &lt;property&gt;        &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;        &lt;value&gt;hdfs://ns1/hive/scratchdir&lt;/value&gt;      &lt;/property&gt;      &lt;property&gt;        &lt;name&gt;hive.querylog.location&lt;/name&gt;        &lt;value&gt;/home/hadoop/hive-1.2.2/logs&lt;/value&gt;      &lt;/property&gt;      &lt;property&gt;        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;        &lt;value&gt;jdbc:mysql://192.168.56.101:3306/hivedb?createDatabaseIfNotExist=true&lt;/value&gt;      &lt;/property&gt;      &lt;property&gt;        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;      &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;        &lt;value&gt;root&lt;/value&gt;      &lt;/property&gt;      &lt;property&gt;        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;        &lt;value&gt;root&lt;/value&gt;      &lt;/property&gt;    &lt;/configuration&gt;    设置环境变量：    vim /etc/profile    export HIVE_HOME=/home/hadoop/hive-1.2.2    export PATH=$PATH:$HIVE_HOME/bin    source /etc/profile    在hive-1.2.2/lib下有个jline的jar，将hadoop原来的那个jar包换成一致的，否则会启动hive会报错。    cp hive-1.2.1/lib/jline-2.12.jar   /home/hadoop/hadoop-2.7.5/share/hadoop/yarn/lib将mysql-connector-java-5.1.46.jar连接jar拷贝到hive-1.2.1/lib目录下    cp mysql-connector-java-5.1.46.jar  ~/hive-1.2.2/lib/    # 运行下面命令    启动HIVE命令：hive    http://192.168.56.101:50070，查看是否多了hive目录。    退出hive的客户端接口：  quit</code></pre><h4 id="7、flume安装"><a href="#7、flume安装" class="headerlink" title="7、flume安装"></a>7、flume安装</h4><pre class="language-none"><code class="language-none">flume这个可以设置环境变量也可以不设置看自己！ 我没设置flume的环境变量tar zxvf apache-flume-1.8.0-bin.tar.gzcd apache-flume-1.8.0-bin/conf/cp flume-env.sh.template flume-env.shvi flume-env.sh添加：    JAVA_HOME=/home/hadoop/jdk1.8.0_144在conf目录下：vi   netcat-logger.conf# 定义这个agent中各组件的名字a1.sources = r1a1.sinks = k1a1.channels = c1# 描述和配置source组件：r1a1.sources.r1.type = netcata1.sources.r1.bind = localhosta1.sources.r1.port = 44444# 描述和配置sink组件：k1a1.sinks.k1.type = logger# 描述和配置channel组件，此处使用是内存缓存的方式a1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# 描述和配置source  channel   sink之间的连接关系a1.sources.r1.channels = c1a1.sinks.k1.channel = c12、启动agent去采集数据bin/flume-ng agent -c conf -f conf/netcat-logger.conf -n a1  -Dflume.root.logger=INFO,console按ctrl+c停止-c conf   指定flume自身的配置文件所在目录-f conf/netcat-logger.con  指定我们所描述的采集方案-n a1  指定我们这个agent的名字3、测试先要往agent采集监听的端口上发送数据，让agent有数据可采随便在一个能跟agent节点联网的机器上yum install telnettelnet anget-hostname  port   （telnet localhost 44444）发送数据 flume能接受到   安装成功！</code></pre><h4 id="8-azkaban安装"><a href="#8-azkaban安装" class="headerlink" title="8.azkaban安装"></a>8.azkaban安装</h4><pre class="language-none"><code class="language-none">上传tar包到家目录    Azkaban Web服务器    azkaban-web-server-2.5.0.tar.gz    Azkaban执行服务器     azkaban-executor-server-2.5.0.tar.gz    azkaban-sql-script-2.5.0.tar.gz    中共3个tar包    将安装文件上传到集群,最好上传到安装 hive、sqoop的机器上,方便命令的执行    mkdir azkaban-2.5.0    tar zxvf azkaban-web-server-2.5.0.tar.gz -C azkaban-2.5.0/server    tar zxvf azkaban-executor-server-2.5.0.tar.gz -C azkaban-2.5.0/executor    tar zxvf azkaban-sql-script-2.5.0.tar.gz -C azkaban-2.5.0/    azkaban脚本导入:    mysql -uroot -p    root     create database azkaban;     use azkaban;     source /home/hadoop/azkaban-2.5.0/azkaban-2.5.0//create-all-sql-2.5.0.sql;     创建SSL配置:     cd  ～     命令: keytool -keystore keystore -alias jetty -genkey -keyalg RSA运行此命令后,会提示输入当前生成 keystor的密码及相应信息,输入的密码请劳记,信息如下:    输入keystore密码：     再次输入新密码:    您的名字与姓氏是什么？      [Unknown]：     您的组织单位名称是什么？      [Unknown]：     您的组织名称是什么？      [Unknown]：     您所在的城市或区域名称是什么？      [Unknown]：     您所在的州或省份名称是什么？      [Unknown]：     该单位的两字母国家代码是什么      [Unknown]：  CN    CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=CN 正确吗？      [否]：  y    输入&lt;jetty&gt;的主密码        （如果和 keystore 密码相同，按回车）：     再次输入新密码:    完成上述工作后,将在当前目录生成 keystore 证书文件,将keystore 考贝到 azkaban web服务器根目录中     cp  keystore azkaban-2.5.0/server    配置文件：    如果服务器默认的是Asia/Shanghai时区， 此项可以不配    注：先配置好服务器节点上的时区    1、先生成时区配置文件Asia/Shanghai，用交互式命令 tzselect 即可    2、拷贝该时区文件，覆盖系统本地时区配置    cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime     cd azkaban-2.5.0/server/conf    vi azkaban.properties    内容说明如下:   ***可以修改        #Azkaban Personalization Settings        azkaban.name=Test                           #服务器UI名称,用于服务器上方显示的名字        azkaban.label=My Local Azkaban                               #描述        azkaban.color=#FF3601                                                 #UI颜色        azkaban.default.servlet.path=/index                         #        web.resource.dir=/home/hadoop/azkaban-2.5.0/server/web/                                                #默认根web目录        default.timezone.id=Asia/Shanghai                           #默认时区,已改为亚洲/上海 默认为美国    ***        #Azkaban UserManager class        user.manager.class=azkaban.user.XmlUserManager        user.manager.xml.file=/home/hadoop/azkaban-2.5.0/server/conf/azkaban-users.xml  ***        #Loader for projects        executor.global.properties=/home/hadoop/azkaban-2.5.0/server/cconf/global.properties        azkaban.project.dir=projects        database.type=mysql        mysql.port=3306        mysql.host=localhost        mysql.database=azkaban        mysql.user=root        mysql.password=root        mysql.numconnections=100        # Velocity dev mode        velocity.dev.mode=false        # Azkaban Jetty server properties.        jetty.maxThreads=25        jetty.ssl.port=8443        jetty.port=8081        jetty.keystore=/home/hadoop/azkaban-2.5.0/keystore        jetty.password=123456        jetty.keypassword=123456        jetty.truststore=/home/hadoop/azkaban-2.5.0/keystore        jetty.trustpassword=123456        # Azkaban Executor settings        executor.port=12321        # mail settings        mail.sender=        mail.host=        job.failure.email=        job.success.email=        lockdown.create.projects=false        cache.directory=cache    vi azkaban-users.xml     &lt;azkaban-users&gt;        &lt;user username="azkaban" password="azkaban" roles="admin" groups="azkaban" /&gt;        &lt;user username="metrics" password="metrics" roles="metrics"/&gt;        &lt;user username="admin" password="admin" roles="admin,metrics" /&gt;        &lt;role name="admin" permissions="ADMIN" /&gt;        &lt;role name="metrics" permissions="METRICS"/&gt;&lt;/azkaban-users&gt;    cd ../../executor/conf/    vi azkaban.properties    #Azkaban        default.timezone.id=Asia/Shanghai        # Azkaban JobTypes Plugins        azkaban.jobtype.plugin.dir=/home/hadoop/azkaban-2.5.0/executor/plugins/jobtypes        #Loader for projects        executor.global.properties=/home/hadoop/azkaban-2.5.0/executor/conf/global.properties        azkaban.project.dir=projects        database.type=mysql        mysql.port=3306        mysql.host=localhost        mysql.database=azkaban        mysql.user=root        mysql.password=root        mysql.numconnections=100        # Azkaban Executor settings        executor.maxThreads=50        executor.port=12321        executor.flow.threads=30    启动：        web服务器：            在azkaban web服务器目录下执行启动命令            bin/azkaban-web-start.sh            启动到后台            nohup  bin/azkaban-web-start.sh  1&gt;/tmp/azstd.out  2&gt;/tmp/azerr.out &amp;        执行服务器：            在执行服务器目录下执行启动命令            bin/azkaban-executor-start.sh        启动完成后,在浏览器(建议使用谷歌浏览器)中输入https://服务器IP地址:8443 ,即可访问azkaban服务了.在登录中输入刚才新的户用名及密码,点击 login    停止：        bin/azkaban-web-stop.sh        bin/azkaban-executor-stop.sh    </code></pre><h4 id="9、sqoop安装"><a href="#9、sqoop安装" class="headerlink" title="9、sqoop安装"></a>9、sqoop安装</h4><pre class="language-none"><code class="language-none">只需要在hadoop-master安装就可以了tar zxvf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gzcp mysql-connector-java-5.1.29.jar  sqoop-1.4.7.bin__hadoop-2.6.0/lib/cd   /home/hadoop/sqoop-1.4.7.bin__hadoop-2.6.0/confmv sqoop-env-template.sh sqoop-env.shvim sqoop-env.sh修改如下：export HADOOP_COMMON_HOME=/home/hadoop/hadoop-2.7.5/export HADOOP_MAPRED_HOME=/home/hadoop/hadoop-2.7.5/export HIVE_HOME=/home/hadoop/hive-1.2.2/hbase这个可以现在用修改   现在还没安装hbaseexport HBASE_HOME=/home/hadoop/hbase-1.2.2修改环境变量：vim  /etc/profile# 增加export SQOOP_HOME=/home/hadoop/sqoop-1.4.7.bin__hadoop-2.6.0export PATH=$PATH:$SQOOP_HOME/binsource /etc/profile验证启动:cd $SQOOP_HOME/bin$ sqoop    version15/12/17 14:52:32 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6Sqoop 1.4.6 git commit id 5b34accaca7de251fc91161733f906af2eddbe83Compiled by abe on Fri Aug 1 11:19:26 PDT 2015到这里，整个Sqoop安装工作完成。</code></pre><h4 id="10、hbase集群安装"><a href="#10、hbase集群安装" class="headerlink" title="10、hbase集群安装"></a>10、hbase集群安装</h4><pre class="language-none"><code class="language-none">tar  zxvf hbase-1.2.6-bin.tar.gz进行配置：    cd hbase-1.2.6/lib    cp ~/hadoop-2.7.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.5.jar .    cp ~/hadoop-2.7.5/share/hadoop/tools/lib/hadoop-auth-2.7.5.jar .    cp ~/hadoop-2.7.5/share/hadoop/common/hadoop-common-2.7.5.jar .    cp ~/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-2.7.5.jar .    cp ~/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.5.jar .     cp ~/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.5.jar .    cp ~/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.5.jar .     cp ~/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5 .      cp ~/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5.jar .     cp ~/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.5.jar .     cp ~/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-api-2.7.5.jar .     cp ~/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-client-2.7.5.jar .      cp ~/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-common-2.7.5.jar .     cp ~/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-common-2.7.5.jar .     # 解决java.lang.NoClassDefFoundError: org/htrace/Trace    cp ~/hadoop-2.7.5/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar     # 删除老版的jar    rm *-2.5.1.jar    vim hbase-env.sh    export JAVA_HOME=/home/hadoop/jdk1.8.0_144    export HBASE_MANAGES_ZK=false    export HBASE_CLASSPATH=/home/hadoop/hadoop-2.7.5/etc/hadoop    # 注释掉下面的配置（因为1.8JDK没有这个选项）    #export HBASE_MASTER_OPTS="$HBASE_MASTER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m"    #export HBASE_REGIONSERVER_OPTS="$HBASE_REGIONSERVER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m"    vim  hbase-site.xml    &lt;configuration&gt;          &lt;property&gt;            &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;            &lt;value&gt;true&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;            &lt;name&gt;hbase.tmp.dir&lt;/name&gt;            &lt;value&gt;/home/hadoop/hbase-1.2.6/tmp&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;            &lt;name&gt;hbase.rootdir&lt;/name&gt;            &lt;value&gt;hdfs://ns1/hbase&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;            &lt;name&gt;zookeeper.session.timeout&lt;/name&gt;            &lt;value&gt;120000&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;            &lt;name&gt;hbase.zookeeper.property.tickTime&lt;/name&gt;            &lt;value&gt;6000&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;            &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;            &lt;value&gt;2181&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;            &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;            &lt;value&gt;hadoop-master,hadoop-node1,hadoop-node2&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;            &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;             &lt;value&gt;/home/hadoop/zookeeper-3.4.10/data&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;            &lt;name&gt;dfs.replication&lt;/name&gt;            &lt;value&gt;1&lt;/value&gt;          &lt;/property&gt;          &lt;property&gt;             &lt;name&gt;hbase.master.maxclockskew&lt;/name&gt;             &lt;value&gt;180000&lt;/value&gt;          &lt;/property&gt;         &lt;/configuration&gt;    vim  regionservers    添加： hadoop-node1  hadoop-node2    拷贝hbase到其他节点:    cd hbase-1.2.6/conf    cp ~/hadoop-2.7.5/etc/hadoop/hdfs-site.xml  .    cp ~/hadoop-2.7.5/etc/hadoop/core-site.xml   .    scp -r /home/hadoop/hbase-1.2.6  hadoop-node1:~/    scp -r /home/hadoop/hbase-1.2.6  hadoop-node2:~/    在其他节点source  /etc/profile    配置环境变量:    sudo vim /etc/profile    export HBASE_HOME=/home/hadoop/hbase-1.2.6    export PATH=$PATH:$HBASE_HOME/bin    source /etc/profile    在其余2台机器上都要执行    启动验证：        在启动之前需要讲zookeeper集群和Hadoop集群启动起来        # 启动  只需要在hadoop-master上就可以了        start-hbase.sh        使用命令查看：jps   有HMaster进程        # 通过浏览器访问hbase HMaster Web页面        http://hadoop-master:16010        # HRegionServer Web页面        http://hadoop-node1:16030   有HRegionServer进程        http://hadoop-node2:16030        # shell验证        hbase shell        # list验证        list        # 建表验证        create 'user','name','sex'         停止：        stop-hbase.sh</code></pre><h4 id="11、storm集群安装"><a href="#11、storm集群安装" class="headerlink" title="11、storm集群安装"></a>11、storm集群安装</h4><pre class="language-none"><code class="language-none">前提条件：ZooKeeper、JDK、Python2.6.6（安装操作系统时已安装）tar zxvf  apache-storm-1.2.1.tar.gzcd apache-storm-1.2.1mkdir data配置环境变量：vim  /etc/profileexport STORM_HOME=/home/hadoop/apache-storm-1.2.1export PATH=$PATH:$STORM_HOME/binsource /etc/profilecd  confvim  sotrm.yaml  添加：    storm.zookeeper.servers:        - "hadoop-node1"        - "hadoop-node2"    nimbus.host: "hadoop-master"    storm.local.dir: "/home/hadoop/apache-storm-1.2.1/data"复制Storm到其他节点：scp -r apache-storm-1.2.1 hadoop@hadoop-node1:/home/hadoopscp -r apache-storm-1.2.1 hadoop@hadoop-node2:/home/hadoop在其他节点上也进行环境变量的配置启动：    # hadoop-master节点    storm nimbus &gt; /dev/null 2&gt;&amp;1 &amp;    storm ui &gt; /dev/null 2&gt;&amp;1 &amp;    # hadoop-node1   和  node2  节点    storm supervisor &gt; /dev/null 2&gt;&amp;1 &amp;验证:    # 参看storm ui    http://hadoop-master:8080/index.html关闭:    [zkpk@hsm01 ~]$ jps    5505 nimbus    5635 Jps    2710 QuorumPeerMain    [zkpk@hsm01 ~]$ kill 5505    # 关闭nimbus相关进程:     kill `ps aux | egrep '(daemon\.nimbus)|(storm\.ui\.core)' |fgrep -v egrep | awk '{print $2}'`     # 干掉supervisor上的所有storm进程:     kill `ps aux | fgrep storm | fgrep -v 'fgrep' | awk '{print$2}'`添加启动关闭脚本：在storm目录下vim conf/slaveshadoop-node1hadoop-node2start-storm.sh    #!/usr/bin/env bash    # Start all storm daemons    # Run this on master node    # Starts a worker on each node specified in conf/slaves    if [ -z "${STORM_HOME}" ]; then      export STORM_HOME="$(cd "`dirname "$0"`"/..; pwd)"    fi    SLAVE_FILE=${STORM_HOME}/conf/slaves    SLAVE_NAMES=$(cat "$SLAVE_FILE" | sed  's/#.*$//;/^$/d')    "${STORM_HOME}/bin"/storm nimbus &gt; /dev/null 2&gt;&amp;1 &amp;    echo start nimbus [ done ]    sleep 1    "${STORM_HOME}/bin"/storm ui &gt; /dev/null 2&gt;&amp;1 &amp;    echo start ui [ done ]    sleep 1    for slave in $SLAVE_NAMES ;     do    ssh -T $slave &lt;&lt;EOF        source ~/.bash_profile        cd \$STORM_HOME        python bin/storm supervisor &gt;/dev/null 2&gt;&amp;1 &amp;    EOF    echo start $slave supervisor [ done ]    sleep 1    done    echo start storm [ done ]stop-storm.sh    #!/usr/bin/env bash    # Stop all storm daemons    # Run this on master node    # Stops a worker on each node specified in conf/slaves    if [ -z "${STORM_HOME}" ]; then      export STORM_HOME="$(cd "`dirname "$0"`"/..; pwd)"    fi    kill `ps aux | egrep '(daemon\.nimbus)|(storm\.ui\.core)' |fgrep -v egrep | awk '{print $2}'`     echo stop nimbus [ done ]    sleep 1    SLAVE_FILE=${STORM_HOME}/conf/slaves    SLAVE_NAMES=$(cat "$SLAVE_FILE" | sed  's/#.*$//;/^$/d')    for slave in $SLAVE_NAMES ;    do    ssh $slave '/bin/kill `ps -ef | grep storm | grep -v grep | awk '\'{print \$2}\''`'    echo stop $slave supervisor [ done ]    sleep 1    done    echo stop storm [ done ]就可以在家目录下 启动和关闭</code></pre><h4 id="12、kafaka集群安装"><a href="#12、kafaka集群安装" class="headerlink" title="12、kafaka集群安装"></a>12、kafaka集群安装</h4><pre class="language-none"><code class="language-none">tar -xf  kafka_2.11-1.1.0.tgzcd  kafka_2.11-1.1.0/config修改配置文件vim server.properties    broker.id=0    listeners=PLAINTEXT://192.168.56.101:9092    num.network.threads=3    num.io.threads=8    socket.send.buffer.bytes=102400    socket.receive.buffer.bytes=102400    socket.request.max.bytes=104857600zookeeper.connect=192.168.56.101:2181,192.168.56.102:2181,192.168.56.103:2181    zookeeper.connection.timeout.ms=6000复制文件到各个节点上：scp  -r kafka_2.11-1.1.0 hadoop@hadoop-node1:/home/hadoopscp  -r kafka_2.11-1.1.0 hadoop@hadoop-node2:/home/hadoop在各个节点上配置环境变量vim /etc/profileexport KAFKA_HOME=/home/hadoop/kafka_2.11-1.1.0export PATH=$PATH:$KAFKA_HOME/binsource /etc/profile在hadoop-node1 上修改    broker.id=1    listeners=PLAINTEXT://192.168.56.102:9092在hadoop-node2上修改    broker.id=2    listeners=PLAINTEXT://192.168.56.103:9092启动：    依次在各节点上启动kafka    bin/kafka-server-start.sh  config/server.properties停止：    依次在各节点上停止kafka    bin/kafka-server-stop.sh </code></pre><h4 id="13、scala安装"><a href="#13、scala安装" class="headerlink" title="13、scala安装"></a>13、scala安装</h4><pre class="language-none"><code class="language-none">tar zxf   scala-2.12.5.tgz配置环境变量vim /etc/profileexport SCALA_HOME=/home/hadoop/scala-2.12.5export PATH=$PATH:$SCALA_HOME/binsource vim /etc/profile复制到其他节点上：scp -r scala-2.12.5 hadoop@hadoop-node1:/home/hadoopscp -r scala-2.12.5 hadoop@hadoop-node2:/home/hadoop同样进行环境变量的配置 输入命令：   scala -version安装完成</code></pre><h4 id="14、spark集群安装"><a href="#14、spark集群安装" class="headerlink" title="14、spark集群安装"></a>14、spark集群安装</h4><pre class="language-none"><code class="language-none">tar -xf  spark-2.3.0-bin-hadoop2.7.tgzcd spark-2.3.0-bin-hadoop2.7/conf进行配置：    vim spark-env.sh   添加：    export JAVA_HOME=/home/hadoop/jdk1.8.0_144    export SCALA_HOME=/home/hadoop/scala-2.12.5    export SPARK_MASTER_IP=hadoop-master    export SPARK_WORKER_MEMORY=300m    export HADOOP_CONF_DIR=/home/hadoop/hadoop-2.7.5/etc/hadoop    export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib:$HADOOP_HOME/lib/native"    cp slaves.template slaves    vim  slaves    hadoop-master    hadoop-node1    hadoop-node2复制到其他节点：scp -r spark-2.3.0-bin-hadoop2.7 hadoop@hadoop-node1:/home/hadoopscp -r spark-2.3.0-bin-hadoop2.7 hadoop@hadoop-node2:/home/hadoop在每台机器上进行环境变量的配置：vim /etc/profileexport SPARK_HOME=/home/hadoop/spark-2.3.0-bin-hadoop2.7export PATH=$PATH:$SPARK_HOME/binsource etc/profile启动验证:    # 启动（由于和hadoop的启动shell名字一样，需要注意）    $SPARK_HOME/sbin/start-all.sh    # 查看集群状态    http://hadoop-master:8080/    # 命令行交互验证    ./bin/spark-shell停止：    $SPARK_HOME/sbin/stop-all.sh需要注意：  storm和spark都要需要比较大的内存  所以虚拟机分配内存可以大点</code></pre><h4 id="15、redis集群搭建"><a href="#15、redis集群搭建" class="headerlink" title="15、redis集群搭建"></a>15、redis集群搭建</h4><pre class="language-none"><code class="language-none">集群中应该至少有三个节点，每个节点有一备份节点。需要6台服务器。搭建伪分布式，需要6个redis实例。搭建集群的步骤：第一步：创建6个redis实例指定端口从7001到7006  在redis.conf文件中修改第二步：修改redis.conf 打开Cluster-enable yes前面的注释第三步：需要一个ruby脚本。在redis源码文件夹下的src目录下。redis-trib.rb第四步：把redis-trib.rb文件复制到到redis-cluster目录下第五步：执行ruby脚本之前，需要安装ruby环境    1、yum install ruby    2、yum install rubygems    3、安装redis-trib.rb运行依赖的ruby的包、自行下载redis-3.0.0.gem         gem install redis-3.0.0.gem第六步：启动所有的redis实例第七步：使用redis-trib.rb创建集群。        填写自己主机的IP地址    ./redis-trib.rb create --replicas 1 192.168.25.153:7001 192.168.25.153:7002 192.168.25.153:7003 192.168.25.153:7004 192.168.25.153:7005  192.168.25.153:7006使用客户端连接集群： redis01/redis-cli -p 7001 -c    </code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> big_data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>django学习二</title>
      <link href="/2018/03/28/django-xue-xi-er/"/>
      <url>/2018/03/28/django-xue-xi-er/</url>
      
        <content type="html"><![CDATA[<h2 id="一、admin的配置"><a href="#一、admin的配置" class="headerlink" title="一、admin的配置"></a>一、admin的配置</h2><p>django admin是django自带的一个后台app，提供了后台的管理功能。</p><p>基础知识点：</p><p>一  认识ModelAdmin</p><pre><code>管理界面的定制类，如需扩展特定的model界面需从该类继承</code></pre><p>二 注册medel类到admin的两种方式：</p><pre><code>1   使用register的方法    2   使用register的装饰器</code></pre><p>三 掌握一些常用的设置技巧</p><pre class="language-none"><code class="language-none">list_display:  指定要显示的字段search_fields:指定搜索的字段list_filter: 指定列表过滤器ordering：指定排序字段</code></pre><h2 id="二、Form"><a href="#二、Form" class="headerlink" title="二、Form"></a>二、Form</h2><p>一 什么是Form？什么是DjangoForm？</p><p>Django表单系统中，所有的表单类都作为django.forms.Form的子类创建，包括ModelForm</p><p>关于django的表单系统，主要分两种</p><p>基于django.forms.Form:所有表单类的父类</p><p>基于django.forms.ModelForm:可以和模型类绑定的Form</p><p>实例：实现添加出版社信息的功能</p><p>二、使用Form<br>首先，在app01中建立forms.py</p><pre class="language-none"><code class="language-none">#app01下新建的forms.pyfrom django import formsclass Mypub_form(forms.Form):    name = forms.CharField(label='名称',error_messages={'required':'必填'})    address = forms.CharField(label='地址',error_messages={'required':'必填'})    city = forms.CharField(label='城市',error_messages={'required':'必填'})    state_province = forms.CharField(label='省份',error_messages={'required':'必填'})    country = forms.CharField(label='国家',error_messages={'required':'必填'})    website = forms.URLField(label='网址',error_messages={'required':'必填'})########################################################app01.viewsdef add_publisher(req):    if req.method=='POST':        # #不使用django form        # print(req.POST)        # name=req.POST['name']        # address=req.POST.get('address')        # city=req.POST['city']        # province=req.POST['province']        # country=req.POST['country']        # website=req.POST['website']        # Publisher.objects.create(        #     name=name,        #     city=city,        #     address=address,        #     state_province=province,        #     country=country,        #     website=website        # )        # return HttpResponse("添加出版社信息成功!")        #使用django form的情况        Mypub_form_obj=Mypub_form(req.POST)        if Mypub_form_obj.is_valid():            Publisher.objects.create(                name=Mypub_form_obj.cleaned_data["name"],                address=Mypub_form_obj.cleaned_data["address"],                city=Mypub_form_obj.cleaned_data["city"],                state_province=Mypub_form_obj.cleaned_data["state_province"],                country=Mypub_form_obj.cleaned_data["country"],                website=Mypub_form_obj.cleaned_data["website"],            )            return HttpResponse("添加出版社信息成功!")    else:        Mypub_form_obj=Mypub_form()    return render(req,'add_publisher.html',locals())########################################################add_publisher.html&lt;body&gt;     &lt;form action="{% url 'add_pub' %}" method="post"&gt;         {% csrf_token %}{#           名称:&lt;input type="text" name="name"&gt;&lt;br&gt;#}{#           地址:&lt;input type="text" name="address"&gt;&lt;br&gt;#}{#           城市:&lt;input type="text" name="city"&gt;&lt;br&gt;#}{#           省份:&lt;input type="text" name="province"&gt;&lt;br&gt;#}{#           国家:&lt;input type="text" name="country"&gt;&lt;br&gt;#}{#           网址:&lt;input type="text" name="website"&gt;&lt;br&gt;#}{#           &lt;input type="submit" value="提交"&gt;&lt;br&gt;#}         {{ Mypub_form_obj.as_p }}         &lt;input type="submit" value="提交"&gt;&lt;br&gt;     &lt;/form&gt;&lt;/body&gt;</code></pre><p>三、使用ModelForm的情况</p><pre class="language-none"><code class="language-none">#app01.viewsdef add_publisher(req):    if req.method=='POST':        # #不使用django form        # print(req.POST)        # name=req.POST['name']        # address=req.POST.get('address')        # city=req.POST['city']        # province=req.POST['province']        # country=req.POST['country']        # website=req.POST['website']        # Publisher.objects.create(        #     name=name,        #     city=city,        #     address=address,        #     state_province=province,        #     country=country,        #     website=website        # )        # return HttpResponse("添加出版社信息成功!")        #使用django form的情况        Mypub_form_obj=Mypub_form(req.POST)        if Mypub_form_obj.is_valid():            # Publisher.objects.create(            #     name=Mypub_form_obj.cleaned_data["name"],            #     address=Mypub_form_obj.cleaned_data["address"],            #     city=Mypub_form_obj.cleaned_data["city"],            #     state_province=Mypub_form_obj.cleaned_data["state_province"],            #     country=Mypub_form_obj.cleaned_data["country"],            #     website=Mypub_form_obj.cleaned_data["website"],            # )            Mypub_form_obj.save()            return HttpResponse("添加出版社信息成功!")    else:        Mypub_form_obj=Mypub_form()    return render(req,'add_publisher.html',locals())########################################################add_publisher.html&lt;body&gt;     &lt;form action="{% url 'add_pub' %}" method="post"&gt;         {% csrf_token %}{#           名称:&lt;input type="text" name="name"&gt;&lt;br&gt;#}{#           地址:&lt;input type="text" name="address"&gt;&lt;br&gt;#}{#           城市:&lt;input type="text" name="city"&gt;&lt;br&gt;#}{#           省份:&lt;input type="text" name="province"&gt;&lt;br&gt;#}{#           国家:&lt;input type="text" name="country"&gt;&lt;br&gt;#}{#           网址:&lt;input type="text" name="website"&gt;&lt;br&gt;#}{#           &lt;input type="submit" value="提交"&gt;&lt;br&gt;#}         {{ Mypub_form_obj.as_p }}         &lt;input type="submit" value="提交"&gt;&lt;br&gt;     &lt;/form&gt;&lt;/body&gt;</code></pre><p>总结：</p><pre><code>使用Django中Form可以大大简化代码，常用的表单功能特性都整合到了Form中，而ModelForm可以和Model进行绑定，更进一步简化操作。</code></pre><h2 id="三、Form-验证"><a href="#三、Form-验证" class="headerlink" title="三、Form 验证"></a>三、Form 验证</h2><p>django提供了3种方式来验证表单</p><p>实例：自定义验证，不能插入重名的出版社名称</p><p>一 表单字段的验证器</p><p><img src="/images/20180328/1.png"></p><p>二 clean_filedname,验证字段，针对某个字段进行验证。</p><p><img src="/images/20180328/2.png"></p><p>三 表单clean方法，可针对整个表单进行验证</p><p><img src="/images/20180328/3.png"></p><p>像注册时需要输入两次密码的验证，用clean来做就非常好，因为前两种都只是针对某一个字段进行验证，而确认密码则需要将两个字段信息都拿来进行匹配。    </p><h2 id="四、cookie和session"><a href="#四、cookie和session" class="headerlink" title="四、cookie和session"></a>四、cookie和session</h2><pre class="language-none"><code class="language-none">1、cookie不属于http协议范围，由于http协议无法保持状态，但实际情况，我们却又需要“保持状态”，因此cookie就是在这样一个场景下诞生。cookie的工作原理是：由服务器产生内容，浏览器收到请求后保存在本地；当浏览器再次访问时，浏览器会自动带上cookie，这样服务器就能通过cookie的内容来判断这个是“谁”了。2、cookie虽然在一定程度上解决了“保持状态”的需求，但是由于cookie本身最大支持4096字节，以及cookie本身保存在客户端，可能被拦截或窃取，因此就需要有一种新的东西，它能支持更多的字节，并且他保存在服务器，有较高的安全性。这就是session。问题来了，基于http协议的无状态特征，服务器根本就不知道访问者是“谁”。那么上述的cookie就起到桥接的作用。我们可以给每个客户端的cookie分配一个唯一的id，这样用户在访问时，通过cookie，服务器就知道来的人是“谁”。然后我们再根据不同的cookie的id，在服务器上保存一段时间的私密资料，如“账号密码”等等。3、总结而言：cookie弥补了http无状态的不足，让服务器知道来的人是“谁”；但是cookie以文本的形式保存在本地，自身安全性较差；所以我们就通过cookie识别不同的用户，对应的在session里保存私密的信息以及超过4096字节的文本。4、另外，上述所说的cookie和session其实是共通性的东西，不限于语言和框架前几节的介绍中我们已经有能力制作一个登陆页面，在验证了用户名和密码的正确性后跳转到后台的页面。但是测试后也发现，如果绕过登陆页面。直接输入后台的url地址也可以直接访问的。这个显然是不合理的。其实我们缺失的就是cookie和session配合的验证。有了这个验证过程，我们就可以实现和其他网站一样必须登录才能进入后台页面了。      先说一下这种认证的机制。每当我们使用一款浏览器访问一个登陆页面的时候，一旦我们通过了认证。服务器端就会发送一组随机唯一的字符串（假设是123abc）到浏览器端，这个被存储在浏览端的东西就叫cookie。而服务器端也会自己存储一下用户当前的状态，比如login=true，username=hahaha之类的用户信息。但是这种存储是以字典形式存储的，字典的唯一key就是刚才发给用户的唯一的cookie值。那么如果在服务器端查看session信息的话，理论上就会看到如下样子的字典{'123abc':{'login':true,'username:hahaha'}}因为每个cookie都是唯一的，所以我们在电脑上换个浏览器再登陆同一个网站也需要再次验证。那么为什么说我们只是理论上看到这样子的字典呢？因为处于安全性的考虑，其实对于上面那个大字典不光key值123abc是被加密的，value值{'login':true,'username:hahaha'}在服务器端也是一样被加密的。所以我们服务器上就算打开session信息看到的也是类似与以下样子的东西{'123abc':dasdasdasd1231231da1231231}知道了原理，我们下面就来用代码实现</code></pre><p>先在templates目录下创建两个html，login.html负责登录页面。backend页面代表后台页面</p><p>login.html</p><pre class="language-none"><code class="language-none">&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt;    &lt;meta charset="UTF-8"&gt;    &lt;title&gt;login&lt;/title&gt;    &lt;link rel="stylesheet" href="http://830909.blog.51cto.com/static/plugins/bootstrap-3.3.5-dist/css/bootstrap.min.css"&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class="container"&gt;        &lt;form action="login.html" method="post"&gt;            &lt;div class="form-group"&gt;                &lt;label class="sr-only"&gt;username&lt;/label&gt;                &lt;input type="text" class="form-control" name="username" placeholder="用户名"/&gt;            &lt;/div&gt;            &lt;div class="form-group"&gt;                &lt;label class="sr-only"&gt;Password&lt;/label&gt;                &lt;input type="password" class="form-control" name="passwd" placeholder="密码"/&gt;            &lt;/div&gt;            &lt;div class="form-group"&gt;                &lt;input class="btn btn-primary" type="submit" value="http://830909.blog.51cto.com/8311014/Submit"&gt;            &lt;/div&gt;        &lt;/form&gt;&lt;/div&gt;&lt;script type="application/Javascript" src="http://830909.blog.51cto.com/static/js/jquery-2.2.1.min.js"&gt;&lt;/script&gt;&lt;script type="application/javascript" src="http://830909.blog.51cto.com/static/plugins/bootstrap-3.3.5-dist/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><p>backend.html</p><pre class="language-none"><code class="language-none">&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt;    &lt;meta charset="UTF-8"&gt;    &lt;title&gt;backend&lt;/title&gt;    &lt;link rel="stylesheet" href="http://830909.blog.51cto.com/static/plugins/bootstrap-3.3.5-dist/css/bootstrap.min.css"&gt;    &lt;link rel="stylesheet" href="http://830909.blog.51cto.com/static/css/commons.css"&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="container"&gt;    &lt;h2&gt;cookie 内容是 {{ cookie_content }}&lt;/h2&gt;    &lt;h2&gt;session 内容是 {{ session_content }}&lt;/h2&gt;    &lt;h2&gt;登录用户名 ：{{ username }}&lt;/h2&gt;    &lt;a href="http://830909.blog.51cto.com/logout/"&gt;注销&lt;/a&gt;&lt;/div&gt;&lt;script type="application/javascript" src="http://830909.blog.51cto.com/static/js/jquery-2.2.1.min.js"&gt;&lt;/script&gt;&lt;script type="application/javascript" src="http://830909.blog.51cto.com/static/plugins/bootstrap-3.3.5-dist/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><p>第二步 编辑app01应用下的views.py文件，编写代码逻辑部分</p><p>views.py</p><pre class="language-none"><code class="language-none"># /usr/bin/env python# coding:utf-8from django.shortcuts import renderfrom django.shortcuts import redirectdef login(request):    if request.method=="POST":        username=request.POST['username']        pwd=request.POST['passwd']        if username=='abc' and pwd=='123':            #设置session内部的字典内容            request.session['is_login']='true'            request.session['username']='abc'            #登录成功就将url重定向到后台的url            return redirect('/backend/')    #登录不成功或第一访问就停留在登录页面    return render(request,'login.html')def backend(request):    """    这里必须用读取字典的get()方法把is_login的value缺省设置为False，    当用户访问backend这个url先尝试获取这个浏览器对应的session中的    is_login的值。如果对方登录成功的话，在login里就已经把is_login    的值修改为了True,反之这个值就是False的    """    is_login=request.session.get('is_login',False)    #如果为真，就说明用户是正常登陆的    if is_login:        #获取字典的内容并传入页面文件        cookie_content=request.COOKIES        session_content=request.session        username=request.session['username']        return render(request,'backend.html',                      {            'cookie_content':cookie_content,            'session_content':session_content,            'username':username                      })    else:        """        如果访问的时候没有携带正确的session，        就直接被重定向url回login页面        """        return redirect('/login/')def logout(request):    """    直接通过request.session['is_login']回去返回的时候，    如果is_login对应的value值不存在会导致程序异常。所以    需要做异常处理    """    try:        #删除is_login对应的value值        del request.session['is_login']    except KeyError:        pass    #点击注销之后，直接重定向回登录页面    return redirect('/login/')        </code></pre><p>第三步，编辑mydjango目录下的urls.py文件。设置函数与页面的绑定关系</p><p>urls.py</p><pre class="language-none"><code class="language-none">from django.conf.urls import urlfrom django.contrib import adminfrom app01 import viewsurlpatterns = [    url(r'^admin/', admin.site.urls),    url(r'^login/', views.login),    url(r'^backend/', views.backend),    url(r'^logout/', views.logout),]</code></pre><p>最后打开浏览器直接访问/backend/页面的时候直接就被重定向到了/login/</p><p>只有在输入了正确的用户名和密码之后才进入到了/backend/页面</p><pre class="language-none"><code class="language-none">1、login页面正确登录的话，后台页面可以获取到浏览器携带的cookie的。2、第一行的sessionid其实就是cookie值3、session的内容是加密的，从客户端获取不到session的内容4、服务端可以通过预设的key值取出session的内容并打印到前段</code></pre><p>django的session默认是存储在数据库里的，我们再到数据库查看一下真正session内容</p><p>下面我们再来最后的总结一下cookie和session的知识点</p><pre class="language-none"><code class="language-none">一、操作Cookie　　获取cookie：request.COOKIES[key]　　设置cookie：response.set_cookie(key,value)由于cookie保存在客户端的电脑上，所以，jquery也可以操作cookie。&lt;script src='http://830909.blog.51cto.com/static/js/jquery.cookie.js'&gt;&lt;/script&gt;$.cookie("list_pager_num", 30,{ path: '/' });二、操作Session(session默认在服务器端保存15天)　　获取session：request.session[key]　　设置session：reqeust.session[key] = value　　删除session：del request.session[key]    （这个删除其实就是把数据库的session_data更新为一个其他的值了，并没有立即删除）request.session.set_expiry(value)* 如果value是个整数，session会在些秒数后失效。* 如果value是个datatime或timedelta，session就会在这个时间后失效。* 如果value是0,用户关闭浏览器session就会失效。* 如果value是None,session会依赖全局session失效策略。</code></pre><p>参考：<a href="http://www.cnblogs.com/yuanchenqi/articles/5716193.html">http://www.cnblogs.com/yuanchenqi/articles/5716193.html</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> django </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>django学习一</title>
      <link href="/2018/03/28/django-xue-xi-yi/"/>
      <url>/2018/03/28/django-xue-xi-yi/</url>
      
        <content type="html"><![CDATA[<h2 id="一、什么是web框架"><a href="#一、什么是web框架" class="headerlink" title="一、什么是web框架"></a>一、什么是web框架</h2><p>对于所有的Web应用，本质上其实就是一个socket服务端，用户的浏览器其实就是一个socket客户端。</p><h2 id="二、MVC和MVT模式"><a href="#二、MVC和MVT模式" class="headerlink" title="二、MVC和MVT模式"></a>二、MVC和MVT模式</h2><p>著名的MVC模式：所谓MVC就是把web应用分为模型(M),控制器(C),视图(V)三层；他们之间以一种插件似的，松耦合的方式连接在一起。</p><p>Django的MTV分别代表：</p><pre><code>   Model(模型)：负责业务对象与数据库的对象(ORM)   Template(模版)：负责如何把页面展示给用户   View(视图)：负责业务逻辑，并在适当的时候调用Model和Template</code></pre><h2 id="三、django的流程和命令行"><a href="#三、django的流程和命令行" class="headerlink" title="三、django的流程和命令行"></a>三、django的流程和命令行</h2><pre class="language-none"><code class="language-none">1 安装：conda/pip  install django2 创建project：django -admin startproject mydjango3 创建app：django manage.py startapp myapp4 settings配置：    TEMPLATES    STATICFILES_DIRS=(        os.path.join(BASE_DIR,"statics"),    )       STATIC_URL = '/static/'       #  我们只能用 STATIC_URL，但STATIC_URL会按着你的STATICFILES_DIRS去找#4  根据需求设计代码       url.py       view.py5 使用模板：    render(req,"index.html") 6 启动项目：    python manage.py runserver 807 链接数据库    查看model.py8 启动交互界面    python manage.py shell9 查看命令帮助 直接输入python manage.py 可以看到子命令     在子命令后输入 --help 就可以查看命令的详细信息</code></pre><h2 id="四、django的配置文件"><a href="#四、django的配置文件" class="headerlink" title="四、django的配置文件"></a>四、django的配置文件</h2><p>由于配置相太多 我没发一一列举出来 有兴趣的可以去官网查看 <a href="https://docs.djangoproject.com/en/1.10/topics/settings/">djaongo配置文件</a></p><h2 id="五、django的路由系统"><a href="#五、django的路由系统" class="headerlink" title="五、django的路由系统"></a>五、django的路由系统</h2><p>URL配置(URLconf)就像Django 所支撑网站的目录。它的本质是URL模式以及要为该URL模式调用的视图函数之间的映射表；你就是以这种方式告诉Django，对于这个URL调用这段代码，对于那个URL调用那段代码。</p><pre class="language-none"><code class="language-none">django URL格式为：    urlpatterns = [        url(正则表达式, views视图函数，参数，别名),    ]参数说明：    一个正则表达式字符串    一个可调用对象，通常为一个视图函数或一个指定视图函数路径的字符串    可选的要传递给视图函数的默认参数（字典形式）    一个可选的name参数</code></pre><h4 id="5-1-Here’s-a-sample-URLconf"><a href="#5-1-Here’s-a-sample-URLconf" class="headerlink" title="5.1 Here’s a sample URLconf:"></a>5.1 Here’s a sample URLconf:</h4><pre class="language-none"><code class="language-none">from django.conf.urls import urlfrom django.contrib import adminfrom app01 import viewsurlpatterns = [    url(r'^articles/2003/$', views.special_case_2003),    #url(r'^articles/[0-9]{4}/$', views.year_archive),    url(r'^articles/([0-9]{4})/$', views.year_archive),  #no_named group    url(r'^articles/([0-9]{4})/([0-9]{2})/$', views.month_archive),    url(r'^articles/([0-9]{4})/([0-9]{2})/([0-9]+)/$', views.article_detail),]</code></pre><h4 id="5-2-Named-groups-命名空间"><a href="#5-2-Named-groups-命名空间" class="headerlink" title="5.2 Named groups 命名空间"></a>5.2 Named groups 命名空间</h4><pre class="language-none"><code class="language-none">import reret=re.search('(?P&lt;id&gt;\d{3})/(?P&lt;name&gt;\w{3})','weeew34ttt123/ooo')print(ret.group())print(ret.group('id'))print(ret.group('name'))</code></pre><h4 id="5-3-name-param-名称参数"><a href="#5-3-name-param-名称参数" class="headerlink" title="5.3 name param 名称参数"></a>5.3 name param 名称参数</h4><pre class="language-none"><code class="language-none">urlpatterns = [    url(r'^index',views.index,name='bieming'),]在templates中可以这样使用：    &lt;form action="{% url 'bieming' %}" method="post"&gt;</code></pre><h4 id="5-4-Including-other-URLconfs-包含其他的url"><a href="#5-4-Including-other-URLconfs-包含其他的url" class="headerlink" title="5.4 Including other URLconfs 包含其他的url"></a>5.4 Including other URLconfs 包含其他的url</h4><pre class="language-none"><code class="language-none">from django.conf.urls import include, urlurlpatterns = [   url(r'^admin/', admin.site.urls),   url(r'^blog/', include('blog.urls')),]</code></pre><h2 id="六-VIEWS-即（V）"><a href="#六-VIEWS-即（V）" class="headerlink" title="六 VIEWS 即（V）"></a>六 VIEWS 即（V）</h2><p>http请求中产生两个核心对象：</p><ul><li><p>http请求：HttpRequest对象</p></li><li><p>http响应：HttpResponse对象</p></li></ul><p>所在位置：django.http</p><p>之前我们用到的参数request就是HttpRequest    检测方法：isinstance(request,HttpRequest)</p><h4 id="6-1-HttpRequest对象的属性和方法："><a href="#6-1-HttpRequest对象的属性和方法：" class="headerlink" title="6.1 HttpRequest对象的属性和方法："></a>6.1 HttpRequest对象的属性和方法：</h4><pre class="language-none"><code class="language-none">属性：    path：       请求页面的全路径，不包括域名    method：     请求中使用的HTTP方法的字符串表示。全大写表示    GET:         包含所有HTTP GET参数的类字典对象    POST：       包含所有HTTP POST参数的类字典对象    COOKIES:     包含所有cookies的标准Python字典对象；keys和values都是字符串。    FILES：      包含所有上传文件的类字典对象；FILES中的每一个Key都是&lt;input type="file" name="" /&gt;标签中                     name属性的值，FILES中的每一个value同时也是一个标准的python字典对象，包含下面三个Keys：        filename：      上传文件名，用字符串表示        content_type:   上传文件的Content Type        content：       上传文件的原始内容    user：       是一个django.contrib.auth.models.User对象，代表当前登陆的用户,可以通过user的is_authenticated()方法来辨别用户是否登陆    session：    唯一可读写的属性，代表当前会话的字典对象；自己有激活Django中的session支持时该属性才可用方法:    get_full_path(),   比如：http://127.0.0.1:8000/index33/?name=123 ,req.get_full_path()得到的结果就是/index33/?name=123    request.POST.getlist('')</code></pre><h4 id="6-2HttpResponse对象："><a href="#6-2HttpResponse对象：" class="headerlink" title="6.2HttpResponse对象："></a>6.2HttpResponse对象：</h4><p>对于HttpRequest对象来说，是由django自动创建的，但是，HttpResponse对象就必须我们自己创建。每个view请求处理方法必须返回一个HttpResponse对象。</p><p>  HttpResponse类在django.http.HttpResponse</p><pre class="language-none"><code class="language-none">在HttpResponse对象上扩展的常用方法：    1.页面渲染：         render()（推荐）&lt;br&gt;                 render_to_response(),    2.页面跳转：         redirect("路径")    3.locals()：    可以直接将函数中所有的变量传给模板总结: render和redirect的区别:     1 if render的页面需要模板语言渲染,需要的将数据库的数据加载到html,那么所有的这一部分，除了写在yuan_back的视图函数中,必须还要写在login中,代码重复,没有解耦.     2 the most important: url没有跳转到/yuan_back/,而是还在/login/,所以当刷新后又得重新登录.</code></pre><h2 id="七、Template基础-即（T）"><a href="#七、Template基础-即（T）" class="headerlink" title="七、Template基础 即（T）"></a>七、Template基础 即（T）</h2><p>模板主要是学习他的语法！</p><h4 id="一模版的组成"><a href="#一模版的组成" class="headerlink" title="一模版的组成"></a>一模版的组成</h4><p>组成：HTML代码＋逻辑控制代码</p><h4 id="二-逻辑控制代码的组成"><a href="#二-逻辑控制代码的组成" class="headerlink" title="二 逻辑控制代码的组成"></a>二 逻辑控制代码的组成</h4><ul><li><p>1  变量（使用双大括号来引用变量）：</p><pre><code>  * 语法格式：       {{var_name}}  * Template和Context对象：  同一模板，多个上下文，一旦有了模板对象，你就可以通过它渲染多个context，  无论何时我们都可以像这样使用同一模板源渲染多个context，只进行 一次模板创建然后多次调用render()方法渲染会  t = Template('Hello, {{ name }}')  for name in ('John', 'Julie', 'Pat'):      print t.render(Context({'name': name}))   Django 模板解析非常快捷。 大部分的解析工作都是在后台通过对简短正则表达式一次性调用来完成。 这和基于 XML 的模板引擎形成鲜明对比，那些引擎承担了 XML 解析器的开销，且往往比 Django 模板渲染引擎要慢上几个数量级。  * 深度变量的查找（万能的句点号）：      在到目前为止的例子中，我们通过 context 传递的简单参数值主要是字符串，然而，模板系统能够非常简洁地处理更加复杂的数据结构，例如list、dictionary和自定义的对象。      在 Django 模板中遍历复杂数据结构的关键是句点字符 (.)。      1.句点可用于访问列表索引      2.要通过字典键访问该字典的值，可使用一个句点      3.也可以通过句点来访问对象的属性。 比方说， Python 的 datetime.date 对象有year 、 month 和 day 几个属性，你同样可以在模板中使用句点来访问这些属性      4.使用了一个自定义的类，演示了通过实例变量加一点(dots)来访问它的属性，这个方法适用于任意的对象      5.点语法也可以用来引用对象的方法。 例如，每个 Python 字符串都有 upper() 和 isdigit()      6.注意这里调用方法时并* 没有* 使用圆括号 而且也无法给该方法传递参数；你只能调用不需参数的方法。  * 变量的过滤器(filter)的使用      语法格式：      {{obj|filter:param}}      1  add          ：   给变量加上相应的值      2  addslashes   :    给变量中的引号前加上斜线      3  capfirst     :    首字母大写      4  cut          ：   从字符串中移除指定的字符      5  date         ：   格式化日期字符串      6  default      ：   如果值是False,就替换成设置的默认值，否则就是用本来的值      7  default_if_none:  如果值是None，就替换成设置的默认值，否则就使用本来的值      #实例:          #value1="aBcDe"          {{ value1|upper }}&lt;br&gt;          #value2=5          {{ value2|add:3 }}&lt;br&gt;          #value3='he  llo wo r ld'          {{ value3|cut:' ' }}&lt;br&gt;</code></pre></li><li><p>2 标签(tag)的使用（使用大括号和百分比的组合来表示使用tag）<br>&lt;!–hexoPostRenderEscape:</p><pre class="language-none"><code class="language-none">{% tags %}<p></p></code></pre></li><code class="language-none"></code></ul><code class="language-none"><ul><li><p>{% if %} 的使用</p><p>  {% if %}标签计算一个变量值，如果是“true”，即它存在、不为空并且不是false的boolean值,系统则会显示{% if %}和{% endif %}间的所有内容</p><p>  {% if %} 标签接受and，or或者not来测试多个变量值或者否定一个给定的变量<br>  {% if %} 标签不允许同一标签里同时出现and和or，否则逻辑容易产生歧义，例如下面的标签是不合法的：</p><p>  {% if obj1 and obj2 or obj3 %}</p></li><li><p>{% for %}的使用</p><p>  {% for %}标签允许你按顺序遍历一个序列中的各个元素,每次循环模板系统都会渲染{% for %}和{% endfor %}之间的所有内容</p><p>  &lt;ul&gt;</p><pre><code>  &amp;#123;% for obj in list %&amp;#125;      &amp;lt;li&amp;gt;&amp;#123;&amp;#123; obj.name &amp;#125;&amp;#125;&amp;lt;&amp;#x2F;li&amp;gt;  &amp;#123;% endfor %&amp;#125;</code></pre><p>  &lt;/ul&gt;</p><p>  在标签里添加reversed来反序循环列表：<br>  {% for %}标签可以嵌套：<br>  统不支持中断循环，系统也不支持continue语句，{% for %}标签内置了一个forloop模板变量，这个变量含有一些属性可以提供给你一些关于循环的信息</p></li><li><p>{%csrf_token%}：csrf_token标签<br>  用于生成csrf_token的标签，用于防治跨站攻击验证。注意如果你在view的index里用的是render_to_response方法，不会生效</p><pre><code>      其实，这里是会生成一个input标签，和其他表单标签一起提交给后台的。  * &amp;#123;% url %&amp;#125;:  引用路由配置的地址      &amp;lt;form action&amp;#x3D;&amp;quot;&amp;#123;% url &amp;quot;bieming&amp;quot;%&amp;#125;&amp;quot; &amp;gt;    &amp;lt;input type&amp;#x3D;&amp;quot;text&amp;quot;&amp;gt;    &amp;lt;input type&amp;#x3D;&amp;quot;submit&amp;quot;value&amp;#x3D;&amp;quot;提交&amp;quot;&amp;gt;    &amp;#123;%csrf_token%&amp;#125;</code></pre><p>  &lt;/form&gt;</p></li><li><p>{% with %}:用更简单的变量名替代复杂的变量名<br>  {% with total=fhjsaldfhjsdfhlasdfhljsdal %} {{ total }} {% endwith %}</p></li><li><p>{% verbatim %}: 禁止render<br>  {% verbatim %}</p><pre><code>   &amp;#123;&amp;#123; hello &amp;#125;&amp;#125;</code></pre><p>  {% endverbatim %}</p></li><li><p>{% load %}: 加载标签库 </p></li></ul><p>*** 自定义filter和simple_tag（重点）</p><pre><code>a、在app中创建templatetags模块(必须的)b、创建任意 .py 文件，如：my_tags.pyc、在使用自定义simple_tag和filter的html文件中导入之前创建的 my_tags.py ：&amp;#123;% load my_tags %&amp;#125;d、使用simple_tag和filter（如何调用）e、在settings中的INSTALLED_APPS配置当前app，不然django无法找到自定义的simple_tag.注意：    filter可以用在if等语句后，simple_tag不可以</code></pre><ul><li><p>extend模板继承<br> {% include %} 。该标签允许在（模板中）包含其它的模板的内容</p><p> extend(继承)模板标签</p><p> {% block %} 我们使用模板标签： {% block %} 。 所有的 {% block %} 标签告诉模板引擎，子模板可以重载这些部分。 每个{% block %}标签所要做的是告诉模板引擎，该模板下的这一块内容将有可能被子模板覆盖</p></li></ul><pre><code>&amp;lt;1&amp;gt;如果在模板中使用 &amp;#123;% extends %&amp;#125; ，必须保证其为模板中的第一个模板标记。 否则，模板继承将不起作用。&amp;lt;2&amp;gt;一般来说，基础模板中的 &amp;#123;% block %&amp;#125; 标签越多越好。 记住，子模板不必定义父模板中所有的代码块，因此你可以用合理的缺省值对一些代码块进行填充，然后只对子模板所需的代码块进行（重）定义。 俗话说，钩子越多越好&amp;lt;3&amp;gt;如果发觉自己在多个模板之间拷贝代码，你应该考虑将该代码段放置到父模板的某个 &amp;#123;% block %&amp;#125; 中。如果你需要访问父模板中的块的内容，使用 &amp;#123;&amp;#123; block.super &amp;#125;&amp;#125;这个标签吧，这一个魔法变量将会表现出父模板中的内容。 如果只想在上级代码块基础上添加内容，而不是全部重载，该变量就显得非常有用了&amp;lt;4&amp;gt;不允许在同一个模板中定义多个同名的 &amp;#123;% block %&amp;#125; 。 存在这样的限制是因为block 标签的工作方式是双向的。也就是说，block 标签不仅挖了一个要填的坑，也定义了在父模板中这个坑所填充的内容。如果模板中出现了两个相同名称的 &amp;#123;% block %&amp;#125; 标签，父模板将无从得知要使用哪个块的内容</code></pre></code><p><code class="language-none"></code>:hexoPostRenderEscape–&gt;</p><h2 id="八、Models-即（M）"><a href="#八、Models-即（M）" class="headerlink" title="八、Models 即（M）"></a>八、Models 即（M）</h2><h4 id="1-数据库的配置"><a href="#1-数据库的配置" class="headerlink" title="1.数据库的配置"></a>1.数据库的配置</h4><pre class="language-none"><code class="language-none">1    django默认支持sqlite，mysql, oracle,postgresql数据库。    &lt;1&gt; sqlite    django默认使用sqlite的数据库，默认自带sqlite的数据库驱动 , 引擎名称：django.db.backends.sqlite3    &lt;2&gt; mysql    引擎名称：django.db.backends.mysql2    mysql驱动程序        MySQLdb(mysql python)        mysqlclient        MySQL        PyMySQL(纯python的mysql驱动程序)3  在django的项目中会默认使用MySQL数据库，在settings里有如下设置：    DATABASES = {        'default': {        'ENGINE': 'django.db.backends.mysql',         'NAME': 'books',    #你的数据库名称        'USER': 'root',   #你的数据库用户名        'PASSWORD': '', #你的数据库密码        'HOST': '', #你的数据库主机，留空默认为localhost        'PORT': '3306', #你的数据库端口        }    }    注意：        所以，我们只需要找到项目名文件下的__init__,在里面写入：        import pymysql        pymysql.install_as_MySQLdb()</code></pre><h4 id="2-ORM-对象关系映射"><a href="#2-ORM-对象关系映射" class="headerlink" title="2.ORM(对象关系映射)"></a>2.ORM(对象关系映射)</h4><p>用于实现面向对象编程语言里不同类型系统的数据之间的转换，换言之，就是用面向对象的方式去操作数据库的创建表以及增删改查等操作</p><p>优点：</p><ul><li>1 ORM使得我们的通用数据库交互变得简单易行，而且完全不用考虑该死的SQL语句。快速开发，由此而来</li><li>2 可以避免一些新手程序猿写sql语句带来的性能问题</li></ul><p>缺点：</p><ul><li>1  性能有所牺牲，不过现在的各种ORM框架都在尝试各种方法，比如缓存，延迟加载登来减轻这个问题。效果很显著</li><li>2  对于个别复杂查询，ORM仍然力不从心，为了解决这个问题，ORM一般也支持写raw sql</li><li>3  通过QuerySet的query属性查询对应操作的sql语句</li></ul><h4 id="3-表-模型-的创建"><a href="#3-表-模型-的创建" class="headerlink" title="3.表(模型)的创建"></a>3.表(模型)的创建</h4><pre class="language-none"><code class="language-none">from django.db import models&lt;br&gt;class Publisher(models.Model):    name = models.CharField(max_length=30, verbose_name="名称")    address = models.CharField("地址", max_length=50)    city = models.CharField('城市',max_length=60)    state_province = models.CharField(max_length=30)    country = models.CharField(max_length=50)    website = models.URLField()    class Meta:        verbose_name = '出版商'        verbose_name_plural = verbose_name    def __str__(self):        return self.nameclass Author(models.Model):    name = models.CharField(max_length=30)    def __str__(self):        return self.nameclass AuthorDetail(models.Model):    sex = models.BooleanField(max_length=1, choices=((0, '男'),(1, '女'),))    email = models.EmailField()    address = models.CharField(max_length=50)    birthday = models.DateField()    author = models.OneToOneField(Author)class Book(models.Model):    title = models.CharField(max_length=100)    authors = models.ManyToManyField(Author)    publisher = models.ForeignKey(Publisher)    publication_date = models.DateField()    price=models.DecimalField(max_digits=5,decimal_places=2,default=10)    def __str__(self):        return self.title</code></pre><p>分析代码：</p><p>&lt;1&gt;  每个数据模型都是django.db.models.Model的子类，它的父类Model包含了所有必要的和数据库交互的方法。并提供了一个简介漂亮的定义数据库字段的语法。</p><p>&lt;2&gt;  每个模型相当于单个数据库表（多对多关系例外，会多生成一张关系表），每个属性也是这个表中的字段。属性名就是字段名，它的类型（例如CharField）相当于数据库的字段类型（例如varchar）。大家可以留意下其它的类型都和数据库里的什么字段对应</p><p>&lt;3&gt;  模型之间的三种关系：一对一，一对多，多对多</p><pre><code>一对一：实质就是在主外键（author_id就是foreign key）的关系基础上，给外键加了一个UNIQUE＝True的属性；一对多：就是主外键关系；（foreign key）多对多：(ManyToManyField) 自动创建第三张表(当然我们也可以自己创建第三张表：两个foreign key)</code></pre><p>&lt;4&gt;  模型常用的字段类型参数</p><pre class="language-none"><code class="language-none">&lt;1&gt; CharField        #字符串字段, 用于较短的字符串.        #CharField 要求必须有一个参数 maxlength, 用于从数据库层和Django校验层限制该字段所允许的最大字符数.&lt;2&gt; IntegerField       #用于保存一个整数.&lt;3&gt; FloatField        # 一个浮点数. 必须 提供两个参数:        #        # 参数    描述        # max_digits    总位数(不包括小数点和符号)        # decimal_places    小数位数                # 举例来说, 要保存最大值为 999 (小数点后保存2位),你要这样定义字段:                #                # models.FloatField(..., max_digits=5, decimal_places=2)                # 要保存最大值一百万(小数点后保存10位)的话,你要这样定义:                #                # models.FloatField(..., max_digits=19, decimal_places=10)                # admin 用一个文本框(&lt;input type="text"&gt;)表示该字段保存的数据.&lt;4&gt; AutoField        # 一个 IntegerField, 添加记录时它会自动增长. 你通常不需要直接使用这个字段;         # 自定义一个主键：my_id=models.AutoField(primary_key=True)        # 如果你不指定主键的话,系统会自动添加一个主键字段到你的 model.&lt;5&gt; BooleanField        # A true/false field. admin 用 checkbox 来表示此类字段.&lt;6&gt; TextField        # 一个容量很大的文本字段.        # admin 用一个 &lt;textarea&gt; (文本区域)表示该字段数据.(一个多行编辑框).&lt;7&gt; EmailField        # 一个带有检查Email合法性的 CharField,不接受 maxlength 参数.&lt;8&gt; DateField        # 一个日期字段. 共有下列额外的可选参数:        # Argument    描述        # auto_now    当对象被保存时,自动将该字段的值设置为当前时间.通常用于表示 "last-modified" 时间戳.        # auto_now_add    当对象首次被创建时,自动将该字段的值设置为当前时间.通常用于表示对象创建时间.        #（仅仅在admin中有意义...)&lt;9&gt; DateTimeField        #  一个日期时间字段. 类似 DateField 支持同样的附加选项.&lt;10&gt; ImageField        # 类似 FileField, 不过要校验上传对象是否是一个合法图片.#它有两个可选参数:height_field和width_field,        # 如果提供这两个参数,则图片将按提供的高度和宽度规格保存.  &lt;11&gt; FileField     # 一个文件上传字段.     #要求一个必须有的参数: upload_to, 一个用于保存上载文件的本地文件系统路径. 这个路径必须包含 strftime #formatting,      #该格式将被上载文件的 date/time      #替换(so that uploaded files don't fill up the given directory).     # admin 用一个&lt;input type="file"&gt;部件表示该字段保存的数据(一个文件上传部件) .     #注意：在一个 model 中使用 FileField 或 ImageField 需要以下步骤:            #（1）在你的 settings 文件中, 定义一个完整路径给 MEDIA_ROOT 以便让 Django在此处保存上传文件.             # (出于性能考虑,这些文件并不保存到数据库.) 定义MEDIA_URL 作为该目录的公共 URL. 要确保该目录对             #  WEB服务器用户帐号是可写的.            #（2） 在你的 model 中添加 FileField 或 ImageField, 并确保定义了 upload_to 选项,以告诉 Django            # 使用 MEDIA_ROOT 的哪个子目录保存上传文件.你的数据库中要保存的只是文件的路径(相对于 MEDIA_ROOT).             # 出于习惯你一定很想使用 Django 提供的 get_&lt;#fieldname&gt;_url 函数.举例来说,如果你的 ImageField             # 叫作 mug_shot, 你就可以在模板中以 {{ object.#get_mug_shot_url }} 这样的方式得到图像的绝对路径.&lt;12&gt; URLField      # 用于保存 URL. 若 verify_exists 参数为 True (默认), 给定的 URL 会预先检查是否存在( 即URL是否被有效装入且      # 没有返回404响应).      # admin 用一个 &lt;input type="text"&gt; 文本框表示该字段保存的数据(一个单行编辑框)&lt;13&gt; NullBooleanField       # 类似 BooleanField, 不过允许 NULL 作为其中一个选项. 推荐使用这个字段而不要用 BooleanField 加 null=True 选项       # admin 用一个选择框 &lt;select&gt; (三个可选择的值: "Unknown", "Yes" 和 "No" ) 来表示这种字段数据.           &lt;14&gt; SlugField       # "Slug" 是一个报纸术语. slug 是某个东西的小小标记(短签), 只包含字母,数字,下划线和连字符.#它们通常用于URLs       # 若你使用 Django 开发版本,你可以指定 maxlength. 若 maxlength 未指定, Django 会使用默认长度: 50.  #在       # 以前的 Django 版本,没有任何办法改变50 这个长度.       # 这暗示了 db_index=True.       # 它接受一个额外的参数: prepopulate_from, which is a list of fields from which to auto-#populate        # the slug, via JavaScript,in the object's admin form: models.SlugField       # (prepopulate_from=("pre_name", "name"))prepopulate_from 不接受 DateTimeFields.&lt;13&gt; XMLField        #一个校验值是否为合法XML的 TextField,必须提供参数: schema_path, 它是一个用来校验文本的 RelaxNG schema #的文件系统路径.&lt;14&gt; FilePathField        # 可选项目为某个特定目录下的文件名. 支持三个特殊的参数, 其中第一个是必须提供的.        # 参数    描述        # path    必需参数. 一个目录的绝对文件系统路径. FilePathField 据此得到可选项目.         # Example: "/home/images".        # match    可选参数. 一个正则表达式, 作为一个字符串, FilePathField 将使用它过滤文件名.          # 注意这个正则表达式只会应用到 base filename 而不是        # 路径全名. Example: "foo.*\.txt^", 将匹配文件 foo23.txt 却不匹配 bar.txt 或 foo23.gif.        # recursive可选参数.要么 True 要么 False. 默认值是 False. 是否包括 path 下面的全部子目录.        # 这三个参数可以同时使用.        # match 仅应用于 base filename, 而不是路径全名. 那么,这个例子:        # FilePathField(path="/home/images", match="foo.*", recursive=True)        # ...会匹配 /home/images/foo.gif 而不匹配 /home/images/foo/bar.gif&lt;15&gt; IPAddressField        # 一个字符串形式的 IP 地址, (i.e. "24.124.1.30").&lt;16&gt;# CommaSeparatedIntegerField        # 用于存放逗号分隔的整数值. 类似 CharField, 必须要有maxlength参数.               </code></pre><p>&lt;5&gt;  Field重要参数</p><pre class="language-none"><code class="language-none">&lt;1&gt; null ： 数据库中字段是否可以为空&lt;2&gt; blank： django的 Admin 中添加数据时是否可允许空值&lt;3&gt; default：设定缺省值&lt;4&gt; editable：如果为假，admin模式下将不能改写。缺省为真&lt;5&gt; primary_key：设置主键，如果没有设置django创建表时会自动加上：    id = meta.AutoField('ID', primary_key=True)    primary_key=True implies blank=False, null=False and unique=True. Only one    primary key is allowed on an object.&lt;6&gt; unique：数据唯一&lt;7&gt; verbose_name　　Admin中字段的显示名称&lt;8&gt; validator_list：有效性检查。非有效产生 django.core.validators.ValidationError 错误&lt;9&gt; db_column，db_index 如果为真将为此字段创建索引&lt;10&gt;choices：一个用来选择值的2维元组。第一个值是实际存储的值，第二个用来方便进行选择。            如SEX_CHOICES= (( ‘F’,'Female’),(‘M’,'Male’),)            gender = models.CharField(max_length=2,choices = SEX_CHOICES)</code></pre><h4 id="4表的操作-增删改查-："><a href="#4表的操作-增删改查-：" class="headerlink" title="4表的操作(增删改查)："></a>4表的操作(增删改查)：</h4><p>一、增(create  ,  save):</p><pre class="language-none"><code class="language-none">    from app01.models import *    #create方式一:   Author.objects.create(name='Alvin')    #create方式二:   Author.objects.create(**{"name":"alex"})    #save方式一:     author=Author(name="alvin")                    author.save()    #save方式二:     author=Author()                    author.name="alvin"                    author.save()重点来了－－－－－－－&gt;那么如何创建存在一对多或多对多关系的一本书的信息呢？(如何处理外键关系的字段如一对多的publisher和多对多的authors)#一对多(ForeignKey):    #方式一: 由于绑定一对多的字段,比如publish,存到数据库中的字段名叫publish_id,所以我们可以直接给这个    #       字段设定对应值:           Book.objects.create(title='php',                               publisher_id=2,   #这里的2是指为该book对象绑定了Publisher表中id=2的行对象                               publication_date='2017-7-7',                               price=99)    #方式二:    #       &lt;1&gt; 先获取要绑定的Publisher对象:        pub_obj=Publisher(name='河大出版社',address='保定',city='保定',                state_province='河北',country='China',website='http://www.hbu.com')    OR  pub_obj=Publisher.objects.get(id=1)    #       &lt;2&gt;将 publisher_id=2 改为  publisher=pub_obj#多对多(ManyToManyField()):    author1=Author.objects.get(id=1)    author2=Author.objects.filter(name='alvin')[0]    book=Book.objects.get(id=1)    book.authors.add(author1,author2)    #等同于:    book.authors.add(*[author1,author2])    book.authors.remove(*[author1,author2])    #-------------------    book=models.Book.objects.filter(id__gt=1)    authors=models.Author.objects.filter(id=1)[0]    authors.book_set.add(*book)    authors.book_set.remove(*book)    #-------------------    book.authors.add(1)    book.authors.remove(1)    authors.book_set.add(1)    authors.book_set.remove(1)#注意: 如果第三张表是通过models.ManyToManyField()自动创建的,那么绑定关系只有上面一种方式#     如果第三张表是自己创建的:     class Book2Author(models.Model):            author=models.ForeignKey("Author")            Book=  models.ForeignKey("Book")#     那么就还有一种方式:            author_obj=models.Author.objects.filter(id=2)[0]            book_obj  =models.Book.objects.filter(id=3)[0]            s=models.Book2Author.objects.create(author_id=1,Book_id=2)            s.save()            s=models.Book2Author(author=author_obj,Book_id=1)            s.save()             </code></pre><p>二、删（delete）</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; Book.objects.filter(id=1).delete()(3, {'app01.Book_authors': 2, 'app01.Book': 1})我们表面上删除了一条信息，实际却删除了三条，因为我们删除的这本书在Book_authors表中有两条相关信息，这种删除方式就是django默认的级联删除。如果是多对多的关系： remove()和clear()方法：#正向book = models.Book.objects.filter(id=1)#删除第三张表中和女孩1关联的所有关联信息book.author.clear()        #清空与book中id=1 关联的所有数据book.author.remove(2)  #可以为idbook.author.remove(*[1,2,3,4])     #可以为列表,前面加*#反向author = models.Author.objects.filter(id=1)author.book_set.clear() #清空与boy中id=1 关联的所有数据</code></pre><p>三、改（update和save）</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; author=Author.objects.get(id=5)&gt;&gt;&gt; author.name='hello'&gt;&gt;&gt; author.save()Publisher.objects.filter(id=2).update(name="hello") # 不能用get注意：    &lt;1&gt; 第二种方式修改不能用get的原因是：update是QuerySet对象的方法，get返回的是一个model对象，它没有update方法，而filter返回的是一个QuerySet对象(filter里面的条件可能有多个条件符合，比如name＝'alvin',可能有两个name＝'alvin'的行数据)    &lt;2&gt;在“插入和更新数据”小节中，我们有提到模型的save()方法，这个方法会更新一行里的所有列。 而某些情况下，我们只需要更新行里的某几列。#---------------- update方法直接设定对应属性----------------    models.Book.objects.filter(id=3).update(title="PHP")    ##sql:    ##UPDATE "app01_book" SET "title" = 'PHP' WHERE "app01_book"."id" = 3; args=('PHP', 3)#--------------- save方法会将所有属性重新设定一遍,效率低-----------    obj=models.Book.objects.filter(id=3)[0]    obj.title="Python"    obj.save()    在这个例子里我们可以看到Django的save()方法更新了不仅仅是title列的值，还有更新了所有的列。 若title以外的列有可能会被其他的进程所改动的情况下，只更改title列显然是更加明智的。更改某一指定的列，我们可以调用结果集（QuerySet）对象的update()方法,与之等同的SQL语句变得更高效，并且不会引起竞态条件。此外，update()方法对于任何结果集（QuerySet）均有效，这意味着你可以同时更新多条记录update()方法会返回一个整型数值，表示受影响的记录条数。注意，这里因为update返回的是一个整形，所以没法用query属性；对于每次创建一个对象，想显示对应的raw sql，需要在settings加上日志记录部分：LOGGING = {    'version': 1,    'disable_existing_loggers': False,    'handlers': {        'console':{            'level':'DEBUG',            'class':'logging.StreamHandler',        },    },    'loggers': {        'django.db.backends': {            'handlers': ['console'],            'propagate': True,            'level':'DEBUG',        },    }}注意：如果是多对多的改：    obj=Book.objects.filter(id=1)[0]    author=Author.objects.filter(id__gt=2)    obj.author.clear()    obj.author.add(*author)</code></pre><p>四、查（filter，value等)<br>———-&gt;查询API：</p><pre class="language-none"><code class="language-none"># 查询相关API：#  &lt;1&gt;filter(**kwargs):      它包含了与所给筛选条件相匹配的对象#  &lt;2&gt;all():                 查询所有结果#  &lt;3&gt;get(**kwargs):         返回与所给筛选条件相匹配的对象，返回结果有且只有一个，如果符合筛选条件的对象超过一个或者没有都会抛出错误。#-----------下面的方法都是对查询的结果再进行处理:比如 objects.filter.values()--------#  &lt;4&gt;values(*field):        返回一个ValueQuerySet——一个特殊的QuerySet，运行后得到的并不是一系列 model的实例化对象，而是一个可迭代的字典序列#  &lt;5&gt;exclude(**kwargs):     它包含了与所给筛选条件不匹配的对象#  &lt;6&gt;order_by(*field):      对查询结果排序#  &lt;7&gt;reverse():             对查询结果反向排序#  &lt;8&gt;distinct():            从返回结果中剔除重复纪录#  &lt;9&gt;values_list(*field):   它与values()非常相似，它返回的是一个元组序列，values返回的是一个字典序列#  &lt;10&gt;count():              返回数据库中匹配查询(QuerySet)的对象数量。# &lt;11&gt;first():               返回第一条记录# &lt;12&gt;last():                返回最后一条记录#  &lt;13&gt;exists():             如果QuerySet包含数据，就返回True，否则返回False。#扩展查询,有时候DJANGO的查询API不能方便的设置查询条件，提供了另外的扩展查询方法extra:#extra(select=None, where=None, params=None, tables=None,order_by=None, select_params=None(1)  Entry.objects.extra(select={'is_recent': "pub_date &gt; '2006-01-01'"})(2)  Blog.objects.extra(        select=SortedDict([('a', '%s'), ('b', '%s')]),        select_params=('one', 'two'))(3)  q = Entry.objects.extra(select={'is_recent': "pub_date &gt; '2006-01-01'"})     q = q.extra(order_by = ['-is_recent'])(4)  Entry.objects.extra(where=['headline=%s'], params=['Lennon']) </code></pre><p>———-&gt;惰性机制：<br>所谓惰性机制：Publisher.objects.all()或者.filter()等都只是返回了一个QuerySet（查询结果集对象），它并不会马上执行sql，而是当调用QuerySet的时候才执行。</p><p>QuerySet特点：</p><ul><li>可迭代的</li><li>可切片</li></ul><p>QuerySet的高效使用：</p><pre class="language-none"><code class="language-none">&lt;1&gt;Django的queryset是惰性的     Django的queryset对应于数据库的若干记录（row），通过可选的查询来过滤。例如，下面的代码会得     到数据库中名字为‘Dave’的所有的人:person_set = Person.objects.filter(first_name="Dave")     上面的代码并没有运行任何的数据库查询。你可以使用person_set，给它加上一些过滤条件，或者将它传给某个函数，     这些操作都不会发送给数据库。这是对的，因为数据库查询是显著影响web应用性能的因素之一。&lt;2&gt;要真正从数据库获得数据，你可以遍历queryset或者使用if queryset,总之你用到数据时就会执行sql.   为了验证这些,需要在settings里加入 LOGGING(验证方式)        obj=models.Book.objects.filter(id=3)        # for i in obj:        #     print(i)        # if obj:        #     print("ok")&lt;3&gt;queryset是具有cache的     当你遍历queryset时，所有匹配的记录会从数据库获取，然后转换成Django的model。这被称为执行    （evaluation）.这些model会保存在queryset内置的cache中，这样如果你再次遍历这个queryset，     你不需要重复运行通用的查询。        obj=models.Book.objects.filter(id=3)        # for i in obj:        #     print(i)                          ## models.Book.objects.filter(id=3).update(title="GO")                          ## obj_new=models.Book.objects.filter(id=3)        # for i in obj:        #     print(i)   #LOGGING只会打印一次&lt;4&gt;     简单的使用if语句进行判断也会完全执行整个queryset并且把数据放入cache，虽然你并不需要这些     数据！为了避免这个，可以用exists()方法来检查是否有数据：            obj = Book.objects.filter(id=4)            #  exists()的检查可以避免数据放入queryset的cache。            if obj.exists():                print("hello world!")&lt;5&gt;当queryset非常巨大时，cache会成为问题     处理成千上万的记录时，将它们一次装入内存是很浪费的。更糟糕的是，巨大的queryset可能会锁住系统     进程，让你的程序濒临崩溃。要避免在遍历数据的同时产生queryset cache，可以使用iterator()方法     来获取数据，处理完数据就将其丢弃。        objs = Book.objects.all().iterator()        # iterator()可以一次只从数据库获取少量数据，这样可以节省内存        for obj in objs:            print(obj.name)        #BUT,再次遍历没有打印,因为迭代器已经在上一次遍历(next)到最后一次了,没得遍历了        for obj in objs:            print(obj.name)     #当然，使用iterator()方法来防止生成cache，意味着遍历同一个queryset时会重复执行查询。所以使     #用iterator()的时候要当心，确保你的代码在操作一个大的queryset时没有重复执行查询总结:    queryset的cache是用于减少程序对数据库的查询，在通常的使用下会保证只有在需要的时候才会查询数据库。使用exists()和iterator()方法可以优化程序对内存的使用。不过，由于它们并不会生成queryset cache，可能会造成额外的数据库查询。                        </code></pre><p>———-&gt;对象查询，单表条件查询，多表条件关联查询</p><pre class="language-none"><code class="language-none">#--------------------对象形式的查找--------------------------    # 正向查找    ret1=models.Book.objects.first()    print(ret1.title)    print(ret1.price)    print(ret1.publisher)    print(ret1.publisher.name)  #因为一对多的关系所以ret1.publisher是一个对象,而不是一个queryset集合    # 反向查找    ret2=models.Publish.objects.last()    print(ret2.name)    print(ret2.city)    #如何拿到与它绑定的Book对象呢?    print(ret2.book_set.all()) #ret2.book_set是一个queryset集合#---------------了不起的双下划线(__)之单表条件查询----------------#    models.Tb1.objects.filter(id__lt=10, id__gt=1)   # 获取id大于1 且 小于10的值##    models.Tb1.objects.filter(id__in=[11, 22, 33])   # 获取id等于11、22、33的数据#    models.Tb1.objects.exclude(id__in=[11, 22, 33])  # not in##    models.Tb1.objects.filter(name__contains="ven")#    models.Tb1.objects.filter(name__icontains="ven") # icontains大小写不敏感##    models.Tb1.objects.filter(id__range=[1, 2])   # 范围bettwen and##    startswith，istartswith, endswith, iendswith,#----------------了不起的双下划线(__)之多表条件关联查询---------------# 正向查找(条件)#     ret3=models.Book.objects.filter(title='Python').values('id')#     print(ret3)#[{'id': 1}]      #正向查找(条件)之一对多      ret4=models.Book.objects.filter(title='Python').values('publisher__city')      print(ret4)  #[{'publisher__city': '北京'}]      #正向查找(条件)之多对多      ret5=models.Book.objects.filter(title='Python').values('author__name')      print(ret5)      ret6=models.Book.objects.filter(author__name="alex").values('title')      print(ret6)      #注意      #正向查找的publisher__city或者author__name中的publisher,author是book表中绑定的字段      #一对多和多对多在这里用法没区别# 反向查找(条件)    #反向查找之一对多:    ret8=models.Publisher.objects.filter(book__title='Python').values('name')    print(ret8)#[{'name': '人大出版社'}]  注意,book__title中的book就是Publisher的关联表名    ret9=models.Publisher.objects.filter(book__title='Python').values('book__authors')    print(ret9)#[{'book__authors': 1}, {'book__authors': 2}]    #反向查找之多对多:    ret10=models.Author.objects.filter(book__title='Python').values('name')    print(ret10)#[{'name': 'alex'}, {'name': 'alvin'}]    #注意    #正向查找的book__title中的book是表名Book    #一对多和多对多在这里用法没区别      </code></pre><p>注意：条件查询即与对象查询对应，是指在filter，values等方法中的通过__来明确查询条件。</p><p>———-&gt;聚合查询和分组查询</p><pre class="language-none"><code class="language-none">&lt;1&gt; aggregate(*args,**kwargs):    通过对QuerySet进行计算，返回一个聚合值的字典。aggregate()中每一个参数都指定一个包含在字典中的返回值。即在查询集上生成聚合。    from django.db.models import Avg,Min,Sum,Max    从整个查询集生成统计值。比如，你想要计算所有在售书的平均价钱。Django的查询语法提供了一种方式描述所有    图书的集合。    &gt;&gt;&gt; Book.objects.all().aggregate(Avg('price'))    {'price__avg': 34.35}    aggregate()子句的参数描述了我们想要计算的聚合值，在这个例子中，是Book模型中price字段的平均值    aggregate()是QuerySet 的一个终止子句，意思是说，它返回一个包含一些键值对的字典。键的名称是聚合值的    标识符，值是计算出来的聚合值。键的名称是按照字段和聚合函数的名称自动生成出来的。如果你想要为聚合值指定    一个名称，可以向聚合子句提供它:    &gt;&gt;&gt; Book.objects.aggregate(average_price=Avg('price'))    {'average_price': 34.35}    如果你也想知道所有图书价格的最大值和最小值，可以这样查询：    &gt;&gt;&gt; Book.objects.aggregate(Avg('price'), Max('price'), Min('price'))    {'price__avg': 34.35, 'price__max': Decimal('81.20'), 'price__min': Decimal('12.99')}&lt;2&gt; annotate(*args,**kwargs):        可以通过计算查询结果中每一个对象所关联的对象集合，从而得出总计值(也可以是平均值或总和)，即为查询集的每一项生成聚合。</code></pre><p>———-&gt;F查询和Q查询<br>仅仅靠单一的关键字参数查询已经很难满足查询要求。此时Django为我们提供了F和Q查询：</p><pre class="language-none"><code class="language-none"># F 使用查询条件的值,专门取对象中某列值的操作    # from django.db.models import F    # models.Tb1.objects.update(num=F('num')+1)# Q 构建搜索条件    from django.db.models import Q    #1 Q对象(django.db.models.Q)可以对关键字参数进行封装，从而更好地应用多个查询    q1=models.Book.objects.filter(Q(title__startswith='P')).all()    print(q1)#[&lt;Book: Python&gt;, &lt;Book: Perl&gt;]    # 2、可以组合使用&amp;,|操作符，当一个操作符是用于两个Q的对象,它产生一个新的Q对象。    Q(title__startswith='P') | Q(title__startswith='J')    # 3、Q对象可以用~操作符放在前面表示否定，也可允许否定与不否定形式的组合    Q(title__startswith='P') | ~Q(pub_date__year=2005)    # 4、应用范围：    # Each lookup function that takes keyword-arguments (e.g. filter(),    #  exclude(), get()) can also be passed one or more Q objects as    # positional (not-named) arguments. If you provide multiple Q object    # arguments to a lookup function, the arguments will be “AND”ed    # together. For example:    Book.objects.get(        Q(title__startswith='P'),        Q(pub_date=date(2005, 5, 2)) | Q(pub_date=date(2005, 5, 6))    )    #sql:    # SELECT * from polls WHERE question LIKE 'P%'    #     AND (pub_date = '2005-05-02' OR pub_date = '2005-05-06')    # import datetime    # e=datetime.date(2005,5,6)  #2005-05-06    # 5、Q对象可以与关键字参数查询一起使用，不过一定要把Q对象放在关键字参数查询的前面。    # 正确：    Book.objects.get(        Q(pub_date=date(2005, 5, 2)) | Q(pub_date=date(2005, 5, 6)),        title__startswith='P')    # 错误：    Book.objects.get(        question__startswith='P',        Q(pub_date=date(2005, 5, 2)) | Q(pub_date=date(2005, 5, 6)))   </code></pre><p>—————-&gt; raw sql<br>django中models的操作,也是调用了ORM框架来实现的,pymysql 或者mysqldb,所以我们也可以使用原生的SQL语句来操作数据库!</p><p>参考文献：<a href="http://www.cnblogs.com/yuanchenqi/articles/6083427.html">http://www.cnblogs.com/yuanchenqi/articles/6083427.html</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> django </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> django </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop学习一之概述</title>
      <link href="/2018/03/27/hadoop-xue-xi-yi-zhi-gai-shu/"/>
      <url>/2018/03/27/hadoop-xue-xi-yi-zhi-gai-shu/</url>
      
        <content type="html"><![CDATA[<h2 id="大数据应用发展前景"><a href="#大数据应用发展前景" class="headerlink" title="大数据应用发展前景"></a>大数据应用发展前景</h2><p>现在大家都在讨论大数据、云计算、人工智能等，我虽然只是一个屌丝程序员，做网站后台的，我也准备学习大数据框架。从今天开始，开始第二轮学习，准备吧学习到的东西记录下来。OK，废话不多说了，Hadoop现在就业前景还比较好，工资也还OK，学习一下吧！</p><p>当然在学习这个之前、应该具备英语、liunx、shell等技能、当然能用Python更好</p><h3 id="1-HADOOP背景介绍"><a href="#1-HADOOP背景介绍" class="headerlink" title="1. HADOOP背景介绍"></a>1. HADOOP背景介绍</h3><h4 id="1-1-什么是hadoop？"><a href="#1-1-什么是hadoop？" class="headerlink" title="1.1 什么是hadoop？"></a>1.1 什么是hadoop？</h4><p>Apache Hadoop是一款支持数据密集型分布式应用并以Apache 2.0许可协议发布的开源软件框架</p><pre><code>1.    HADOOP是apache旗下的一套开源软件平台2.    HADOOP提供的功能：利用服务器集群，根据用户的自定义业务逻辑，对海量数据进行分布式处理3.    HADOOP的核心组件有    A.    HDFS（分布式文件系统）    B.    YARN（运算资源调度系统）    C.    MAPREDUCE（分布式运算编程框架）4.    广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈</code></pre><h4 id="1-2-HADOOP产生背景"><a href="#1-2-HADOOP产生背景" class="headerlink" title="1.2 HADOOP产生背景"></a>1.2 HADOOP产生背景</h4><ol><li><p>HADOOP最早起源于Nutch。Nutch的设计目标是构建一个大型的全网搜索引擎，包括网页抓取、索引、查询等功能，但随着抓取网页数量的增加，遇到了严重的可扩展性问题——如何解决数十亿网页的存储和索引问题。</p></li><li><p>2003年、2004年谷歌发表的两篇论文为该问题提供了可行的解决方案。<br>——分布式文件系统（GFS），可用于处理海量网页的存储<br>——分布式计算框架MAPREDUCE，可用于处理海量网页的索引计算问题。</p></li><li><p>Nutch的开发人员完成了相应的开源实现HDFS和MAPREDUCE，并从Nutch中剥离成为独立项目HADOOP，到2008年1月，HADOOP成为Apache顶级项目，迎来了它的快速发展期。</p></li></ol><h4 id="1-3-HADOOP在大数据、云计算中的位置和关系"><a href="#1-3-HADOOP在大数据、云计算中的位置和关系" class="headerlink" title="1.3 HADOOP在大数据、云计算中的位置和关系"></a>1.3 HADOOP在大数据、云计算中的位置和关系</h4><ol><li><p>云计算是分布式计算、并行计算、网格计算、多核计算、网络存储、虚拟化、负载均衡等传统计算机技术和互联网技术融合发展的产物。借助IaaS(基础设施即服务)、PaaS(平台即服务)、SaaS（软件即服务）等业务模式，把强大的计算能力提供给终端用户。</p></li><li><p>现阶段，云计算的两大底层支撑技术为“虚拟化”和“大数据技术”</p></li><li><p>而HADOOP则是云计算的PaaS层的解决方案之一，并不等同于PaaS，更不等同于云计算本身。</p></li></ol><h4 id="1-4-HADOOP生态圈以及各组成部分的简介"><a href="#1-4-HADOOP生态圈以及各组成部分的简介" class="headerlink" title="1.4 HADOOP生态圈以及各组成部分的简介"></a>1.4 HADOOP生态圈以及各组成部分的简介</h4><p>重点组件：<br>HDFS：分布式文件系统<br>MAPREDUCE：分布式运算程序开发框架<br>HIVE：基于大数据技术（文件系统+运算框架）的SQL数据仓库工具<br>HBASE：基于HADOOP的分布式海量数据库<br>ZOOKEEPER：分布式协调服务基础组件<br>Mahout：基于mapreduce/spark/flink等分布式运算框架的机器学习算法库<br>Oozie：工作流调度框架<br>Sqoop：数据导入导出工具<br>Flume：日志数据采集框架</p><h4 id="1-5、Hadoop项目主要包含一下几个模块"><a href="#1-5、Hadoop项目主要包含一下几个模块" class="headerlink" title="1.5、Hadoop项目主要包含一下几个模块"></a>1.5、Hadoop项目主要包含一下几个模块</h4><ul><li>hadoop common :为其他Hadoop模块提供基础设施或者说组件</li><li>hadoop HDFS：一个分布式、高性能、 高可靠的文件存储系统</li><li>hadoop MapReduce: 分布式的离线的计算框架</li><li>haoop YARN: 一个新的mapreduce框架、任务调度与资源管理</li><li>Apache HBase：分布式NoSQL列数据库，类似谷歌公司BigTable</li><li>Apache Hive：构建于hadoop之上的数据仓库，通过一种类SQL语言HiveQL为用户提供数据的归纳、查询和分析等功能。Hive最初由Facebook贡献</li><li>Apache Mahout：机器学习算法软件包</li><li>Apache Sqoop：结构化数据（如关系数据库）与Apache Hadoop之间的数据转换工具</li><li>Apache ZooKeeper：分布式锁设施，提供类似Google Chubby的功能，由Facebook贡献</li><li>Apache Avro：新的数据序列化格式与传输工具，将逐步取代Hadoop原有的IPC机制</li></ul><h4 id="1-6、HDFS系统架构图"><a href="#1-6、HDFS系统架构图" class="headerlink" title="1.6、HDFS系统架构图"></a>1.6、HDFS系统架构图</h4><p><img src="/images/20180327/1.png"></p><p>他的意思是说： HDFS仍然采用master/slave模式。主控节点仍然是NameNode，从节点仍然是多个DataNode，NameNode记录数据集的元数据。由于每个大文件load到HDFS时，都会被分割成默认64MB的数据块(Block)，且这些数据块被分散到多个DataNode中做并行处理，因此NameNode需要管理一个文件分成了哪些Block，这些Block又分散在哪些DataNode上。这些映射关系就是元数据。当DataNode上的Block发生变化时，需向NameNode报告更新元数据。客户端操作数据时，需向NameNode查询元数据，在查询到数据所在的DataNode后，直接与DataNode交互，执行读/写操作。不同的数据块Block会有多个副本(主要是为了数据安全)。Rack是机架，一份数据的多个副本可能存在不同机架的服务器上</p><h3 id="2-分布式系统概述"><a href="#2-分布式系统概述" class="headerlink" title="2.分布式系统概述"></a>2.分布式系统概述</h3><p>由于大数据技术领域的各类技术框架基本上都是分布式系统，因此，理解hadoop、storm、spark等技术框架，都需要具备基本的分布式系统概念</p><h4 id="2-1-分布式软件系统-Distributed-Software-Systems"><a href="#2-1-分布式软件系统-Distributed-Software-Systems" class="headerlink" title="2.1 分布式软件系统(Distributed Software Systems)"></a>2.1 分布式软件系统(Distributed Software Systems)</h4><ul><li>该软件系统会划分成多个子系统或模块，各自运行在不同的机器上，子系统或模块之间通过网络通信进行协作，实现最终的整体功能</li><li>比如分布式操作系统、分布式程序设计语言及其编译(解释)系统、分布式文件系统和分布式数据库系统等</li></ul><h4 id="2-2分布式软件系统举例：solrcloud"><a href="#2-2分布式软件系统举例：solrcloud" class="headerlink" title="2.2分布式软件系统举例：solrcloud"></a>2.2分布式软件系统举例：solrcloud</h4><p>A.    一个solrcloud集群通常有多台solr服务器<br>B.    每一个solr服务器节点负责存储整个索引库的若干个shard（数据分片）<br>C.    每一个shard又有多台服务器存放若干个副本互为主备用<br>D.    索引的建立和查询会在整个集群的各个节点上并发执行<br>E.    solrcloud集群作为整体对外服务，而其内部细节可对客户端透明<br>总结：利用多个节点共同协作完成一项或多项具体业务功能的系统就是分布式系统。</p><h3 id="3-离线数据分析流程介绍"><a href="#3-离线数据分析流程介绍" class="headerlink" title="3. 离线数据分析流程介绍"></a>3. 离线数据分析流程介绍</h3><p>本环节主要感受数据分析系统的宏观概念及处理流程，初步理解hadoop等框架在其中的应用环节，不用过于关注代码细节</p><h4 id="3-1需求分析"><a href="#3-1需求分析" class="headerlink" title="3.1需求分析"></a>3.1需求分析</h4><pre class="language-none"><code class="language-none">3.1.1 案例名称网站或APP点击流日志数据挖掘系统”3.1.2 案例需求描述“Web点击流日志”包含着网站运营很重要的信息，通过日志分析，我们可以知道网站的访问量，哪个网页访问人数最多，哪个网页最有价值，广告转化率、访客的来源信息，访客的终端信息等。3.1.3 数据来源本案例的数据主要由用户的点击行为记录获取方式：在页面预埋一段js程序，为页面上想要监听的标签绑定事件，只要用户点击或移动到标签，即可触发ajax请求到后台servlet程序，用log4j记录下事件信息，从而在web服务器（nginx、tomcat等）上形成不断增长的日志文件。形如：58.215.204.118 - - [18/Sep/2013:06:51:35 +0000] "GET /wp-includes/js/jquery/jquery.js?ver=1.10.2 HTTP/1.1" 304 0 "http://blog.fens.me/nodejs-socketio-chat/" "Mozilla/5.0 (Windows NT 5.1; rv:23.0) Gecko/20100101 Firefox/23.0"</code></pre><h4 id="3-2数据处理流程"><a href="#3-2数据处理流程" class="headerlink" title="3.2数据处理流程"></a>3.2数据处理流程</h4><pre class="language-none"><code class="language-none">3.2.1 流程图解析由于本案例的前提是处理海量数据，因而，流程中各环节所使用的技术则跟传统BI完全不同，后续课程都会一一讲解：1)    数据采集：定制开发采集程序，或使用开源框架FLUME2)    数据预处理：定制开发mapreduce程序运行于hadoop集群3)    数据仓库技术：基于hadoop之上的Hive4)    数据导出：基于hadoop的sqoop数据导入导出工具5)    数据可视化：定制开发web程序或使用kettle等产品6)    整个过程的流程调度：hadoop生态圈中的oozie工具或其他类似开源产品</code></pre><h3 id="4-hadoop的搭建-参考我Hadoop安装文档"><a href="#4-hadoop的搭建-参考我Hadoop安装文档" class="headerlink" title="4.hadoop的搭建　参考我Ｈａｄｏｏｐ安装文档"></a>4.hadoop的搭建　参考我Ｈａｄｏｏｐ安装文档</h3><p>测试:</p><pre class="language-none"><code class="language-none">1、上传文件到HDFS从本地上传一个文本文件到hdfs的/wordcount/input目录下[HADOOP@hdp-node-01 ~]$ HADOOP fs -mkdir -p /wordcount/input[HADOOP@hdp-node-01 ~]$ HADOOP fs -put /home/HADOOP/somewords.txt  /wordcount/input2、运行一个mapreduce程序在HADOOP安装目录下，运行一个示例mr程序cd $HADOOP_HOME/share/hadoop/mapreduce/hadoop jar mapredcue-example-2.6.1.jar wordcount /wordcount/input  /wordcount/output HDFS使用1、查看集群状态命令：   hdfs  dfsadmin  –report 也可打开web控制台查看HDFS集群信息，在浏览器打开http://hdp-node-01:50070/查看HDFS中的目录信息命令：   hadoop  fs  –ls  /上传文件命令：   hadoop  fs  -put  ./ scala-2.10.6.tgz  to  /从HDFS下载文件命令：  hadoop  fs  -get  /yarn-site.xml</code></pre><h3 id="5-MAPREDUCE使用"><a href="#5-MAPREDUCE使用" class="headerlink" title="5.MAPREDUCE使用"></a>5.MAPREDUCE使用</h3><p>mapreduce是hadoop中的分布式运算编程框架，只要按照其编程规范，只需要编写少量的业务逻辑代码即可实现一个强大的海量数据并发处理程序</p><ul><li>Demo开发——wordcount<br>&lt;!–hexoPostRenderEscape:<pre class="language-none"><code class="language-none">1、需求<br>从大量（比如T级别）文本文件中，统计出每一个单词出现的总次数</code></pre></li><code class="language-none"></code></ul><code class="language-none"><p>2、mapreduce实现思路<br>Map阶段：<br>    a)    从HDFS的源数据文件中逐行读取数据<br>    b)    将每一行数据切分出单词<br>    c)    为每一个单词构造一个键值对(单词，1)<br>    d)    将键值对发送给reduce</p></code><p><code class="language-none">Reduce阶段：<br>    a)    接收map阶段输出的单词键值对<br>    b)    将相同单词的键值对汇聚成一组<br>    c)    对每一组，遍历组中的所有“值”，累加求和，即得到每一个单词的总次数<br>    d)    将(单词，总次数)输出到HDFS的文件中</code>:hexoPostRenderEscape–&gt;</p><ul><li>具体编码实现<br>&lt;!–hexoPostRenderEscape:<pre class="language-none"><code class="language-none">(1)定义一个mapper类<br>//首先要定义四个泛型的类型<br>//keyin:  LongWritable    valuein: Text<br>//keyout: Text            valueout:IntWritable</code></pre></li><code class="language-none"></code></ul><code class="language-none"><p>public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt;{<br>    //map方法的生命周期：  框架每传一行数据就被调用一次<br>    //key :  这一行的起始点在文件中的偏移量<br>    //value: 这一行的内容<br>    @Override<br>    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {<br>        //拿到一行数据转换为string<br>        String line = value.toString();<br>        //将这一行切分出各个单词<br>        String[] words = line.split(" ");<br>        //遍历数组，输出&lt;单词，1&gt;<br>        for(String word:words){<br>            context.write(new Text(word), new IntWritable(1));<br>        }<br>    }<br>}</p><p>(2)定义一个reducer类<br>//生命周期：框架每传递进来一个kv 组，reduce方法被调用一次<br>    @Override<br>    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {<br>        //定义一个计数器<br>        int count = 0;<br>        //遍历这一组kv的所有v，累加到count中<br>        for(IntWritable value:values){<br>            count += value.get();<br>        }<br>        context.write(key, new IntWritable(count));<br>    }<br>}</p><p>(3)定义一个主类，用来描述job并提交job<br>public class WordCountRunner {<br>    //把业务逻辑相关的信息（哪个是mapper，哪个是reducer，要处理的数据在哪里，输出的结果放哪里。。。。。。）描述成一个job对象<br>    //把这个描述好的job提交给集群去运行<br>    public static void main(String[] args) throws Exception {<br>        Configuration conf = new Configuration();<br>        Job wcjob = Job.getInstance(conf);<br>        //指定我这个job所在的jar包<br>//        wcjob.setJar("/home/hadoop/wordcount.jar");<br>        wcjob.setJarByClass(WordCountRunner.class);</p><pre><code>    wcjob.setMapperClass(WordCountMapper.class);    wcjob.setReducerClass(WordCountReducer.class);    &amp;#x2F;&amp;#x2F;设置我们的业务逻辑Mapper类的输出key和value的数据类型    wcjob.setMapOutputKeyClass(Text.class);    wcjob.setMapOutputValueClass(IntWritable.class);    &amp;#x2F;&amp;#x2F;设置我们的业务逻辑Reducer类的输出key和value的数据类型    wcjob.setOutputKeyClass(Text.class);    wcjob.setOutputValueClass(IntWritable.class);    &amp;#x2F;&amp;#x2F;指定要处理的数据所在的位置    FileInputFormat.setInputPaths(wcjob, &amp;quot;hdfs:&amp;#x2F;&amp;#x2F;hdp-server01:9000&amp;#x2F;wordcount&amp;#x2F;data&amp;#x2F;big.txt&amp;quot;);    &amp;#x2F;&amp;#x2F;指定处理完成之后的结果所保存的位置    FileOutputFormat.setOutputPath(wcjob, new Path(&amp;quot;hdfs:&amp;#x2F;&amp;#x2F;hdp-server01:9000&amp;#x2F;wordcount&amp;#x2F;output&amp;#x2F;&amp;quot;));    &amp;#x2F;&amp;#x2F;向yarn集群提交这个job    boolean res &amp;#x3D; wcjob.waitForCompletion(true);    System.exit(res?0:1);&amp;#125;</code></pre></code><p><code class="language-none"></code>:hexoPostRenderEscape–&gt;</p><h3 id="6-程序打包运行"><a href="#6-程序打包运行" class="headerlink" title="6.程序打包运行"></a>6.程序打包运行</h3><pre class="language-none"><code class="language-none">1.    将程序打包2.    准备输入数据vi  /home/hadoop/test.txt    Hello tom    Hello jim    Hello ketty    Hello world    Ketty tom在hdfs上创建输入数据文件夹：    hadoop   fs  mkdir  -p  /wordcount/input将words.txt上传到hdfs上    hadoop  fs  –put  /home/hadoop/words.txt  /wordcount/input3.    将程序jar包上传到集群的任意一台服务器上4.    使用命令启动执行wordcount程序jar包    $ hadoop jar wordcount.jar cn.itcast.bigdata.mrsimple.WordCountDriver /wordcount/input /wordcount/out5.    查看执行结果$ hadoop fs –cat /wordcount/out/part-r-00000</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据学习 </category>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> big_data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python数据库之mongodb</title>
      <link href="/2018/01/02/python-shu-ju-ku-zhi-mongodb/"/>
      <url>/2018/01/02/python-shu-ju-ku-zhi-mongodb/</url>
      
        <content type="html"><![CDATA[<h2 id="1-基本操作"><a href="#1-基本操作" class="headerlink" title="1.基本操作"></a>1.基本操作</h2><h3 id="1-1环境安装"><a href="#1-1环境安装" class="headerlink" title="1.1环境安装"></a>1.1环境安装</h3><ul><li><p>下载mongodb的版本，两点注意</p><ul><li>根据业界规则，偶数为稳定版，如1.6.X，奇数为开发版，如1.7.X</li><li>32bit的mongodb最大只能存放2G的数据，64bit就没有限制</li></ul></li><li><p>到官网，选择合适的版本下载</p></li><li><p>解压</p></li></ul><p>tar -zxvf mongodb-linux-x86_64-ubuntu1604-3.4.0.tgz</p><ul><li>移动到/usr/local/目录下</li></ul><p>sudo mv -r mongodb-linux-x86_64-ubuntu1604-3.4.0/ /usr/local/mongodb</p><ul><li>将可执行文件添加到PATH路径中</li></ul><p>export PATH=/usr/local/mongodb/bin:$PATH</p><h4 id="管理mongo"><a href="#管理mongo" class="headerlink" title="管理mongo"></a>管理mongo</h4><ul><li><p>配置文件在/etc/mongod.conf</p></li><li><p>默认端口27017</p></li><li><p>启动</p></li></ul><p>sudo service mongod start</p><ul><li>停止</li></ul><p>sudo service mongod stop</p><ul><li>使用终端连接</li><li>这个shell就是mongodb的客户端，同时也是一个js的编译器</li></ul><p>mongo</p><ul><li>命令</li></ul><p>db查看当前数据库名称<br>db.stats()查看当前数据库信息</p><ul><li>终端退出连接</li></ul><p>exit<br>或ctrl+c<br>GUI：robomongo，解压后在bin目录下找到运行程序</p><h3 id="1-2数据库操作"><a href="#1-2数据库操作" class="headerlink" title="1.2数据库操作"></a>1.2数据库操作</h3><h4 id="数据库切换"><a href="#数据库切换" class="headerlink" title="数据库切换"></a>数据库切换</h4><p>查看当前数据库名称： db</p><p>查看所有数据库名称<br>列出所有在物理上存在的数据库: show dbs</p><p>切换数据库<br>如果数据库不存在，则指向数据库，但不创建，直到插入数据或创建集合时数据库才被创建: use 数据库名称</p><p>默认的数据库为test，如果你没有创建新的数据库，集合将存放在test数据库中</p><h4 id="数据库删除"><a href="#数据库删除" class="headerlink" title="数据库删除"></a>数据库删除</h4><p>删除当前指向的数据库<br>如果数据库不存在，则什么也不做<br>：db.dropDatabase()</p><h3 id="1-3-集合操作"><a href="#1-3-集合操作" class="headerlink" title="1.3 集合操作"></a>1.3 集合操作</h3><h4 id="集合创建"><a href="#集合创建" class="headerlink" title="集合创建"></a>集合创建</h4><p>语法<br>db.createCollection(name, options)</p><p>name是要创建的集合的名称<br>options是一个文档，用于指定集合的配置<br>选项​​参数是可选的，所以只需要到指定的集合名称。以下是可以使用的选项列表：<br>例1：不限制集合大小</p><p>db.createCollection(“stu”)</p><p>例2：限制集合大小，后面学会插入语句后可以查看效果<br>参数capped：默认值为false表示不设置上限，值为true表示设置上限<br>参数size：当capped值为true时，需要指定此参数，表示上限大小，当文档达到上限时，会将之前的数据覆盖，单位为字节</p><p>db.createCollection(“sub”, { capped : true, size : 10 } )</p><h4 id="查看当前数据库的集合"><a href="#查看当前数据库的集合" class="headerlink" title="查看当前数据库的集合"></a>查看当前数据库的集合</h4><p>语法<br>show collections</p><h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><p>语法<br>db.集合名称.drop()</p><h3 id="1-4数据类型"><a href="#1-4数据类型" class="headerlink" title="1.4数据类型"></a>1.4数据类型</h3><p>下表为MongoDB中常用的几种数据类型：<br>Object ID：文档ID<br>String：字符串，最常用，必须是有效的UTF-8<br>Boolean：存储一个布尔值，true或false<br>Integer：整数可以是32位或64位，这取决于服务器<br>Double：存储浮点值<br>Arrays：数组或列表，多个值存储到一个键<br>Object：用于嵌入式的文档，即一个值为一个文档<br>Null：存储Null值<br>Timestamp：时间戳<br>Date：存储当前日期或时间的UNIX时间格式</p><h4 id="object-id"><a href="#object-id" class="headerlink" title="object id"></a>object id</h4><p>每个文档都有一个属性，为_id，保证每个文档的唯一性<br>可以自己去设置_id插入文档<br>如果没有提供，那么MongoDB为每个文档提供了一个独特的_id，类型为objectID<br>objectID是一个12字节的十六进制数<br>前4个字节为当前时间戳<br>接下来3个字节的机器ID<br>接下来的2个字节中MongoDB的服务进程id<br>最后3个字节是简单的增量值</p><h3 id="1-5数据操作"><a href="#1-5数据操作" class="headerlink" title="1.5数据操作"></a>1.5数据操作</h3><h4 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h4><p>语法<br>db.集合名称.insert(document)<br>插入文档时，如果不指定_id参数，MongoDB会为文档分配一个唯一的ObjectId<br>例1<br>db.stu.insert({name:’gj’,gender:1})<br>例2<br>s1={_id:’20160101’,name:’hr’}<br>s1.gender=0<br>db.stu.insert(s1)</p><h4 id="简单查询"><a href="#简单查询" class="headerlink" title="简单查询"></a>简单查询</h4><p>语法<br>db.集合名称.find()</p><h4 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h4><p>语法<br>db.集合名称.update(<br>   <query>,<br>   <update>,<br>   {multi: <boolean>}<br>)<br>参数query:查询条件，类似sql语句update中where部分<br>参数update:更新操作符，类似sql语句update中set部分<br>参数multi:可选，默认是false，表示只更新找到的第一条记录，值为true表示把满足条件的文档全部更新<br>例3：全文档更新<br>db.stu.update({name:’hr’},{name:’mnc’})<br>例4：指定属性更新，通过操作符$set<br>db.stu.insert({name:’hr’,gender:0})<br>db.stu.update({name:’hr’},{$set:{name:’hys’}})<br>例5：修改多条匹配到的数据<br>db.stu.update({},{$set:{gender:0}},{multi:true})</boolean></update></query></p><h4 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h4><p>语法<br>db.集合名称.save(document)<br>如果文档的_id已经存在则修改，如果文档的_id不存在则添加</p><p>例6</p><p>db.stu.save({_id:’20160102’,’name’:’yk’,gender:1})<br>例7<br>db.stu.save({_id:’20160102’,’name’:’wyk’})</p><h4 id="删除-1"><a href="#删除-1" class="headerlink" title="删除"></a>删除</h4><p>语法<br>db.集合名称.remove(<br>   <query>,<br>   {<br>     justOne: <boolean><br>   }<br>)<br>参数query:可选，删除的文档的条件<br>参数justOne:可选，如果设为true或1，则只删除一条，默认false，表示删除多条<br>例8：只删除匹配到的第一条<br>db.stu.remove({gender:0},{justOne:true})<br>例9：全部删除<br>db.stu.remove({})</boolean></query></p><h3 id="1-6数据查询"><a href="#1-6数据查询" class="headerlink" title="1.6数据查询"></a>1.6数据查询</h3><h4 id="基本查询"><a href="#基本查询" class="headerlink" title="基本查询"></a>基本查询</h4><p>方法find()：查询<br>db.集合名称.find({条件文档})<br>方法findOne()：查询，只返回第一个<br>db.集合名称.findOne({条件文档})<br>方法pretty()：将结果格式化<br>db.集合名称.find({条件文档}).pretty()</p><h4 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h4><p>等于，默认是等于判断，没有运算符<br>小于$lt<br>小于或等于$lte<br>大于$gt<br>大于或等于$gte<br>不等于$ne<br>例1：查询名称等于’gj’的学生<br>db.stu.find({name:’gj’})<br>例2：查询年龄大于或等于18的学生<br>db.stu.find({age:{$gte:18}})</p><h4 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h4><p>查询时可以有多个条件，多个条件之间需要通过逻辑运算符连接<br>逻辑与：默认是逻辑与的关系<br>例3：查询年龄大于或等于18，并且性别为1的学生<br>db.stu.find({age:{$gte:18},gender:1})<br>逻辑或：使用$or<br>例4：查询年龄大于18，或性别为0的学生<br>db.stu.find({$or:[{age:{$gt:18}},{gender:1}]})<br>and和or一起使用<br>例5：查询年龄大于18或性别为0的学生，并且学生的姓名为gj<br>db.stu.find({$or:[{age:{$gte:18}},{gender:1}],name:’gj’})</p><h4 id="范围运算符"><a href="#范围运算符" class="headerlink" title="范围运算符"></a>范围运算符</h4><p>使用”$in”，”$nin” 判断是否在某个范围内<br>例6：查询年龄为18、28的学生<br>db.stu.find({age:{$in:[18,28]}})</p><h4 id="支持正则表达式"><a href="#支持正则表达式" class="headerlink" title="支持正则表达式"></a>支持正则表达式</h4><p>使用//或$regex编写正则表达式<br>例7：查询姓黄的学生<br>db.stu.find({name:/^黄/})<br>db.stu.find({name:{$regex:’^黄’}}})</p><h4 id="自定义查询"><a href="#自定义查询" class="headerlink" title="自定义查询"></a>自定义查询</h4><p>使用$where后面写一个函数，返回满足条件的数据<br>例7：查询年龄大于30的学生<br>db.stu.find({$where:function(){return this.age&gt;20}})</p><h4 id="Limit"><a href="#Limit" class="headerlink" title="Limit"></a>Limit</h4><p>方法limit()：用于读取指定数量的文档<br>语法：<br>db.集合名称.find().limit(NUMBER)<br>参数NUMBER表示要获取文档的条数<br>如果没有指定参数则显示集合中的所有文档<br>例1：查询2条学生信息<br>db.stu.find().limit(2)</p><h4 id="skip"><a href="#skip" class="headerlink" title="skip"></a>skip</h4><p>方法skip()：用于跳过指定数量的文档<br>语法：<br>db.集合名称.find().skip(NUMBER)<br>参数NUMBER表示跳过的记录条数，默认值为0<br>例2：查询从第3条开始的学生信息<br>db.stu.find().skip(2)</p><h4 id="一起使用"><a href="#一起使用" class="headerlink" title="一起使用"></a>一起使用</h4><p>方法limit()和skip()可以一起使用，不分先后顺序</p><p>创建数据集</p><pre class="language-none"><code class="language-none">for(i=0;i&lt;15;i++){db.t1.insert({_id:i})}查询第5至8条数据db.stu.find().limit(4).skip(5)或db.stu.find().skip(5).limit(4)</code></pre><h4 id="投影"><a href="#投影" class="headerlink" title="投影"></a>投影</h4><p>在查询到的返回结果中，只选择必要的字段，而不是选择一个文档的整个字段<br>如：一个文档有5个字段，需要显示只有3个，投影其中3个字段即可<br>语法：<br>参数为字段与值，值为1表示显示，值为0不显示<br>db.集合名称.find({},{字段名称:1,…})<br>对于需要显示的字段，设置为1即可，不设置即为不显示<br>特殊：对于_id列默认是显示的，如果不显示需要明确设置为0<br>例1<br>db.stu.find({},{name:1,gender:1})<br>例2<br>db.stu.find({},{_id:0,name:1,gender:1})</p><h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><p>方法sort()，用于对结果集进行排序<br>语法<br>db.集合名称.find().sort({字段:1,…})<br>参数1为升序排列<br>参数-1为降序排列<br>例1：根据性别降序，再根据年龄升序<br>db.stu.find().sort({gender:-1,age:1})</p><h4 id="统计个数"><a href="#统计个数" class="headerlink" title="统计个数"></a>统计个数</h4><p>方法count()用于统计结果集中文档条数<br>语法<br>db.集合名称.find({条件}).count()<br>也可以与为<br>db.集合名称.count({条件})<br>例1：统计男生人数<br>db.stu.find({gender:1}).count()<br>例2：统计年龄大于20的男生人数<br>db.stu.count({age:{$gt:20},gender:1})</p><h4 id="消除重复"><a href="#消除重复" class="headerlink" title="消除重复"></a>消除重复</h4><p>方法distinct()对数据进行去重<br>语法<br>db.集合名称.distinct(‘去重字段’,{条件})<br>例1:查找年龄大于18的性别（去重）<br>db.stu.distinct(‘gender’,{age:{$gt:18}})            </p><h3 id="与python交互"><a href="#与python交互" class="headerlink" title="与python交互"></a>与python交互</h3><p>点击查看官方文档<br>安装python包<br>进入虚拟环境<br>sudo pip install pymongo<br>或源码安装<br>python setup.py<br>引入包pymongo<br>import pymongo<br>连接，创建客户端<br>client=pymongo.MongoClient(“localhost”, 27017)<br>获得数据库test1<br>db=client.test1<br>获得集合stu<br>stu = db.stu<br>添加文档<br>s1={name:’gj’,age:18}<br>s1_id = stu.insert_one(s1).inserted_id<br>查找一个文档<br>s2=stu.find_one()<br>查找多个文档1<br>for cur in stu.find():<br>    print cur<br>查找多个文档2<br>cur=stu.find()<br>cur.next()<br>cur.next()<br>cur.next()<br>获取文档个数<br>print stu.count()</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python数据结构与算法二</title>
      <link href="/2018/01/01/python-shu-ju-jie-gou-yu-suan-fa-er/"/>
      <url>/2018/01/01/python-shu-ju-jie-gou-yu-suan-fa-er/</url>
      
        <content type="html"><![CDATA[<h4 id="排序与搜索"><a href="#排序与搜索" class="headerlink" title="排序与搜索"></a>排序与搜索</h4><p>排序算法（英语：Sorting algorithm）是一种能将一串数据依照特定顺序进行排列的一种算法。</p><h3 id="排序算法的稳定性"><a href="#排序算法的稳定性" class="headerlink" title="排序算法的稳定性"></a>排序算法的稳定性</h3><p>稳定性：稳定排序算法会让原本有相等键值的纪录维持相对次序。也就是如果一个排序算法是稳定的，当有两个相等键值的纪录R和S，且在原本的列表中R出现在S之前，在排序过的列表中R也将会是在S之前。</p><p>当相等的元素是无法分辨的，比如像是整数，稳定性并不是一个问题。然而，假设以下的数对将要以他们的第一个数字来排序。</p><p>(4, 1)  (3, 1)  (3, 7)（5, 6）<br>在这个状况下，有可能产生两种不同的结果，一个是让相等键值的纪录维持相对的次序，而另外一个则没有：</p><p>(3, 1)  (3, 7)  (4, 1)  (5, 6)  （维持次序）<br>(3, 7)  (3, 1)  (4, 1)  (5, 6)  （次序被改变）<br>不稳定排序算法可能会在相等的键值中改变纪录的相对次序，但是稳定排序算法从来不会如此。不稳定排序算法可以被特别地实现为稳定。作这件事情的一个方式是人工扩充键值的比较，如此在其他方面相同键值的两个对象间之比较，（比如上面的比较中加入第二个标准：第二个键值的大小）就会被决定使用在原先数据次序中的条目，当作一个同分决赛。然而，要记住这种次序通常牵涉到额外的空间负担。</p><h4 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h4><p>冒泡排序（英语：Bubble Sort）是一种简单的排序算法。它重复地遍历要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。遍历数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。</p><p>冒泡排序算法的运作如下：</p><p>比较相邻的元素。如果第一个比第二个大（升序），就交换他们两个。<br>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。<br>针对所有的元素重复以上的步骤，除了最后一个。<br>持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。</p><pre class="language-none"><code class="language-none">def bubble_sort(alist):    for j in range(len(alist)-1,0,-1):        # j表示每次遍历需要比较的次数，是逐渐减小的        for i in range(j):            if alist[i] &gt; alist[i+1]:                alist[i], alist[i+1] = alist[i+1], alist[i]li = [54,26,93,17,77,31,44,55,20]bubble_sort(li)print(li)</code></pre><h4 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h4><p>选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理如下。首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。</p><p>选择排序的主要优点与数据移动有关。如果某个元素位于正确的最终位置上，则它不会被移动。选择排序每次交换一对元素，它们当中至少有一个将被移到其最终位置上，因此对n个元素的表进行排序总共进行至多n-1次交换。在所有的完全依靠交换去移动元素的排序方法中，选择排序属于非常好的一种。</p><pre class="language-none"><code class="language-none">def selection_sort(alist):    n = len(alist)    # 需要进行n-1次选择操作    for i in range(n-1):        # 记录最小位置        min_index = i        # 从i+1位置到末尾选择出最小数据        for j in range(i+1, n):            if alist[j] &lt; alist[min_index]:                min_index = j        # 如果选择出的数据不在正确位置，进行交换        if min_index != i:            alist[i], alist[min_index] = alist[min_index], alist[i]alist = [54,226,93,17,77,31,44,55,20]selection_sort(alist)print(alist)</code></pre><h4 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h4><p>插入排序（英语：Insertion Sort）是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。</p><pre class="language-none"><code class="language-none">def insert_sort(alist):    # 从第二个位置，即下标为1的元素开始向前插入    for i in range(1, len(alist)):        # 从第i个元素开始向前比较，如果小于前一个元素，交换位置        for j in range(i, 0, -1):            if alist[j] &lt; alist[j-1]:                alist[j], alist[j-1] = alist[j-1], alist[j]alist = [54,26,93,17,77,31,44,55,20]insert_sort(alist)print(alist)</code></pre><h4 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h4><p>快速排序（英语：Quicksort），又称划分交换排序（partition-exchange sort），通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。</p><p>步骤为：</p><p>从数列中挑出一个元素，称为”基准”（pivot），<br>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。<br>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。<br>递归的最底部情形，是数列的大小是零或一，也就是永远都已经被排序好了。虽然一直递归下去，但是这个算法总会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。</p><pre class="language-none"><code class="language-none">def quick_sort(alist, start, end):    """快速排序"""    # 递归的退出条件    if start &gt;= end:        return    # 设定起始元素为要寻找位置的基准元素    mid = alist[start]    # low为序列左边的由左向右移动的游标    low = start    # high为序列右边的由右向左移动的游标    high = end    while low &lt; high:        # 如果low与high未重合，high指向的元素不比基准元素小，则high向左移动        while low &lt; high and alist[high] &gt;= mid:            high -= 1        # 将high指向的元素放到low的位置上        alist[low] = alist[high]        # 如果low与high未重合，low指向的元素比基准元素小，则low向右移动        while low &lt; high and alist[low] &lt; mid:            low += 1        # 将low指向的元素放到high的位置上        alist[high] = alist[low]        # 退出循环后，low与high重合，此时所指位置为基准元素的正确位置    # 将基准元素放到该位置    alist[low] = mid    # 对基准元素左边的子序列进行快速排序    quick_sort(alist, start, low-1)    # 对基准元素右边的子序列进行快速排序    quick_sort(alist, low+1, end)    alist = [54,26,93,17,77,31,44,55,20]    quick_sort(alist,0,len(alist)-1)    print(alist)</code></pre><h4 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h4><p>希尔排序(Shell Sort)是插入排序的一种。也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL．Shell于1959年提出而得名。 希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。</p><pre class="language-none"><code class="language-none">def shell_sort(alist):    n = len(alist)    # 初始步长    gap = n / 2    while gap &gt; 0:        # 按步长进行插入排序        for i in range(gap, n):            j = i            # 插入排序            while j&gt;=gap and alist[j-gap] &gt; alist[j]:                alist[j-gap], alist[j] = alist[j], alist[j-gap]                j -= gap        # 得到新的步长        gap = gap / 2alist = [54,26,93,17,77,31,44,55,20]shell_sort(alist)print(alist)</code></pre><h4 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h4><p>归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，再合并数组。</p><p>将数组分解最小之后，然后合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可。</p><pre class="language-none"><code class="language-none">def merge_sort(alist):    if len(alist) &lt;= 1:        return alist    # 二分分解    num = len(alist)/2    left = merge_sort(alist[:num])    right = merge_sort(alist[num:])    # 合并    return merge(left,right)def merge(left, right):    '''合并操作，将两个有序数组left[]和right[]合并成一个大的有序数组'''    #left与right的下标指针    l, r = 0, 0    result = []    while l&lt;len(left) and r&lt;len(right):        if left[l] &lt; right[r]:            result.append(left[l])            l += 1        else:            result.append(right[r])            r += 1    result += left[l:]    result += right[r:]    return result    alist = [54,26,93,17,77,31,44,55,20]    sorted_alist = mergeSort(alist)    print(sorted_alist)</code></pre><h4 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h4><p>搜索是在一个项目集合中找到一个特定项目的算法过程。搜索通常的答案是真的或假的，因为该项目是否存在。 搜索的几种常见方法：顺序查找、二分法查找、二叉树查找、哈希查找</p><h3 id="二分法查找"><a href="#二分法查找" class="headerlink" title="二分法查找"></a>二分法查找</h3><p>二分查找又称折半查找，优点是比较次数少，查找速度快，平均性能好；其缺点是要求待查表为有序表，且插入删除困难。因此，折半查找方法适用于不经常变动而查找频繁的有序列表。首先，假设表中元素是按升序排列，将表中间位置记录的关键字与查找关键字比较，如果两者相等，则查找成功；否则利用中间位置记录将表分成前、后两个子表，如果中间位置记录的关键字大于查找关键字，则进一步查找前一子表，否则进一步查找后一子表。重复以上过程，直到找到满足条件的记录，使查找成功，或直到子表不存在为止，此时查找不成功。</p><pre class="language-none"><code class="language-none">def binary_search(alist, item):    if len(alist) == 0:        return False    else:        midpoint = len(alist)//2        if alist[midpoint]==item:          return True        else:          if item&lt;alist[midpoint]:            return binary_search(alist[:midpoint],item)          else:            return binary_search(alist[midpoint+1:],item)testlist = [0, 1, 2, 8, 13, 17, 19, 32, 42,]print(binary_search(testlist, 3))print(binary_search(testlist, 13))</code></pre><h4 id="树与树算法"><a href="#树与树算法" class="headerlink" title="树与树算法"></a>树与树算法</h4><h3 id="树的概念"><a href="#树的概念" class="headerlink" title="树的概念"></a>树的概念</h3><p>树（英语：tree）是一种抽象数据类型（ADT）或是实作这种抽象数据类型的数据结构，用来模拟具有树状结构性质的数据集合。它是由n（n&gt;=1）个有限节点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点：</p><p>每个节点有零个或多个子节点；<br>没有父节点的节点称为根节点；<br>每一个非根节点有且只有一个父节点；<br>除了根节点外，每个子节点可以分为多个不相交的子树；</p><h2 id="树的术语"><a href="#树的术语" class="headerlink" title="树的术语"></a>树的术语</h2><p>节点的度：一个节点含有的子树的个数称为该节点的度；<br>树的度：一棵树中，最大的节点的度称为树的度；<br>叶节点或终端节点：度为零的节点；<br>父亲节点或父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点；<br>孩子节点或子节点：一个节点含有的子树的根节点称为该节点的子节点；<br>兄弟节点：具有相同父节点的节点互称为兄弟节点；<br>节点的层次：从根开始定义起，根为第1层，根的子节点为第2层，以此类推；<br>树的高度或深度：树中节点的最大层次；<br>堂兄弟节点：父节点在同一层的节点互为堂兄弟；<br>节点的祖先：从根到该节点所经分支上的所有节点；<br>子孙：以某节点为根的子树中任一节点都称为该节点的子孙。<br>森林：由m（m&gt;=0）棵互不相交的树的集合称为森林；</p><h2 id="树的种类"><a href="#树的种类" class="headerlink" title="树的种类"></a>树的种类</h2><p>无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树；<br>有序树：树中任意节点的子节点之间有顺序关系，这种树称为有序树；<br>二叉树：每个节点最多含有两个子树的树称为二叉树；<br>完全二叉树：对于一颗二叉树，假设其深度为d(d&gt;1)。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树，其中满二叉树的定义是所有叶节点都在最底层的完全二叉树;<br>平衡二叉树（AVL树）：当且仅当任何节点的两棵子树的高度差不大于1的二叉树；<br>排序二叉树（二叉查找树（英语：Binary Search Tree），也称二叉搜索树、有序二叉树）；<br>霍夫曼树（用于信息编码）：带权路径最短的二叉树称为哈夫曼树或最优二叉树；<br>B树：一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多余两个子树。</p><h4 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h4><h3 id="二叉树的基本概念"><a href="#二叉树的基本概念" class="headerlink" title="二叉树的基本概念"></a>二叉树的基本概念</h3><p>二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）</p><h3 id="二叉树的性质-特性"><a href="#二叉树的性质-特性" class="headerlink" title="二叉树的性质(特性)"></a>二叉树的性质(特性)</h3><p>性质1: 在二叉树的第i层上至多有2^(i-1)个结点（i&gt;0）<br>性质2: 深度为k的二叉树至多有2^k - 1个结点（k&gt;0）<br>性质3: 对于任意一棵二叉树，如果其叶结点数为N0，而度数为2的结点总数为N2，则N0=N2+1;<br>性质4:具有n个结点的完全二叉树的深度必为 log2(n+1)<br>性质5:对完全二叉树，若从上至下、从左至右编号，则编号为i 的结点，其左孩子编号必为2i，其右孩子编号必为2i＋1；其双亲的编号必为i/2（i＝1 时为根,除外）</p><h3 id="二叉树的节点表示以及树的创建"><a href="#二叉树的节点表示以及树的创建" class="headerlink" title="二叉树的节点表示以及树的创建"></a>二叉树的节点表示以及树的创建</h3><p>通过使用Node类中定义三个属性，分别为elem本身的值，还有lchild左孩子和rchild右孩子</p><pre class="language-none"><code class="language-none">class Node(object):    """节点类"""    def __init__(self, elem=-1, lchild=None, rchild=None):        self.elem = elem        self.lchild = lchild        self.rchild = rchild</code></pre><p>树的创建,创建一个树的类，并给一个root根节点，一开始为空，随后添加节点</p><pre class="language-none"><code class="language-none">class Tree(object):    """树类"""    def __init__(self, root=None):        self.root = root    def add(self, elem):        """为树添加节点"""        node = Node(elem)        #如果树是空的，则对根节点赋值        if self.root == None:            self.root = node        else:            queue = []            queue.append(self.root)            #对已有的节点进行层次遍历            while queue:                #弹出队列的第一个元素                cur = queue.pop(0)                if cur.lchild == None:                    cur.lchild = node                    return                elif cur.rchild == None:                    cur.rchild = node                    return                else:                    #如果左右子树都不为空，加入队列继续判断                    queue.append(cur.lchild)                    queue.append(cur.rchild)</code></pre><h4 id="二叉树的遍历"><a href="#二叉树的遍历" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h4><p>树的遍历是树的一种重要的运算。所谓遍历是指对树中所有结点的信息的访问，即依次对树中每个结点访问一次且仅访问一次，我们把这种对所有节点的访问称为遍历（traversal）。那么树的两种重要的遍历模式是深度优先遍历和广度优先遍历,深度优先一般用递归，广度优先一般用队列。一般情况下能用递归实现的算法大部分也能用堆栈来实现。</p><h3 id="深度优先遍历"><a href="#深度优先遍历" class="headerlink" title="深度优先遍历"></a>深度优先遍历</h3><p>对于一颗二叉树，深度优先搜索(Depth First Search)是沿着树的深度遍历树的节点，尽可能深的搜索树的分支。<br>那么深度遍历有重要的三种方法。这三种方式常被用于访问树的节点，它们之间的不同在于访问每个节点的次序不同。这三种遍历分别叫做先序遍历（preorder），中序遍历（inorder）和后序遍历（postorder）。我们来给出它们的详细定义，然后举例看看它们的应用。</p><p>先序遍历 在先序遍历中，我们先访问根节点，然后递归使用先序遍历访问左子树，再递归使用先序遍历访问右子树<br>根节点-&gt;左子树-&gt;右子树</p><pre class="language-none"><code class="language-none">def preorder(self, root):      """递归实现先序遍历"""      if root == None:          return      print root.elem      self.preorder(root.lchild)      self.preorder(root.rchild)</code></pre><p>中序遍历 在中序遍历中，我们递归使用中序遍历访问左子树，然后访问根节点，最后再递归使用中序遍历访问右子树<br>左子树-&gt;根节点-&gt;右子树</p><pre class="language-none"><code class="language-none">def inorder(self, root):      """递归实现中序遍历"""      if root == None:          return      self.inorder(root.lchild)      print root.elem      self.inorder(root.rchild)</code></pre><p>后序遍历 在后序遍历中，我们先递归使用后序遍历访问左子树和右子树，最后访问根节点<br>左子树-&gt;右子树-&gt;根节点</p><pre class="language-none"><code class="language-none">def postorder(self, root):      """递归实现后续遍历"""      if root == None:          return      self.postorder(root.lchild)      self.postorder(root.rchild)      print root.elem</code></pre><h4 id="广度优先遍历-层次遍历"><a href="#广度优先遍历-层次遍历" class="headerlink" title="广度优先遍历(层次遍历)"></a>广度优先遍历(层次遍历)</h4><p>从树的root开始，从上到下从从左到右遍历整个树的节点</p><pre class="language-none"><code class="language-none">def breadth_travel(self, root):        """利用队列实现树的层次遍历"""        if root == None:            return        queue = []        queue.append(root)        while queue:            node = queue.pop(0)            print node.elem,            if node.lchild != None:                queue.append(node.lchild)            if node.rchild != None:                queue.append(node.rchild)</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python数据结构与算法一</title>
      <link href="/2018/01/01/python-shu-ju-jie-gou-yu-suan-fa-yi/"/>
      <url>/2018/01/01/python-shu-ju-jie-gou-yu-suan-fa-yi/</url>
      
        <content type="html"><![CDATA[<h4 id="1、引入概念"><a href="#1、引入概念" class="headerlink" title="1、引入概念"></a>1、引入概念</h4><h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>先来看一道题:</p><p>如果 a+b+c=1000，且 a^2+b^2=c^2（a,b,c 为自然数），如何求出所有a、b、c可能的组合?</p><h3 id="第一次尝试"><a href="#第一次尝试" class="headerlink" title="第一次尝试"></a>第一次尝试</h3><pre class="language-none"><code class="language-none">import timestart_time = time.time()# 注意是三重循环for a in range(0, 1001):    for b in range(0, 1001):        for c in range(0, 1001):            if a**2 + b**2 == c**2 and a+b+c == 1000:                print("a, b, c: %d, %d, %d" % (a, b, c))end_time = time.time()print("elapsed: %f" % (end_time - start_time))print("complete!")</code></pre><p><strong>注意运行的时间:214.583347秒</strong></p><h4 id="算法的提出"><a href="#算法的提出" class="headerlink" title="算法的提出"></a>算法的提出</h4><h3 id="算法的概念"><a href="#算法的概念" class="headerlink" title="算法的概念"></a>算法的概念</h3><p>算法是计算机处理信息的本质，因为计算机程序本质上是一个算法来告诉计算机确切的步骤来执行一个指定的任务。一般地，当算法在处理信息时，会从输入设备或数据的存储地址读取数据，把结果写入输出设备或某个存储地址供以后再调用。</p><p><strong>算法是独立存在的一种解决问题的方法和思想。</strong></p><p>对于算法而言，实现的语言并不重要，重要的是思想。</p><p>算法可以有不同的语言描述实现版本（如C描述、C++描述、Python描述等），我们现在是在用Python语言进行描述实现。</p><h3 id="算法的五大特性"><a href="#算法的五大特性" class="headerlink" title="算法的五大特性"></a>算法的五大特性</h3><p>1.输入: 算法具有0个或多个输入<br>2.输出: 算法至少有1个或多个输出<br>3.有穷性: 算法在有限的步骤之后会自动结束而不会无限循环，并且每一个步骤可以在可接受的时间内完成<br>4.确定性：算法中的每一步都有确定的含义，不会出现二义性<br>5.可行性：算法的每一步都是可行的，也就是说每一步都能够执行有限的次数完成</p><h4 id="第二次尝试"><a href="#第二次尝试" class="headerlink" title="第二次尝试"></a>第二次尝试</h4><pre class="language-none"><code class="language-none">import timestart_time = time.time()# 注意是两重循环for a in range(0, 1001):    for b in range(0, 1001-a):        c = 1000 - a - b        if a**2 + b**2 == c**2:            print("a, b, c: %d, %d, %d" % (a, b, c))end_time = time.time()print("elapsed: %f" % (end_time - start_time))print("complete!")</code></pre><p><strong>注意运行的时间:0.182897秒</strong></p><h4 id="算法效率衡量"><a href="#算法效率衡量" class="headerlink" title="算法效率衡量"></a>算法效率衡量</h4><h3 id="执行时间反应算法效率"><a href="#执行时间反应算法效率" class="headerlink" title="执行时间反应算法效率"></a>执行时间反应算法效率</h3><p>对于同一问题，我们给出了两种解决算法，在两种算法的实现中，我们对程序执行的时间进行了测算，发现两段程序执行的时间相差悬殊（214.583347秒相比于0.182897秒），由此我们可以得出结论：<strong>实现算法程序的执行时间可以反应出算法的效率，即算法的优劣。</strong></p><h3 id="单靠时间值绝对可信吗？"><a href="#单靠时间值绝对可信吗？" class="headerlink" title="单靠时间值绝对可信吗？"></a>单靠时间值绝对可信吗？</h3><p>假设我们将第二次尝试的算法程序运行在一台配置古老性能低下的计算机中，情况会如何？很可能运行的时间并不会比在我们的电脑中运行算法一的214.583347秒快多少。</p><p><strong>单纯依靠运行的时间来比较算法的优劣并不一定是客观准确的！</strong></p><p>程序的运行离不开计算机环境（包括硬件和操作系统），这些客观原因会影响程序运行的速度并反应在程序的执行时间上。那么如何才能客观的评判一个算法的优劣呢？</p><h3 id="时间复杂度与“大O记法”"><a href="#时间复杂度与“大O记法”" class="headerlink" title="时间复杂度与“大O记法”"></a>时间复杂度与“大O记法”</h3><p>我们假定计算机执行算法每一个基本操作的时间是固定的一个时间单位，那么有多少个基本操作就代表会花费多少时间单位。算然对于不同的机器环境而言，确切的单位时间是不同的，但是对于算法进行多少个基本操作（即花费多少时间单位）在规模数量级上却是相同的，由此可以忽略机器环境的影响而客观的反应算法的时间效率。</p><p>对于算法的时间效率，我们可以用“大O记法”来表示。</p><p>“*<em>大O记法”：对于单调的整数函数f，如果存在一个整数函数g和实常数c&gt;0，使得对于充分大的n总有f(n)&lt;=c</em>g(n)，就说函数g是f的一个渐近函数（忽略常数），记为f(n)=O(g(n))。也就是说，在趋向无穷的极限意义下，函数f的增长速度受到函数g的约束，亦即函数f与函数g的特征相似。</p><p>时间复杂度：假设存在函数g，使得算法A处理规模为n的问题示例所用时间为T(n)=O(g(n))，则称O(g(n))为算法A的渐近时间复杂度，简称时间复杂度，记为T(n)**</p><h3 id="如何理解“大O记法”"><a href="#如何理解“大O记法”" class="headerlink" title="如何理解“大O记法”"></a>如何理解“大O记法”</h3><p>对于算法进行特别具体的细致分析虽然很好，但在实践中的实际价值有限。对于算法的时间性质和空间性质，最重要的是其数量级和趋势，这些是分析算法效率的主要部分。而计量算法基本操作数量的规模函数中那些常量因子可以忽略不计。例如，可以认为3n2和100n2属于同一个量级，如果两个算法处理同样规模实例的代价分别为这两个函数，就认为它们的效率“差不多”，都为n2级。</p><h3 id="最坏时间复杂度"><a href="#最坏时间复杂度" class="headerlink" title="最坏时间复杂度"></a>最坏时间复杂度</h3><p>分析算法时，存在几种可能的考虑：</p><ul><li>算法完成工作最少需要多少基本操作，即最优时间复杂度</li><li>算法完成工作最多需要多少基本操作，即最坏时间复杂度</li><li>算法完成工作平均需要多少基本操作，即平均时间复杂度</li></ul><p>对于最优时间复杂度，其价值不大，因为它没有提供什么有用信息，其反映的只是最乐观最理想的情况，没有参考价值。</p><p>对于最坏时间复杂度，提供了一种保证，表明算法在此种程度的基本操作中一定能完成工作。</p><p>对于平均时间复杂度，是对算法的一个全面评价，因此它完整全面的反映了这个算法的性质。但另一方面，这种衡量并没有保证，不是每个计算都能在这个基本操作内完成。而且，对于平均情况的计算，也会因为应用算法的实例分布可能并不均匀而难以计算。</p><p>因此，我们主要关注算法的最坏情况，亦即最坏时间复杂度。</p><h3 id="时间复杂度的几条基本计算规则"><a href="#时间复杂度的几条基本计算规则" class="headerlink" title="时间复杂度的几条基本计算规则"></a>时间复杂度的几条基本计算规则</h3><p>1.基本操作，即只有常数项，认为其时间复杂度为O(1)<br>2.顺序结构，时间复杂度按加法进行计算<br>3.循环结构，时间复杂度按乘法进行计算<br>4.分支结构，时间复杂度取最大值<br>5.判断一个算法的效率时，往往只需要关注操作数量的最高次项，其它次要项和常数项可以忽略<br>6.在没有特殊说明时，我们所分析的算法的时间复杂度都是指最坏时间复杂度</p><h3 id="常见时间复杂度"><a href="#常见时间复杂度" class="headerlink" title="常见时间复杂度"></a>常见时间复杂度</h3><table><thead><tr><th>执行次数函数举例</th><th>阶</th><th>非正式术语</th></tr></thead><tbody><tr><td>12</td><td>O(1)</td><td>常数阶</td></tr><tr><td>2n+3</td><td>O(n)</td><td>线性阶</td></tr><tr><td>3n2+2n+1</td><td>O(n2)</td><td>平方阶</td></tr><tr><td>5log2n+20</td><td>O(logn)</td><td>对数阶</td></tr><tr><td>2n+3nlog2n+19</td><td>O(nlogn)</td><td>nlogn阶</td></tr><tr><td>6n3+2n2+3n+4</td><td>O(n3)</td><td>立方阶</td></tr><tr><td>2n</td><td>O(2n)</td><td>指数阶</td></tr></tbody></table><p><strong>注意，经常将log2n（以2为底的对数）简写成logn</strong></p><p>所消耗的时间从小到大</p><p>O(1) &lt; O(logn) &lt; O(n) &lt; O(nlogn) &lt; O(n2) &lt; O(n3) &lt; O(2n) &lt; O(n!) &lt; O(nn)</p><h4 id="Python内置类型性能分析"><a href="#Python内置类型性能分析" class="headerlink" title="Python内置类型性能分析"></a>Python内置类型性能分析</h4><h3 id="timeit模块"><a href="#timeit模块" class="headerlink" title="timeit模块"></a>timeit模块</h3><p>timeit模块可以用来测试一小段Python代码的执行速度。</p><p>class timeit.Timer(stmt=’pass’, setup=’pass’, timer=<timer function="">)<br>Timer是测量小段代码执行速度的类。</timer></p><p>stmt参数是要测试的代码语句（statment）；</p><p>setup参数是运行代码时需要的设置；</p><p>timer参数是一个定时器函数，与平台有关。</p><p>timeit.Timer.timeit(number=1000000)<br>Timer类中测试语句执行速度的对象方法。number参数是测试代码时的测试次数，默认为1000000次。方法返回执行代码的平均耗时，一个float类型的秒数。</p><h3 id="list的操作测试"><a href="#list的操作测试" class="headerlink" title="list的操作测试"></a>list的操作测试</h3><pre class="language-none"><code class="language-none">def test1():   l = []   for i in range(1000):      l = l + [i]def test2():   l = []   for i in range(1000):      l.append(i)def test3():   l = [i for i in range(1000)]def test4():   l = list(range(1000))from timeit import Timert1 = Timer("test1()", "from __main__ import test1")print("concat ",t1.timeit(number=1000), "seconds")t2 = Timer("test2()", "from __main__ import test2")print("append ",t2.timeit(number=1000), "seconds")t3 = Timer("test3()", "from __main__ import test3")print("comprehension ",t3.timeit(number=1000), "seconds")t4 = Timer("test4()", "from __main__ import test4")print("list range ",t4.timeit(number=1000), "seconds")# ('concat ', 1.7890608310699463, 'seconds')# ('append ', 0.13796091079711914, 'seconds')# ('comprehension ', 0.05671119689941406, 'seconds')# ('list range ', 0.014147043228149414, 'seconds')</code></pre><h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><p>我们如何用Python中的类型来保存一个班的学生信息？ 如果想要快速的通过学生姓名获取其信息呢？</p><p>实际上当我们在思考这个问题的时候，我们已经用到了数据结构。列表和字典都可以存储一个班的学生信息，但是想要在列表中获取一名同学的信息时，就要遍历这个列表，其时间复杂度为O(n)，而使用字典存储时，可将学生姓名作为字典的键，学生信息作为值，进而查询时不需要遍历便可快速获取到学生信息，其时间复杂度为O(1)。</p><p>我们为了解决问题，需要将数据保存下来，然后根据数据的存储方式来设计算法实现进行处理，那么数据的存储方式不同就会导致需要不同的算法进行处理。我们希望算法解决问题的效率越快越好，于是我们就需要考虑数据究竟如何保存的问题，这就是数据结构。</p><p>在上面的问题中我们可以选择Python中的列表或字典来存储学生信息。列表和字典就是Python内建帮我们封装好的两种数据结构。</p><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>数据是一个抽象的概念，将其进行分类后得到程序设计语言中的基本类型。如：int，float，char等。数据元素之间不是独立的，存在特定的关系，这些关系便是结构。数据结构指数据对象中数据元素之间的关系。</p><p>Python给我们提供了很多现成的数据结构类型，这些系统自己定义好的，不需要我们自己去定义的数据结构叫做Python的内置数据结构，比如列表、元组、字典。而有些数据组织方式，Python系统里面没有直接定义，需要我们自己去定义实现这些数据的组织方式，这些数据组织方式称之为Python的扩展数据结构，比如栈，队列等。</p><h4 id="算法与数据结构的区别"><a href="#算法与数据结构的区别" class="headerlink" title="算法与数据结构的区别"></a>算法与数据结构的区别</h4><p>数据结构只是静态的描述了数据元素之间的关系。</p><p>高效的程序需要在数据结构的基础上设计和选择算法。</p><p>程序 = 数据结构 + 算法</p><p><strong>总结：算法是为了解决实际问题而设计的，数据结构是算法需要处理的问题载体</strong></p><h4 id="抽象数据类型-Abstract-Data-Type"><a href="#抽象数据类型-Abstract-Data-Type" class="headerlink" title="抽象数据类型(Abstract Data Type)"></a>抽象数据类型(Abstract Data Type)</h4><p>抽象数据类型(ADT)的含义是指一个数学模型以及定义在此数学模型上的一组操作。即把数据类型和数据类型上的运算捆在一起，进行封装。引入抽象数据类型的目的是把数据类型的表示和数据类型上运算的实现与这些数据类型和运算在程序中的引用隔开，使它们相互独立。</p><p>最常用的数据运算有五种：</p><ul><li>插入</li><li>删除</li><li>修改</li><li>查找</li><li>排序</li></ul><h4 id="顺序表"><a href="#顺序表" class="headerlink" title="顺序表"></a>顺序表</h4><p>在程序中，经常需要将一组（通常是同为某个类型的）数据元素作为整体管理和使用，需要创建这种元素组，用变量记录它们，传进传出函数等。一组数据中包含的元素个数可能发生变化（可以增加或删除元素）。</p><p>对于这种需求，最简单的解决方案便是将这样一组元素看成一个序列，用元素在序列里的位置和顺序，表示实际应用中的某种有意义的信息，或者表示数据之间的某种关系。</p><p>这样的一组序列元素的组织形式，我们可以将其抽象为线性表。一个线性表是某类元素的一个集合，还记录着元素之间的一种顺序关系。线性表是最基本的数据结构之一，在实际程序中应用非常广泛，它还经常被用作更复杂的数据结构的实现基础。</p><p>根据线性表的实际存储方式，分为两种实现模型：</p><p>顺序表，将元素顺序地存放在一块连续的存储区里，元素间的顺序关系由它们的存储顺序自然表示。<br>链表，将元素存放在通过链接构造起来的一系列存储块中。</p><h3 id="顺序表的基本形式"><a href="#顺序表的基本形式" class="headerlink" title="顺序表的基本形式"></a>顺序表的基本形式</h3><p>图a表示的是顺序表的基本形式，数据元素本身连续存储，每个元素所占的存储单元大小固定相同，元素的下标是其逻辑地址，而元素存储的物理地址（实际内存地址）可以通过存储区的起始地址Loc (e0)加上逻辑地址（第i个元素）与存储单元大小（c）的乘积计算而得，即：</p><p>Loc(ei) = Loc(e0) + c*i</p><p>故，访问指定元素时无需从头遍历，通过计算便可获得对应地址，其时间复杂度为O(1)。</p><p>如果元素的大小不统一，则须采用图b的元素外置的形式，将实际数据元素另行存储，而顺序表中各单元位置保存对应元素的地址信息（即链接）。由于每个链接所需的存储量相同，通过上述公式，可以计算出元素链接的存储位置，而后顺着链接找到实际存储的数据元素。注意，图b中的c不再是数据元素的大小，而是存储一个链接地址所需的存储量，这个量通常很小。</p><p>图b这样的顺序表也被称为对实际数据的索引，这是最简单的索引结构。</p><h4 id="Python中的顺序表"><a href="#Python中的顺序表" class="headerlink" title="Python中的顺序表"></a>Python中的顺序表</h4><p>Python中的list和tuple两种类型采用了顺序表的实现技术，具有前面讨论的顺序表的所有性质。</p><p>tuple是不可变类型，即不变的顺序表，因此不支持改变其内部状态的任何操作，而其他方面，则与list的性质类似。</p><h3 id="list的基本实现技术"><a href="#list的基本实现技术" class="headerlink" title="list的基本实现技术"></a>list的基本实现技术</h3><p>Python标准类型list就是一种元素个数可变的线性表，可以加入和删除元素，并在各种操作中维持已有元素的顺序（即保序），而且还具有以下行为特征：</p><p>基于下标（位置）的高效元素访问和更新，时间复杂度应该是O(1)；</p><p>为满足该特征，应该采用顺序表技术，表中元素保存在一块连续的存储区中。</p><p>允许任意加入元素，而且在不断加入元素的过程中，表对象的标识（函数id得到的值）不变。</p><p>为满足该特征，就必须能更换元素存储区，并且为保证更换存储区时list对象的标识id不变，只能采用分离式实现技术。</p><p>在Python的官方实现中，list就是一种采用分离式技术实现的动态顺序表。这就是为什么用list.append(x) （或 list.insert(len(list), x)，即尾部插入）比在指定位置插入元素效率高的原因。</p><p>在Python的官方实现中，list实现采用了如下的策略：在建立空表（或者很小的表）时，系统分配一块能容纳8个元素的存储区；在执行插入操作（insert或append）时，如果元素存储区满就换一块4倍大的存储区。但如果此时的表已经很大（目前的阀值为50000），则改变策略，采用加一倍的方法。引入这种改变策略的方式，是为了避免出现过多空闲的存储位置。</p><h4 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h4><h3 id="为什么需要链表"><a href="#为什么需要链表" class="headerlink" title="为什么需要链表"></a>为什么需要链表</h3><p>顺序表的构建需要预先知道数据大小来申请连续的存储空间，而在进行扩充时又需要进行数据的搬迁，所以使用起来并不是很灵活。</p><p>链表结构可以充分利用计算机内存空间，实现灵活的内存动态管理。</p><h3 id="链表的定义"><a href="#链表的定义" class="headerlink" title="链表的定义"></a>链表的定义</h3><p>链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是不像顺序表一样连续存储数据，而是在每一个节点（数据存储单元）里存放下一个节点的位置信息（即地址）。</p><h3 id="单向链表"><a href="#单向链表" class="headerlink" title="单向链表"></a>单向链表</h3><p>单向链表也叫单链表，是链表中最简单的一种形式，它的每个节点包含两个域，一个信息域（元素域）和一个链接域。这个链接指向链表中的下一个节点，而最后一个节点的链接域则指向一个空值。</p><p>表元素域elem用来存放具体的数据。<br>链接域next用来存放下一个节点的位置（python中的标识）<br>变量p指向链表的头节点（首节点）的位置，从p出发能找到表中的任意节点。</p><h3 id="节点实现"><a href="#节点实现" class="headerlink" title="节点实现"></a>节点实现</h3><pre class="language-none"><code class="language-none">class SingleNode(object):    """单链表的结点"""    def __init__(self,item):        # _item存放数据元素        self.item = item        # _next是下一个节点的标识        self.next = None</code></pre><p>单链表的操作<br>is_empty() 链表是否为空<br>length() 链表长度<br>travel() 遍历整个链表<br>add(item) 链表头部添加元素<br>append(item) 链表尾部添加元素<br>insert(pos, item) 指定位置添加元素<br>remove(item) 删除节点<br>search(item) 查找节点是否存在</p><h4 id="单链表的实现"><a href="#单链表的实现" class="headerlink" title="单链表的实现"></a>单链表的实现</h4><pre class="language-none"><code class="language-none">class SingleLinkList(object):    """单链表"""    def __init__(self):        self._head = None    def is_empty(self):        """判断链表是否为空"""        return self._head == None    def length(self):        """链表长度"""        # cur初始时指向头节点        cur = self._head        count = 0        # 尾节点指向None，当未到达尾部时        while cur != None:            count += 1            # 将cur后移一个节点            cur = cur.next        return count    def travel(self):        """遍历链表"""        cur = self._head        while cur != None:            print cur.item,            cur = cur.next        print ""</code></pre><h2 id="头部添加元素"><a href="#头部添加元素" class="headerlink" title="头部添加元素"></a>头部添加元素</h2><pre class="language-none"><code class="language-none">def add(self, item):        """头部添加元素"""        # 先创建一个保存item值的节点        node = SingleNode(item)        # 将新节点的链接域next指向头节点，即_head指向的位置        node.next = self._head        # 将链表的头_head指向新节点        self._head = node</code></pre><p>##尾部添加元素</p><pre class="language-none"><code class="language-none">def append(self, item):        """尾部添加元素"""        node = SingleNode(item)        # 先判断链表是否为空，若是空链表，则将_head指向新节点        if self.is_empty():            self._head = node        # 若不为空，则找到尾部，将尾节点的next指向新节点        else:            cur = self._head            while cur.next != None:                cur = cur.next            cur.next = node</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python正则表达式</title>
      <link href="/2018/01/01/python-zheng-ze-biao-da-shi/"/>
      <url>/2018/01/01/python-zheng-ze-biao-da-shi/</url>
      
        <content type="html"><![CDATA[<h4 id="一、正则表达式概述"><a href="#一、正则表达式概述" class="headerlink" title="一、正则表达式概述"></a>一、正则表达式概述</h4><p>正则表达式，又称正规表示式、正规表示法、正规表达式、规则表达式、常规表示法（英语：Regular Expression，在代码中常简写为regex、regexp或RE），是计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。</p><p>Regular Expression的“Regular”一般被译为“正则”、“正规”、“常规”。此处的“Regular”即是“规则”、“规律”的意思，Regular Expression即“描述某种规则的表达式”之意。</p><h4 id="二、re模块操作"><a href="#二、re模块操作" class="headerlink" title="二、re模块操作"></a>二、re模块操作</h4><p>在Python中需要通过正则表达式对字符串进行匹配的时候，可以使用一个模块，名字为re</p><h3 id="1-re模块的使用过程"><a href="#1-re模块的使用过程" class="headerlink" title="1. re模块的使用过程"></a>1. re模块的使用过程</h3><pre class="language-none"><code class="language-none">#coding=utf-8   # 导入re模块   import re   # 使用match方法进行匹配操作   result = re.match(正则表达式,要匹配的字符串)   # 如果上一步匹配到数据的话，可以使用group方法来提取数据   result.group()</code></pre><p>re.match是用来进行正则匹配检查的方法，若字符串匹配正则表达式，则match方法返回匹配对象（Match Object），否则返回None（注意不是空字符串””）。<br>匹配对象Macth Object具有group方法，用来返回字符串的匹配部分。</p><h3 id="2-re模块示例-匹配以itcast开头的语句"><a href="#2-re模块示例-匹配以itcast开头的语句" class="headerlink" title="2. re模块示例(匹配以itcast开头的语句)"></a>2. re模块示例(匹配以itcast开头的语句)</h3><pre class="language-none"><code class="language-none">#coding=utf-8   import re   result = re.match("itcast","itcast.cn")   result.group()运行结果为：itcast</code></pre><h3 id="3-说明"><a href="#3-说明" class="headerlink" title="3. 说明"></a>3. 说明</h3><ul><li>re.match() 能够匹配出以xxx开头的字符串</li></ul><h3 id="三、表示字符"><a href="#三、表示字符" class="headerlink" title="三、表示字符"></a>三、表示字符</h3><p>re模块能够完成使用正则表达式来匹配字符串  正则表达式的单字符匹配</p><table><thead><tr><th>字符</th><th>功能</th></tr></thead><tbody><tr><td>.</td><td>匹配任意1个字符（除了\n）</td></tr><tr><td>[ ]</td><td>匹配[ ]中列举的字符</td></tr><tr><td>\d</td><td>匹配数字，即0-9</td></tr><tr><td>\D</td><td>匹配非数字，即不是数字</td></tr><tr><td>\s</td><td>匹配空白，即 空格，tab键</td></tr><tr><td>\S</td><td>匹配非空白</td></tr><tr><td>\w</td><td>匹配单词字符，即a-z、A-Z、0-9、_</td></tr><tr><td>\W</td><td>匹配非单词字符</td></tr></tbody></table><h3 id="示例1："><a href="#示例1：" class="headerlink" title="示例1： ."></a>示例1： .</h3><pre class="language-none"><code class="language-none">#coding=utf-8   import re   ret = re.match(".","a")   ret.group()   ret = re.match(".","b")   ret.group()   ret = re.match(".","M")   ret.group()</code></pre><h3 id="示例2："><a href="#示例2：" class="headerlink" title="示例2：[ ]"></a>示例2：[ ]</h3><pre class="language-none"><code class="language-none">#coding=utf-8    import re    # 如果hello的首字符小写，那么正则表达式需要小写的h    ret = re.match("h","hello Python")    ret.group()    # 如果hello的首字符大写，那么正则表达式需要大写的H    ret = re.match("H","Hello Python")    ret.group()    # 大小写h都可以的情况    ret = re.match("[hH]","hello Python")    ret.group()    ret = re.match("[hH]","Hello Python")    ret.group()    # 匹配0到9第一种写法    ret = re.match("[0123456789]","7Hello Python")    ret.group()    # 匹配0到9第二种写法    ret = re.match("[0-9]","7Hello Python")    ret.group()</code></pre><h3 id="示例3：-d"><a href="#示例3：-d" class="headerlink" title="示例3：\d"></a>示例3：\d</h3><pre class="language-none"><code class="language-none">#coding=utf-8    import re    # 普通的匹配方式    ret = re.match("嫦娥1号","嫦娥1号发射成功")    print ret.group()    ret = re.match("嫦娥2号","嫦娥2号发射成功")    print ret.group()    ret = re.match("嫦娥3号","嫦娥3号发射成功")    print ret.group()    # 使用\d进行匹配    ret = re.match("嫦娥\d号","嫦娥1号发射成功")    print ret.group()    ret = re.match("嫦娥\d号","嫦娥2号发射成功")    print ret.group()    ret = re.match("嫦娥\d号","嫦娥3号发射成功")    print ret.group()</code></pre><h4 id="四、原始字符串"><a href="#四、原始字符串" class="headerlink" title="四、原始字符串"></a>四、原始字符串</h4><p>Python中字符串前面加上 r 表示原生字符串，</p><p>与大多数编程语言相同，正则表达式里使用”"作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符”"，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\“：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。</p><p>Python里的原生字符串很好地解决了这个问题，有了原始字符串，你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; ret = re.match(r"c:\\a",mm).group()&gt;&gt;&gt; print(ret)c:\a</code></pre><h4 id="五、表示数量"><a href="#五、表示数量" class="headerlink" title="五、表示数量"></a>五、表示数量</h4><p>匹配多个字符的相关格式</p><table><thead><tr><th>字符</th><th>功能</th></tr></thead><tbody><tr><td>*</td><td>匹配前一个字符出现0次或者无限次，即可有可无</td></tr><tr><td>+</td><td>匹配前一个字符出现1次或者无限次，即至少有1次</td></tr><tr><td>?</td><td>匹配前一个字符出现1次或者0次，即要么有1次，要么没有</td></tr><tr><td>{m}</td><td>匹配前一个字符出现m次</td></tr><tr><td>{m,}</td><td>匹配前一个字符至少出现m次</td></tr><tr><td>{m,n}</td><td>匹配前一个字符出现从m到n次</td></tr></tbody></table><h3 id="示例1：-1"><a href="#示例1：-1" class="headerlink" title="示例1：*"></a>示例1：*</h3><p>需求：匹配出，一个字符串第一个字母为大小字符，后面都是小写字母并且这些小写字母可有可无、</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.match("[A-Z][a-z]*","Mm")ret.group()ret = re.match("[A-Z][a-z]*","Aabcdef")ret.group()</code></pre><h3 id="示例2：-1"><a href="#示例2：-1" class="headerlink" title="示例2：+"></a>示例2：+</h3><p>需求：匹配出，变量名是否有效</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.match("[a-zA-Z_]+[\w_]*","name1")ret.group()ret = re.match("[a-zA-Z_]+[\w_]*","_name")ret.group()ret = re.match("[a-zA-Z_]+[\w_]*","2_name")ret.group()</code></pre><h3 id="示例3："><a href="#示例3：" class="headerlink" title="示例3：?"></a>示例3：?</h3><p>需求：匹配出，0到99之间的数字</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.match("[1-9]?[0-9]","7")ret.group()ret = re.match("[1-9]?[0-9]","33")ret.group()ret = re.match("[1-9]?[0-9]","09")ret.group()</code></pre><h3 id="示例4：-m"><a href="#示例4：-m" class="headerlink" title="示例4：{m}"></a>示例4：{m}</h3><p>需求：匹配出，8到20位的密码，可以是大小写英文字母、数字、下划线</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.match("[a-zA-Z0-9_]{6}","12a3g45678")ret.group()ret = re.match("[a-zA-Z0-9_]{8,20}","1ad12f23s34455ff66")ret.group()</code></pre><h4 id="六、表示边界"><a href="#六、表示边界" class="headerlink" title="六、表示边界"></a>六、表示边界</h4><table><thead><tr><th>字符</th><th>功能</th></tr></thead><tbody><tr><td>^</td><td>匹配字符串开头</td></tr><tr><td>$</td><td>匹配字符串结尾</td></tr><tr><td>\b</td><td>匹配一个单词的边界</td></tr><tr><td>\B</td><td>匹配非单词边界</td></tr></tbody></table><h3 id="示例1：-2"><a href="#示例1：-2" class="headerlink" title="示例1：$"></a>示例1：$</h3><p>需求：匹配163.com的邮箱地址</p><pre class="language-none"><code class="language-none">#coding=utf-8import re# 正确的地址ret = re.match("[\w]{4,20}@163\.com", "xiaoWang@163.com")ret.group()# 不正确的地址ret = re.match("[\w]{4,20}@163\.com", "xiaoWang@163.comheihei")ret.group()# 通过$来确定末尾ret = re.match("[\w]{4,20}@163\.com$", "xiaoWang@163.comheihei")ret.group()</code></pre><h4 id="七、匹配分组"><a href="#七、匹配分组" class="headerlink" title="七、匹配分组"></a>七、匹配分组</h4><table><thead><tr><th>字符</th><th>功能</th></tr></thead><tbody><tr><td></td><td></td></tr><tr><td>(ab)</td><td>将括号中字符作为一个分组</td></tr><tr><td>\num</td><td>引用分组num匹配到的字符串</td></tr><tr><td>(?P<name>)</name></td><td>分组起别名</td></tr><tr><td>(?P=name)</td><td>引用别名为name分组匹配到的字符串</td></tr></tbody></table><h3 id="示例1：-3"><a href="#示例1：-3" class="headerlink" title="示例1：|"></a>示例1：|</h3><p>需求：匹配出0-100之间的数字</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.match("[1-9]?\d","8")ret.group()ret = re.match("[1-9]?\d","78")ret.group()# 不正确的情况ret = re.match("[1-9]?\d","08")ret.group()# 修正之后的ret = re.match("[1-9]?\d$","08")ret.group()# 添加|ret = re.match("[1-9]?\d$|100","8")ret.group()ret = re.match("[1-9]?\d$|100","78")ret.group()ret = re.match("[1-9]?\d$|100","08")ret.group()ret = re.match("[1-9]?\d$|100","100")ret.group()</code></pre><h3 id="示例2：-2"><a href="#示例2：-2" class="headerlink" title="示例2：( )"></a>示例2：( )</h3><p>示例2：( )</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.match("\w{4,20}@163\.com", "test@163.com")ret.group()ret = re.match("\w{4,20}@(163|126|qq)\.com", "test@126.com")ret.group()ret = re.match("\w{4,20}@(163|126|qq)\.com", "test@qq.com")ret.group()ret = re.match("\w{4,20}@(163|126|qq)\.com", "test@gmail.com")ret.group()</code></pre><h3 id="示例3：-1"><a href="#示例3：-1" class="headerlink" title="示例3：\"></a>示例3：\</h3><ul><li>需求：匹配出hh</li></ul><pre class="language-none"><code class="language-none">#coding=utf-8import re# 能够完成对正确的字符串的匹配ret = re.match("&lt;[a-zA-Z]*&gt;\w*&lt;/[a-zA-Z]*&gt;", "&lt;html&gt;hh&lt;/html&gt;")ret.group()# 如果遇到非正常的html格式字符串，匹配出错ret = re.match("&lt;[a-zA-Z]*&gt;\w*&lt;/[a-zA-Z]*&gt;", "&lt;html&gt;hh&lt;/htmlbalabala&gt;")ret.group()# 正确的理解思路：如果在第一对&lt;&gt;中是什么，按理说在后面的那对&lt;&gt;中就应该是什么# 通过引用分组中匹配到的数据即可，但是要注意是元字符串，即类似 r""这种格式ret = re.match(r"&lt;([a-zA-Z]*)&gt;\w*&lt;/\1&gt;", "&lt;html&gt;hh&lt;/html&gt;")ret.group()# 因为2对&lt;&gt;中的数据不一致，所以没有匹配出来ret = re.match(r"&lt;([a-zA-Z]*)&gt;\w*&lt;/\1&gt;", "&lt;html&gt;hh&lt;/htmlbalabala&gt;")ret.group()</code></pre><h3 id="示例4：-number"><a href="#示例4：-number" class="headerlink" title="示例4：\number"></a>示例4：\number</h3><p>需求：匹配出<code>&lt;html&gt;&lt;h1&gt;www.itcast.cn&lt;/h1&gt;&lt;/html&gt;</code></p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.match(r"&lt;(\w*)&gt;&lt;(\w*)&gt;.*&lt;/\2&gt;&lt;/\1&gt;", "&lt;html&gt;&lt;h1&gt;www.itcast.cn&lt;/h1&gt;&lt;/html&gt;")ret.group()ret = re.match(r"&lt;(\w*)&gt;&lt;(\w*)&gt;.*&lt;/\2&gt;&lt;/\1&gt;", "&lt;html&gt;&lt;h1&gt;www.itcast.cn&lt;/h2&gt;&lt;/html&gt;")ret.group()</code></pre><h3 id="示例5：-P-P-name"><a href="#示例5：-P-P-name" class="headerlink" title="示例5：(?P) (?P=name)"></a>示例5：(?P<name>) (?P=name)</name></h3><p>需求：匹配出<code>&lt;html&gt;&lt;h1&gt;www.itcast.cn&lt;/h1&gt;&lt;/html&gt;</code></p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.match(r"&lt;(?P&lt;name1&gt;\w*)&gt;&lt;(?P&lt;name2&gt;\w*)&gt;.*&lt;/(?P=name2)&gt;&lt;/(?P=name1)&gt;", "&lt;html&gt;&lt;h1&gt;www.itcast.cn&lt;/h1&gt;&lt;/html&gt;")ret.group()ret = re.match(r"&lt;(?P&lt;name1&gt;\w*)&gt;&lt;(?P&lt;name2&gt;\w*)&gt;.*&lt;/(?P=name2)&gt;&lt;/(?P=name1)&gt;", "&lt;html&gt;&lt;h1&gt;www.itcast.cn&lt;/h2&gt;&lt;/html&gt;")ret.group()</code></pre><h4 id="八、re模块的高级用法"><a href="#八、re模块的高级用法" class="headerlink" title="八、re模块的高级用法"></a>八、re模块的高级用法</h4><p>search<br>需求：匹配出文章阅读的次数</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.search(r"\d+", "阅读次数为 9999")ret.group()</code></pre><p>findall<br>需求：统计出python、c、c++相应文章阅读的次数</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.findall(r"\d+", "python = 9999, c = 7890, c++ = 12345")print ret</code></pre><p>sub 将匹配到的数据进行替换<br>需求：将匹配到的阅读次数加1</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.sub(r"\d+", '998', "python = 997")print ret</code></pre><p>split 根据匹配进行切割字符串，并返回一个列表<br>需求：切割字符串“info:xiaoZhang 33 shandong”</p><pre class="language-none"><code class="language-none">#coding=utf-8import reret = re.split(r":| ","info:xiaoZhang 33 shandong")print ret</code></pre><h4 id="九、python贪婪和非贪婪"><a href="#九、python贪婪和非贪婪" class="headerlink" title="九、python贪婪和非贪婪"></a>九、python贪婪和非贪婪</h4><p>Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；</p><p>非贪婪则相反，总是尝试匹配尽可能少的字符。</p><p>在”*”,”?”,”+”,”{m,n}”后面加上？，使贪婪变成非贪婪。</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; s="This is a number 234-235-22-423"&gt;&gt;&gt; r=re.match(".+(\d+-\d+-\d+-\d+)",s)&gt;&gt;&gt; r.group(1)'4-235-22-423'&gt;&gt;&gt; r=re.match(".+?(\d+-\d+-\d+-\d+)",s)&gt;&gt;&gt; r.group(1)'234-235-22-423'&gt;&gt;&gt;</code></pre><p>正则表达式模式中使用到通配字，那它在从左到右的顺序求值时，会尽量“抓取”满足匹配最长字符串，在我们上面的例子里面，“.+”会从字符串的启始处抓取满足模式的最长字符，其中包括我们想得到的第一个整型字段的中的大部分，“\d+”只需一位字符就可以匹配，所以它匹配了数字“4”，而“.+”则匹配了从字符串起始到这个第一位数字4之前的所有字符。</p><p>解决方式：非贪婪操作符“？”，这个操作符可以用在”*”,”+”,”?”的后面，要求正则匹配的越少越好。</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; re.match(r"aa(\d+)","aa2343ddd").group(1)'2343'&gt;&gt;&gt; re.match(r"aa(\d+?)","aa2343ddd").group(1)'2'&gt;&gt;&gt; re.match(r"aa(\d+)ddd","aa2343ddd").group(1) '2343'&gt;&gt;&gt; re.match(r"aa(\d+?)ddd","aa2343ddd").group(1)'2343'&gt;&gt;&gt;</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python网络编程-TCP</title>
      <link href="/2017/11/28/python-wang-luo-bian-cheng-tcp/"/>
      <url>/2017/11/28/python-wang-luo-bian-cheng-tcp/</url>
      
        <content type="html"><![CDATA[<h3 id="tcp服务器"><a href="#tcp服务器" class="headerlink" title="tcp服务器"></a>tcp服务器</h3><h4 id="生活中的电话机"><a href="#生活中的电话机" class="headerlink" title="生活中的电话机"></a>生活中的电话机</h4><p>如果想让别人能更够打通咱们的电话获取相应服务的话，需要做一下几件事情：</p><p>买个手机<br>插上手机卡<br>设计手机为正常接听状态（即能够响铃）<br>静静的等着别人拨打</p><h4 id="tcp服务器-1"><a href="#tcp服务器-1" class="headerlink" title="tcp服务器"></a>tcp服务器</h4><p>如同上面的电话机过程一样，在程序中，如果想要完成一个tcp服务器的功能，需要的流程如下：</p><p>socket创建一个套接字<br>bind绑定ip和port<br>listen使套接字变为可以被动链接<br>accept等待客户端的链接<br>recv/send接收发送数据<br>一个很简单的tcp服务器如下：</p><pre class="language-none"><code class="language-none">#coding=utf-8from socket import *# 创建sockettcpSerSocket = socket(AF_INET, SOCK_STREAM)# 绑定本地信息address = ('', 7788)tcpSerSocket.bind(address)# 使用socket创建的套接字默认的属性是主动的，使用listen将其变为被动的，这样就可以接收别人的链接了tcpSerSocket.listen(5)# 如果有新的客户端来链接服务器，那么就产生一个新的套接字专门为这个客户端服务器# newSocket用来为这个客户端服务# tcpSerSocket就可以省下来专门等待其他新客户端的链接newSocket, clientAddr = tcpSerSocket.accept()# 接收对方发送过来的数据，最大接收1024个字节recvData = newSocket.recv(1024)print '接收到的数据为:',recvData# 发送一些数据到客户端newSocket.send("thank you !")# 关闭为这个客户端服务的套接字，只要关闭了，就意味着为不能再为这个客户端服务了，如果还需要服务，只能再次重新连接newSocket.close()# 关闭监听套接字，只要这个套接字关闭了，就意味着整个程序不能再接收任何新的客户端的连接tcpSerSocket.close()</code></pre><h3 id="tcp客户端"><a href="#tcp客户端" class="headerlink" title="tcp客户端"></a>tcp客户端</h3><p>tcp客户端，并不是像之前一个段子：一个顾客去饭馆吃饭，这个顾客要点菜，就问服务员咱们饭店有客户端么，然后这个服务员非常客气的说道：先生 我们饭店不用客户端，我们直接送到您的餐桌上</p><p>如果，不学习网络的知识是不是 说不定也会发生那样的笑话 ，哈哈</p><p>所谓的服务器端：就是提供服务的一方，而客户端，就是需要被服务的一方</p><p>tcp的客户端要比服务器端简单很多，如果说服务器端是需要自己买手机、查手机卡、设置铃声、等待别人打电话流程的话，那么客户端就只需要找一个电话亭，拿起电话拨打即可，流程要少很多</p><p>示例代码：</p><pre class="language-none"><code class="language-none">#coding=utf-8from socket import *# 创建sockettcpClientSocket = socket(AF_INET, SOCK_STREAM)# 链接服务器serAddr = ('192.168.1.102', 7788)tcpClientSocket.connect(serAddr)# 提示用户输入数据sendData = raw_input("请输入要发送的数据：")tcpClientSocket.send(sendData)# 接收对方发送过来的数据，最大接收1024个字节recvData = tcpClientSocket.recv(1024)print '接收到的数据为:',recvData# 关闭套接字tcpClientSocket.close()</code></pre><h4 id="客户端参考代码"><a href="#客户端参考代码" class="headerlink" title="客户端参考代码"></a>客户端参考代码</h4><pre class="language-none"><code class="language-none">#coding=utf-8from socket import *# 创建sockettcpClientSocket = socket(AF_INET, SOCK_STREAM)# 链接服务器serAddr = ('192.168.1.102', 7788)tcpClientSocket.connect(serAddr)while True:    # 提示用户输入数据    sendData = raw_input("send：")    if len(sendData)&gt;0:        tcpClientSocket.send(sendData)    else:        break    # 接收对方发送过来的数据，最大接收1024个字节    recvData = tcpClientSocket.recv(1024)    print 'recv:',recvData# 关闭套接字tcpClientSocket.close()</code></pre><h4 id="服务器端参考代码"><a href="#服务器端参考代码" class="headerlink" title="服务器端参考代码"></a>服务器端参考代码</h4><pre class="language-none"><code class="language-none">#coding=utf-8from socket import *# 创建sockettcpSerSocket = socket(AF_INET, SOCK_STREAM)# 绑定本地信息address = ('', 7788)tcpSerSocket.bind(address)# 使用socket创建的套接字默认的属性是主动的，使用listen将其变为被动的，这样就可以接收别人的链接了tcpSerSocket.listen(5)while True:    # 如果有新的客户端来链接服务器，那么就产生一个信心的套接字专门为这个客户端服务器    # newSocket用来为这个客户端服务    # tcpSerSocket就可以省下来专门等待其他新客户端的链接    newSocket, clientAddr = tcpSerSocket.accept()    while True:        # 接收对方发送过来的数据，最大接收1024个字节        recvData = newSocket.recv(1024)        # 如果接收的数据的长度为0，则意味着客户端关闭了链接        if len(recvData)&gt;0:            print 'recv:',recvData        else:            break            # 发送一些数据到客户端        sendData = raw_input("send:")        newSocket.send(sendData)    # 关闭为这个客户端服务的套接字，只要关闭了，就意味着为不能再为这个客户端服务了，如果还需要服务，只能再次重新连接    newSocket.close()# 关闭监听套接字，只要这个套接字关闭了，就意味着整个程序不能再接收任何新的客户端的连接tcpSerSocket.close()</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python网络编程-UDP</title>
      <link href="/2017/11/28/python-wang-luo-bian-cheng-udp/"/>
      <url>/2017/11/28/python-wang-luo-bian-cheng-udp/</url>
      
        <content type="html"><![CDATA[<h3 id="UDP介绍"><a href="#UDP介绍" class="headerlink" title="UDP介绍"></a>UDP介绍</h3><p>UDP — 用户数据报协议，是一个无连接的简单的面向数据报的运输层协议。UDP不提供可靠性，它只是把应用程序传给IP层的数据报发送出去，但是并不能保证它们能到达目的地。由于UDP在传输数据报前不用在客户和服务器之间建立一个连接，且没有超时重发等机制，故而传输速度很快。</p><p>UDP是一种面向无连接的协议，每个数据报都是一个独立的信息，包括完整的源地址或目的地址，它在网络上以任何可能的路径传往目的地，因此能否到达目的地，到达目的地的时间以及内容的正确性都是不能被保证的。</p><h4 id="UDP特点："><a href="#UDP特点：" class="headerlink" title="UDP特点："></a>UDP特点：</h4><p>UDP是面向无连接的通讯协议，UDP数据包括目的端口号和源端口号信息，由于通讯不需要连接，所以可以实现广播发送。 UDP传输数据时有大小限制，每个被传输的数据报必须限定在64KB之内。 UDP是一个不可靠的协议，发送方所发送的数据报并不一定以相同的次序到达接收方。</p><p>【适用情况】</p><p>UDP是面向消息的协议，通信时不需要建立连接，数据的传输自然是不可靠的，UDP一般用于多点通信和实时的数据业务，比如</p><p>语音广播<br>视频<br>QQ<br>TFTP(简单文件传送）<br>SNMP（简单网络管理协议）<br>RIP（路由信息协议，如报告股票市场，航空信息）<br>DNS(域名解释）<br>注重速度流畅</p><p>UDP操作简单，而且仅需要较少的监护，因此通常用于局域网高可靠性的分散系统中client/server应用程序。例如视频会议系统，并不要求音频视频数据绝对的正确，只要保证连贯性就可以了，这种情况下显然使用UDP会更合理一些。</p><h4 id="udp网络程序-发送数据"><a href="#udp网络程序-发送数据" class="headerlink" title="udp网络程序-发送数据"></a>udp网络程序-发送数据</h4><p>创建一个udp客户端程序的流程是简单，具体步骤如下：</p><p>创建客户端套接字<br>发送/接收数据<br>关闭套接字</p><pre class="language-none"><code class="language-none">#coding=utf-8from socket import *#1. 创建套接字udpSocket = socket(AF_INET, SOCK_DGRAM)#2. 准备接收方的地址sendAddr = ('192.168.1.103', 8080)#3. 从键盘获取数据sendData = raw_input("请输入要发送的数据:")#4. 发送数据到指定的电脑上udpSocket.sendto(sendData, sendAddr)#5. 关闭套接字udpSocket.close()</code></pre><h3 id="udp网络程序-发送、接收数据"><a href="#udp网络程序-发送、接收数据" class="headerlink" title="udp网络程序-发送、接收数据"></a>udp网络程序-发送、接收数据</h3><h4 id="1-创建udp网络程序-接收数据"><a href="#1-创建udp网络程序-接收数据" class="headerlink" title="1. 创建udp网络程序-接收数据"></a>1. 创建udp网络程序-接收数据</h4><pre class="language-none"><code class="language-none">#coding=utf-8from socket import *#1. 创建套接字udpSocket = socket(AF_INET, SOCK_DGRAM)#2. 准备接收方的地址sendAddr = ('192.168.1.103', 8080)#3. 从键盘获取数据sendData = raw_input("请输入要发送的数据:")#4. 发送数据到指定的电脑上udpSocket.sendto(sendData, sendAddr)#5. 等待接收对方发送的数据recvData = udpSocket.recvfrom(1024) # 1024表示本次接收的最大字节数#6. 显示对方发送的数据print(recvData)#7. 关闭套接字udpSocket.close()</code></pre><h4 id="udp网络程序-端口问题"><a href="#udp网络程序-端口问题" class="headerlink" title="udp网络程序-端口问题"></a>udp网络程序-端口问题</h4><p>说明：</p><p>每重新运行一次网络程序，上图中红圈中的数字，不一样的原因在于，这个数字标识这个网络程序，当重新运行时，如果没有确定到底用哪个，系统默认会随机分配<br>记住一点：这个网络程序在运行的过程中，这个就唯一标识这个程序，所以如果其他电脑上的网络程序如果想要向此程序发送数据，那么就需要向这个数字（即端口）标识的程序发送即可</p><h3 id="udp绑定信息"><a href="#udp绑定信息" class="headerlink" title="udp绑定信息"></a>udp绑定信息</h3><h4 id="1-绑定信息"><a href="#1-绑定信息" class="headerlink" title="1. 绑定信息"></a>1. 绑定信息</h4><p>还记得在上一节课中，如果一个网络程序在每次运行的时候端口是随机变化的么？</p><p>一般情况下，在一天电脑上运行的网络程序有很多，而各自用的端口号很多情况下不知道，为了不与其他的网络程序占用同一个端口号，往往在编程中，udp的端口号一般不绑定</p><p>但是如果需要做成一个服务器端的程序的话，是需要绑定的，想想看这又是为什么呢？</p><p>如果报警电话每天都在变，想必世界就会乱了，所以一般服务性的程序，往往需要一个固定的端口号，这就是所谓的端口绑定</p><h4 id="2-绑定示例"><a href="#2-绑定示例" class="headerlink" title="2. 绑定示例"></a>2. 绑定示例</h4><pre class="language-none"><code class="language-none">#coding=utf-8from socket import *#1. 创建套接字udpSocket = socket(AF_INET, SOCK_DGRAM)#2. 绑定本地的相关信息，如果一个网络程序不绑定，则系统会随机分配bindAddr = ('', 7788) # ip地址和端口号，ip一般不用写，表示本机的任何一个ipudpSocket.bind(bindAddr)#3. 等待接收对方发送的数据recvData = udpSocket.recvfrom(1024) # 1024表示本次接收的最大字节数#4. 显示接收到的数据print recvData#5. 关闭套接字udpSocket.close()</code></pre><h4 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h4><p>一个udp网络程序，可以不绑定，此时操作系统会随机进行分配一个端口，如果重新运行次程序端口可能会发生变化<br>一个udp网络程序，也可以绑定信息（ip地址，端口号），如果绑定成功，那么操作系统用这个端口号来进行区别收到的网络数据是否是此进程的</p><h3 id="udp应用：echo服务器"><a href="#udp应用：echo服务器" class="headerlink" title="udp应用：echo服务器"></a>udp应用：echo服务器</h3><p>参考代码</p><pre class="language-none"><code class="language-none">#coding=utf-8from socket import *#1. 创建套接字udpSocket = socket(AF_INET, SOCK_DGRAM)#2. 绑定本地的相关信息bindAddr = ('', 7788) # ip地址和端口号，ip一般不用写，表示本机的任何一个ipudpSocket.bind(bindAddr)num = 1while True:    #3. 等待接收对方发送的数据    recvData = udpSocket.recvfrom(1024) # 1024表示本次接收的最大字节数    #4. 将接收到的数据再发送给对方    udpSocket.sendto(recvData[0], recvData[1])    #5. 统计信息    print('已经将接收到的第%d个数据返回给对方,内容为:%s'%(num,recvData[0]))    num+=1#5. 关闭套接字udpSocket.close()</code></pre><h3 id="udp总结"><a href="#udp总结" class="headerlink" title="udp总结"></a>udp总结</h3><h4 id="1-udp是TCP-IP协议族中的一种协议能够完成不同机器上的程序间的数据通信"><a href="#1-udp是TCP-IP协议族中的一种协议能够完成不同机器上的程序间的数据通信" class="headerlink" title="1. udp是TCP/IP协议族中的一种协议能够完成不同机器上的程序间的数据通信"></a>1. udp是TCP/IP协议族中的一种协议能够完成不同机器上的程序间的数据通信</h4><h4 id="2-udp服务器、客户端"><a href="#2-udp服务器、客户端" class="headerlink" title="2. udp服务器、客户端"></a>2. udp服务器、客户端</h4><p>udp的服务器和客户端的区分：往往是通过请求服务和提供服务来进行区分<br>请求服务的一方称为：客户端<br>提供服务的一方称为：服务器</p><h4 id="3-udp绑定问题"><a href="#3-udp绑定问题" class="headerlink" title="3. udp绑定问题"></a>3. udp绑定问题</h4><p>一般情况下，服务器端，需要绑定端口，目的是为了让其他的客户端能够正确发送到此进程<br>客户端，一般不需要绑定，而是让操作系统随机分配，这样就不会因为需要绑定的端口被占用而导致程序无法运行的情况</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python网络编程-网络通信</title>
      <link href="/2017/11/28/python-wang-luo-bian-cheng-wang-luo-tong-xin/"/>
      <url>/2017/11/28/python-wang-luo-bian-cheng-wang-luo-tong-xin/</url>
      
        <content type="html"><![CDATA[<h1 id="网络通信概述"><a href="#网络通信概述" class="headerlink" title="网络通信概述"></a>网络通信概述</h1><h4 id="1-什么是网络"><a href="#1-什么是网络" class="headerlink" title="1. 什么是网络"></a>1. 什么是网络</h4><p><strong>说明</strong></p><p>网络就是一种辅助双方或者多方能够连接在一起的工具<br>如果没有网络可想单机的世界是多么的孤单</p><h4 id="2-使用网络的目的"><a href="#2-使用网络的目的" class="headerlink" title="2. 使用网络的目的"></a>2. 使用网络的目的</h4><p>就是为了联通多方然后进行通信用的，即把数据从一方传递给另外一方</p><p>前面的学习编写的程序都是单机的，即不能和其他电脑上的程序进行通信</p><p>为了让在不同的电脑上运行的软件，之间能够互相传递数据，就需要借助网络的功能</p><h4 id="3-小总结"><a href="#3-小总结" class="headerlink" title="3.小总结"></a>3.小总结</h4><p>使用网络能够把多方链接在一起，然后可以进行数据传递<br>所谓的网络编程就是，让在不同的电脑上的软件能够进行数据传递，即进程之间的通信</p><h3 id="tcp-ip简介"><a href="#tcp-ip简介" class="headerlink" title="tcp/ip简介"></a>tcp/ip简介</h3><p>作为新时代标杆的我们，已经离不开手机、离不开网络，对于互联网大家可能耳熟能详，但是计算机网络的出现比互联网要早很多</p><h4 id="1-什么是协议"><a href="#1-什么是协议" class="headerlink" title="1. 什么是协议"></a>1. 什么是协议</h4><p>有的说英语，有的说中文，有的说德语，说同一种语言的人可以交流，不同的语言之间就不行了</p><p>为了解决不同种族人之间的语言沟通障碍，现规定国际通用语言是英语，这就是一个规定，这就是协议</p><h4 id="2-计算机网络沟通用什么"><a href="#2-计算机网络沟通用什么" class="headerlink" title="2. 计算机网络沟通用什么"></a>2. 计算机网络沟通用什么</h4><p>现在的生活中，不同的计算机只需要能够联网（有线无线都可以）那么就可以相互进行传递数据<br>那么不同种类之间的计算机到底是怎么进行数据传递的呢？</p><p>就像说不同语言的人沟通一样，只要有一种大家都认可都遵守的协议即可，那么这个计算机都遵守的网络通信协议叫做TCP/IP协议</p><h4 id="3-TCP-IP协议-族"><a href="#3-TCP-IP协议-族" class="headerlink" title="3. TCP/IP协议(族)"></a>3. TCP/IP协议(族)</h4><p>早期的计算机网络，都是由各厂商自己规定一套协议，IBM、Apple和Microsoft都有各自的网络协议，互不兼容</p><p>为了把全世界的所有不同类型的计算机都连接起来，就必须规定一套全球通用的协议，为了实现互联网这个目标，互联网协议簇（Internet Protocol Suite）就是通用协议标准。</p><p>因为互联网协议包含了上百种协议标准，但是最重要的两个协议是TCP和IP协议，所以，大家把互联网的协议简称TCP/IP协议</p><p>说明：</p><p>网际层也称为：网络层<br>网络接口层也称为：链路层</p><h3 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h3><h4 id="1-什么是端口"><a href="#1-什么是端口" class="headerlink" title="1. 什么是端口"></a>1. 什么是端口</h4><p>那么TCP/IP协议中的端口指的是什么呢？</p><p>端口就好一个房子的门，是出入这间房子的必经之路。</p><p>如果一个进程需要收发网络数据，那么就需要有这样的端口</p><p>在linux系统中，端口可以有65536（2的16次方）个之多！</p><p>既然有这么多，操作系统为了统一管理，所以进行了编号，这就是端口号</p><h4 id="2-端口号"><a href="#2-端口号" class="headerlink" title="2. 端口号"></a>2. 端口号</h4><p>端口是通过端口号来标记的，端口号只有整数，范围是从0到65535</p><h4 id="3-端口是怎样分配的"><a href="#3-端口是怎样分配的" class="headerlink" title="3. 端口是怎样分配的"></a>3. 端口是怎样分配的</h4><p>端口号不是随意使用的，而是按照一定的规定进行分配。</p><p>端口的分类标准有好几种，我们这里不做详细讲解，只介绍一下知名端口和动态端口</p><h4 id="3-1-知名端口（Well-Known-Ports）"><a href="#3-1-知名端口（Well-Known-Ports）" class="headerlink" title="3.1 知名端口（Well Known Ports）"></a>3.1 知名端口（Well Known Ports）</h4><p>知名端口是众所周知的端口号，范围从0到1023</p><p>80端口分配给HTTP服务<br>21端口分配给FTP服务</p><p>可以理解为，一些常用的功能使用的号码是估计的，好比 电话号码110、10086、10010一样</p><p>一般情况下，如果一个程序需要使用知名端口的需要有root权限</p><h4 id="3-2-动态端口（Dynamic-Ports）"><a href="#3-2-动态端口（Dynamic-Ports）" class="headerlink" title="3.2 动态端口（Dynamic Ports）"></a>3.2 动态端口（Dynamic Ports）</h4><p>动态端口的范围是从1024到65535</p><p>之所以称为动态端口，是因为它一般不固定分配某种服务，而是动态分配。</p><p>动态分配是指当一个系统进程或应用程序进程需要网络通信时，它向主机申请一个端口，主机从可用的端口号中分配一个供它使用。</p><p>当这个进程关闭时，同时也就释放了所占用的端口号。</p><h4 id="3-3-怎样查看端口-？"><a href="#3-3-怎样查看端口-？" class="headerlink" title="3.3 怎样查看端口 ？"></a>3.3 怎样查看端口 ？</h4><p>用“netstat －an”查看端口状态</p><h4 id="4-小总结"><a href="#4-小总结" class="headerlink" title="4. 小总结"></a>4. 小总结</h4><p>端口有什么用呢 ？ 我们知道，一台拥有IP地址的主机可以提供许多服务，比如HTTP（万维网服务）、FTP（文件传输）、SMTP（电子邮件）等，这些服务完全可以通过1个IP地址来实现。那么，主机是怎样区分不同的网络服务呢？显然不能只靠IP地址，因为IP地址与网络服务的关系是一对多的关系。实际上是通过“IP地址+端口号”来区分不同的服务的。 需要注意的是，端口并不是一一对应的。比如你的电脑作为客户机访问一台WWW服务器时，WWW服务器使用“80”端口与你的电脑通信，但你的电脑则可能使用“3457”这样的端口。</p><h3 id="ip地址"><a href="#ip地址" class="headerlink" title="ip地址"></a>ip地址</h3><h4 id="1-什么是地址"><a href="#1-什么是地址" class="headerlink" title="1. 什么是地址"></a>1. 什么是地址</h4><p>地址就是用来标记地点的</p><p>p地址：用来在网络中标记一台电脑的一串数字，比如192.168.1.1；在本地局域网上是惟一的。</p><p>每一个IP地址包括两部分：网络地址和主机地址</p><h4 id="A类IP地址"><a href="#A类IP地址" class="headerlink" title="A类IP地址"></a>A类IP地址</h4><p>一个A类IP地址由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”，</p><p>地址范围1.0.0.1-126.255.255.254</p><p>二进制表示为：00000001 00000000 00000000 00000001 - 01111110 11111111 11111111 11111110</p><p>可用的A类网络有126个，每个网络能容纳1677214个主机</p><h4 id="B类IP地址"><a href="#B类IP地址" class="headerlink" title="B类IP地址"></a>B类IP地址</h4><p>一个B类IP地址由2个字节的网络地址和2个字节的主机地址组成，网络地址的最高位必须是“10”，</p><p>地址范围128.1.0.1-191.255.255.254</p><p>二进制表示为：10000000 00000001 00000000 00000001 - 10111111 11111111 11111111 11111110</p><p>可用的B类网络有16384个，每个网络能容纳65534主机</p><h4 id="C类IP地址"><a href="#C类IP地址" class="headerlink" title="C类IP地址"></a>C类IP地址</h4><p>一个C类IP地址由3字节的网络地址和1字节的主机地址组成，网络地址的最高位必须是“110”</p><p>范围192.0.1.1-223.255.255.254</p><p>二进制表示为: 11000000 00000000 00000001 00000001 - 11011111 11111111 11111110 11111110</p><p>C类网络可达2097152个，每个网络能容纳254个主机</p><h4 id="D类地址用于多点广播"><a href="#D类地址用于多点广播" class="headerlink" title="D类地址用于多点广播"></a>D类地址用于多点广播</h4><p>D类IP地址第一个字节以“1110”开始，它是一个专门保留的地址。</p><p>它并不指向特定的网络，目前这一类地址被用在多点广播（Multicast）中</p><p>多点广播地址用来一次寻址一组计算机</p><p>地址范围224.0.0.1-239.255.255.254</p><h4 id="E类IP地址"><a href="#E类IP地址" class="headerlink" title="E类IP地址"></a>E类IP地址</h4><p>以“1111”开始，为将来使用保留</p><p>E类地址保留，仅作实验和开发用</p><h4 id="私有ip"><a href="#私有ip" class="headerlink" title="私有ip"></a>私有ip</h4><p>在这么多网络IP中，国际规定有一部分IP地址是用于我们的局域网使用，也就</p><p>是属于私网IP，不在公网中使用的，它们的范围是：</p><p>10.0.0.0～10.255.255.255</p><p>172.16.0.0～172.31.255.255</p><p>192.168.0.0～192.168.255.255</p><h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>IP地址127．0．0．1~127．255．255．255用于回路测试，</p><p>如：127.0.0.1可以代表本机IP地址，用<a href="http://127.0.0.1就可以测试本机中配置的web服务器./">http://127.0.0.1就可以测试本机中配置的Web服务器。</a></p><h3 id="子网掩码"><a href="#子网掩码" class="headerlink" title="子网掩码"></a>子网掩码</h3><p>要想理解什么是子网掩码，就不能不了解IP地址的构成。互联网是由许多小型网络构成的，每个网络上都有许多主机，这样便构成了一个有层次的结构。IP地址在设计时就考虑到地址分配的层次特点，将每个IP地址都分割成网络号和主机号两部分，以便于IP地址的寻址操作。</p><p>IP地址的网络号和主机号各是多少位呢？</p><p>如果不指定，就不知道哪些位是网络号、哪些是主机号，这就需要通过子网掩码来实现。</p><p>子网掩码不能单独存在，它必须结合IP地址一起使用。</p><p>子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分子网掩码的设定必须遵循一定的规则。</p><p>与IP地址相同，子网掩码的长度也是32位，</p><p>左边是网络位，用二进制数字“1”表示；<br>右边是主机位，用二进制数字“0”表示。<br>假设IP地址为“192.168.1.1”子网掩码为“255.255.255.0”。</p><p>其中，“1”有24个，代表与此相对应的IP地址左边24位是网络号；</p><p>“0”有8个，代表与此相对应的IP地址右边8位是主机号。</p><p>这样，子网掩码就确定了一个IP地址的32位二进制数字中哪些是网络号、哪些是主机号。</p><p>这对于采用TCP/IP协议的网络来说非常重要，只有通过子网掩码，才能表明一台主机所在的子网与其他子网的关系，使网络正常工作</p><p>最常用的两种子网掩码</p><p>子网掩码是“255.255.255.0”的网络：</p><p>最后面一个数字可以在0~255范围内任意变化，因此可以提供256个IP地址。<br>但是实际可用的IP地址数量是256-2，即254个，因为主机号不能全是“0”或全是“1”。<br>主机号全为0，表示网络号</p><p>主机号全为1，表示网络广播</p><p>注意</p><p>如果将子网掩码设置过大，也就是说子网范围扩大，那么，根据子网寻径规则，很可能发往和本地主机不在同一子网内的目标主机的数据，会因为错误的判断而认为目标主机是在同一子网内，那么，数据包将在本子网内循环，直到超时并抛弃，使数据不能正确到达目标主机，导致网络传输错误；如果将子网掩码设置得过小，那么就会将本来属于同一子网内的机器之间的通信当做是跨子网传输，数据包都交给缺省网关处理，这样势必增加缺省网关(文章下方有解释)的负担，造成网络效率下降。因此，子网掩码应该根据网络的规模进行设置。如果一个网络的规模不超过254台电脑，采用“255.255.255.0”作为子网掩码就可以了，现在大多数局域网都不会超过这个数字，因此“255.255.255.0”是最常用的IP地址子网掩码；假如在一所大学具有1500多台电脑，这种规模的局域网可以使用“255.255.0.0”。</p><h3 id="socket简介"><a href="#socket简介" class="headerlink" title="socket简介"></a>socket简介</h3><h4 id="1-本地的进程间通信（IPC）有很多种方式，例如"><a href="#1-本地的进程间通信（IPC）有很多种方式，例如" class="headerlink" title="1.本地的进程间通信（IPC）有很多种方式，例如"></a>1.本地的进程间通信（IPC）有很多种方式，例如</h4><p>队列<br>同步（互斥锁、条件变量等）<br>以上通信方式都是在一台机器上不同进程之间的通信方式，那么问题来了</p><p>网络中进程之间如何通信？</p><h4 id="2-网络中进程之间如何通信"><a href="#2-网络中进程之间如何通信" class="headerlink" title="2. 网络中进程之间如何通信"></a>2. 网络中进程之间如何通信</h4><p>首要解决的问题是如何唯一标识一个进程，否则通信无从谈起！</p><p>在本地可以通过进程PID来唯一标识一个进程，但是在网络中这是行不通的。</p><p>其实TCP/IP协议族已经帮我们解决了这个问题，网络层的“ip地址”可以唯一标识网络中的主机，而传输层的“协议+端口”可以唯一标识主机中的应用程序（进程）。</p><p>这样利用ip地址，协议，端口就可以标识网络的进程了，网络中的进程通信就可以利用这个标志与其它进程进行交互</p><h4 id="3-什么是socket"><a href="#3-什么是socket" class="headerlink" title="3. 什么是socket"></a>3. 什么是socket</h4><p>socket(简称 套接字) 是进程间通信的一种方式，它与其他进程间通信的一个主要不同是：</p><p>它能实现不同主机间的进程间通信，我们网络上各种各样的服务大多都是基于 Socket 来完成通信的</p><p>例如我们每天浏览网页、QQ 聊天、收发 email 等等</p><h4 id="4-创建socket"><a href="#4-创建socket" class="headerlink" title="4. 创建socket"></a>4. 创建socket</h4><p>在 Python 中 使用socket 模块的函数 socket 就可以完成：</p><pre class="language-none"><code class="language-none">socket.socket(AddressFamily, Type)</code></pre><p>说明：<br>函数 socket.socket 创建一个 socket，返回该 socket 的描述符，该函数带有两个参数：</p><p>Address Family：可以选择 AF_INET（用于 Internet 进程间通信） 或者 AF_UNIX（用于同一台机器进程间通信）,实际工作中常用AF_INET<br>Type：套接字类型，可以是 SOCK_STREAM（流式套接字，主要用于 TCP 协议）或者 SOCK_DGRAM（数据报套接字，主要用于 UDP 协议）<br>创建一个tcp socket（tcp套接字）</p><pre class="language-none"><code class="language-none">import sockets = socket.socket(socket.AF_INET, socket.SOCK_STREAM)print 'Socket Created'</code></pre><p>创建一个udp socket（udp套接字）</p><pre class="language-none"><code class="language-none">import sockets = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)print 'Socket Created'</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python系统编程-线程</title>
      <link href="/2017/11/27/python-xi-tong-bian-cheng-xian-cheng/"/>
      <url>/2017/11/27/python-xi-tong-bian-cheng-xian-cheng/</url>
      
        <content type="html"><![CDATA[<h3 id="多线程-threading"><a href="#多线程-threading" class="headerlink" title="多线程-threading"></a>多线程-threading</h3><p>python的thread模块是比较底层的模块，python的threading模块是对thread做了一些包装的，可以更加方便的被使用</p><h4 id="1-使用threading模块"><a href="#1-使用threading模块" class="headerlink" title="1. 使用threading模块"></a>1. 使用threading模块</h4><p>单线程执行</p><pre class="language-none"><code class="language-none">#coding=utf-8import timedef saySorry():    print("亲爱的，我错了，我能吃饭了吗？")    time.sleep(1)if __name__ == "__main__":    for i in range(5):        saySorry()</code></pre><p>多线程执行</p><pre class="language-none"><code class="language-none">#coding=utf-8import threadingimport timedef saySorry():    print("亲爱的，我错了，我能吃饭了吗？")    time.sleep(1)if __name__ == "__main__":    for i in range(5):        t = threading.Thread(target=saySorry)        t.start() #启动线程，即让线程开始执行</code></pre><h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><p>可以明显看出使用了多线程并发的操作，花费时间要短很多<br>创建好的线程，需要调用start()方法来启动</p><h4 id="2-主线程会等待所有的子线程结束后才结束"><a href="#2-主线程会等待所有的子线程结束后才结束" class="headerlink" title="2. 主线程会等待所有的子线程结束后才结束"></a>2. 主线程会等待所有的子线程结束后才结束</h4><pre class="language-none"><code class="language-none">#coding=utf-8import threadingfrom time import sleep,ctimedef sing():    for i in range(3):        print("正在唱歌...%d"%i)        sleep(1)def dance():    for i in range(3):        print("正在跳舞...%d"%i)        sleep(1)if __name__ == '__main__':    print('---开始---:%s'%ctime())    t1 = threading.Thread(target=sing)    t2 = threading.Thread(target=dance)    t1.start()    t2.start()    #sleep(5) # 屏蔽此行代码，试试看，程序是否会立马结束？    print('---结束---:%s'%ctime())</code></pre><h4 id="3-查看线程数量"><a href="#3-查看线程数量" class="headerlink" title="3. 查看线程数量"></a>3. 查看线程数量</h4><pre class="language-none"><code class="language-none">#coding=utf-8import threadingfrom time import sleep,ctimedef sing():    for i in range(3):        print("正在唱歌...%d"%i)        sleep(1)def dance():    for i in range(3):        print("正在跳舞...%d"%i)        sleep(1)if __name__ == '__main__':    print('---开始---:%s'%ctime())    t1 = threading.Thread(target=sing)    t2 = threading.Thread(target=dance)    t1.start()    t2.start()    while True:        length = len(threading.enumerate())        print('当前运行的线程数为：%d'%length)        if length&lt;=1:            breaksleep(0.5)</code></pre><h3 id="threading注意点"><a href="#threading注意点" class="headerlink" title="threading注意点"></a>threading注意点</h3><h4 id="1-线程执行代码的封装"><a href="#1-线程执行代码的封装" class="headerlink" title="1. 线程执行代码的封装"></a>1. 线程执行代码的封装</h4><p>通过上一小节，能够看出，通过使用threading模块能完成多任务的程序开发，为了让每个线程的封装性更完美，所以使用threading模块时，往往会定义一个新的子类class，只要继承threading.Thread就可以了，然后重写run方法</p><p>示例如下：</p><pre class="language-none"><code class="language-none">#coding=utf-8import threadingimport timeclass MyThread(threading.Thread):    def run(self):        for i in range(3):            time.sleep(1)            msg = "I'm "+self.name+' @ '+str(i) #name属性中保存的是当前线程的名字            print(msg)if __name__ == '__main__':    t = MyThread()    t.start()</code></pre><h4 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h4><p>python的threading.Thread类有一个run方法，用于定义线程的功能函数，可以在自己的线程类中覆盖该方法。而创建自己的线程实例后，通过Thread类的start方法，可以启动该线程，交给python虚拟机进行调度，当该线程获得执行的机会时，就会调用run方法执行线程。</p><h4 id="2-线程的执行顺序"><a href="#2-线程的执行顺序" class="headerlink" title="2. 线程的执行顺序"></a>2. 线程的执行顺序</h4><pre class="language-none"><code class="language-none">#coding=utf-8import threadingimport timeclass MyThread(threading.Thread):    def run(self):        for i in range(3):            time.sleep(1)            msg = "I'm "+self.name+' @ '+str(i)            print(msg)def test():    for i in range(5):        t = MyThread()        t.start()if __name__ == '__main__':    test()</code></pre><h4 id="说明-2"><a href="#说明-2" class="headerlink" title="说明"></a>说明</h4><p>从代码和执行结果我们可以看出，多线程程序的执行顺序是不确定的。当执行到sleep语句时，线程将被阻塞（Blocked），到sleep结束后，线程进入就绪（Runnable）状态，等待调度。而线程调度将自行选择一个线程执行。上面的代码中只能保证每个线程都运行完整个run函数，但是线程的启动顺序、run函数中每次循环的执行顺序都不能确定。</p><h4 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h4><p>每个线程一定会有一个名字，尽管上面的例子中没有指定线程对象的name，但是python会自动为线程指定一个名字。<br>当线程的run()方法结束时该线程完成。<br>无法控制线程调度程序，但可以通过别的方式来影响线程调度的方式。<br>线程的几种状态</p><h3 id="多线程-共享全局变量"><a href="#多线程-共享全局变量" class="headerlink" title="多线程-共享全局变量"></a>多线程-共享全局变量</h3><pre class="language-none"><code class="language-none">from threading import Threadimport timeg_num = 100def work1():    global g_num    for i in range(3):        g_num += 1    print("----in work1, g_num is %d---"%g_num)def work2():    global g_num    print("----in work2, g_num is %d---"%g_num)print("---线程创建之前g_num is %d---"%g_num)t1 = Thread(target=work1)t1.start()#延时一会，保证t1线程中的事情做完time.sleep(1)t2 = Thread(target=work2)t2.start()</code></pre><h4 id="列表当做实参传递到线程中"><a href="#列表当做实参传递到线程中" class="headerlink" title="列表当做实参传递到线程中"></a>列表当做实参传递到线程中</h4><pre class="language-none"><code class="language-none">from threading import Threadimport timedef work1(nums):    nums.append(44)    print("----in work1---",nums)def work2(nums):    #延时一会，保证t1线程中的事情做完    time.sleep(1)    print("----in work2---",nums)g_nums = [11,22,33]t1 = Thread(target=work1, args=(g_nums,))t1.start()t2 = Thread(target=work2, args=(g_nums,))t2.start()</code></pre><h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>在一个进程内的所有线程共享全局变量，能够在不适用其他方式的前提下完成多线程之间的数据共享（这点要比多进程要好）<br>缺点就是，线程是对全局变量随意遂改可能造成多线程之间对全局变量的混乱（即线程非安全）</p><h3 id="进程VS线程"><a href="#进程VS线程" class="headerlink" title="进程VS线程"></a>进程VS线程</h3><h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><p>进程，能够完成多任务，比如 在一台电脑上能够同时运行多个QQ<br>线程，能够完成多任务，比如 一个QQ中的多个聊天窗口</p><h4 id="定义的不同"><a href="#定义的不同" class="headerlink" title="定义的不同"></a>定义的不同</h4><p>进程是系统进行资源分配和调度的一个独立单位.</p><p>线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.</p><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><p>一个程序至少有一个进程,一个进程至少有一个线程.</p><p>线程的划分尺度小于进程(资源比进程少)，使得多线程程序的并发性高。</p><p>进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率</p><p>线线程不能够独立执行，必须依存在进程中</p><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p>线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。</p><h3 id="同步的概念"><a href="#同步的概念" class="headerlink" title="同步的概念"></a>同步的概念</h3><h4 id="1-多线程开发可能遇到的问题"><a href="#1-多线程开发可能遇到的问题" class="headerlink" title="1. 多线程开发可能遇到的问题"></a>1. 多线程开发可能遇到的问题</h4><p>假设两个线程t1和t2都要对num=0进行增1运算，t1和t2都各对num修改10次，num的最终的结果应该为20。</p><p>但是由于是多线程访问，有可能出现下面情况：</p><p>在num=0时，t1取得num=0。此时系统把t1调度为”sleeping”状态，把t2转换为”running”状态，t2也获得num=0。然后t2对得到的值进行加1并赋给num，使得num=1。然后系统又把t2调度为”sleeping”，把t1转为”running”。线程t1又把它之前得到的0加1后赋值给num。这样，明明t1和t2都完成了1次加1工作，但结果仍然是num=1。</p><pre class="language-none"><code class="language-none">from threading import Threadimport timeg_num = 0def test1():    global g_num    for i in range(1000000):        g_num += 1    print("---test1---g_num=%d"%g_num)def test2():    global g_num    for i in range(1000000):        g_num += 1    print("---test2---g_num=%d"%g_num)p1 = Thread(target=test1)p1.start()# time.sleep(3) #取消屏蔽之后 再次运行程序，结果会不一样，，，为啥呢？p2 = Thread(target=test2)p2.start()print("---g_num=%d---"%g_num)</code></pre><p>问题产生的原因就是没有控制多个线程对同一资源的访问，对数据造成破坏，使得线程运行的结果不可预期。这种现象称为“线程不安全”。</p><h4 id="2-什么是同步"><a href="#2-什么是同步" class="headerlink" title="2. 什么是同步"></a>2. 什么是同步</h4><p>同步就是协同步调，按预定的先后次序进行运行。如:你说完，我再说。</p><p>“同”字从字面上容易理解为一起动作</p><p>其实不是，”同”字应是指协同、协助、互相配合。</p><p>如进程、线程同步，可理解为进程或线程A和B一块配合，A执行到一定程度时要依靠B的某个结果，于是停下来，示意B运行;B依言执行，再将结果给A;A再继续操作。</p><h4 id="3-解决问题的思路"><a href="#3-解决问题的思路" class="headerlink" title="3. 解决问题的思路"></a>3. 解决问题的思路</h4><p>对于本小节提出的那个计算错误的问题，可以通过线程同步来进行解决</p><p>思路，如下:</p><p>系统调用t1，然后获取到num的值为0，此时上一把锁，即不允许其他现在操作num<br>对num的值进行+1<br>解锁，此时num的值为1，其他的线程就可以使用num了，而且是num的值不是0而是1<br>同理其他线程在对num进行修改时，都要先上锁，处理完后再解锁，在上锁的整个过程中不允许其他线程访问，就保证了数据的正确性</p><h3 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h3><p>当多个线程几乎同时修改某一个共享数据的时候，需要进行同步控制</p><p>线程同步能够保证多个线程安全访问竞争资源，最简单的同步机制是引入互斥锁。</p><p>互斥锁为资源引入一个状态：锁定/非锁定。</p><p>某个线程要更改共享数据时，先将其锁定，此时资源的状态为“锁定”，其他线程不能更改；直到该线程释放资源，将资源的状态变成“非锁定”，其他的线程才能再次锁定该资源。互斥锁保证了每次只有一个线程进行写入操作，从而保证了多线程情况下数据的正确性。</p><p>threading模块中定义了Lock类，可以方便的处理锁定：</p><pre class="language-none"><code class="language-none">#创建锁mutex = threading.Lock()#锁定mutex.acquire([blocking])#释放mutex.release()</code></pre><p>其中，锁定方法acquire可以有一个blocking参数。</p><p>如果设定blocking为True，则当前线程会堵塞，直到获取到这个锁为止（如果没有指定，那么默认为True）<br>如果设定blocking为False，则当前线程不会堵塞<br>使用互斥锁实现上面的例子的代码如下：</p><pre class="language-none"><code class="language-none">from threading import Thread, Lockimport timeg_num = 0def test1():    global g_num    for i in range(1000000):        #True表示堵塞 即如果这个锁在上锁之前已经被上锁了，那么这个线程会在这里一直等待到解锁为止         #False表示非堵塞，即不管本次调用能够成功上锁，都不会卡在这,而是继续执行下面的代码        mutexFlag = mutex.acquire(True)         if mutexFlag:            g_num += 1            mutex.release()    print("---test1---g_num=%d"%g_num)def test2():    global g_num    for i in range(1000000):        mutexFlag = mutex.acquire(True) #True表示堵塞        if mutexFlag:            g_num += 1            mutex.release()print("---test2---g_num=%d"%g_num)#创建一个互斥锁#这个所默认是未上锁的状态mutex = Lock()p1 = Thread(target=test1)p1.start()p2 = Thread(target=test2)p2.start()print("---g_num=%d---"%g_num)</code></pre><p>可以看到，加入互斥锁后，运行结果与预期相符。</p><h4 id="上锁解锁过程"><a href="#上锁解锁过程" class="headerlink" title="上锁解锁过程"></a>上锁解锁过程</h4><p>当一个线程调用锁的acquire()方法获得锁时，锁就进入“locked”状态。</p><p>每次只有一个线程可以获得锁。如果此时另一个线程试图获得这个锁，该线程就会变为“blocked”状态，称为“阻塞”，直到拥有锁的线程调用锁的release()方法释放锁之后，锁进入“unlocked”状态。</p><p>线程调度程序从处于同步阻塞状态的线程中选择一个来获得锁，并使得该线程进入运行（running）状态。</p><h4 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a>总结：</h4><p>锁的好处<br>确保了某段关键代码只能由一个线程从头到尾完整地执行<br>锁的坏处：</p><p>阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了<br>由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁</p><h3 id="多线程-非共享数据"><a href="#多线程-非共享数据" class="headerlink" title="多线程-非共享数据"></a>多线程-非共享数据</h3><p>对于全局变量，在多线程中要格外小心，否则容易造成数据错乱的情况发生</p><h4 id="1-非全局变量是否要加锁呢？"><a href="#1-非全局变量是否要加锁呢？" class="headerlink" title="1. 非全局变量是否要加锁呢？"></a>1. 非全局变量是否要加锁呢？</h4><pre class="language-none"><code class="language-none">#coding=utf-8    import threading    import time    class MyThread(threading.Thread):        # 重写 构造方法        def __init__(self,num,sleepTime):            threading.Thread.__init__(self)            self.num = num            self.sleepTime = sleepTime        def run(self):            self.num += 1            time.sleep(self.sleepTime)            print('线程(%s),num=%d'%(self.name, self.num))    if __name__ == '__main__':        mutex = threading.Lock()        t1 = MyThread(100,5)        t1.start()        t2 = MyThread(200,1)        t2.start()</code></pre><h4 id="小总结"><a href="#小总结" class="headerlink" title="小总结"></a>小总结</h4><p>在多线程开发中，全局变量是多个线程都共享的数据，而局部变量等是各自线程的，是非共享的</p><h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><h4 id="1-死锁"><a href="#1-死锁" class="headerlink" title="1. 死锁"></a>1. 死锁</h4><p>在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时等待对方的资源，就会造成死锁。</p><p>尽管死锁很少发生，但一旦发生就会造成应用的停止响应。下面看一个死锁的例子</p><pre class="language-none"><code class="language-none">#coding=utf-8import threadingimport timeclass MyThread1(threading.Thread):    def run(self):        if mutexA.acquire():            print(self.name+'----do1---up----')            time.sleep(1)            if mutexB.acquire():                print(self.name+'----do1---down----')                mutexB.release()            mutexA.release()class MyThread2(threading.Thread):    def run(self):        if mutexB.acquire():            print(self.name+'----do2---up----')            time.sleep(1)            if mutexA.acquire():                print(self.name+'----do2---down----')                mutexA.release()            mutexB.release()mutexA = threading.Lock()mutexB = threading.Lock()if __name__ == '__main__':    t1 = MyThread1()    t2 = MyThread2()    t1.start()    t2.start()</code></pre><h4 id="避免死锁"><a href="#避免死锁" class="headerlink" title="避免死锁"></a>避免死锁</h4><p>程序设计时要尽量避免（银行家算法）<br>添加超时时间等</p><h3 id="同步应用"><a href="#同步应用" class="headerlink" title="同步应用"></a>同步应用</h3><h4 id="多个线程有序执行"><a href="#多个线程有序执行" class="headerlink" title="多个线程有序执行"></a>多个线程有序执行</h4><pre class="language-none"><code class="language-none">from threading import Thread,Lockfrom time import sleepclass Task1(Thread):    def run(self):        while True:            if lock1.acquire():                print("------Task 1 -----")                sleep(0.5)                lock2.release()class Task2(Thread):    def run(self):        while True:            if lock2.acquire():                print("------Task 2 -----")                sleep(0.5)                lock3.release()class Task3(Thread):    def run(self):        while True:            if lock3.acquire():                print("------Task 3 -----")                sleep(0.5)                lock1.release()#使用Lock创建出的锁默认没有“锁上”lock1 = Lock()#创建另外一把锁，并且“锁上”lock2 = Lock()lock2.acquire()#创建另外一把锁，并且“锁上”lock3 = Lock()lock3.acquire()t1 = Task1()t2 = Task2()t3 = Task3()t1.start()t2.start()t3.start()</code></pre><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>可以使用互斥锁完成多个任务，有序的进程工作，这就是线程的同步</p><h3 id="生产者与消费者模式"><a href="#生产者与消费者模式" class="headerlink" title="生产者与消费者模式"></a>生产者与消费者模式</h3><p>Python的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语（可以理解为原子操作，即要么不做，要么就做完），能够在多线程中直接使用。可以使用队列来实现线程间的同步。</p><p>用FIFO队列实现上述生产者与消费者问题的代码如下：</p><pre class="language-none"><code class="language-none">#encoding=utf-8import threadingimport time#python2中from Queue import Queue#python3中# from queue import Queueclass Producer(threading.Thread):    def run(self):        global queue        count = 0        while True:            if queue.qsize() &lt; 1000:                for i in range(100):                    count = count +1                    msg = '生成产品'+str(count)                    queue.put(msg)                    print(msg)            time.sleep(0.5)class Consumer(threading.Thread):    def run(self):        global queue        while True:            if queue.qsize() &gt; 100:                for i in range(3):                    msg = self.name + '消费了 '+queue.get()                    print(msg)                    time.sleep(1)if __name__ == '__main__':    queue = Queue()    for i in range(500):        queue.put('初始产品'+str(i))    for i in range(2):        p = Producer()        p.start()    for i in range(5):        c = Consumer()        c.start()</code></pre><h4 id="Queue的说明"><a href="#Queue的说明" class="headerlink" title="Queue的说明"></a>Queue的说明</h4><p>对于Queue，在多线程通信之间扮演重要的角色<br>添加数据到队列中，使用put()方法<br>从队列中取数据，使用get()方法<br>判断队列中是否还有数据，使用qsize()方法</p><h4 id="生产者消费者模式的说明"><a href="#生产者消费者模式的说明" class="headerlink" title="生产者消费者模式的说明"></a>生产者消费者模式的说明</h4><p>为什么要使用生产者和消费者模式<br>在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式。</p><p>什么是生产者消费者模式<br>生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。</p><p>这个阻塞队列就是用来给生产者和消费者解耦的。纵观大多数设计模式，都会找一个第三者出来进行解耦</p><h3 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h3><p>在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。</p><h4 id="1-使用函数传参的方法"><a href="#1-使用函数传参的方法" class="headerlink" title="1. 使用函数传参的方法"></a>1. 使用函数传参的方法</h4><p>但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦：</p><pre class="language-none"><code class="language-none">def process_student(name):    std = Student(name)    # std是局部变量，但是每个函数都要用它，因此必须传进去：    do_task_1(std)    do_task_2(std)def do_task_1(std):    do_subtask_1(std)    do_subtask_2(std)def do_task_2(std):    do_subtask_2(std)    do_subtask_2(std)</code></pre><p>每个函数一层一层调用都这么传参数那还得了？用全局变量？也不行，因为每个线程处理不同的Student对象，不能共享。</p><h3 id="2-使用全局字典的方法"><a href="#2-使用全局字典的方法" class="headerlink" title="2. 使用全局字典的方法"></a>2. 使用全局字典的方法</h3><p>如果用一个全局dict存放所有的Student对象，然后以thread自身作为key获得线程对应的Student对象如何？</p><pre class="language-none"><code class="language-none">global_dict = {}def std_thread(name):    std = Student(name)    # 把std放到全局变量global_dict中：    global_dict[threading.current_thread()] = std    do_task_1()    do_task_2()def do_task_1():    # 不传入std，而是根据当前线程查找：    std = global_dict[threading.current_thread()]    ...def do_task_2():    # 任何函数都可以查找出当前线程的std变量：    std = global_dict[threading.current_thread()]    ...</code></pre><p>这种方式理论上是可行的，它最大的优点是消除了std对象在每层函数中的传递问题，但是，每个函数获取std的代码有点low。</p><p>有没有更简单的方式？</p><h3 id="3-使用ThreadLocal的方法"><a href="#3-使用ThreadLocal的方法" class="headerlink" title="3. 使用ThreadLocal的方法"></a>3. 使用ThreadLocal的方法</h3><p>ThreadLocal应运而生，不用查找dict，ThreadLocal帮你自动做这件事：</p><pre class="language-none"><code class="language-none">import threading# 创建全局ThreadLocal对象:local_school = threading.local()def process_student():    # 获取当前线程关联的student:    std = local_school.student    print('Hello, %s (in %s)' % (std, threading.current_thread().name))def process_thread(name):    # 绑定ThreadLocal的student:    local_school.student = name    process_student()t1 = threading.Thread(target= process_thread, args=('dongGe',), name='Thread-A')t2 = threading.Thread(target= process_thread, args=('老王',), name='Thread-B')t1.start()t2.start()t1.join()t2.join()</code></pre><h4 id="说明-3"><a href="#说明-3" class="headerlink" title="说明"></a>说明</h4><p>全局变量local_school就是一个ThreadLocal对象，每个Thread对它都可以读写student属性，但互不影响。你可以把local_school看成全局变量，但每个属性如local_school.student都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。</p><p>可以理解为全局变量local_school是一个dict，不但可以用local_school.student，还可以绑定其他变量，如local_school.teacher等等。</p><p>ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。</p><h4 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a>4. 小结</h4><p>一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题</p><h3 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h3><p>同步调用就是你 喊 你朋友吃饭 ，你朋友在忙 ，你就一直在那等，等你朋友忙完了 ，你们一起去<br>异步调用就是你 喊 你朋友吃饭 ，你朋友说知道了 ，待会忙完去找你 ，你就去做别的了。</p><pre class="language-none"><code class="language-none">from multiprocessing import Poolimport timeimport osdef test():    print("---进程池中的进程---pid=%d,ppid=%d--"%(os.getpid(),os.getppid()))    for i in range(3):        print("----%d---"%i)        time.sleep(1)    return "hahah"def test2(args):    print("---callback func--pid=%d"%os.getpid())    print("---callback func--args=%s"%args)pool = Pool(3)pool.apply_async(func=test,callback=test2)time.sleep(5)print("----主进程-pid=%d----"%os.getpid())</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python系统编程-进程</title>
      <link href="/2017/11/27/python-xi-tong-bian-cheng-jin-cheng/"/>
      <url>/2017/11/27/python-xi-tong-bian-cheng-jin-cheng/</url>
      
        <content type="html"><![CDATA[<p>#进程</p><h3 id="现实生活中"><a href="#现实生活中" class="headerlink" title="现实生活中"></a>现实生活中</h3><p>有很多的场景中的事情是同时进行的，比如开车的时候 手和脚共同来驾驶汽车，再比如唱歌跳舞也是同时进行的；</p><p>如下视频是：迈克杰克逊的一段视频</p><p><a href="http://v.youku.com/v_show/id_XMzE5NjEzNjA0.html?&amp;sid=40117&amp;from=y1.2-1.999.6">http://v.youku.com/v_show/id_XMzE5NjEzNjA0.html?&amp;sid=40117&amp;from=y1.2-1.999.6</a></p><p>试想，如果把唱歌和跳舞这2件事情分开依次完成的话，估计就没有那么好的效果了（想一下场景：先唱歌，然后在跳舞，O(∩_∩)O哈哈~）</p><h3 id="程序中"><a href="#程序中" class="headerlink" title="程序中"></a>程序中</h3><p>如下程序，来模拟“唱歌跳舞”这件事情</p><pre class="language-none"><code class="language-none">#coding=utf-8    from time import sleep    def sing():        for i in range(3):            print("正在唱歌...%d"%i)            sleep(1)    def dance():        for i in range(3):            print("正在跳舞...%d"%i)            sleep(1)    if __name__ == '__main__':        sing() #唱歌        dance() #跳舞</code></pre><h3 id="注意"><a href="#注意" class="headerlink" title="!!!注意"></a>!!!注意</h3><p>很显然刚刚的程序并没有完成唱歌和跳舞同时进行的要求<br>如果想要实现“唱歌跳舞”同时进行，那么就需要一个新的方法，叫做：多任务</p><h3 id="多任务的概念"><a href="#多任务的概念" class="headerlink" title="多任务的概念"></a>多任务的概念</h3><p>什么叫“多任务”呢？简单地说，就是操作系统可以同时运行多个任务。打个比方，你一边在用浏览器上网，一边在听MP3，一边在用Word赶作业，这就是多任务，至少同时有3个任务正在运行。还有很多任务悄悄地在后台同时运行着，只是桌面上没有显示而已。</p><p>现在，多核CPU已经非常普及了，但是，即使过去的单核CPU，也可以执行多任务。由于CPU执行代码都是顺序执行的，那么，单核CPU是怎么执行多任务的呢？</p><p>答案就是操作系统轮流让各个任务交替执行，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们感觉就像所有任务都在同时执行一样。</p><p>真正的并行执行多任务只能在多核CPU上实现，但是，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。</p><h3 id="进程的创建-fork"><a href="#进程的创建-fork" class="headerlink" title="进程的创建-fork"></a>进程的创建-fork</h3><h4 id="1-进程-VS-程序"><a href="#1-进程-VS-程序" class="headerlink" title="1. 进程 VS 程序"></a>1. 进程 VS 程序</h4><p>编写完毕的代码，在没有运行的时候，称之为<strong>程序</strong></p><p>正在运行着的代码，就成为<strong>进程</strong></p><p>进程，除了包含代码以外，还有需要运行的环境等，所以和程序是有区别的</p><h4 id="2-fork"><a href="#2-fork" class="headerlink" title="2. fork( )"></a>2. fork( )</h4><p>Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程：</p><pre class="language-none"><code class="language-none">import os    # 注意，fork函数，只在Unix/Linux/Mac上运行，windows不可以    pid = os.fork()    if pid == 0:        print('哈哈1')    else:        print('哈哈2')</code></pre><h4 id="说明："><a href="#说明：" class="headerlink" title="说明："></a>说明：</h4><p>程序执行到os.fork()时，操作系统会创建一个新的进程（子进程），然后复制父进程的所有信息到子进程中<br>然后父进程和子进程都会从fork()函数中得到一个返回值，在子进程中这个值一定是0，而父进程中是子进程的 id号<br>在Unix/Linux操作系统中，提供了一个fork()系统函数，它非常特殊。</p><p>普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。</p><p>子进程永远返回0，而父进程返回子进程的ID。</p><p>这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。</p><h4 id="3-getpid-、getppid"><a href="#3-getpid-、getppid" class="headerlink" title="3. getpid()、getppid()"></a>3. getpid()、getppid()</h4><pre class="language-none"><code class="language-none">import osrpid = os.fork()if rpid&lt;0:    print("fork调用失败。")elif rpid == 0:    print("我是子进程（%s），我的父进程是（%s）"%(os.getpid(),os.getppid()))    x+=1else:    print("我是父进程（%s），我的子进程是（%s）"%(os.getpid(),rpid))print("父子进程都可以执行这里的代码")</code></pre><h4 id="多进程修改全局变量"><a href="#多进程修改全局变量" class="headerlink" title="多进程修改全局变量"></a>多进程修改全局变量</h4><pre class="language-none"><code class="language-none">#coding=utf-8import osimport timenum = 0# 注意，fork函数，只在Unix/Linux/Mac上运行，windows不可以pid = os.fork()if pid == 0:    num+=1    print('哈哈1---num=%d'%num)else:    time.sleep(1)    num+=1    print('哈哈2---num=%d'%num)</code></pre><h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>多进程中，每个进程中所有数据（包括全局变量）都各有拥有一份，互不影响</p><h4 id="多次fork问题"><a href="#多次fork问题" class="headerlink" title="多次fork问题"></a>多次fork问题</h4><p>如果在一个程序，有2次的fork函数调用，是否就会有3个进程呢？</p><pre class="language-none"><code class="language-none">#coding=utf-8import osimport time# 注意，fork函数，只在Unix/Linux/Mac上运行，windows不可以pid = os.fork()if pid == 0:    print('哈哈1')else:    print('哈哈2')pid = os.fork()if pid == 0:    print('哈哈3')else:    print('哈哈4')time.sleep(1)</code></pre><h4 id="父子进程的执行顺序"><a href="#父子进程的执行顺序" class="headerlink" title="父子进程的执行顺序"></a>父子进程的执行顺序</h4><p>父进程、子进程执行顺序没有规律，完全取决于操作系统的调度算法</p><h3 id="multiprocessing"><a href="#multiprocessing" class="headerlink" title="multiprocessing"></a>multiprocessing</h3><p>如果你打算编写多进程的服务程序，Unix/Linux无疑是正确的选择。由于Windows没有fork调用，难道在Windows上无法用Python编写多进程的程序？</p><p>由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。multiprocessing模块就是跨平台版本的多进程模块。</p><p>multiprocessing模块提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束：</p><pre class="language-none"><code class="language-none">#coding=utf-8from multiprocessing import Processimport os# 子进程要执行的代码def run_proc(name):    print('子进程运行中，name= %s ,pid=%d...' % (name, os.getpid()))if __name__=='__main__':    print('父进程 %d.' % os.getpid())    p = Process(target=run_proc, args=('test',))    print('子进程将要执行')    p.start()    p.join()    print('子进程已结束')</code></pre><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。<br>join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。</p><h4 id="Process语法结构如下："><a href="#Process语法结构如下：" class="headerlink" title="Process语法结构如下："></a>Process语法结构如下：</h4><p>Process([group [, target [, name [, args [, kwargs]]]]])</p><p>target：表示这个进程实例所调用对象；</p><p>args：表示调用对象的位置参数元组；</p><p>kwargs：表示调用对象的关键字参数字典；</p><p>name：为当前进程实例的别名；</p><p>group：大多数情况下用不到；</p><p>Process类常用方法：</p><p>is_alive()：判断进程实例是否还在执行；</p><p>join([timeout])：是否等待进程实例执行结束，或等待多少秒；</p><p>start()：启动进程实例（创建子进程）；</p><p>run()：如果没有给定target参数，对这个对象调用start()方法时，就将执行对象中的run()方法；</p><p>terminate()：不管任务是否完成，立即终止；</p><p>Process类常用属性：</p><p>name：当前进程实例别名，默认为Process-N，N为从1开始递增的整数；</p><p>pid：当前进程实例的PID值；</p><h4 id="实例1"><a href="#实例1" class="headerlink" title="实例1"></a>实例1</h4><pre class="language-none"><code class="language-none">from multiprocessing import Processimport osfrom time import sleep# 子进程要执行的代码def run_proc(name, age, **kwargs):    for i in range(10):        print('子进程运行中，name= %s,age=%d ,pid=%d...' % (name, age,os.getpid()))        print(kwargs)        sleep(0.5)if __name__=='__main__':    print('父进程 %d.' % os.getpid())    p = Process(target=run_proc, args=('test',18), kwargs={"m":20})    print('子进程将要执行')    p.start()    sleep(1)    p.terminate()    p.join()    print('子进程已结束')</code></pre><h4 id="实例2"><a href="#实例2" class="headerlink" title="实例2"></a>实例2</h4><pre class="language-none"><code class="language-none">#coding=utf-8from multiprocessing import Processimport timeimport os#两个子进程将会调用的两个方法def  worker_1(interval):    print("worker_1,父进程(%s),当前进程(%s)"%(os.getppid(),os.getpid()))    t_start = time.time()    time.sleep(interval) #程序将会被挂起interval秒    t_end = time.time()    print("worker_1,执行时间为'%0.2f'秒"%(t_end - t_start))def  worker_2(interval):    print("worker_2,父进程(%s),当前进程(%s)"%(os.getppid(),os.getpid()))    t_start = time.time()    time.sleep(interval)    t_end = time.time()    print("worker_2,执行时间为'%0.2f'秒"%(t_end - t_start))#输出当前程序的IDprint("进程ID：%s"%os.getpid())#创建两个进程对象，target指向这个进程对象要执行的对象名称，#args后面的元组中，是要传递给worker_1方法的参数，#因为worker_1方法就一个interval参数，这里传递一个整数2给它，#如果不指定name参数，默认的进程对象名称为Process-N，N为一个递增的整数p1=Process(target=worker_1,args=(2,))p2=Process(target=worker_2,name="dongGe",args=(1,))#使用"进程对象名称.start()"来创建并执行一个子进程，#这两个进程对象在start后，就会分别去执行worker_1和worker_2方法中的内容p1.start()p2.start()#同时父进程仍然往下执行，如果p2进程还在执行，将会返回Trueprint("p2.is_alive=%s"%p2.is_alive())#输出p1和p2进程的别名和pidprint("p1.name=%s"%p1.name)print("p1.pid=%s"%p1.pid)print("p2.name=%s"%p2.name)print("p2.pid=%s"%p2.pid)#join括号中不携带参数，表示父进程在这个位置要等待p1进程执行完成后，#再继续执行下面的语句，一般用于进程间的数据同步，如果不写这一句，#下面的is_alive判断将会是True，在shell（cmd）里面调用这个程序时#可以完整的看到这个过程，大家可以尝试着将下面的这条语句改成p1.join(1)，#因为p2需要2秒以上才可能执行完成，父进程等待1秒很可能不能让p1完全执行完成，#所以下面的print会输出True，即p1仍然在执行p1.join()print("p1.is_alive=%s"%p1.is_alive())</code></pre><h4 id="进程的创建-Process子类"><a href="#进程的创建-Process子类" class="headerlink" title="进程的创建-Process子类"></a>进程的创建-Process子类</h4><p>创建新的进程还能够使用类的方式，可以自定义一个类，继承Process类，每次实例化这个类的时候，就等同于实例化一个进程对象，请看下面的实例：</p><pre class="language-none"><code class="language-none">from multiprocessing import Processimport timeimport os#继承Process类class Process_Class(Process):    #因为Process类本身也有__init__方法，这个子类相当于重写了这个方法，    #但这样就会带来一个问题，我们并没有完全的初始化一个Process类，所以就不能使用从这个类继承的一些方法和属性，    #最好的方法就是将继承类本身传递给Process.__init__方法，完成这些初始化操作    def __init__(self,interval):        Process.__init__(self)        self.interval = interval    #重写了Process类的run()方法    def run(self):        print("子进程(%s) 开始执行，父进程为（%s）"%(os.getpid(),os.getppid()))        t_start = time.time()        time.sleep(self.interval)        t_stop = time.time()        print("(%s)执行结束，耗时%0.2f秒"%(os.getpid(),t_stop-t_start))      if __name__=="__main__":    t_start = time.time()    print("当前程序进程(%s)"%os.getpid())            p1 = Process_Class(2)    #对一个不包含target属性的Process类执行start()方法，就会运行这个类中的run()方法，所以这里会执行p1.run()    p1.start()    p1.join()    t_stop = time.time()    print("(%s)执行结束，耗时%0.2f"%(os.getpid(),t_stop-t_start))</code></pre><h3 id="进程池Pool"><a href="#进程池Pool" class="headerlink" title="进程池Pool"></a>进程池Pool</h3><p>当需要创建的子进程数量不多时，可以直接利用multiprocessing中的Process动态成生多个进程，但如果是上百甚至上千个目标，手动的去创建进程的工作量巨大，此时就可以用到multiprocessing模块提供的Pool方法。</p><p>初始化Pool时，可以指定一个最大进程数，当有新的请求提交到Pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到指定的最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行，请看下面的实例：</p><pre class="language-none"><code class="language-none">from multiprocessing import Poolimport os,time,randomdef worker(msg):    t_start = time.time()    print("%s开始执行,进程号为%d"%(msg,os.getpid()))    #random.random()随机生成0~1之间的浮点数    time.sleep(random.random()*2)     t_stop = time.time()    print(msg,"执行完毕，耗时%0.2f"%(t_stop-t_start))po=Pool(3) #定义一个进程池，最大进程数3for i in range(0,10):    #Pool.apply_async(要调用的目标,(传递给目标的参数元祖,))    #每次循环将会用空闲出来的子进程去调用目标    po.apply_async(worker,(i,))print("----start----")po.close() #关闭进程池，关闭后po不再接收新的请求po.join() #等待po中所有子进程执行完成，必须放在close语句之后print("-----end-----")</code></pre><p>multiprocessing.Pool常用函数解析：</p><p>apply_async(func[, args[, kwds]]) ：使用非阻塞方式调用func（并行执行，堵塞方式必须等待上一个进程退出才能执行下一个进程），args为传递给func的参数列表，kwds为传递给func的关键字参数列表；</p><p>apply(func[, args[, kwds]])：使用阻塞方式调用func</p><p>close()：关闭Pool，使其不再接受新的任务；</p><p>terminate()：不管任务是否完成，立即终止；</p><p>join()：主进程阻塞，等待子进程的退出， 必须在close或terminate之后使用；</p><h4 id="apply堵塞式"><a href="#apply堵塞式" class="headerlink" title="apply堵塞式"></a>apply堵塞式</h4><pre class="language-none"><code class="language-none">from multiprocessing import Poolimport os,time,randomdef worker(msg):    t_start = time.time()    print("%s开始执行,进程号为%d"%(msg,os.getpid()))    #random.random()随机生成0~1之间的浮点数    time.sleep(random.random()*2)     t_stop = time.time()    print(msg,"执行完毕，耗时%0.2f"%(t_stop-t_start))po=Pool(3) #定义一个进程池，最大进程数3for i in range(0,10):    po.apply(worker,(i,))print("----start----")po.close() #关闭进程池，关闭后po不再接收新的请求po.join() #等待po中所有子进程执行完成，必须放在close语句之后print("-----end-----")</code></pre><h3 id="进程间通信-Queue"><a href="#进程间通信-Queue" class="headerlink" title="进程间通信-Queue"></a>进程间通信-Queue</h3><p>Process之间有时需要通信，操作系统提供了很多机制来实现进程间的通信。</p><h4 id="1-Queue的使用"><a href="#1-Queue的使用" class="headerlink" title="1. Queue的使用"></a>1. Queue的使用</h4><p>可以使用multiprocessing模块的Queue实现多进程之间的数据传递，Queue本身是一个消息列队程序，首先用一个小实例来演示一下Queue的工作原理：</p><pre class="language-none"><code class="language-none">#coding=utf-8from multiprocessing import Queueq=Queue(3) #初始化一个Queue对象，最多可接收三条put消息q.put("消息1") q.put("消息2")print(q.full())  #Falseq.put("消息3")print(q.full()) #True#因为消息列队已满下面的try都会抛出异常，第一个try会等待2秒后再抛出异常，第二个Try会立刻抛出异常try:    q.put("消息4",True,2)except:    print("消息列队已满，现有消息数量:%s"%q.qsize())try:    q.put_nowait("消息4")except:    print("消息列队已满，现有消息数量:%s"%q.qsize())#推荐的方式，先判断消息列队是否已满，再写入if not q.full():    q.put_nowait("消息4")#读取消息时，先判断消息列队是否为空，再读取if not q.empty():    for i in range(q.qsize()):        print(q.get_nowait())</code></pre><h4 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h4><p>初始化Queue()对象时（例如：q=Queue()），若括号中没有指定最大可接收的消息数量，或数量为负值，那么就代表可接受的消息数量没有上限（直到内存的尽头）；</p><p>Queue.qsize()：返回当前队列包含的消息数量；</p><p>Queue.empty()：如果队列为空，返回True，反之False ；</p><p>Queue.full()：如果队列满了，返回True,反之False；</p><p>Queue.get([block[, timeout]])：获取队列中的一条消息，然后将其从列队中移除，block默认值为True；</p><p>1）如果block使用默认值，且没有设置timeout（单位秒），消息列队如果为空，此时程序将被阻塞（停在读取状态），直到从消息列队读到消息为止，如果设置了timeout，则会等待timeout秒，若还没读取到任何消息，则抛出”Queue.Empty”异常；</p><p>2）如果block值为False，消息列队如果为空，则会立刻抛出”Queue.Empty”异常；</p><p>Queue.get_nowait()：相当Queue.get(False)；</p><p>Queue.put(item,[block[, timeout]])：将item消息写入队列，block默认值为True；</p><p>1）如果block使用默认值，且没有设置timeout（单位秒），消息列队如果已经没有空间可写入，此时程序将被阻塞（停在写入状态），直到从消息列队腾出空间为止，如果设置了timeout，则会等待timeout秒，若还没空间，则抛出”Queue.Full”异常；</p><p>2）如果block值为False，消息列队如果没有空间可写入，则会立刻抛出”Queue.Full”异常；</p><p>Queue.put_nowait(item)：相当Queue.put(item, False)；</p><h4 id="2-Queue实例"><a href="#2-Queue实例" class="headerlink" title="2. Queue实例"></a>2. Queue实例</h4><p>我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据：</p><pre class="language-none"><code class="language-none">from multiprocessing import Process, Queueimport os, time, random# 写数据进程执行的代码:def write(q):    for value in ['A', 'B', 'C']:        print 'Put %s to queue...' % value        q.put(value)        time.sleep(random.random())# 读数据进程执行的代码:def read(q):    while True:        if not q.empty():            value = q.get(True)            print 'Get %s from queue.' % value            time.sleep(random.random())        else:            breakif __name__=='__main__':    # 父进程创建Queue，并传给各个子进程：    q = Queue()    pw = Process(target=write, args=(q,))    pr = Process(target=read, args=(q,))    # 启动子进程pw，写入:    pw.start()    # 等待pw结束:    pw.join()    # 启动子进程pr，读取:    pr.start()    pr.join()    # pr进程里是死循环，无法等待其结束，只能强行终止:    print ''    print '所有数据都写入并且读完'    </code></pre><h4 id="3-进程池中的Queue"><a href="#3-进程池中的Queue" class="headerlink" title="3. 进程池中的Queue"></a>3. 进程池中的Queue</h4><p>如果要使用Pool创建进程，就需要使用multiprocessing.Manager()中的Queue()，而不是multiprocessing.Queue()，否则会得到一条如下的错误信息：</p><p>RuntimeError: Queue objects should only be shared between processes through inheritance.</p><p>下面的实例演示了进程池中的进程如何通信：</p><pre class="language-none"><code class="language-none">#coding=utf-8#修改import中的Queue为Managerfrom multiprocessing import Manager,Poolimport os,time,randomdef reader(q):    print("reader启动(%s),父进程为(%s)"%(os.getpid(),os.getppid()))    for i in range(q.qsize()):        print("reader从Queue获取到消息：%s"%q.get(True))def writer(q):    print("writer启动(%s),父进程为(%s)"%(os.getpid(),os.getppid()))    for i in "dongGe":        q.put(i)if __name__=="__main__":    print("(%s) start"%os.getpid())    q=Manager().Queue() #使用Manager中的Queue来初始化    po=Pool()    #使用阻塞模式创建进程，这样就不需要在reader中使用死循环了，可以让writer完全执行完成后，再用reader去读取    po.apply(writer,(q,))    po.apply(reader,(q,))    po.close()    po.join()    print("(%s) End"%os.getpid())</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python面向对象进阶之装饰器</title>
      <link href="/2017/11/14/python-mian-xiang-dui-xiang-jin-jie-zhi-zhuang-shi-qi/"/>
      <url>/2017/11/14/python-mian-xiang-dui-xiang-jin-jie-zhi-zhuang-shi-qi/</url>
      
        <content type="html"><![CDATA[<h3 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h3><h4 id="1-函数引用"><a href="#1-函数引用" class="headerlink" title="1. 函数引用"></a>1. 函数引用</h4><pre class="language-none"><code class="language-none">def test1():    print("--- in test1 func----")#调用函数test1()#引用函数ret = test1print(id(ret))print(id(test1))#通过引用调用函数ret()</code></pre><h4 id="2-什么是闭包"><a href="#2-什么是闭包" class="headerlink" title="2. 什么是闭包"></a>2. 什么是闭包</h4><pre class="language-none"><code class="language-none">#定义一个函数def test(number):    #在函数内部再定义一个函数，并且这个函数用到了外边函数的变量，那么将这个函数以及用到的一些变量称之为闭包    def test_in(number_in):        print("in test_in 函数, number_in is %d"%number_in)        return number+number_in    #其实这里返回的就是闭包的结果    return test_in#给test函数赋值，这个20就是给参数numberret = test(20)#注意这里的100其实给参数number_inprint(ret(100))#注意这里的200其实给参数number_inprint(ret(200))</code></pre><h4 id="3-闭包再理解"><a href="#3-闭包再理解" class="headerlink" title="3. 闭包再理解"></a>3. 闭包再理解</h4><p>内部函数对外部函数作用域里变量的引用（非全局变量），则称内部函数为闭包。</p><pre class="language-none"><code class="language-none"># closure.pydef counter(start=0):    count=[start]    def incr():        count[0] += 1        return count[0]    return incr</code></pre><h4 id="4-看一个闭包的实际例子："><a href="#4-看一个闭包的实际例子：" class="headerlink" title="4. 看一个闭包的实际例子："></a>4. 看一个闭包的实际例子：</h4><pre class="language-none"><code class="language-none">def line_conf(a, b):    def line(x):        return a*x + b    return lineline1 = line_conf(1, 1)line2 = line_conf(4, 5)print(line1(5))print(line2(5))</code></pre><p>这个例子中，函数line与变量a,b构成闭包。在创建闭包的时候，我们通过line_conf的参数a,b说明了这两个变量的取值，这样，我们就确定了函数的最终形式(y = x + 1和y = 4x + 5)。我们只需要变换参数a,b，就可以获得不同的直线表达函数。由此，我们可以看到，闭包也具有提高代码可复用性的作用。</p><p>如果没有闭包，我们需要每次创建直线函数的时候同时说明a,b,x。这样，我们就需要更多的参数传递，也减少了代码的可移植性。</p><p>闭包思考：</p><p>1.闭包似优化了变量，原来需要类对象完成的工作，闭包也可以完成<br>2.由于闭包引用了外部函数的局部变量，则外部函数的局部变量没有及时释放，消耗内存</p><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>装饰器是程序开发中经常会用到的一个功能，用好了装饰器，开发效率如虎添翼，所以这也是Python面试中必问的问题，但对于好多初次接触这个知识的人来讲，这个功能有点绕，自学时直接绕过去了，然后面试问到了就挂了，因为装饰器是程序开发的基础知识，这个都不会，别跟人家说你会Python, 看了下面的文章，保证你学会装饰器。</p><pre class="language-none"><code class="language-none">def w1(func):    def inner():        # 验证1        # 验证2        # 验证3        func()    return inner@w1def f1():    print('f1')</code></pre><p>python解释器就会从上到下解释代码，步骤如下：</p><p>def w1(func): ==&gt;将w1函数加载到内存<br>@w1<br>没错， 从表面上看解释器仅仅会解释这两句代码，因为函数在 没有被调用之前其内部代码不会被执行。</p><p>从表面上看解释器着实会执行这两句，但是 @w1 这一句代码里却有大文章， @函数名 是python的一种语法糖。</p><p>上例@w1内部会执行一下操作：</p><p>执行w1函数</p><p>执行w1函数 ，并将 @w1 下面的函数作为w1函数的参数，即：@w1 等价于 w1(f1) 所以，内部就会去执行：</p><pre class="language-none"><code class="language-none">def inner():     #验证 1    #验证 2    #验证 3    f1()     # func是参数，此时 func 等于 f1 return inner# 返回的 inner，inner代表的是函数，非执行函数 ,其实就是将原来的 f1 函数塞进另外一个函数中</code></pre><p>w1的返回值</p><p>将执行完的w1函数返回值 赋值 给@w1下面的函数的函数名f1 即将w1的返回值再重新赋值给 f1，即：</p><pre class="language-none"><code class="language-none">新f1 = def inner():             #验证 1            #验证 2            #验证 3            原来f1()        return inner</code></pre><p>想要执行 f1 函数时，就会执行 新f1 函数，在新f1 函数内部先执行验证，再执行原来的f1函数，然后将原来f1 函数的返回值返回给了业务调用者。</p><h4 id="再议装饰器"><a href="#再议装饰器" class="headerlink" title="再议装饰器"></a>再议装饰器</h4><pre class="language-none"><code class="language-none">#定义函数：完成包裹数据def makeBold(fn):    def wrapped():        return "&lt;b&gt;" + fn() + "&lt;/b&gt;"    return wrapped#定义函数：完成包裹数据def makeItalic(fn):    def wrapped():        return "&lt;i&gt;" + fn() + "&lt;/i&gt;"    return wrapped@makeBolddef test1():    return "hello world-1"@makeItalicdef test2():    return "hello world-2"@makeBold@makeItalicdef test3():    return "hello world-3"print(test1()))print(test2()))print(test3()))</code></pre><h4 id="装饰器-decorator-功能"><a href="#装饰器-decorator-功能" class="headerlink" title="装饰器(decorator)功能"></a>装饰器(decorator)功能</h4><p>引入日志<br>函数执行时间统计<br>执行函数前预备处理<br>执行函数后清理功能<br>权限校验等场景<br>缓存</p><h3 id="装饰器示例"><a href="#装饰器示例" class="headerlink" title="装饰器示例"></a>装饰器示例</h3><h4 id="例1-无参数的函数"><a href="#例1-无参数的函数" class="headerlink" title="例1:无参数的函数"></a>例1:无参数的函数</h4><pre class="language-none"><code class="language-none">from time import ctime, sleepdef timefun(func):    def wrappedfunc():        print("%s called at %s"%(func.__name__, ctime()))        func()    return wrappedfunc@timefundef foo():    print("I am foo")foo()sleep(2)foo()</code></pre><p>上面代码理解装饰器执行行为可理解成</p><pre class="language-none"><code class="language-none">foo = timefun(foo)#foo先作为参数赋值给func后,foo接收指向timefun返回的wrappedfuncfoo()#调用foo(),即等价调用wrappedfunc()#内部函数wrappedfunc被引用，所以外部函数的func变量(自由变量)并没有释放#func里保存的是原foo函数对象</code></pre><h4 id="例2-被装饰的函数有参数"><a href="#例2-被装饰的函数有参数" class="headerlink" title="例2:被装饰的函数有参数"></a>例2:被装饰的函数有参数</h4><pre class="language-none"><code class="language-none">from time import ctime, sleepdef timefun(func):    def wrappedfunc(a, b):        print("%s called at %s"%(func.__name__, ctime()))        print(a, b)        func(a, b)    return wrappedfunc@timefundef foo(a, b):    print(a+b)foo(3,5)sleep(2)foo(2,4)</code></pre><h4 id="例3-被装饰的函数有不定长参数"><a href="#例3-被装饰的函数有不定长参数" class="headerlink" title="例3:被装饰的函数有不定长参数"></a>例3:被装饰的函数有不定长参数</h4><pre class="language-none"><code class="language-none">from time import ctime, sleepdef timefun(func):    def wrappedfunc(*args, **kwargs):        print("%s called at %s"%(func.__name__, ctime()))        func(*args, **kwargs)    return wrappedfunc@timefundef foo(a, b, c):    print(a+b+c)foo(3,5,7)sleep(2)foo(2,4,9)</code></pre><h4 id="例4-装饰器中的return"><a href="#例4-装饰器中的return" class="headerlink" title="例4:装饰器中的return"></a>例4:装饰器中的return</h4><pre class="language-none"><code class="language-none">from time import ctime, sleepdef timefun(func):    def wrappedfunc():        print("%s called at %s"%(func.__name__, ctime()))        func()    return wrappedfunc@timefundef foo():    print("I am foo")@timefundef getInfo():    return '----hahah---'foo()sleep(2)foo()print(getInfo())</code></pre><p>总结：<br>一般情况下为了让装饰器更通用，可以有return</p><h4 id="例5-装饰器带参数-在原有装饰器的基础上，设置外部变量"><a href="#例5-装饰器带参数-在原有装饰器的基础上，设置外部变量" class="headerlink" title="例5:装饰器带参数,在原有装饰器的基础上，设置外部变量"></a>例5:装饰器带参数,在原有装饰器的基础上，设置外部变量</h4><pre class="language-none"><code class="language-none">#decorator2.pyfrom time import ctime, sleepdef timefun_arg(pre="hello"):    def timefun(func):        def wrappedfunc():            print("%s called at %s %s"%(func.__name__, ctime(), pre))            return func()        return wrappedfunc    return timefun@timefun_arg("itcast")def foo():    print("I am foo")@timefun_arg("python")def too():    print("I am too")foo()sleep(2)foo()too()sleep(2)too()</code></pre><h4 id="例6：类装饰器（扩展，非重点）"><a href="#例6：类装饰器（扩展，非重点）" class="headerlink" title="例6：类装饰器（扩展，非重点）"></a>例6：类装饰器（扩展，非重点）</h4><p>装饰器函数其实是这样一个接口约束，它必须接受一个callable对象作为参数，然后返回一个callable对象。在Python中一般callable对象都是函数，但也有例外。只要某个对象重写了 <strong>call</strong>() 方法，那么这个对象就是callable的。<br>类装饰器demo</p><pre class="language-none"><code class="language-none">class Test(object):    def __init__(self, func):        print("---初始化---")        print("func name is %s"%func.__name__)        self.__func = func    def __call__(self):        print("---装饰器中的功能---")        self.__func()#说明：#1. 当用Test来装作装饰器对test函数进行装饰的时候，首先会创建Test的实例对象#    并且会把test这个函数名当做参数传递到__init__方法中#    即在__init__方法中的func变量指向了test函数体##2. test函数相当于指向了用Test创建出来的实例对象##3. 当在使用test()进行调用时，就相当于让这个对象()，因此会调用这个对象的__call__方法##4. 为了能够在__call__方法中调用原来test指向的函数体，所以在__init__方法中就需要一个实例属性来保存这个函数体的引用#    所以才有了self.__func = func这句代码，从而在调用__call__方法中能够调用到test之前的函数体@Testdef test():    print("----test---")test()showpy()#如果把这句话注释，重新运行程序，依然会看到"--初始化--"</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python面向对象进阶</title>
      <link href="/2017/11/14/python-mian-xiang-dui-xiang-jin-jie/"/>
      <url>/2017/11/14/python-mian-xiang-dui-xiang-jin-jie/</url>
      
        <content type="html"><![CDATA[<h3 id="python是动态语言"><a href="#python是动态语言" class="headerlink" title="python是动态语言"></a>python是动态语言</h3><h4 id="1-动态语言的定义"><a href="#1-动态语言的定义" class="headerlink" title="1. 动态语言的定义"></a>1. 动态语言的定义</h4><p>动态编程语言 是 高级程序设计语言 的一个类别，在计算机科学领域已被广泛应用。它是一类 在运行时可以改变其结构的语言 ：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。动态语言目前非常具有活力。例如JavaScript便是一个动态语言，除此之外如 PHP 、 Ruby 、 Python 等也都属于动态语言，而 C 、 C++ 等语言则不属于动态语言。—-来自 维基百科</p><h4 id="2-运行的过程中给对象绑定-添加-属性"><a href="#2-运行的过程中给对象绑定-添加-属性" class="headerlink" title="2. 运行的过程中给对象绑定(添加)属性"></a>2. 运行的过程中给对象绑定(添加)属性</h4><pre class="language-none"><code class="language-none">&gt;&gt;&gt; class Person(object):    def __init__(self, name = None, age = None):        self.name = name        self.age = age&gt;&gt;&gt; P = Person("小明", "24")&gt;&gt;&gt;</code></pre><p>在这里，我们定义了1个类Person，在这个类里，定义了两个初始属性name和age，但是人还有性别啊！如果这个类不是你写的是不是你会尝试访问性别这个属性呢？</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; P.sex = "male"&gt;&gt;&gt; P.sex'male'&gt;&gt;&gt;</code></pre><p>这时候就发现问题了，我们定义的类里面没有sex这个属性啊！怎么回事呢？ 这就是动态语言的魅力和坑！ 这里 实际上就是 动态给实例绑定属性！</p><h4 id="3-运行的过程中给类绑定-添加-属性"><a href="#3-运行的过程中给类绑定-添加-属性" class="headerlink" title="3. 运行的过程中给类绑定(添加)属性"></a>3. 运行的过程中给类绑定(添加)属性</h4><pre class="language-none"><code class="language-none">&gt;&gt;&gt; P1 = Person("小丽", "25")&gt;&gt;&gt; P1.sexTraceback (most recent call last):  File "&lt;pyshell#21&gt;", line 1, in &lt;module&gt;    P1.sexAttributeError: Person instance has no attribute 'sex'&gt;&gt;&gt;</code></pre><p>我们尝试打印P1.sex，发现报错，P1没有sex这个属性！—- 给P这个实例绑定属性对P1这个实例不起作用！ 那我们要给所有的Person的实例加上 sex属性怎么办呢？ 答案就是直接给Person绑定属性！</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt;&gt; Person.sex = None #给类Person添加一个属性&gt;&gt;&gt; P1 = Person("小丽", "25")&gt;&gt;&gt; print(P1.sex) #如果P1这个实例对象中没有sex属性的话，那么就会访问它的类属性None #可以看到没有出现异常&gt;&gt;&gt;</code></pre><h4 id="4-运行的过程中给类绑定-添加-方法"><a href="#4-运行的过程中给类绑定-添加-方法" class="headerlink" title="4. 运行的过程中给类绑定(添加)方法"></a>4. 运行的过程中给类绑定(添加)方法</h4><p>我们直接给Person绑定sex这个属性，重新实例化P1后，P1就有sex这个属性了！ 那么function呢？怎么绑定？</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; class Person(object):    def __init__(self, name = None, age = None):        self.name = name        self.age = age    def eat(self):        print("eat food")&gt;&gt;&gt; def run(self, speed):    print("%s在移动, 速度是 %d km/h"%(self.name, speed))&gt;&gt;&gt; P = Person("老王", 24)&gt;&gt;&gt; P.eat()eat food&gt;&gt;&gt; &gt;&gt;&gt; P.run()Traceback (most recent call last):  File "&lt;pyshell#5&gt;", line 1, in &lt;module&gt;    P.run()AttributeError: Person instance has no attribute 'run'&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; import types&gt;&gt;&gt; P.run = types.MethodType(run, P)&gt;&gt;&gt; P.run(180)老王在移动,速度是 180 km/h</code></pre><p>既然给类添加方法，是使用类名.方法名 = xxxx，那么给对象添加一个方法也是类似的对象.方法名 = xxxx</p><pre class="language-none"><code class="language-none">import types#定义了一个类class Person(object):    num = 0    def __init__(self, name = None, age = None):        self.name = name        self.age = age    def eat(self):        print("eat food")#定义一个实例方法def run(self, speed):    print("%s在移动, 速度是 %d km/h"%(self.name, speed))#定义一个类方法@classmethoddef testClass(cls):    cls.num = 100#定义一个静态方法@staticmethoddef testStatic():    print("---static method----")    #创建一个实例对象P = Person("老王", 24)#调用在class中的方法P.eat()#给这个对象添加实例方法P.run = types.MethodType(run, P)#调用实例方法P.run(180)#给Person类绑定类方法Person.testClass = testClass#调用类方法print(Person.num)Person.testClass()print(Person.num)#给Person类绑定静态方法Person.testStatic = testStatic#调用静态方法Person.testStatic()</code></pre><h4 id="5-运行的过程中删除属性、方法"><a href="#5-运行的过程中删除属性、方法" class="headerlink" title="5. 运行的过程中删除属性、方法"></a>5. 运行的过程中删除属性、方法</h4><p>删除的方法:</p><p>del 对象.属性名<br>delattr(对象, “属性名”)<br>通过以上例子可以得出一个结论：相对于动态语言，静态语言具有严谨性！所以，玩动态语言的时候，小心动态的坑！</p><p>那么怎么避免这种情况呢？ 请使用__slots__，</p><h3 id="slots"><a href="#slots" class="headerlink" title="slots"></a><strong>slots</strong></h3><p>现在我们终于明白了，动态语言与静态语言的不同</p><p>动态语言：可以在运行的过程中，修改代码</p><p>静态语言：编译时已经确定好代码，运行过程中不能修改</p><p>如果我们想要限制实例的属性怎么办？比如，只允许对Person实例添加name和age属性。</p><p>为了达到限制的目的，Python允许在定义class的时候，定义一个特殊的__slots__变量，来限制该class实例能添加的属性：</p><pre class="language-none"><code class="language-none">&gt;&gt; class Person(object):    __slots__ = ("name", "age")&gt;&gt;&gt; P = Person()&gt;&gt;&gt; P.name = "老王"&gt;&gt;&gt; P.age = 20&gt;&gt;&gt; P.score = 100Traceback (most recent call last):  File "&lt;pyshell#3&gt;", line 1, in &lt;module&gt;AttributeError: Person instance has no attribute 'score'&gt;&gt;&gt;</code></pre><p>注意:<br>使用__slots__要注意，__slots__定义的属性仅对当前类实例起作用，对继承的子类是不起作用的</p><pre class="language-none"><code class="language-none">In [67]: class Test(Person):    ...:     pass    ...:In [68]: t = Test()In [69]: t.score = 100</code></pre><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><h4 id="1-什么是生成器"><a href="#1-什么是生成器" class="headerlink" title="1. 什么是生成器"></a>1. 什么是生成器</h4><p>通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。</p><h4 id="2-创建生成器方法1"><a href="#2-创建生成器方法1" class="headerlink" title="2. 创建生成器方法1"></a>2. 创建生成器方法1</h4><p>要创建一个生成器，有很多种方法。第一种方法很简单，只要把一个列表生成式的 [ ] 改成 ( )</p><pre class="language-none"><code class="language-none">In [15]: L = [ x*2 for x in range(5)]In [16]: LOut[16]: [0, 2, 4, 6, 8]In [17]: G = ( x*2 for x in range(5))In [18]: GOut[18]: &lt;generator object &lt;genexpr&gt; at 0x7f626c132db0&gt;In [19]:</code></pre><p>创建 L 和 G 的区别仅在于最外层的 [ ] 和 ( ) ， L 是一个列表，而 G 是一个生成器。我们可以直接打印出L的每一个元素，但我们怎么打印出G的每一个元素呢？如果要一个一个打印出来，可以通过 next() 函数获得生成器的下一个返回值：</p><pre class="language-none"><code class="language-none">In [19]: next(G)Out[19]: 0In [20]: next(G)Out[20]: 2In [21]: next(G)Out[21]: 4In [22]: next(G)Out[22]: 6In [23]: next(G)Out[23]: 8In [24]: next(G)---------------------------------------------------------------------------StopIteration                             Traceback (most recent call last)&lt;ipython-input-24-380e167d6934&gt; in &lt;module&gt;()----&gt; 1 next(G)StopIteration: In [25]:In [26]: G = ( x*2 for x in range(5))In [27]: for x in G:   ....:     print(x)   ....:     02468In [28]:</code></pre><p>生成器保存的是算法，每次调用 next(G) ，就计算出 G 的下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出 StopIteration 的异常。当然，这种不断调用 next() 实在是太变态了，正确的方法是使用 for 循环，因为生成器也是可迭代对象。所以，我们创建了一个生成器后，基本上永远不会调用 next() ，而是通过 for 循环来迭代它，并且不需要关心 StopIteration 异常。</p><h4 id="3-创建生成器方法2"><a href="#3-创建生成器方法2" class="headerlink" title="3. 创建生成器方法2"></a>3. 创建生成器方法2</h4><p>generator非常强大。如果推算的算法比较复杂，用类似列表生成式的 for 循环无法实现的时候，还可以用函数来实现。</p><p>比如，著名的斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到：</p><p>1, 1, 2, 3, 5, 8, 13, 21, 34, …</p><p>斐波拉契数列用列表生成式写不出来，但是，用函数把它打印出来却很容易：</p><pre class="language-none"><code class="language-none">In [28]: def fib(times):   ....:     n = 0   ....:     a,b = 0,1   ....:     while n&lt;times:   ....:         print(b)   ....:         a,b = b,a+b   ....:         n+=1   ....:     return 'done'   ....: In [29]: fib(5)11235Out[29]: 'done'</code></pre><p>仔细观察，可以看出，fib函数实际上是定义了斐波拉契数列的推算规则，可以从第一个元素开始，推算出后续任意的元素，这种逻辑其实非常类似generator。</p><p>也就是说，上面的函数和generator仅一步之遥。要把fib函数变成generator，只需要把print(b)改为yield b就可以了：</p><pre class="language-none"><code class="language-none">In [30]: def fib(times):   ....:     n = 0   ....:     a,b = 0,1   ....:     while n&lt;times:   ....:         yield b   ....:         a,b = b,a+b   ....:         n+=1   ....:     return 'done'   ....: In [31]: F = fib(5)In [32]: next(F)Out[32]: 1In [33]: next(F)Out[33]: 1In [34]: next(F)Out[34]: 2In [35]: next(F)Out[35]: 3In [36]: next(F)Out[36]: 5In [37]: next(F)    ---------------------------------------------------------------------------StopIteration                             Traceback (most recent call last)&lt;ipython-input-37-8c2b02b4361a&gt; in &lt;module&gt;()    ----&gt; 1 next(F)StopIteration: done</code></pre><p>在上面fib 的例子，我们在循环过程中不断调用 yield ，就会不断中断。当然要给循环设置一个条件来退出循环，不然就会产生一个无限数列出来。同样的，把函数改成generator后，我们基本上从来不会用 next() 来获取下一个返回值，而是直接使用 for 循环来迭代：</p><pre class="language-none"><code class="language-none">In [38]: for n in fib(5):   ....:     print(n)   ....:     11235In [39]:</code></pre><p>但是用for循环调用generator时，发现拿不到generator的return语句的返回值。如果想要拿到返回值，必须捕获StopIteration错误，返回值包含在StopIteration的value中：</p><pre class="language-none"><code class="language-none">In [39]: g = fib(5)In [40]: while True:   ....:     try:   ....:         x = next(g)   ....:         print("value:%d"%x)         ....:     except StopIteration as e:   ....:         print("生成器返回值:%s"%e.value)   ....:         break   ....:     value:1value:1value:2value:3value:5生成器返回值:doneIn [41]:### 4. send例子：执行到yield时，gen函数作用暂时保存，返回i的值;temp接收下次c.send("python")，send发送过来的值，c.next()等价c.send(None)</code></pre><pre class="language-none"><code class="language-none">In [10]: def gen():   ....:     i = 0   ....:     while i&lt;5:   ....:         temp = yield i   ....:         print(temp)   ....:         i+=1   ....:</code></pre><p>使用next函数</p><pre class="language-none"><code class="language-none">In [11]: f = gen()In [12]: next(f)Out[12]: 0In [13]: next(f)NoneOut[13]: 1In [14]: next(f)NoneOut[14]: 2In [15]: next(f)NoneOut[15]: 3In [16]: next(f)NoneOut[16]: 4In [17]: next(f)None---------------------------------------------------------------------------StopIteration                             Traceback (most recent call last)&lt;ipython-input-17-468f0afdf1b9&gt; in &lt;module&gt;()----&gt; 1 next(f)StopIteration:</code></pre><p>使用<strong>next</strong>()方法</p><pre class="language-none"><code class="language-none">In [18]: f = gen()In [19]: f.__next__()Out[19]: 0In [20]: f.__next__()NoneOut[20]: 1In [21]: f.__next__()NoneOut[21]: 2In [22]: f.__next__()NoneOut[22]: 3In [23]: f.__next__()NoneOut[23]: 4In [24]: f.__next__()None---------------------------------------------------------------------------StopIteration                             Traceback (most recent call last)&lt;ipython-input-24-39ec527346a9&gt; in &lt;module&gt;()----&gt; 1 f.__next__()StopIteration:</code></pre><p>使用send</p><pre class="language-none"><code class="language-none">In [43]: f = gen()In [44]: f.__next__()Out[44]: 0In [45]: f.send('haha')hahaOut[45]: 1In [46]: f.__next__()NoneOut[46]: 2In [47]: f.send('haha')hahaOut[47]: 3In [48]:</code></pre><p><strong>总结</strong><br>生成器是这样一个函数，它记住上一次返回时在函数体中的位置。对生成器函数的第二次（或第 n 次）调用跳转至该函数中间，而上次调用的所有局部变量都保持不变。</p><p>生成器不仅“记住”了它数据状态；生成器还“记住”了它在流控制构造（在命令式编程中，这种构造不只是数据值）中的位置。</p><p>生成器的特点：</p><p>节约内存<br>迭代到下一次的调用时，所使用的参数都是第一次所保留下的，即是说，在整个所有函数调用的参数都是第一次所调用时保留的，而不是新创建的</p><h3 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h3><p>迭代是访问集合元素的一种方式。迭代器是一个可以记住遍历的位置的对象。迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。</p><h4 id="1-可迭代对象"><a href="#1-可迭代对象" class="headerlink" title="1. 可迭代对象"></a>1. 可迭代对象</h4><p>以直接作用于 for 循环的数据类型有以下几种：</p><p>一类是集合数据类型，如 list 、 tuple 、 dict 、 set 、 str 等；</p><p>一类是 generator ，包括生成器和带 yield 的generator function。</p><p>这些可以直接作用于 for 循环的对象统称为可迭代对象： Iterable 。</p><h4 id="2-判断是否可以迭代"><a href="#2-判断是否可以迭代" class="headerlink" title="2. 判断是否可以迭代"></a>2. 判断是否可以迭代</h4><p>可以使用 isinstance() 判断一个对象是否是 Iterable 对象：</p><pre class="language-none"><code class="language-none">In [50]: from collections import IterableIn [51]: isinstance([], Iterable)Out[51]: TrueIn [52]: isinstance({}, Iterable)Out[52]: TrueIn [53]: isinstance('abc', Iterable)Out[53]: TrueIn [54]: isinstance((x for x in range(10)), Iterable)Out[54]: TrueIn [55]: isinstance(100, Iterable)Out[55]: False</code></pre><p>而生成器不但可以作用于 for 循环，还可以被 next() 函数不断调用并返回下一个值，直到最后抛出 StopIteration 错误表示无法继续返回下一个值了。</p><h4 id="3-迭代器"><a href="#3-迭代器" class="headerlink" title="3.迭代器"></a>3.迭代器</h4><p>可以被next()函数调用并不断返回下一个值的对象称为迭代器：Iterator。</p><p>可以使用 isinstance() 判断一个对象是否是 Iterator 对象：</p><pre class="language-none"><code class="language-none">In [56]: from collections import IteratorIn [57]: isinstance((x for x in range(10)), Iterator)Out[57]: TrueIn [58]: isinstance([], Iterator)Out[58]: FalseIn [59]: isinstance({}, Iterator)Out[59]: FalseIn [60]: isinstance('abc', Iterator)Out[60]: FalseIn [61]: isinstance(100, Iterator)Out[61]: False</code></pre><h4 id="4-iter-函数"><a href="#4-iter-函数" class="headerlink" title="4.iter()函数"></a>4.iter()函数</h4><p>生成器都是 Iterator 对象，但 list 、 dict 、 str 虽然是 Iterable ，却不是 Iterator 。</p><p>把 list 、 dict 、 str 等 Iterable 变成 Iterator 可以使用 iter() 函数：</p><pre class="language-none"><code class="language-none">In [62]: isinstance(iter([]), Iterator)Out[62]: TrueIn [63]: isinstance(iter('abc'), Iterator)Out[63]: True</code></pre><p><strong>总结</strong></p><p>凡是可作用于 for 循环的对象都是 Iterable 类型；<br>凡是可作用于 next() 函数的对象都是 Iterator 类型<br>集合数据类型如 list 、 dict 、 str 等是 Iterable 但不是 Iterator ，不过可以通过 iter() 函数获得一个 Iterator 对象。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python高级知识点</title>
      <link href="/2017/11/14/python-gao-ji-zhi-shi-dian/"/>
      <url>/2017/11/14/python-gao-ji-zhi-shi-dian/</url>
      
        <content type="html"><![CDATA[<h3 id="import导入模块"><a href="#import导入模块" class="headerlink" title="import导入模块"></a>import导入模块</h3><h4 id="1-import-搜索路径"><a href="#1-import-搜索路径" class="headerlink" title="1. import 搜索路径"></a>1. import 搜索路径</h4><pre class="language-none"><code class="language-none">import syssys.path</code></pre><p>程序执行时导入模块路径</p><pre class="language-none"><code class="language-none">sys.path.append('/home/itcast/xxx')sys.path.insert(0, '/home/itcast/xxx')    #可以确保先搜索这个路径In [37]: sys.path.insert(0,"/home/python/xxxx")In [38]: sys.pathOut[38]: ['/home/python/xxxx', '', '/usr/bin', '/usr/lib/python35.zip', '/usr/lib/python3.5', '/usr/lib/python3.5/plat-x86_64-linux-gnu', '/usr/lib/python3.5/lib-dynload', '/usr/local/lib/python3.5/dist-packages', '/usr/lib/python3/dist-packages', '/usr/lib/python3/dist-packages/IPython/extensions', '/home/python/.ipython']</code></pre><h4 id="2-重新导入模块"><a href="#2-重新导入模块" class="headerlink" title="2. 重新导入模块"></a>2. 重新导入模块</h4><p>模块被导入后，import module不能重新导入模块，重新导入需用</p><h3 id="循环导入"><a href="#循环导入" class="headerlink" title="循环导入"></a>循环导入</h3><h4 id="1-什么是循环导入"><a href="#1-什么是循环导入" class="headerlink" title="1. 什么是循环导入"></a>1. 什么是循环导入</h4><p>a.py</p><pre class="language-none"><code class="language-none">from b import b print '---------this is module a.py----------'def a():    print("hello, a")    b() a()</code></pre><p>b.py</p><pre class="language-none"><code class="language-none">from a import aprint '----------this is module b.py----------'def b():    print("hello, b")def c():    a() c()</code></pre><h4 id="2-怎样避免循环导入"><a href="#2-怎样避免循环导入" class="headerlink" title="2. 怎样避免循环导入"></a>2. 怎样避免循环导入</h4><ul><li>程序设计上分层，降低耦合</li><li>导入语句放在后面需要导入时再导入，例如放在函数体内导入<h3 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h3><h4 id="什么是命名空间"><a href="#什么是命名空间" class="headerlink" title="什么是命名空间"></a>什么是命名空间</h4>比如有一个学校，有10个班级，在7班和8班中都有一个叫“小王”的同学，如果在学校的广播中呼叫“小王”时，7班和8班中的这2个人就纳闷了，你是喊谁呢！！！如果是“7班的小王”的话，那么就很明确了，那么此时的7班就是小王所在的范围，即命名空间<h4 id="globals、locals"><a href="#globals、locals" class="headerlink" title="globals、locals"></a>globals、locals</h4>在之前学习变量的作用域时，经常会提到局部变量和全局变量，之所有称之为局部、全局，就是因为他们的自作用的区域不同，这就是作用域</li></ul><h4 id="LEGB-规则"><a href="#LEGB-规则" class="headerlink" title="LEGB 规则"></a>LEGB 规则</h4><p>Python 使用 LEGB 的顺序来查找一个符号对应的对象</p><pre class="language-none"><code class="language-none">locals -&gt; enclosing function -&gt; globals -&gt; builtins</code></pre><ul><li>locals，当前所在命名空间（如函数、模块），函数的参数也属于命名空间内的变量</li><li>enclosing，外部嵌套函数的命名空间（闭包中常见）</li></ul><pre class="language-none"><code class="language-none">def fun1():  a = 10  def fun2():      # a 位于外部嵌套函数的命名空间      print(a)</code></pre><ul><li>globals，全局变量，函数定义所在模块的命名空间</li></ul><pre class="language-none"><code class="language-none">a = 1def fun():  # 需要通过 global 指令来声明全局变量  global a  # 修改全局变量，而不是创建一个新的 local 变量  a = 2</code></pre><ul><li>builtins，内建模块的命名空间。</li></ul><pre class="language-none"><code class="language-none">Python 在启动的时候会自动为我们载入很多内建的函数、类，  比如 dict，list，type，print，这些都位于 __builtin__ 模块中，  可以使用 dir(__builtin__) 来查看。  这也是为什么我们在没有 import任何模块的情况下，  就能使用这么多丰富的函数和功能了。  在Python中，有一个内建模块，该模块中有一些常用函数;在Python启动后，  且没有执行程序员所写的任何代码前，Python会首先加载该内建函数到内存。  另外，该内建模块中的功能可以直接使用，不用在其前添加内建模块前缀，  其原因是对函数、变量、类等标识符的查找是按LEGB法则，其中B即代表内建模块  比如：内建模块中有一个abs()函数，其功能求绝对值，如abs(-20)将返回20。</code></pre><h3 id="、is"><a href="#、is" class="headerlink" title="==、is"></a>==、is</h3><ul><li>is 是比较两个引用是否指向了同一个对象（引用比较）。</li><li>== 是比较两个对象是否相等。</li></ul><h3 id="深拷贝、浅拷贝"><a href="#深拷贝、浅拷贝" class="headerlink" title="深拷贝、浅拷贝"></a>深拷贝、浅拷贝</h3><h4 id="1-浅拷贝"><a href="#1-浅拷贝" class="headerlink" title="1. 浅拷贝"></a>1. 浅拷贝</h4><p>浅拷贝是对于一个对象的顶层拷贝<br>通俗的理解是：拷贝了引用，并没有拷贝内容</p><p>深拷贝<br>深拷贝是对于一个对象所有层次的拷贝(递归)</p><p>拷贝的其他方式<br>浅拷贝对不可变类型和可变类型的copy不同</p><h3 id="私有化"><a href="#私有化" class="headerlink" title="私有化"></a>私有化</h3><ul><li>xx: 公有变量</li><li>_x: 单前置下划线,私有化属性或方法，from somemodule import *禁止导入,类对象和子类可以访问</li><li>__xx：双前置下划线,避免与子类中的属性命名冲突，无法在外部直接访问(名字重整所以访问不到)</li><li><strong>xx</strong>:双前后下划线,用户名字空间的魔法对象或属性。例如:<strong>init</strong> , __ 不要自己发明这样的名字</li><li>xx_:单后置下划线,用于避免与Python关键词的冲突</li></ul><p>通过name mangling（名字重整(目的就是以防子类意外重写基类的方法或者属性)如：_Class__object）机制就可以访问private了。</p><pre class="language-none"><code class="language-none">#coding=utf-8class Person(object):    def __init__(self, name, age, taste):        self.name = name        self._age = age         self.__taste = taste    def showperson(self):        print(self.name)        print(self._age)        print(self.__taste)    def dowork(self):        self._work()        self.__away()    def _work(self):        print('my _work')    def __away(self):        print('my __away')        class Student(Person):    def construction(self, name, age, taste):        self.name = name        self._age = age         self.__taste = taste    def showstudent(self):        print(self.name)        print(self._age)        print(self.__taste)    @staticmethod    def testbug():        _Bug.showbug()#模块内可以访问，当from  cur_module import *时，不导入class _Bug(object):    @staticmethod    def showbug():        print("showbug")s1 = Student('jack', 25, 'football')s1.showperson()print('*'*20)#无法访问__taste,导致报错#s1.showstudent() s1.construction('rose', 30, 'basketball')s1.showperson()print('*'*20)s1.showstudent()print('*'*20)Student.testbug()</code></pre><p>总结</p><ul><li>父类中属性名为__名字的，子类不继承，子类不能访问</li><li>如果在子类中向__名字赋值，那么会在子类中定义的一个与父类相同名字的属性</li><li>_名的变量、函数、类在使用from xxx import *时都不会被导入</li></ul><h3 id="属性property"><a href="#属性property" class="headerlink" title="属性property"></a>属性property</h3><h4 id="1-私有属性添加getter和setter方法"><a href="#1-私有属性添加getter和setter方法" class="headerlink" title="1. 私有属性添加getter和setter方法"></a>1. 私有属性添加getter和setter方法</h4><pre class="language-none"><code class="language-none">class Money(object):    def __init__(self):        self.__money = 0    def getMoney(self):        return self.__money    def setMoney(self, value):        if isinstance(value, int):            self.__money = value        else:            print("error:不是整型数字")</code></pre><h4 id="2-使用property升级getter和setter方法"><a href="#2-使用property升级getter和setter方法" class="headerlink" title="2. 使用property升级getter和setter方法"></a>2. 使用property升级getter和setter方法</h4><pre class="language-none"><code class="language-none">class Money(object):    def __init__(self):        self.__money = 0    def getMoney(self):        return self.__money    def setMoney(self, value):        if isinstance(value, int):            self.__money = value        else:            print("error:不是整型数字")    money = property(getMoney, setMoney)</code></pre><h4 id="3-使用property取代getter和setter方法"><a href="#3-使用property取代getter和setter方法" class="headerlink" title="3. 使用property取代getter和setter方法"></a>3. 使用property取代getter和setter方法</h4><p>@property成为属性函数，可以对属性赋值时做必要的检查，并保证代码的清晰短小，主要有2个作用</p><p>将方法转换为只读<br>重新实现一个属性的设置和读取方法,可做边界判定</p><pre class="language-none"><code class="language-none">class Money(object):    def __init__(self):        self.__money = 0    @property    def money(self):        return self.__money    @money.setter    def money(self, value):        if isinstance(value, int):            self.__money = value        else:            print("error:不是整型数字")</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python面向对象三、异常、模块</title>
      <link href="/2017/11/13/python-mian-xiang-dui-xiang-san-yi-chang-mo-kuai/"/>
      <url>/2017/11/13/python-mian-xiang-dui-xiang-san-yi-chang-mo-kuai/</url>
      
        <content type="html"><![CDATA[<h3 id="new-方法"><a href="#new-方法" class="headerlink" title="__new__方法"></a>__new__方法</h3><h4 id="new-和-init-的作用"><a href="#new-和-init-的作用" class="headerlink" title="__new__和__init__的作用"></a>__new__和__init__的作用</h4><pre class="language-none"><code class="language-none">class A(object):    def __init__(self):        print("这是 init 方法")    def __new__(cls):        print("这是 new 方法")        return object.__new__(cls)A()</code></pre><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul><li><p>__new__至少要有一个参数cls，代表要实例化的类，此参数在实例化时由Python解释器自动提供</p></li><li><p>__new__必须要有返回值，返回实例化出来的实例，这点在自己实现__new__时要特别注意，可以return父类__new__出来的实例，或者直接是object的__new__出来的实例</p></li><li><p>__init__有一个参数self，就是这个__new__返回的实例，__init__在__new__的基础上可以完成一些其它初始化的动作，__init__不需要返回值</p></li><li><p>我们可以将类比作制造商，__new__方法就是前期的原材料购买环节，__init__方法就是在有原材料的基础上，加工，初始化商品环节</p></li></ul><h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><h4 id="1-单例是什么"><a href="#1-单例是什么" class="headerlink" title="1. 单例是什么"></a>1. 单例是什么</h4><p>举个常见的单例模式例子，我们日常使用的电脑上都有一个回收站，在整个操作系统中，回收站只能有一个实例，整个系统都使用这个唯一的实例，而且回收站自行提供自己的实例。因此回收站是单例模式的应用。</p><p><strong>确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，单例模式是一种对象创建型模式。</strong></p><h4 id="2-创建单例-保证只有1个对象"><a href="#2-创建单例-保证只有1个对象" class="headerlink" title="2. 创建单例-保证只有1个对象"></a>2. 创建单例-保证只有1个对象</h4><pre class="language-none"><code class="language-none"># 实例化一个单例class Singleton(object):    __instance = None    def __new__(cls, age, name):        #如果类数字能够__instance没有或者没有赋值        #那么就创建一个对象，并且赋值为这个对象的引用，保证下次调用这个方法时        #能够知道之前已经创建过对象了，这样就保证了只有1个对象        if not cls.__instance:            cls.__instance = object.__new__(cls)        return cls.__instancea = Singleton(18, "dongGe")b = Singleton(8, "dongGe")print(id(a))print(id(b))a.age = 19 #给a指向的对象添加一个属性print(b.age)#获取b指向的对象的age属性</code></pre><p>运行结果：</p><pre class="language-none"><code class="language-none">In [12]: class Singleton(object):    ...:     __instance = None    ...:     ...:     def __new__(cls, age, name):    ...:         if not cls.__instance:    ...:             cls.__instance = object.__new__(cls)    ...:         return cls.__instance    ...:     ...: a = Singleton(18, "dongGe")    ...: b = Singleton(8, "dongGe")    ...:     ...: print(id(a))    ...: print(id(b))    ...:     ...: a.age = 19    ...: print(b.age)    ...: 43910232244391023224</code></pre><h4 id="3-创建单例时，只执行1次-init-方法"><a href="#3-创建单例时，只执行1次-init-方法" class="headerlink" title="3. 创建单例时，只执行1次__init__方法"></a>3. 创建单例时，只执行1次__init__方法</h4><pre class="language-none"><code class="language-none"># 实例化一个单例class Singleton(object):    __instance = None    __first_init = False    def __new__(cls, age, name):        if not cls.__instance:            cls.__instance = object.__new__(cls)        return cls.__instance    def __init__(self, age, name):        if not self.__first_init:            self.age = age            self.name = name            Singleton.__first_init = Truea = Singleton(18, "dongGe")b = Singleton(8, "dongGe")print(id(a))print(id(b))print(a.age)print(b.age)a.age = 19print(b.age)</code></pre><h3 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h3><h4 id="lt-1-gt-异常简介"><a href="#lt-1-gt-异常简介" class="headerlink" title="<1>异常简介"></a>&lt;1&gt;异常简介</h4><p>看如下示例:</p><pre class="language-none"><code class="language-none">print '-----test--1---'    open('123.txt','r')    print '-----test--2---'</code></pre><p><strong>说明:</strong><br>打开一个不存在的文件123.txt，当找不到123.txt 文件时，就会抛出给我们一个IOError类型的错误，No such file or directory：123.txt （没有123.txt这样的文件或目录）<br><strong>异常:</strong><br>当Python检测到一个错误时，解释器就无法继续执行了，反而出现了一些错误的提示，这就是所谓的”异常”</p><h4 id="lt-2-gt-捕获异常-try…except…"><a href="#lt-2-gt-捕获异常-try…except…" class="headerlink" title="<2>捕获异常 try…except…"></a>&lt;2&gt;捕获异常 try…except…</h4><p>看如下示例:</p><pre class="language-none"><code class="language-none">try:    print('-----test--1---')    open('123.txt','r')    print('-----test--2---')except IOError:    pass</code></pre><p>说明:</p><ul><li><p>此程序看不到任何错误，因为用except 捕获到了IOError异常，并添加了处理的方法</p></li><li><p>pass 表示实现了相应的实现，但什么也不做；如果把pass改为print语句，那么就会输出其他信息<br>总结:</p></li><li><p>把可能出现问题的代码，放在try中</p></li><li><p>把处理异常的代码，放在except中</p></li></ul><h4 id="lt-3-gt-except捕获多个异常"><a href="#lt-3-gt-except捕获多个异常" class="headerlink" title="<3> except捕获多个异常"></a>&lt;3&gt; except捕获多个异常</h4><pre class="language-none"><code class="language-none">try:    print numexcept IOError:    print('产生错误了')</code></pre><p>except捕获的错误类型是IOError，而此时程序产生的异常为 NameError ，所以except没有生效</p><p><strong>实际开发中，捕获多个异常的方式，如下：</strong></p><pre class="language-none"><code class="language-none">#coding=utf-8try:    print('-----test--1---')    open('123.txt','r') # 如果123.txt文件不存在，那么会产生 IOError 异常    print('-----test--2---')    print(num)# 如果num变量没有定义，那么会产生 NameError 异常except (IOError,NameError):     #如果想通过一次except捕获到多个异常可以用一个元组的方式    # errorMsg里会保存捕获到的错误信息    print(errorMsg)</code></pre><p><strong>注意：</strong><br>当捕获多个异常时，可以把要捕获的异常的名字，放到except 后，并使用元组的方式仅进行存储</p><h4 id="lt-4-gt-获取异常的信息描述"><a href="#lt-4-gt-获取异常的信息描述" class="headerlink" title="<4>获取异常的信息描述"></a>&lt;4&gt;获取异常的信息描述</h4><h4 id="lt-5-gt-捕获所有异常"><a href="#lt-5-gt-捕获所有异常" class="headerlink" title="<5>捕获所有异常"></a>&lt;5&gt;捕获所有异常</h4><h4 id="lt-6-gt-else"><a href="#lt-6-gt-else" class="headerlink" title="<6> else"></a>&lt;6&gt; else</h4><p>咱们应该对else并不陌生，在if中，它的作用是当条件不满足时执行的实行；同样在try…except…中也是如此，即如果没有捕获到异常，那么就执行else中的事情</p><pre class="language-none"><code class="language-none">try:    num = 100    print numexcept NameError as errorMsg:    print('产生错误了:%s'%errorMsg)else:    print('没有捕获到异常，真高兴')</code></pre><h4 id="lt-7-gt-try…finally…"><a href="#lt-7-gt-try…finally…" class="headerlink" title="<7> try…finally…"></a>&lt;7&gt; try…finally…</h4><p>try…finally…语句用来表达这样的情况：<br>在程序中，如果一个段代码必须要执行，即无论异常是否产生都要执行，那么此时就需要使用finally。 比如文件关闭，释放锁，把数据库连接返还给连接池等</p><pre class="language-none"><code class="language-none">import timetry:    f = open('test.txt')    try:        while True:            content = f.readline()            if len(content) == 0:                break            time.sleep(2)            print(content)    except:        #如果在读取文件的过程中，产生了异常，那么就会捕获到        #比如 按下了 ctrl+c        pass    finally:        f.close()        print('关闭文件')except:    print("没有这个文件")</code></pre><p>说明:<br>test.txt文件中每一行数据打印，但是我有意在每打印一行之前用time.sleep方法暂停2秒钟。这样做的原因是让程序运行得慢一些。在程序运行的时候，按Ctrl+c中断（取消）程序。</p><p>我们可以观察到KeyboardInterrupt异常被触发，程序退出。但是在程序退出之前，finally从句仍然被执行，把文件关闭。</p><h3 id="异常的传递"><a href="#异常的传递" class="headerlink" title="异常的传递"></a>异常的传递</h3><h4 id="1-try嵌套中"><a href="#1-try嵌套中" class="headerlink" title="1. try嵌套中"></a>1. try嵌套中</h4><pre class="language-none"><code class="language-none">import timetry:    f = open('test.txt')    try:        while True:            content = f.readline()            if len(content) == 0:                break            time.sleep(2)            print(content)    finally:        f.close()        print('关闭文件')except:    print("没有这个文件")</code></pre><p>运行结果:</p><pre class="language-none"><code class="language-none">In [26]: import time    ...: try:    ...:     f = open('test.txt')    ...:     try:    ...:         while True:    ...:             content = f.readline()    ...:             if len(content) == 0:    ...:                 break    ...:             time.sleep(2)    ...:             print(content)    ...:     finally:    ...:         f.close()    ...:         print('关闭文件')    ...: except:    ...:     print("没有这个文件")    ...: finally:    ...:     print("最后的finally")    ...:     xxxxxxx---&gt;这是test.txt文件中读取到信息^C关闭文件没有这个文件最后的finally</code></pre><h4 id="2-函数嵌套调用中"><a href="#2-函数嵌套调用中" class="headerlink" title="2. 函数嵌套调用中"></a>2. 函数嵌套调用中</h4><pre class="language-none"><code class="language-none">def test1():       print("----test1-1----")       print(num)       print("----test1-2----")   def test2():       print("----test2-1----")       test1()       print("----test2-2----")   def test3():       try:           print("----test3-1----")           test1()           print("----test3-2----")       except Exception as result:           print("捕获到了异常，信息是:%s"%result)       print("----test3-2----")   test3()   print("------华丽的分割线-----")   test2()</code></pre><p><strong>总结：</strong></p><ul><li>如果try嵌套，那么如果里面的try没有捕获到这个异常，那么外面的try会接收到这个异常，然后进行处理，如果外边的try依然没有捕获到，那么再进行传递。。。</li><li>如果一个异常是在一个函数中产生的，例如函数A—-&gt;函数B—-&gt;函数C,而异常是在函数C中产生的，那么如果函数C中没有对这个异常进行处理，那么这个异常会传递到函数B中，如果函数B有异常处理那么就会按照函数B的处理方式进行执行；如果函数B也没有异常处理，那么这个异常会继续传递，以此类推。。。如果所有的函数都没有处理，那么此时就会进行异常的默认处理，即通常见到的那样</li><li>注意观察上图中，当调用test3函数时，在test1函数内部产生了异常，此异常被传递到test3函数中完成了异常处理，而当异常处理完后，并没有返回到函数test1中进行执行，而是在函数test3中继续执行</li></ul><h3 id="抛出自定义的异常"><a href="#抛出自定义的异常" class="headerlink" title="抛出自定义的异常"></a>抛出自定义的异常</h3><p>你可以用raise语句来引发一个异常。异常/错误对象必须有一个名字，且它们应是Error或Exception类的子类</p><p>下面是一个引发异常的例子:</p><pre class="language-none"><code class="language-none">class ShortInputException(Exception):    '''自定义的异常类'''    def __init__(self, length, atleast):        #super().__init__()        self.length = length        self.atleast = atleastdef main():    try:        s = input('请输入 --&gt; ')        if len(s) &lt; 3:            # raise引发一个你定义的异常            raise ShortInputException(len(s), 3)    except ShortInputException as result:#x这个变量被绑定到了错误的实例        print('ShortInputException: 输入的长度是 %d,长度至少应是 %d'% (result.length, result.atleast))    else:        print('没有异常发生.')main()</code></pre><p><strong>注意</strong><br>以上程序中，关于代码#super().<strong>init</strong>()的说明<br>这一行代码，可以调用也可以不调用，建议调用，因为__init__方法往往是用来对创建完的对象进行初始化工作，如果在子类中重写了父类的__init__方法，即意味着父类中的很多初始化工作没有做，这样就不保证程序的稳定了，所以在以后的开发中，如果重写了父类的__init__方法，最好是先调用父类的这个方法，然后再添加自己的功能</p><h3 id="异常处理中抛出异常"><a href="#异常处理中抛出异常" class="headerlink" title="异常处理中抛出异常"></a>异常处理中抛出异常</h3><pre class="language-none"><code class="language-none">lass Test(object):    def __init__(self, switch):        self.switch = switch #开关    def calc(self, a, b):        try:            return a/b        except Exception as result:            if self.switch:                print("捕获开启，已经捕获到了异常，信息如下:")                print(result)            else:                #重新抛出这个异常，此时就不会被这个异常处理给捕获到，从而触发默认的异常处理                raisea = Test(True)a.calc(11,0)print("----------------------华丽的分割线----------------")a.switch = Falsea.calc(11,0)</code></pre><h3 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h3><h4 id="lt-1-gt-Python中的模块"><a href="#lt-1-gt-Python中的模块" class="headerlink" title="<1>Python中的模块"></a>&lt;1&gt;Python中的模块</h4><p>有过C语言编程经验的朋友都知道在C语言中如果要引用sqrt函数，必须用语句#include &lt;math.h&gt;引入math.h这个头文件，否则是无法正常进行调用的。</p><p>那么在Python中，如果要引用一些其他的函数，该怎么处理呢？</p><p>在Python中有一个概念叫做模块（module），这个和C语言中的头文件以及Java中的包很类似，比如在Python中要调用sqrt函数，必须用import关键字引入math这个模块，下面就来了解一下Python中的模块。</p><p>说的通俗点：模块就好比是工具包，要想使用这个工具包中的工具(就好比函数)，就需要导入这个模块</p><h4 id="lt-2-gt-import"><a href="#lt-2-gt-import" class="headerlink" title="<2>import"></a>&lt;2&gt;import</h4><p>在Python中用关键字import来引入某个模块，比如要引用模块math，就可以在文件最开始的地方用import math来引入。</p><p>形如:</p><pre class="language-none"><code class="language-none">import module1,mudule2...</code></pre><p>当解释器遇到import语句，如果模块在当前的搜索路径就会被导入。</p><p>在调用math模块中的函数时，必须这样引用：</p><pre class="language-none"><code class="language-none">模块名.函数名</code></pre><p>有时候我们只需要用到模块中的某个函数，只需要引入该函数即可，此时可以用下面方法实现：</p><pre class="language-none"><code class="language-none">from 模块名 import 函数名1,函数名2....</code></pre><p>不仅可以引入函数，还可以引入一些全局变量、类等<br><strong>注意:</strong></p><ul><li><p>通过这种方式引入的时候，调用函数时只能给出函数名，不能给出模块名，但是当两个模块中含有相同名称函数的时候，后面一次引入会覆盖前一次引入。也就是说假如模块A中有函数function( )，在模块B中也有函数function( )，如果引入A中的function在先、B中的function在后，那么当调用function函数的时候，是去执行模块B中的function函数。</p></li><li><p>如果想一次性引入math中所有的东西，还可以通过from math import *来实现</p></li></ul><h3 id="lt-3-gt-from…import"><a href="#lt-3-gt-from…import" class="headerlink" title="<3>from…import"></a>&lt;3&gt;from…import</h3><p>Python的from语句让你从模块中导入一个指定的部分到当前命名空间中</p><p>语法如下：</p><pre class="language-none"><code class="language-none">from modname import name1[, name2[, ... nameN]]</code></pre><p>例如，要导入模块fib的fibonacci函数，使用如下语句：</p><pre class="language-none"><code class="language-none">from fib import fibonacci</code></pre><p><strong>注意</strong><br>不会把整个fib模块导入到当前的命名空间中，它只会将fib里的fibonacci单个引入</p><h4 id="lt-4-gt-from-…-import"><a href="#lt-4-gt-from-…-import" class="headerlink" title="<4>from … import *"></a>&lt;4&gt;from … import *</h4><p>把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明：</p><pre class="language-none"><code class="language-none">from modname import *</code></pre><p>注意<br>这提供了一个简单的方法来导入一个模块中的所有项目。然而这种声明不该被过多地使用。</p><h4 id="lt-5-gt-as"><a href="#lt-5-gt-as" class="headerlink" title="<5> as"></a>&lt;5&gt; as</h4><pre class="language-none"><code class="language-none">In [1]: import time as tt    In [2]: time.sleep(1)    ---------------------------------------------------------------------------    NameError                                 Traceback (most recent call last)    &lt;ipython-input-2-07a34f5b1e42&gt; in &lt;module&gt;()    ----&gt; 1 time.sleep(1)    NameError: name 'time' is not defined    In [3]:     In [3]:     In [3]: tt.sleep(1)    In [4]:     In [4]:     In [4]: from time import sleep as sp    In [5]: sleep(1)    ---------------------------------------------------------------------------    NameError                                 Traceback (most recent call last)    &lt;ipython-input-5-82e5c2913b44&gt; in &lt;module&gt;()    ----&gt; 1 sleep(1)NameError: name 'sleep' is not defined    In [6]:     In [6]:     In [6]: sp(1)    In [7]:</code></pre><h4 id="lt-6-gt-定位模块"><a href="#lt-6-gt-定位模块" class="headerlink" title="<6>定位模块"></a>&lt;6&gt;定位模块</h4><p>当你导入一个模块，Python解析器对模块位置的搜索顺序是：</p><ol><li>当前目录</li><li>如果不在当前目录，Python则搜索在shell变量PYTHONPATH下的每个目录。</li><li>如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/</li><li>模块搜索路径存储在system模块的sys.path变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录。</li></ol><h3 id="模块制作"><a href="#模块制作" class="headerlink" title="模块制作"></a>模块制作</h3><h4 id="lt-1-gt-定义自己的模块"><a href="#lt-1-gt-定义自己的模块" class="headerlink" title="<1>定义自己的模块"></a>&lt;1&gt;定义自己的模块</h4><p>在Python中，每个Python文件都可以作为一个模块，模块的名字就是文件的名字。</p><p>比如有这样一个文件test.py，在test.py中定义了函数add</p><p>test.py</p><pre class="language-none"><code class="language-none">def add(a,b):        return a+b</code></pre><h4 id="lt-2-gt-调用自己定义的模块"><a href="#lt-2-gt-调用自己定义的模块" class="headerlink" title="<2>调用自己定义的模块"></a>&lt;2&gt;调用自己定义的模块</h4><p>那么在其他文件中就可以先import test，然后通过test.add(a,b)来调用了，当然也可以通过from test import add来引入</p><p>main.py</p><pre class="language-none"><code class="language-none">import test    result = test.add(11,22)    print(result)</code></pre><h3 id="给程序传参数"><a href="#给程序传参数" class="headerlink" title="给程序传参数"></a>给程序传参数</h3><pre class="language-none"><code class="language-none">import sysprint(sys.argv)</code></pre><h3 id="列表推导式"><a href="#列表推导式" class="headerlink" title="列表推导式"></a>列表推导式</h3><p>所谓的列表推导式，就是指的轻量级循环创建列表</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python面向对象二</title>
      <link href="/2017/11/08/python-mian-xiang-dui-xiang-er/"/>
      <url>/2017/11/08/python-mian-xiang-dui-xiang-er/</url>
      
        <content type="html"><![CDATA[<h3 id="保护对象的属性"><a href="#保护对象的属性" class="headerlink" title="保护对象的属性"></a>保护对象的属性</h3><p>如果有一个对象，当需要对其进行修改属性时，有2种方法</p><ul><li>对象名.属性名 = 数据 —-&gt;直接修改</li><li>对象名.方法名() —-&gt;间接修改</li></ul><p>为了更好的保存属性安全，即不能随意修改，一般的处理方式为</p><ul><li>将属性定义为私有属性</li><li>添加一个可以调用的方法，供调用</li></ul><pre class="language-none"><code class="language-none">class People(object):    def __init__(self, name):        self.__name = name    def getName(self):        return self.__name    def setName(self, newName):        if len(newName) &gt;= 5:            self.__name = newName        else:            print("error:名字长度需要大于或者等于5")xiaoming = People("dongGe")print(xiaoming.__name)</code></pre><pre class="language-none"><code class="language-none">class People(object):    def __init__(self, name):        self.__name = name    def getName(self):        return self.__name    def setName(self, newName):        if len(newName) &gt;= 5:            self.__name = newName        else:            print("error:名字长度需要大于或者等于5")xiaoming = People("dongGe")xiaoming.setName("wanger")print(xiaoming.getName())xiaoming.setName("lisi")print(xiaoming.getName())</code></pre><p><strong>总结</strong></p><ul><li>Python中没有像C++中public和private这些关键字来区别公有属性和私有属性</li><li>它是以属性命名方式来区分，如果在属性名前面加了2个下划线’__’，则表明该属性是私有属性，否则为公有属性（方法也是一样，方法名前面加了2个下划线的话表示该方法是私有的，否则为公有的）。</li></ul><pre class="language-none"><code class="language-none">__del__()方法</code></pre><p>创建对象后，python解释器默认调用<strong>init</strong>()方法；</p><p>当删除一个对象时，python解释器也会默认调用一个方法，这个方法为<strong>del</strong>()方法</p><pre class="language-none"><code class="language-none">import timeclass Animal(object):    # 初始化方法    # 创建完对象后会自动被调用    def __init__(self, name):        print('__init__方法被调用')        self.__name = name    # 析构方法    # 当对象被删除时，会自动被调用    def __del__(self):        print("__del__方法被调用")        print("%s对象马上被干掉了..."%self.__name)# 创建对象dog = Animal("哈皮狗")# 删除对象del dogcat = Animal("波斯猫")cat2 = catcat3 = catprint("---马上 删除cat对象")del catprint("---马上 删除cat2对象")del cat2print("---马上 删除cat3对象")del cat3print("程序2秒钟后结束")time.sleep(2)</code></pre><p><strong>总结</strong></p><ul><li>当有1个变量保存了对象的引用时，此对象的引用计数就会加1</li><li>当使用del删除变量指向的对象时，如果对象的引用计数不会1，比如3，那么此时只会让这个引用计数减1，即变为2，当再次调用del时，变为1，如果再调用1次del，此时会真的把对象进行删除</li></ul><h3 id="继承介绍以及单继承"><a href="#继承介绍以及单继承" class="headerlink" title="继承介绍以及单继承"></a>继承介绍以及单继承</h3><h4 id="1-继承的概念"><a href="#1-继承的概念" class="headerlink" title="1. 继承的概念"></a>1. 继承的概念</h4><p>在现实生活中，继承一般指的是子女继承父辈的财产<br>在程序中，继承描述的是事物之间的所属关系，例如猫和狗都属于动物，程序中便可以描述为猫和狗继承自动物；同理，波斯猫和巴厘猫都继承自猫，而沙皮狗和斑点狗都继承足够</p><h4 id="2-继承示例"><a href="#2-继承示例" class="headerlink" title="2. 继承示例"></a>2. 继承示例</h4><pre class="language-none"><code class="language-none"># 定义一个父类，如下:class Cat(object):    def __init__(self, name, color="白色"):        self.name = name        self.color = color    def run(self):        print("%s--在跑"%self.name)# 定义一个子类，继承Cat类如下:class Bosi(Cat):    def setNewName(self, newName):        self.name = newName    def eat(self):        print("%s--在吃"%self.name)bs = Bosi("印度猫")print('bs的名字为:%s'%bs.name)print('bs的颜色为:%s'%bs.color)bs.eat()bs.setNewName('波斯')bs.run()</code></pre><p>说明：</p><ul><li>虽然子类没有定义__init__方法，但是父类有，所以在子类继承父类的时候这个方法就被继承了，所以只要创建Bosi的对象，就默认执行了那个继承过来的__init__方法</li></ul><p><strong>总结</strong></p><ul><li>子类在继承的时候，在定义类时，小括号()中为父类的名字</li><li>父类的属性、方法，会被继承给子类</li></ul><h4 id="3-注意点"><a href="#3-注意点" class="headerlink" title="3. 注意点"></a>3. 注意点</h4><pre class="language-none"><code class="language-none">class Animal(object):    def __init__(self, name='动物', color='白色'):        self.__name = name        self.color = color    def __test(self):        print(self.__name)        print(self.color)    def test(self):        print(self.__name)        print(self.color)class Dog(Animal):    def dogTest1(self):        #print(self.__name) #不能访问到父类的私有属性        print(self.color)    def dogTest2(self):        #self.__test() #不能访问父类中的私有方法        self.test()A = Animal()#print(A.__name) #程序出现异常，不能访问私有属性print(A.color)#A.__test() #程序出现异常，不能访问私有方法A.test()print("------分割线-----")D = Dog(name = "小花狗", color = "黄色")D.dogTest1()D.dogTest2()</code></pre><ul><li>私有的属性，不能通过对象直接访问，但是可以通过方法访问</li><li>私有的方法，不能通过对象直接访问</li><li>私有的属性、方法，不会被子类继承，也不能被访问</li><li>一般情况下，私有的属性、方法都是不对外公布的，往往用来做内部的事情，起到安全的作用</li></ul><h3 id="多继承"><a href="#多继承" class="headerlink" title="多继承"></a>多继承</h3><p>Python中多继承的格式如下:</p><pre class="language-none"><code class="language-none"># 定义一个父类class A:    def printA(self):        print('----A----')# 定义一个父类class B:    def printB(self):        print('----B----')# 定义一个子类，继承自A、Bclass C(A,B):    def printC(self):        print('----C----')obj_C = C()obj_C.printA()obj_C.printB()</code></pre><p>说明</p><ul><li>python中是可以多继承的</li><li>父类中的方法、属性，子类会继承</li></ul><p>注意点:<br>如果在上面的多继承例子中，如果父类A和父类B中，有一个同名的方法，那么通过子类去调用的时候，调用哪个？</p><pre class="language-none"><code class="language-none">#coding=utf-8class base(object):    def test(self):        print('----base test----')class A(base):    def test(self):        print('----A test----')# 定义一个父类class B(base):    def test(self):        print('----B test----')# 定义一个子类，继承自A、Bclass C(A,B):    passobj_C = C()obj_C.test()print(C.__mro__) #可以查看C类的对象搜索方法时的先后顺序</code></pre><h3 id="重写父类方法与调用父类方法"><a href="#重写父类方法与调用父类方法" class="headerlink" title="重写父类方法与调用父类方法"></a>重写父类方法与调用父类方法</h3><h4 id="1-重写父类方法"><a href="#1-重写父类方法" class="headerlink" title="1. 重写父类方法"></a>1. 重写父类方法</h4><p>所谓重写，就是子类中，有一个和父类相同名字的方法，在子类中的方法会覆盖掉父类中同名的方法</p><pre class="language-none"><code class="language-none">`#coding=utf-8class Cat(object):    def sayHello(self):        print("halou-----1")class Bosi(Cat):    def sayHello(self):        print("halou-----2")bosi = Bosi()bosi.sayHello()</code></pre><h4 id="2-调用父类的方法"><a href="#2-调用父类的方法" class="headerlink" title="2. 调用父类的方法"></a>2. 调用父类的方法</h4><pre class="language-none"><code class="language-none">#coding=utf-8class Cat(object):    def __init__(self,name):        self.name = name        self.color = 'yellow'class Bosi(Cat):    def __init__(self,name):        # 调用父类的__init__方法1(python2)        #Cat.__init__(self,name)        # 调用父类的__init__方法2        #super(Bosi,self).__init__(name)        # 调用父类的__init__方法3        super().__init__(name)    def getName(self):        return self.namebosi = Bosi('xiaohua')print(bosi.name)print(bosi.color)</code></pre><h3 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h3><p>多态的概念是应用于Java和C#这一类强类型语言中，而Python崇尚“鸭子类型”。</p><p>所谓多态：定义时的类型和运行时的类型不一样，此时就成为多态</p><p>Python伪代码实现Java或C#的多态</p><pre class="language-none"><code class="language-none">class F1(object):    def show(self):        print 'F1.show'class S1(F1):    def show(self):        print 'S1.show'class S2(F1):    def show(self):        print 'S2.show'# 由于在Java或C#中定义函数参数时，必须指定参数的类型# 为了让Func函数既可以执行S1对象的show方法，又可以执行S2对象的show方法，所以，定义了一个S1和S2类的父类# 而实际传入的参数是：S1对象和S2对象def Func(F1 obj):    """Func函数需要接收一个F1类型或者F1子类的类型"""    print obj.show()s1_obj = S1()Func(s1_obj) # 在Func函数中传入S1类的对象 s1_obj，执行 S1 的show方法，结果：S1.shows2_obj = S2()Func(s2_obj) # 在Func函数中传入Ss类的对象 ss_obj，执行 Ss 的show方法，结果：S2.show</code></pre><h4 id="Python-“鸭子类型”"><a href="#Python-“鸭子类型”" class="headerlink" title="Python “鸭子类型”"></a>Python “鸭子类型”</h4><pre class="language-none"><code class="language-none">class F1(object):    def show(self):        print 'F1.show'class S1(F1):    def show(self):        print 'S1.show'class S2(F1):    def show(self):        print 'S2.show'def Func(obj):    print obj.show()s1_obj = S1()Func(s1_obj) s2_obj = S2()Func(s2_obj)</code></pre><h3 id="类属性、实例属性"><a href="#类属性、实例属性" class="headerlink" title="类属性、实例属性"></a>类属性、实例属性</h3><p>在了解了类基本的东西之后，下面看一下python中这几个概念的区别</p><p>先来谈一下类属性和实例属性</p><p>在前面的例子中我们接触到的就是实例属性（对象属性），顾名思义，类属性就是类对象所拥有的属性，它被所有类对象的实例对象所共有，在内存中只存在一个副本，这个和C++中类的静态成员变量有点类似。对于公有的类属性，在类外可以通过类对象和实例对象访问</p><h4 id="类属性"><a href="#类属性" class="headerlink" title="类属性"></a>类属性</h4><pre class="language-none"><code class="language-none">class People(object):    name = 'Tom'  #公有的类属性    __age = 12     #私有的类属性p = People()print(p.name)           #正确print(People.name)      #正确print(p.__age)            #错误，不能在类外通过实例对象访问私有的类属性print(People.__age)        #错误，不能在类外通过类对象访问私有的类属性</code></pre><h4 id="实例属性-对象属性"><a href="#实例属性-对象属性" class="headerlink" title="实例属性(对象属性)"></a>实例属性(对象属性)</h4><pre class="language-none"><code class="language-none">class People(object):    address = '山东' #类属性    def __init__(self):        self.name = 'xiaowang' #实例属性        self.age = 20 #实例属性p = People()p.age =12 #实例属性print(p.address) #正确print(p.name)    #正确print(p.age)     #正确print(People.address) #正确print(People.name)    #错误print(People.age)     #错误</code></pre><h4 id="通过实例-对象-去修改类属性"><a href="#通过实例-对象-去修改类属性" class="headerlink" title="通过实例(对象)去修改类属性"></a>通过实例(对象)去修改类属性</h4><pre class="language-none"><code class="language-none">class People(object):    country = 'china' #类属性print(People.country)p = People()print(p.country)p.country = 'japan' print(p.country)      #实例属性会屏蔽掉同名的类属性print(People.country)del p.country    #删除实例属性print(p.country)</code></pre><p>总结<br>如果需要在类外修改类属性，必须通过类对象去引用然后进行修改。如果通过实例对象去引用，会产生一个同名的实例属性，这种方式修改的是实例属性，不会影响到类属性，并且之后如果通过实例对象去引用该名称的属性，实例属性会强制屏蔽掉类属性，即引用的是实例属性，除非删除了该实例属性。</p><h3 id="静态方法和类方法"><a href="#静态方法和类方法" class="headerlink" title="静态方法和类方法"></a>静态方法和类方法</h3><h4 id="1-类方法"><a href="#1-类方法" class="headerlink" title="1. 类方法"></a>1. 类方法</h4><p>是类对象所拥有的方法，需要用修饰器@classmethod来标识其为类方法，对于类方法，第一个参数必须是类对象，一般以cls作为第一个参数（当然可以用其他名称的变量作为其第一个参数，但是大部分人都习惯以’cls’作为第一个参数的名字，就最好用’cls’了），能够通过实例对象和类对象去访问。</p><pre class="language-none"><code class="language-none">class People(object):    country = 'china'    #类方法，用classmethod来进行修饰    @classmethod    def getCountry(cls):        return cls.countryp = People()print p.getCountry()    #可以用过实例对象引用print People.getCountry()    #可以通过类对象引用</code></pre><p>类方法还有一个用途就是可以对类属性进行修改：</p><pre class="language-none"><code class="language-none">class People(object):    country = 'china'    #类方法，用classmethod来进行修饰    @classmethod    def getCountry(cls):        return cls.country    @classmethod    def setCountry(cls,country):        cls.country = countryp = People()print p.getCountry()    #可以用过实例对象引用print People.getCountry()    #可以通过类对象引用p.setCountry('japan')   print p.getCountry()   print People.getCountry()</code></pre><p>结果显示在用类方法对类属性修改之后，通过类对象和实例对象访问都发生了改变</p><h4 id="2-静态方法"><a href="#2-静态方法" class="headerlink" title="2. 静态方法"></a>2. 静态方法</h4><p>需要通过修饰器@staticmethod来进行修饰，静态方法不需要多定义参数</p><pre class="language-none"><code class="language-none">class People(object):    country = 'china'    @staticmethod    #静态方法    def getCountry():        return People.countryprint People.getCountry()</code></pre><p>总结<br>从类方法和实例方法以及静态方法的定义形式就可以看出来，类方法的第一个参数是类对象cls，那么通过cls引用的必定是类对象的属性和方法；而实例方法的第一个参数是实例对象self，那么通过self引用的可能是类属性、也有可能是实例属性（这个需要具体分析），不过在存在相同名称的类属性和实例属性的情况下，实例属性优先级更高。静态方法中不需要额外定义参数，因此在静态方法中引用类属性的话，必须通过类对象来引用</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python面向对象一</title>
      <link href="/2017/11/08/python-mian-xiang-dui-xiang-yi/"/>
      <url>/2017/11/08/python-mian-xiang-dui-xiang-yi/</url>
      
        <content type="html"><![CDATA[<h3 id="面向对象编程介绍"><a href="#面向对象编程介绍" class="headerlink" title="面向对象编程介绍"></a>面向对象编程介绍</h3><ul><li>面向过程：根据业务逻辑从上到下写代码</li><li>面向对象：将数据与函数绑定到一起，进行封装，这样能够更快速的开发程序，减少了重复代码的重写过程</li></ul><p>面向过程编程最易被初学者接受，其往往用一长段代码来实现指定功能，开发过程的思路是将数据与函数按照执行的逻辑顺序组织在一起，数据与函数分开考虑。</p><pre class="language-none"><code class="language-none">def 发送邮件(内容)        #发送邮件提醒        连接邮箱服务器        发送邮件        关闭连接while True：        if cpu利用率 &gt; 90%:                发送邮件('CPU报警')        if 硬盘使用空间 &gt; 90%:                发送邮件('硬盘报警')        if 内存占用 &gt; 80%:                发送邮件('内存报警')</code></pre><p>面向对象编程（Object Oriented Programming，OOP，面向对象程序设计）</p><p>面向对象(object-oriented ;简称: OO) 至今还没有统一的概念 我这里把它定义为: 按人们 认识客观世界的系统思维方式,采用基于对象(实体) 的概念建立模型,模拟客观世界分析、设 计、实现软件的办法。</p><p>面向对象编程(Object Oriented Programming-OOP) 是一种解决软件复用的设计和编程方法。 这种方法把软件系统中相近相似的操作逻辑和操作 应用数据、状态,以类的型式描述出来,以对象实例的形式在软件系统中复用,以达到提高软件开发效率的作用。</p><h3 id="类和对象"><a href="#类和对象" class="headerlink" title="类和对象"></a>类和对象</h3><p>面向对象编程的2个非常重要的概念：<strong>类和对象</strong></p><p>对象是面向对象编程的核心，在使用对象的过程中，为了将具有共同特征和行为的一组对象抽象定义，提出了另外一个新的概念——类</p><p><strong>类就相当于制造飞机时的图纸，用它来进行创建的飞机就相当于对象</strong></p><h4 id="1-类"><a href="#1-类" class="headerlink" title="1. 类"></a>1. 类</h4><pre class="language-none"><code class="language-none">人以类聚 物以群分。具有相似内部状态和运动规律的实体的集合(或统称为抽象)。 具有相同属性和行为事物的统称</code></pre><p>类是抽象的,在使用的时候通常会找到这个类的一个具体的存在,使用这个具体的存在。一个类可以找到多个对象</p><h4 id="2-对象"><a href="#2-对象" class="headerlink" title="2. 对象"></a>2. 对象</h4><pre class="language-none"><code class="language-none">某一个具体事物的存在 ,在现实世界中可以是看得见摸得着的。可以是直接使用的</code></pre><h4 id="3-类和对象之间的关系"><a href="#3-类和对象之间的关系" class="headerlink" title="3. 类和对象之间的关系"></a>3. 类和对象之间的关系</h4><p><strong>类就是创建对象的模板</strong></p><h4 id="4-类的构成"><a href="#4-类的构成" class="headerlink" title="4. 类的构成"></a>4. 类的构成</h4><p>类(Class) 由3个部分构成</p><ul><li>类的名称:类名</li><li>类的属性:一组数据</li><li>类的方法:允许对进行操作的方法 (行为)</li></ul><h4 id="5-类的抽象"><a href="#5-类的抽象" class="headerlink" title="5. 类的抽象"></a>5. 类的抽象</h4><p>如何把日常生活中的事物抽象成程序中的类?</p><p><strong>拥有相同(或者类似)属性和行为的对象都可以抽像出一个类</strong></p><p>方法:一般名词都是类(名词提炼法)</p><h3 id="定义类"><a href="#定义类" class="headerlink" title="定义类"></a>定义类</h3><p>定义一个类，格式如下：</p><pre class="language-none"><code class="language-none">class 类名:    方法列表</code></pre><p>demo：定义一个Car类</p><pre class="language-none"><code class="language-none"># 定义类class Car:    # 方法    def getCarInfo(self):        print('车轮子个数:%d, 颜色%s'%(self.wheelNum, self.color))    def move(self):        print("车正在移动...")</code></pre><p><strong>说明：</strong></p><ul><li>定义类时有2种：新式类和经典类，上面的Car为经典类，如果是Car(object)则为新式类</li><li>类名 的命名规则按照”大驼峰”</li></ul><h3 id="创建对象"><a href="#创建对象" class="headerlink" title="创建对象"></a>创建对象</h3><p>定义了一个Car类；就好比有车一个张图纸，那么接下来就应该把图纸交给生成工人们去生成了</p><p>python中，可以根据已经定义的类去创建出一个个对象</p><p>创建对象的格式为:</p><pre class="language-none"><code class="language-none">对象名 = 类名()</code></pre><p>创建对象demo:</p><pre class="language-none"><code class="language-none"># 定义类class Car:    # 移动    def move(self):        print('车在奔跑...')    # 鸣笛    def toot(self):        print("车在鸣笛...嘟嘟..")# 创建一个对象，并用变量BMW来保存它的引用BMW = Car()BMW.color = '黑色'BMW.wheelNum = 4 #轮子数量BMW.move()BMW.toot()print(BMW.color)print(BMW.wheelNum)</code></pre><p><strong>总结：</strong></p><ul><li>MW = Car()，这样就产生了一个Car的实例对象，此时也可以通过实例对象BMW来访问属性或者方法</li><li>第一次使用BMW.color = ‘黑色’表示给BMW这个对象添加属性，如果后面再次出现BMW.color = xxx表示对属性进行修改</li><li>BMW是一个对象，它拥有属性（数据）和方法（函数）</li><li>当创建一个对象时，就是用一个模子，来制造一个实物 </li></ul><hr><pre class="language-none"><code class="language-none">__init__()方法</code></pre><h4 id="lt-1-gt-使用方式"><a href="#lt-1-gt-使用方式" class="headerlink" title="<1>使用方式"></a>&lt;1&gt;使用方式</h4><pre class="language-none"><code class="language-none">def 类名:    #初始化函数，用来完成一些默认的设定    def __init__():        pass</code></pre><h4 id="lt-2-gt-init-方法的调用"><a href="#lt-2-gt-init-方法的调用" class="headerlink" title="<2>init()方法的调用"></a>&lt;2&gt;<strong>init</strong>()方法的调用</h4><pre class="language-none"><code class="language-none"># 定义汽车类class Car:    def __init__(self):        self.wheelNum = 4        self.color = '蓝色'    def move(self):        print('车在跑，目标:夏威夷')# 创建对象BMW = Car()print('车的颜色为:%s'%BMW.color)print('车轮胎数量为:%d'%BMW.wheelNum)</code></pre><p><strong>总结1:</strong></p><p>当创建Car对象后，在没有调用<strong>init</strong>()方法的前提下，BMW就默认拥有了2个属性wheelNum和color，原因是<strong>init</strong>()方法是在创建对象后，就立刻被默认调用了</p><p>能否让对象在调用<strong>init</strong>()方法的时候传递一些参数呢？如果可以，那怎样传递呢？</p><pre class="language-none"><code class="language-none"># 定义汽车类class Car:    def __init__(self, newWheelNum, newColor):        self.wheelNum = newWheelNum        self.color = newColor    def move(self):        print('车在跑，目标:夏威夷')# 创建对象BMW = Car(4, 'green')print('车的颜色为:%s'%BMW.color)print('车轮子数量为:%d'%BMW.wheelNum)</code></pre><p>总结2</p><ul><li><strong>init</strong>()方法，在创建一个对象时默认被调用，不需要手动调用</li><li><strong>init</strong>(self)中，默认有1个参数名字为self，如果在创建对象时传递了2个实参，那么<strong>init</strong>(self)中出了self作为第一个形参外还需要2个形参，例如<strong>init</strong>(self,x,y)</li><li><strong>init</strong>(self)中的self参数，不需要开发者传递，python解释器会自动把当前的对象引用传递进去</li></ul><h3 id="“魔法”方法"><a href="#“魔法”方法" class="headerlink" title="“魔法”方法"></a>“魔法”方法</h3><h4 id="1-打印id"><a href="#1-打印id" class="headerlink" title="1. 打印id()"></a>1. 打印id()</h4><p>看到的是创建出来的BMW对象在内存中的地址</p><h4 id="2-定义str-方法"><a href="#2-定义str-方法" class="headerlink" title="2. 定义str()方法"></a>2. 定义<strong>str</strong>()方法</h4><pre class="language-none"><code class="language-none">    class Car:    def __init__(self, newWheelNum, newColor):        self.wheelNum = newWheelNum        self.color = newColor    def __str__(self):        msg = "嘿。。。我的颜色是" + self.color + "我有" + int(self.wheelNum) + "个轮胎..."        return msg    def move(self):        print('车在跑，目标:夏威夷')BMW = Car(4, "白色")print(BMW)</code></pre><p><strong>总结</strong></p><ul><li>在python中方法名如果是<strong>xxxx</strong>()的，那么就有特殊的功能，因此叫做“魔法”方法</li><li>当使用print输出对象的时候，只要自己定义了<strong>str</strong>(self)方法，那么就会打印从在这个方法中return的数据</li></ul><h3 id="self"><a href="#self" class="headerlink" title="self"></a>self</h3><h4 id="1-理解self"><a href="#1-理解self" class="headerlink" title="1. 理解self"></a>1. 理解self</h4><p>看如下示例:</p><pre class="language-none"><code class="language-none"># 定义一个类class Animal:    # 方法    def __init__(self, name):        self.name = name    def printName(self):        print('名字为:%s'%self.name)# 定义一个函数def myPrint(animal):    animal.printName()dog1 = Animal('西西')myPrint(dog1)dog2 = Animal('北北')myPrint(dog2)</code></pre><p><strong>总结</strong></p><ul><li>所谓的self，可以理解为自己</li><li>可以把self当做C++中类里面的this指针一样理解，就是对象自身的意思</li><li>某个对象调用其方法时，python解释器会把这个对象作为第一个参数传递给self，所以开发者只需要传递后面的参数即可</li></ul><h3 id="隐藏数据"><a href="#隐藏数据" class="headerlink" title="隐藏数据"></a>隐藏数据</h3><p>可能你已经意识到，查看过着修改对象的属性（数据），有2种方法</p><h4 id="1-直接通过对象名修改"><a href="#1-直接通过对象名修改" class="headerlink" title="1. 直接通过对象名修改"></a>1. 直接通过对象名修改</h4><pre class="language-none"><code class="language-none">SweetPotato.cookedLevel = 5</code></pre><h4 id="2-通过方法间接修改"><a href="#2-通过方法间接修改" class="headerlink" title="2. 通过方法间接修改"></a>2. 通过方法间接修改</h4><pre class="language-none"><code class="language-none">SweetPotato.cook(5)</code></pre><p><strong>分析</strong><br>明明可以使用第1种方法直接修改，为什么还要定义方法来间接修改呢？</p><p>至少有2个原因：</p><ul><li>如果直接修改属性，烤地瓜至少需要修改2部分，即修改cookedLevel和cookedString。而使用方法来修改时，只需要调用一次即可完成</li><li>如果直接访问属性，可能会出现一些数据设置错误的情况产生例如cookedLevel = -3。这会使地瓜比以前还生，当然了这也没有任何意义，通过使用方法来进行修改，就可以在方法中进行数据合法性的检查</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python文件操作</title>
      <link href="/2017/11/07/python-wen-jian-cao-zuo/"/>
      <url>/2017/11/07/python-wen-jian-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h3 id="文件操作介绍"><a href="#文件操作介绍" class="headerlink" title="文件操作介绍"></a>文件操作介绍</h3><h4 id="lt-1-gt-什么是文件"><a href="#lt-1-gt-什么是文件" class="headerlink" title="<1>什么是文件"></a>&lt;1&gt;什么是文件</h4><h4 id="lt-2-gt-文件的作用"><a href="#lt-2-gt-文件的作用" class="headerlink" title="<2>文件的作用"></a>&lt;2&gt;文件的作用</h4><p>使用文件的目的：</p><ul><li>就是把一些存储存放起来，可以让程序下一次执行的时候直接使用，而不必重新制 作一份，省时省力</li></ul><h3 id="文件的打开与关闭"><a href="#文件的打开与关闭" class="headerlink" title="文件的打开与关闭"></a>文件的打开与关闭</h3><h4 id="lt-1-gt-打开文件"><a href="#lt-1-gt-打开文件" class="headerlink" title="<1>打开文件"></a>&lt;1&gt;打开文件</h4><p>在python，使用open函数，可以打开一个已经存在的文件，或者创建一个新文件</p><p>open(文件名，访问模式)</p><p>示例如下：</p><pre class="language-none"><code class="language-none">f = open('test.txt', 'w')</code></pre><p>说明:</p><table><thead><tr><th>访问模式</th><th>说明</th></tr></thead><tbody><tr><td>r</td><td>以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。</td></tr><tr><td>w</td><td>打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。</td></tr><tr><td>a</td><td>打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。</td></tr><tr><td>rb</td><td>以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。</td></tr><tr><td>wb</td><td>以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。</td></tr><tr><td>ab</td><td>以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。</td></tr><tr><td>r+</td><td>打开一个文件用于读写。文件指针将会放在文件的开头。</td></tr><tr><td>w+</td><td>打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。</td></tr><tr><td>a+</td><td>打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。</td></tr><tr><td>rb+</td><td>以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。</td></tr><tr><td>wb+</td><td>以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。</td></tr><tr><td>ab+</td><td>以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。</td></tr></tbody></table><h4 id="lt-2-gt-关闭文件"><a href="#lt-2-gt-关闭文件" class="headerlink" title="<2>关闭文件"></a>&lt;2&gt;关闭文件</h4><p>close( ):</p><pre class="language-none"><code class="language-none"># 新建一个文件，文件名为:test.txt    f = open('test.txt', 'w')    # 关闭这个文件    f.close()</code></pre><h3 id="文件的读写"><a href="#文件的读写" class="headerlink" title="文件的读写"></a>文件的读写</h3><h4 id="lt-1-gt-写数据-write"><a href="#lt-1-gt-写数据-write" class="headerlink" title="<1>写数据(write)"></a>&lt;1&gt;写数据(write)</h4><p>使用write()可以完成向文件写入数据</p><p>demo:</p><pre class="language-none"><code class="language-none">f = open('test.txt', 'w')f.write('hello world, i am here!')f.close()</code></pre><p>注意：</p><ul><li>如果文件不存在那么创建，如果存在那么就先清空，然后写入数据</li></ul><h4 id="lt-2-gt-读数据-read"><a href="#lt-2-gt-读数据-read" class="headerlink" title="<2>读数据(read)"></a>&lt;2&gt;读数据(read)</h4><p>使用read(num)可以从文件中读取数据，num表示要从文件中读取的数据的长度（单位是字节），如果没有传入num，那么就表示读取文件中所有的数据</p><pre class="language-none"><code class="language-none">f = open('test.txt', 'r')content = f.read(5)print(content)print("-"*30)content = f.read()print(content)f.close()</code></pre><p>注意：</p><ul><li>如果open是打开一个文件，那么可以不用谢打开的模式，即只写 open(‘test.txt’)</li><li>如果使用读了多次，那么后面读取的数据是从上次读完后的位置开始的</li></ul><h4 id="lt-3-gt-读数据（readlines）"><a href="#lt-3-gt-读数据（readlines）" class="headerlink" title="<3>读数据（readlines）"></a>&lt;3&gt;读数据（readlines）</h4><p>就像read没有参数时一样，readlines可以按照行的方式把整个文件中的内容进行一次性读取，并且返回的是一个列表，其中每一行的数据为一个元素</p><pre class="language-none"><code class="language-none">#coding=utf-8f = open('test.txt', 'r')content = f.readlines()print(type(content))i=1for temp in content:    print("%d:%s"%(i, temp))    i+=1f.close()</code></pre><h4 id="lt-4-gt-读数据（readline）"><a href="#lt-4-gt-读数据（readline）" class="headerlink" title="<4>读数据（readline）"></a>&lt;4&gt;读数据（readline）</h4><pre class="language-none"><code class="language-none">#coding=utf-8f = open('test.txt', 'r')content = f.readline()print("1:%s"%content)content = f.readline()print("2:%s"%content)f.close()</code></pre><h4 id="文件的备份的参考代码"><a href="#文件的备份的参考代码" class="headerlink" title="文件的备份的参考代码"></a>文件的备份的参考代码</h4><pre class="language-none"><code class="language-none">#coding=utf-8oldFileName = input("请输入要拷贝的文件名字:")oldFile = open(oldFileName,'r')# 如果打开文件if oldFile:    # 提取文件的后缀    fileFlagNum = oldFileName.rfind('.')    if fileFlagNum &gt; 0:        fileFlag = oldFileName[fileFlagNum:]    # 组织新的文件名字    newFileName = oldFileName[:fileFlagNum] + '[复件]' + fileFlag    # 创建新文件    newFile = open(newFileName, 'w')    # 把旧文件中的数据，一行一行的进行复制到新文件中    for lineContent in oldFile.readlines():        newFile.write(lineContent)    # 关闭文件    oldFile.close()    newFile.close()</code></pre><h3 id="文件的随机读写"><a href="#文件的随机读写" class="headerlink" title="文件的随机读写"></a>文件的随机读写</h3><h4 id="lt-1-gt-获取当前读写的位置"><a href="#lt-1-gt-获取当前读写的位置" class="headerlink" title="<1>获取当前读写的位置"></a>&lt;1&gt;获取当前读写的位置</h4><p>在读写文件的过程中，如果想知道当前的位置，可以使用tell()来获取</p><pre class="language-none"><code class="language-none"># 打开一个已经存在的文件    f = open("test.txt", "r")    str = f.read(3)    print "读取的数据是 : ", str    # 查找当前位置    position = f.tell()    print "当前文件位置 : ", position    str = f.read(3)    print "读取的数据是 : ", str    # 查找当前位置    position = f.tell()    print "当前文件位置 : ", position    f.close()</code></pre><h4 id="lt-2-gt-定位到某个位置"><a href="#lt-2-gt-定位到某个位置" class="headerlink" title="<2>定位到某个位置"></a>&lt;2&gt;定位到某个位置</h4><p>如果在读写文件的过程中，需要从另外一个位置进行操作的话，可以使用seek()</p><p>seek(offset, from)有2个参数</p><ul><li><p>offset:偏移量</p></li><li><p>from:方向</p><ul><li>表示文件开头</li><li>表示当前位置</li><li>表示文件末尾</li></ul></li></ul><p>demo:把位置设置为：从文件开头，偏移5个字节</p><pre class="language-none"><code class="language-none"># 打开一个已经存在的文件    f = open("test.txt", "r")    str = f.read(30)    print "读取的数据是 : ", str    # 查找当前位置    position = f.tell()    print "当前文件位置 : ", position    # 重新设置位置    f.seek(5,0)    # 查找当前位置    position = f.tell()    print "当前文件位置 : ", position    f.close()</code></pre><p>demo:把位置设置为：离文件末尾，3字节处</p><pre class="language-none"><code class="language-none"># 打开一个已经存在的文件    f = open("test.txt", "r")    # 查找当前位置    position = f.tell()    print "当前文件位置 : ", position    # 重新设置位置    f.seek(-3,2)    # 读取到的数据为：文件最后3个字节数据    str = f.read()    print "读取的数据是 : ", str    f.close()</code></pre><h3 id="文件的重命名、删除"><a href="#文件的重命名、删除" class="headerlink" title="文件的重命名、删除"></a>文件的重命名、删除</h3><p>有些时候，需要对文件进行重命名、删除等一些操作，python的os模块中都有这么功能</p><h4 id="lt-1-gt-文件重命名"><a href="#lt-1-gt-文件重命名" class="headerlink" title="<1>文件重命名"></a>&lt;1&gt;文件重命名</h4><p>os模块中的rename()可以完成对文件的重命名操作</p><p>rename(需要修改的文件名, 新的文件名)</p><pre class="language-none"><code class="language-none">import os   os.rename("毕业论文.txt", "毕业论文-最终版.txt")</code></pre><h4 id="lt-2-gt-删除文件"><a href="#lt-2-gt-删除文件" class="headerlink" title="<2>删除文件"></a>&lt;2&gt;删除文件</h4><p>os模块中的remove()可以完成对文件的删除操作</p><p>remove(待删除的文件名)</p><pre class="language-none"><code class="language-none">import os    os.remove("毕业论文.txt")</code></pre><h3 id="文件夹的相关操作"><a href="#文件夹的相关操作" class="headerlink" title="文件夹的相关操作"></a>文件夹的相关操作</h3><p>实际开发中，有时需要用程序的方式对文件夹进行一定的操作，比如创建、删除等</p><p>就像对文件操作需要os模块一样，如果要操作文件夹，同样需要os模块</p><h4 id="lt-1-gt-创建文件夹"><a href="#lt-1-gt-创建文件夹" class="headerlink" title="<1>创建文件夹"></a>&lt;1&gt;创建文件夹</h4><pre class="language-none"><code class="language-none">import os    os.mkdir("张三")</code></pre><h4 id="lt-2-gt-获取当前目录"><a href="#lt-2-gt-获取当前目录" class="headerlink" title="<2>获取当前目录"></a>&lt;2&gt;获取当前目录</h4><pre class="language-none"><code class="language-none">import os    os.getcwd()</code></pre><h4 id="lt-3-gt-改变默认目录"><a href="#lt-3-gt-改变默认目录" class="headerlink" title="<3>改变默认目录"></a>&lt;3&gt;改变默认目录</h4><pre class="language-none"><code class="language-none">import os    os.chdir("../")</code></pre><h4 id="lt-4-gt-获取目录列表"><a href="#lt-4-gt-获取目录列表" class="headerlink" title="<4>获取目录列表"></a>&lt;4&gt;获取目录列表</h4><pre class="language-none"><code class="language-none">import os    os.listdir("./")</code></pre><h4 id="lt-5-gt-删除文件夹"><a href="#lt-5-gt-删除文件夹" class="headerlink" title="<5>删除文件夹"></a>&lt;5&gt;删除文件夹</h4><pre class="language-none"><code class="language-none">import os    os.rmdir("张三")</code></pre><h3 id="批量修改文件名参考代码"><a href="#批量修改文件名参考代码" class="headerlink" title="批量修改文件名参考代码"></a>批量修改文件名参考代码</h3><pre class="language-none"><code class="language-none">#coding=utf-8    # 批量在文件名前加前缀    import os    funFlag = 1 # 1表示添加标志  2表示删除标志    folderName = './renameDir/'    # 获取指定路径的所有文件名字    dirList = os.listdir(folderName)    # 遍历输出所有文件名字    for name in dirList:        print name        if funFlag == 1:            newName = '[东哥出品]-' + name        elif funFlag == 2:            num = len('[东哥出品]-')            newName = name[num:]        print newName        os.rename(folderName+name, folderName+newName)</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python函数</title>
      <link href="/2017/11/06/python-han-shu/"/>
      <url>/2017/11/06/python-han-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="函数介绍"><a href="#函数介绍" class="headerlink" title="函数介绍"></a>函数介绍</h1><h3 id="什么是函数"><a href="#什么是函数" class="headerlink" title="什么是函数"></a>什么是函数</h3><p>如果在开发程序时，需要某块代码多次，但是为了提高编写的效率以及代码的重用，所以把具有独立功能的代码块组织为一个小模块，这就是函数</p><h3 id="函数定义和调用"><a href="#函数定义和调用" class="headerlink" title="函数定义和调用"></a>函数定义和调用</h3><h4 id="lt-1-gt-定义函数"><a href="#lt-1-gt-定义函数" class="headerlink" title="<1>定义函数"></a>&lt;1&gt;定义函数</h4><p>定义函数的格式如下：</p><pre class="language-none"><code class="language-none">def 函数名():        代码</code></pre><p>demo:</p><pre class="language-none"><code class="language-none"># 定义一个函数，能够完成打印信息的功能    def printInfo():        print '------------------------------------'        print '         人生苦短，我用Python'        print '------------------------------------'</code></pre><h4 id="lt-2-gt-调用函数"><a href="#lt-2-gt-调用函数" class="headerlink" title="<2>调用函数"></a>&lt;2&gt;调用函数</h4><p>定义了函数之后，就相当于有了一个具有某些功能的代码，想要让这些代码能够执行，需要调用它,调用函数很简单的，通过 函数名() 即可完成调用<br>demo:</p><pre class="language-none"><code class="language-none"># 定义完函数后，函数是不会自动执行的，需要调用它才可以    printInfo()</code></pre><h3 id="函数的文档说明"><a href="#函数的文档说明" class="headerlink" title="函数的文档说明"></a>函数的文档说明</h3><pre class="language-none"><code class="language-none">&gt;&gt;&gt; def test(a,b):...     "用来完成对2个数求和"...     print("%d"%(a+b))... &gt;&gt;&gt; &gt;&gt;&gt; test(11,22)33</code></pre><p>如果执行，以下代码</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; help(test)</code></pre><p>能够看到test函数的相关说明:</p><pre class="language-none"><code class="language-none">Help on function test in module __main__:test(a, b)    用来完成对2个数求和(END)</code></pre><h3 id="函数参数-一"><a href="#函数参数-一" class="headerlink" title="函数参数(一)"></a>函数参数(一)</h3><h4 id="lt-1-gt-定义带有参数的函数"><a href="#lt-1-gt-定义带有参数的函数" class="headerlink" title="<1> 定义带有参数的函数"></a>&lt;1&gt; 定义带有参数的函数</h4><p>示例如下：</p><pre class="language-none"><code class="language-none">def add2num(a, b):        c = a+b        print c</code></pre><h4 id="lt-2-gt-调用带有参数的函数"><a href="#lt-2-gt-调用带有参数的函数" class="headerlink" title="<2> 调用带有参数的函数"></a>&lt;2&gt; 调用带有参数的函数</h4><p>以调用上面的add2num(a, b)函数为例:</p><pre class="language-none"><code class="language-none">def add2num(a, b):        c = a+b        print c    add2num(11, 22) #调用带有参数的函数时，需要在小括号中，传递数据</code></pre><h4 id="lt-3-gt-调用函数时参数的顺序"><a href="#lt-3-gt-调用函数时参数的顺序" class="headerlink" title="<3> 调用函数时参数的顺序"></a>&lt;3&gt; 调用函数时参数的顺序</h4><pre class="language-none"><code class="language-none">&gt;&gt;&gt; def test(a,b):...     print(a,b)... &gt;&gt;&gt; test(1,2)1 2&gt;&gt;&gt; test(b=1,a=2)2 1&gt;&gt;&gt; &gt;&gt;&gt; test(b=1,2)  File "&lt;stdin&gt;", line 1SyntaxError: positional argument follows keyword argument&gt;&gt;&gt; &gt;&gt;&gt;</code></pre><h4 id="lt-4-gt-总结"><a href="#lt-4-gt-总结" class="headerlink" title="<4>总结"></a>&lt;4&gt;总结</h4><ul><li>使用def定义函数，要注意有3个参数</li><li>调用的时候，这个函数定义时有几个参数，那么就需要传递几个参数</li><li>定义时小括号中的参数，用来接收参数用的，称为 “形参”</li><li>调用时小括号中的参数，用来传递给函数用的，称为 “实参”</li></ul><h3 id="函数返回值-一"><a href="#函数返回值-一" class="headerlink" title="函数返回值(一)"></a>函数返回值(一)</h3><h4 id="lt-1-gt-“返回值”介绍"><a href="#lt-1-gt-“返回值”介绍" class="headerlink" title="<1>“返回值”介绍"></a>&lt;1&gt;“返回值”介绍</h4><p><strong>所谓“返回值”，就是程序中函数完成一件事情后，最后给调用者的结果</strong></p><h4 id="lt-2-gt-带有返回值的函数"><a href="#lt-2-gt-带有返回值的函数" class="headerlink" title="<2>带有返回值的函数"></a>&lt;2&gt;带有返回值的函数</h4><p>想要在函数中把结果返回给调用者，需要在函数中使用return</p><p>如下示例:</p><pre class="language-none"><code class="language-none">def add2num(a, b):        c = a+b        return c</code></pre><p>或者</p><pre class="language-none"><code class="language-none">def add2num(a, b):        return a+b</code></pre><h4 id="lt-3-gt-保存函数的返回值"><a href="#lt-3-gt-保存函数的返回值" class="headerlink" title="<3>保存函数的返回值"></a>&lt;3&gt;保存函数的返回值</h4><p>保存函数的返回值示例如下:</p><pre class="language-none"><code class="language-none">#定义函数    def add2num(a, b):        return a+b    #调用函数，顺便保存函数的返回值    result = add2num(100,98)    #因为result已经保存了add2num的返回值，所以接下来就可以使用了    print result</code></pre><h3 id="4种函数的类型"><a href="#4种函数的类型" class="headerlink" title="4种函数的类型"></a>4种函数的类型</h3><p>函数根据有没有参数，有没有返回值，可以相互组合，一共有4种:</p><ul><li><p>无参数，无返回值</p></li><li><p>无参数，有返回值</p></li><li><p>有参数，无返回值</p></li><li><p>有参数，有返回值</p><h4 id="lt-1-gt-无参数，无返回值的函数"><a href="#lt-1-gt-无参数，无返回值的函数" class="headerlink" title="<1>无参数，无返回值的函数"></a>&lt;1&gt;无参数，无返回值的函数</h4><p>此类函数，不能接收参数，也没有返回值，一般情况下，打印提示灯类似的功能，使用这类的函数</p><pre class="language-none"><code class="language-none">def printMenu():     print('--------------------------')     print('      xx涮涮锅 点菜系统')     print('')     print('  1.  羊肉涮涮锅')     print('  2.  牛肉涮涮锅')     print('  3.  猪肉涮涮锅')     print('--------------------------')</code></pre><h4 id="lt-2-gt-无参数，有返回值的函数"><a href="#lt-2-gt-无参数，有返回值的函数" class="headerlink" title="<2>无参数，有返回值的函数"></a>&lt;2&gt;无参数，有返回值的函数</h4><p>此类函数，不能接收参数，但是可以返回某个数据，一般情况下，像采集数据，用此类函数</p><pre class="language-none"><code class="language-none"># 获取温度 def getTemperature():     #这里是获取温度的一些处理过程     #为了简单起见，先模拟返回一个数据     return 24 temperature = getTemperature() print('当前的温度为:%d'%temperature)</code></pre><h4 id="lt-3-gt-有参数，无返回值的函数"><a href="#lt-3-gt-有参数，无返回值的函数" class="headerlink" title="<3>有参数，无返回值的函数"></a>&lt;3&gt;有参数，无返回值的函数</h4><p>此类函数，能接收参数，但不可以返回数据，一般情况下，对某些变量设置数据而不需结果时，用此类函数</p><h4 id="lt-4-gt-有参数，有返回值的函数"><a href="#lt-4-gt-有参数，有返回值的函数" class="headerlink" title="<4>有参数，有返回值的函数"></a>&lt;4&gt;有参数，有返回值的函数</h4><p>此类函数，不仅能接收参数，还可以返回某个数据，一般情况下，像数据处理并需要结果的应用，用此类函数</p><pre class="language-none"><code class="language-none"># 计算1~num的累积和 def calculateNum(num):     result = 0     i = 1     while i&lt;=num:         result = result + i         i+=1     return result result = calculateNum(100) print('1~100的累积和为:%d'%result)</code></pre><h4 id="lt-5-gt-总结"><a href="#lt-5-gt-总结" class="headerlink" title="<5>总结"></a>&lt;5&gt;总结</h4></li><li><p>函数根据有没有参数，有没有返回值可以相互组合</p></li><li><p>定义函数时，是根据实际的功能需求来设计的，所以不同开发人员编写的函数类型各不相同</p><h3 id="函数的嵌套调用"><a href="#函数的嵌套调用" class="headerlink" title="函数的嵌套调用"></a>函数的嵌套调用</h3><p>&lt;!–hexoPostRenderEscape:</p><pre class="language-none"><code class="language-none">def testB():<p></p><pre><code>  print(&amp;#39;---- testB start----&amp;#39;)  print(&amp;#39;这里是testB函数执行的代码...(省略)...&amp;#39;)  print(&amp;#39;---- testB end----&amp;#39;)</code></pre></code></pre></li><code class="language-none"></code></ul><code class="language-none"><pre><code>def testA():    print(&amp;#39;---- testA start----&amp;#39;)    testB()    print(&amp;#39;---- testA end----&amp;#39;)testA()&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape--&gt;</code></pre><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul><li>一个函数里面又调用了另外一个函数，这就是所谓的函数嵌套调用 </li><li>如果函数A中，调用了另外一个函数B，那么先把函数B中的任务都执行完毕之后才会回到上次 函数A执行的位置</li></ul><h3 id="局部变量"><a href="#局部变量" class="headerlink" title="局部变量"></a>局部变量</h3><ul><li>局部变量，就是在函数内部定义的变量</li><li>不同的函数，可以定义相同的名字的局部变量，但是各用个的不会产生影响</li><li>局部变量的作用，为了临时保存数据需要在函数中定义变量来进行存储，这就是它的作用</li></ul><h3 id="全局变量"><a href="#全局变量" class="headerlink" title="全局变量"></a>全局变量</h3><h4 id="lt-1-gt-什么是全局变量"><a href="#lt-1-gt-什么是全局变量" class="headerlink" title="<1>什么是全局变量"></a>&lt;1&gt;什么是全局变量</h4><p>如果一个变量，既能在一个函数中使用，也能在其他的函数中使用，这样的变量就是全局变量</p><h4 id="lt-2-gt-全局变量和局部变量名字相同问题"><a href="#lt-2-gt-全局变量和局部变量名字相同问题" class="headerlink" title="<2>全局变量和局部变量名字相同问题"></a>&lt;2&gt;全局变量和局部变量名字相同问题</h4><p>如果局部变量和全局变量名字相同，那么则使用就近原则，即：使用局部变量</p><h4 id="lt-3-gt-修改全局变量"><a href="#lt-3-gt-修改全局变量" class="headerlink" title="<3>修改全局变量"></a>&lt;3&gt;修改全局变量</h4><p>既然全局变量，就是能够在所以的函数中进行使用,可以用global关键字</p><h4 id="lt-4-gt-总结1"><a href="#lt-4-gt-总结1" class="headerlink" title="<4>总结1:"></a>&lt;4&gt;总结1:</h4><ul><li>在函数外边定义的变量叫做全局变量</li><li>全局变量能够在所有的函数中进行访问</li><li>如果在函数中修改全局变量，那么就需要使用global进行声明，否则出错</li><li>如果全局变量的名字和局部变量的名字相同，那么使用的是局部变量的，小技巧强龙不压地头蛇<h4 id="lt-5-gt-可变类型的全局变量"><a href="#lt-5-gt-可变类型的全局变量" class="headerlink" title="<5>可变类型的全局变量"></a>&lt;5&gt;可变类型的全局变量</h4><pre class="language-none"><code class="language-none">&gt;&gt;&gt; a = 1&gt;&gt;&gt; def f():...     a += 1...     print a...&gt;&gt;&gt; f()Traceback (most recent call last):File "&lt;stdin&gt;", line 1, in &lt;module&gt;File "&lt;stdin&gt;", line 2, in fUnboundLocalError: local variable 'a' referenced before assignment&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; li = [1,]&gt;&gt;&gt; def f2():...     li.append(1)...     print li...&gt;&gt;&gt; f2()[1, 1]&gt;&gt;&gt; li[1, 1]</code></pre><h4 id="lt-6-gt-总结2："><a href="#lt-6-gt-总结2：" class="headerlink" title="<6>总结2："></a>&lt;6&gt;总结2：</h4></li><li>在函数中不使用global声明全局变量时不能修改全局变量的本质是不能修改全局变量的指向，即不能将全局变量指向新的数据。</li><li>对于不可变类型的全局变量来说，因其指向的数据不能修改，所以不使用global时无法修改全局变量。</li><li>对于可变类型的全局变量来说，因其指向的数据可以修改，所以不使用global时也可修改全局变量。<h3 id="函数返回值-二"><a href="#函数返回值-二" class="headerlink" title="函数返回值(二)"></a>函数返回值(二)</h3></li><li>*在python中我们可不可以返回多个值？**<pre class="language-none"><code class="language-none">&gt;&gt;&gt; def divid(a, b):...     shang = a//b...     yushu = a%b ...     return shang, yushu...&gt;&gt;&gt; sh, yu = divid(5, 2)&gt;&gt;&gt; sh5&gt;&gt;&gt; yu1</code></pre>本质是利用了元组<h3 id="函数参数-二"><a href="#函数参数-二" class="headerlink" title="函数参数(二)"></a>函数参数(二)</h3><h4 id="1-缺省参数"><a href="#1-缺省参数" class="headerlink" title="1. 缺省参数"></a>1. 缺省参数</h4>调用函数时，缺省参数的值如果没有传入，则被认为是默认值。下例会打印默认的age，如果age没有被传入：<br>&lt;!–hexoPostRenderEscape:<pre class="language-none"><code class="language-none">def printinfo( name, age = 35 ):<h1 id="打印任何传入的字符串"><a href="#打印任何传入的字符串" class="headerlink" title="打印任何传入的字符串"></a>打印任何传入的字符串</h1>  print "Name: ", name<br>  print "Age ", age</code></pre></li><code class="language-none"></code></ul><code class="language-none"><h1 id="调用printinfo函数"><a href="#调用printinfo函数" class="headerlink" title="调用printinfo函数"></a>调用printinfo函数</h1></code><p><code class="language-none">printinfo(name="miki" )<br>printinfo( age=9,name="miki" )</code>:hexoPostRenderEscape–&gt;<br><strong>注意：带有默认值的参数一定要位于参数列表的最后面。</strong></p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; def printinfo(name, age=35, sex):...     print name...  File "&lt;stdin&gt;", line 1SyntaxError: non-default argument follows default argument</code></pre><h4 id="2-不定长参数"><a href="#2-不定长参数" class="headerlink" title="2.不定长参数"></a>2.不定长参数</h4><p>有时可能需要一个函数能处理比当初声明时更多的参数。这些参数叫做不定长参数，声明时不会命名。</p><p>基本语法如下：</p><pre class="language-none"><code class="language-none">def functionname([formal_args,] *args, **kwargs):       "函数_文档字符串"       function_suite       return [expression]</code></pre><p>加了星号（*）的变量args会存放所有未命名的变量参数，args为元组；而加**的变量kwargs会存放命名参数，即形如key=value的参数， kwargs为字典。</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; def fun(a, b, *args, **kwargs):...     """可变参数演示示例"""...     print "a =", a...     print "b =", b...     print "args =", args...     print "kwargs: "...     for key, value in kwargs.items():...         print key, "=", value...&gt;&gt;&gt; fun(1, 2, 3, 4, 5, m=6, n=7, p=8)  # 注意传递的参数对应a = 1b = 2args = (3, 4, 5)kwargs: p = 8m = 6n = 7&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; c = (3, 4, 5)&gt;&gt;&gt; d = {"m":6, "n":7, "p":8}&gt;&gt;&gt; fun(1, 2, *c, **d)    # 注意元组与字典的传参方式a = 1b = 2args = (3, 4, 5)kwargs: p = 8m = 6n = 7&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; fun(1, 2, c, d) # 注意不加星号与上面的区别a = 1b = 2args = ((3, 4, 5), {'p': 8, 'm': 6, 'n': 7})kwargs:&gt;&gt;&gt;&gt;&gt;&gt;</code></pre><h4 id="3-引用传参"><a href="#3-引用传参" class="headerlink" title="3. 引用传参"></a>3. 引用传参</h4><ul><li>可变类型与不可变类型的变量分别作为函数参数时，会有什么不同吗？</li><li>Python有没有类似C语言中的指针传参呢？<pre class="language-none"><code class="language-none">&gt;&gt;&gt; def selfAdd(a):...     """自增"""...     a += a...&gt;&gt;&gt; a_int = 1&gt;&gt;&gt; a_int1&gt;&gt;&gt; selfAdd(a_int)&gt;&gt;&gt; a_int1&gt;&gt;&gt; a_list = [1, 2]&gt;&gt;&gt; a_list[1, 2]&gt;&gt;&gt; selfAdd(a_list)&gt;&gt;&gt; a_list[1, 2, 1, 2]</code></pre>Python中函数参数是引用传递（注意不是值传递）。对于不可变类型，因变量不能修改，所以运算不会影响到变量自身；而对于可变类型来说，函数体中的运算有可能会更改传入的参数变量。<pre class="language-none"><code class="language-none">&gt;&gt;&gt; def selfAdd(a):...     """自增"""...     a = a + a   # 我们更改了函数体的这句话...&gt;&gt;&gt; a_int = 1&gt;&gt;&gt; a_int1&gt;&gt;&gt; selfAdd(a_int)&gt;&gt;&gt; a_int1&gt;&gt;&gt; a_list = [1, 2]&gt;&gt;&gt; a_list[1, 2]&gt;&gt;&gt; selfAdd(a_list)&gt;&gt;&gt; a_list[1, 2]      # 想一想为什么没有变呢？</code></pre><h3 id="递归函数"><a href="#递归函数" class="headerlink" title="递归函数"></a>递归函数</h3><h4 id="lt-1-gt-什么是递归函数"><a href="#lt-1-gt-什么是递归函数" class="headerlink" title="<1>什么是递归函数"></a>&lt;1&gt;什么是递归函数</h4>如果一个函数在内部不调用其它的函数，而是自己本身的话，这个函数就是递归函数。<h4 id="lt-2-gt-递归函数的作用"><a href="#lt-2-gt-递归函数的作用" class="headerlink" title="<2>递归函数的作用"></a>&lt;2&gt;递归函数的作用</h4>举个例子，我们来计算阶乘 n! = 1 * 2 * 3 * … * n<br>看阶乘的规律<pre class="language-none"><code class="language-none">1! = 12! = 2 × 1 = 2 × 1!3! = 3 × 2 × 1 = 3 × 2!4! = 4 × 3 × 2 × 1 = 4 × 3!...n! = n × (n-1)!</code></pre><h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h3>用lambda关键词能创建小型匿名函数。这种函数得名于省略了用def声明函数的标准步骤。</li></ul><p>lambda函数的语法只包含一个语句，如下：</p><pre class="language-none"><code class="language-none">lambda [arg1 [,arg2,.....argn]]:expression</code></pre><p>如下实例：</p><pre class="language-none"><code class="language-none">sum = lambda arg1, arg2: arg1 + arg2   #调用sum函数   print "Value of total : ", sum( 10, 20 )   print "Value of total : ", sum( 20, 20 )</code></pre><p>以上实例输出结果：</p><pre class="language-none"><code class="language-none">Value of total :  30    Value of total :  40</code></pre><p>Lambda函数能接收任何数量的参数但只能返回一个表达式的值</p><p>匿名函数不能直接调用print，因为lambda需要一个表达式</p><h3 id="应用场合"><a href="#应用场合" class="headerlink" title="应用场合"></a>应用场合</h3><h4 id="函数作为参数传递"><a href="#函数作为参数传递" class="headerlink" title="函数作为参数传递"></a>函数作为参数传递</h4><ul><li><p>自己定义函数</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; def fun(a, b, opt):...     print "a =", a...     print "b =", b...     print "result =", opt(a, b)...&gt;&gt;&gt; fun(1, 2, lambda x,y:x+y)a = 1b = 2result = 3</code></pre></li><li><p>作为内置函数的参数<br>想一想，下面的数据如何指定按age或name排序？</p><pre class="language-none"><code class="language-none">stus = [  {"name":"zhangsan", "age":18},   {"name":"lisi", "age":19},   {"name":"wangwu", "age":17}  ]</code></pre><p>按name排序：</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; stus.sort(key = lambda x:x['name'])&gt;&gt;&gt; stus[{'age': 19, 'name': 'lisi'}, {'age': 17, 'name': 'wangwu'}, {'age': 18, 'name': 'zhangsan'}]</code></pre><p>按age排序：</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; stus.sort(key = lambda x:x['age'])&gt;&gt;&gt; stus[{'age': 17, 'name': 'wangwu'}, {'age': 18, 'name': 'zhangsan'}, {'age': 19, 'name': 'lisi'}]</code></pre><h3 id="函数使用注意事项"><a href="#函数使用注意事项" class="headerlink" title="函数使用注意事项"></a>函数使用注意事项</h3><h4 id="1-自定义函数"><a href="#1-自定义函数" class="headerlink" title="1. 自定义函数"></a>1. 自定义函数</h4><h4 id="lt-1-gt-无参数、无返回值"><a href="#lt-1-gt-无参数、无返回值" class="headerlink" title="<1>无参数、无返回值"></a>&lt;1&gt;无参数、无返回值</h4><pre class="language-none"><code class="language-none">def 函数名():      语句</code></pre><h4 id="lt-2-gt-无参数、有返回值"><a href="#lt-2-gt-无参数、有返回值" class="headerlink" title="<2>无参数、有返回值"></a>&lt;2&gt;无参数、有返回值</h4><pre class="language-none"><code class="language-none">def 函数名():      语句      return 需要返回的数值</code></pre></li><li><p>*注意:**</p></li><li><p>一个函数到底有没有返回值，就看有没有return，因为只有return才可以返回数据</p></li><li><p>在开发中往往根据需求来设计函数需不需要返回值</p></li><li><p>函数中，可以有多个return语句，但是只要执行到一个return语句，那么就意味着这个函数的调用完成</p><h4 id="lt-3-gt-有参数、无返回值"><a href="#lt-3-gt-有参数、无返回值" class="headerlink" title="<3>有参数、无返回值"></a>&lt;3&gt;有参数、无返回值</h4><pre class="language-none"><code class="language-none">def 函数名(形参列表):     语句</code></pre></li><li><p>*注意:**</p></li><li><p>在调用函数时，如果需要把一些数据一起传递过去，被调用函数就需要用参数来接收</p></li><li><p>参数列表中变量的个数根据实际传递的数据的多少来确定</p><h4 id="lt-4-gt-有参数、有返回值"><a href="#lt-4-gt-有参数、有返回值" class="headerlink" title="<4>有参数、有返回值"></a>&lt;4&gt;有参数、有返回值</h4><pre class="language-none"><code class="language-none">def 函数名(形参列表):      语句      return 需要返回的数值</code></pre><h4 id="lt-5-gt-函数名不能重复"><a href="#lt-5-gt-函数名不能重复" class="headerlink" title="<5>函数名不能重复"></a>&lt;5&gt;函数名不能重复</h4></li></ul><h4 id="2-调用函数"><a href="#2-调用函数" class="headerlink" title="2. 调用函数"></a>2. 调用函数</h4><p><strong>&lt;1&gt;调用的方式为：</strong></p><pre class="language-none"><code class="language-none">函数名([实参列表])</code></pre><p> <strong>&lt;2&gt;调用时，到底写不写 实参</strong><br>如果调用的函数 在定义时有形参，那么在调用的时候就应该传递参数<br>**&lt;3&gt;调用时，实参的个数和先后顺序应该和定义函数中要求的一致**<br><strong>&lt;4&gt;如果调用的函数有返回值，那么就可以用一个变量来进行保存这个值</strong></p><h4 id="3-作用域"><a href="#3-作用域" class="headerlink" title="3. 作用域"></a>3. 作用域</h4><p> <strong>&lt;1&gt;在一个函数中定义的变量，只能在本函数中用(局部变量</strong><br>  <strong>&lt;2&gt;在函数外定义的变量，可以在所有的函数中使用(全局变量)</strong></p></code><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python公共方法和引用</title>
      <link href="/2017/10/26/python-gong-gong-fang-fa-he-yin-yong/"/>
      <url>/2017/10/26/python-gong-gong-fang-fa-he-yin-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="公共方法"><a href="#公共方法" class="headerlink" title="公共方法"></a>公共方法</h1><h3 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h3><table><thead><tr><th>运算符</th><th>Python</th><th>表达式</th><th>结果</th><th>描述</th><th>支持的数据类型</th></tr></thead></table><ul><li>| [1, 2] + [3, 4]    | [1, 2, 3, 4]    | 合并    | 字符串、列表、元组</li></ul><ul><li>| ‘Hi!’ * 4    | [‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’]    | 复制    | 字符串、列表、元组<br>in    | 3 in (1, 2, 3)    | True    | 元素是否存在    字符串、| 列表、元组、字典<br>not in    | 4 not in (1, 2, 3)    | True    | 元素是否不存在    | 字符串、列表、元组、字典</li><li>*+**<pre class="language-none"><code class="language-none">&gt;&gt;&gt; "hello " + "itcast"'hello itcast'&gt;&gt;&gt; [1, 2] + [3, 4][1, 2, 3, 4]&gt;&gt;&gt; ('a', 'b') + ('c', 'd')('a', 'b', 'c', 'd')</code></pre></li></ul><hr><pre class="language-none"><code class="language-none">&gt;&gt;&gt; 'ab'*4'ababab'&gt;&gt;&gt; [1, 2]*4[1, 2, 1, 2, 1, 2, 1, 2]&gt;&gt;&gt; ('a', 'b')*4('a', 'b', 'a', 'b', 'a', 'b', 'a', 'b')</code></pre><p><strong>in</strong></p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; 'itc' in 'hello itcast'True&gt;&gt;&gt; 3 in [1, 2]False&gt;&gt;&gt; 4 in (1, 2, 3, 4)True&gt;&gt;&gt; "name" in {"name":"Delron", "age":24}True</code></pre><p><strong>注意，in在对字典操作时，判断的是字典的键</strong></p><h3 id="python内置函数"><a href="#python内置函数" class="headerlink" title="python内置函数"></a>python内置函数</h3><p>Python包含了以下内置函数<br>序号    | 方法    | 描述<br>——    |  —–    |——-<br>1    | cmp(item1, item2)    | 比较两个值<br>2    | len(item)    | 计算容器中元素个数<br>3    | max(item)    | 返回容器中元素最大值<br>4    | min(item)    | 返回容器中元素最小值<br>5    | del(item)    | 删除变量</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p>在python中，值是靠引用来传递来的。</p><p>我们可以用id()来判断两个变量是否为同一个值的引用。 我们可以将id值理解为那块内存的地址标示。</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; a = 1&gt;&gt;&gt; b = a&gt;&gt;&gt; id(a) 13033816&gt;&gt;&gt; id(b)   # 注意两个变量的id值相同13033816&gt;&gt;&gt; a = 2&gt;&gt;&gt; id(a)   # 注意a的id值已经变了13033792&gt;&gt;&gt; id(b)   # b的id值依旧13033816</code></pre><pre class="language-none"><code class="language-none">&gt;&gt;&gt; a = [1, 2]&gt;&gt;&gt; b = a&gt;&gt;&gt; id(a)139935018544808&gt;&gt;&gt; id(b)139935018544808&gt;&gt;&gt; a.append(3)&gt;&gt;&gt; a[1, 2, 3]&gt;&gt;&gt; id(a)139935018544808&gt;&gt;&gt; id(b)       # 注意a与b始终指向同一个地址139935018544808</code></pre><h3 id="可变类型与不可变类型"><a href="#可变类型与不可变类型" class="headerlink" title="可变类型与不可变类型"></a>可变类型与不可变类型</h3><p>可变类型，值可以改变：</p><ul><li>列表 list</li><li>字典 dict<br>不可变类型，值不可以改变：</li><li>数值类型 int, long, bool, float</li><li>字符串 str</li><li>元组 tuple</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python元组和字典</title>
      <link href="/2017/10/26/python-yuan-zu-he-zi-dian/"/>
      <url>/2017/10/26/python-yuan-zu-he-zi-dian/</url>
      
        <content type="html"><![CDATA[<h1 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h1><p>Python的元组与列表类似，不同之处在于元组的元素不能修改。元组使用小括号，列表使用方括号。</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; aTuple = ('et',77,99.9)&gt;&gt;&gt; aTuple('et',77,99.9)</code></pre><blockquote><p>&lt;1&gt;访问元组<br>&lt;2&gt;修改元组<br>&lt;3&gt;元组的内置函数count, index<br>index和count与字符串和列表中的用法相同</p></blockquote><pre class="language-none"><code class="language-none">&gt;&gt;&gt; a = ('a', 'b', 'c', 'a', 'b')&gt;&gt;&gt; a.index('a', 1, 3) # 注意是左闭右开区间Traceback (most recent call last):  File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: tuple.index(x): x not in tuple&gt;&gt;&gt; a.index('a', 1, 4)3&gt;&gt;&gt; a.count('b')2&gt;&gt;&gt; a.count('d')0</code></pre><h1 id="字典介绍"><a href="#字典介绍" class="headerlink" title="字典介绍"></a>字典介绍</h1><ul><li><p>变量info为字典类型：</p><pre class="language-none"><code class="language-none">info = {'name':'班长', 'id':100, 'sex':'f', 'address':'地球亚洲中国北京'}</code></pre></li><li><p>*说明：**</p><blockquote><p>字典和列表一样，也能够存储多个数据<br>列表中找某个元素时，是根据下标进行的<br>字典中找某个元素时，是根据’名字’（就是冒号:前面的那个值，例如上面代码中的’name’、’id’、’sex’）<br>字典的每个元素由2部分组成，键:值。例如 ‘name’:’班长’ ,’name’为键，’班长’为值</p></blockquote></li><li><p>根据键访问值</p><pre class="language-none"><code class="language-none">info = {'name':'班长', 'id':100, 'sex':'f', 'address':'地球亚洲中国北京'} print(info['name']) print(info['address'])</code></pre><p>若访问不存在的键，则会报错：</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; info['age']Traceback (most recent call last):File "&lt;stdin&gt;", line 1, in &lt;module&gt;KeyError: 'age'</code></pre></li><li><p>*在我们不确定字典中是否存在某个键而又想获取其值时，可以使用get方法，还可以设置默认值：**</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; age = info.get('age')&gt;&gt;&gt; age #'age'键不存在，所以age为None&gt;&gt;&gt; type(age)&lt;type 'NoneType'&gt;&gt;&gt;&gt; age = info.get('age', 18) # 若info中不存在'age'这个键，就返回默认值18&gt;&gt;&gt; age18</code></pre></li></ul><h3 id="字典的常见操作"><a href="#字典的常见操作" class="headerlink" title="字典的常见操作"></a>字典的常见操作</h3><p><strong>&lt;1&gt;修改元素</strong><br>字典的每个元素中的数据是可以修改的，只要通过key找到，即可修改</p><pre class="language-none"><code class="language-none">info = {'name':'班长', 'id':100, 'sex':'f', 'address':'地球亚洲中国北京'}    newId = input('请输入新的学号')    info['id'] = int(newId)    print('修改之后的id为%d:'%info['id'])</code></pre><p><strong>&lt;2&gt;添加元素</strong><br>demo:访问不存在的元素</p><pre class="language-none"><code class="language-none">info = {'name':'班长', 'sex':'f', 'address':'地球亚洲中国北京'}    print('id为:%d'%info['id'])</code></pre><p>结果会报错<br>如果在使用 变量名[‘键’] = 数据 时，这个“键”在字典中，不存在，那么就会新增这个元素</p><p>demo:添加新的元素</p><pre class="language-none"><code class="language-none">info = {'name':'班长', 'sex':'f', 'address':'地球亚洲中国北京'}    # print('id为:%d'%info['id'])#程序会终端运行，因为访问了不存在的键    newId = input('请输入新的学号')    info['id'] = newId    print('添加之后的id为:%d'%info['id'])</code></pre><p><strong>**&lt;3&gt;删除元素</strong></p><p>对字典进行删除操作，有一下几种：</p><blockquote><p>del<br>clear()<br>demo:del删除指定的元素</p></blockquote><pre class="language-none"><code class="language-none">info = {'name':'班长', 'sex':'f', 'address':'地球亚洲中国北京'}   print('删除前,%s'%info['name'])   del info['name']   print('删除后,%s'%info['name'])</code></pre><p>demo:del删除整个字典</p><pre class="language-none"><code class="language-none">info = {'name':'monitor', 'sex':'f', 'address':'China'}   print('删除前,%s'%info)   del info   print('删除后,%s'%info)</code></pre><p>demo:clear清空整个字典</p><pre class="language-none"><code class="language-none">info = {'name':'monitor', 'sex':'f', 'address':'China'}    print('清空前,%s'%info)    info.clear()    print('清空后,%s'%info)</code></pre><h3 id="字典的常见操作2"><a href="#字典的常见操作2" class="headerlink" title="字典的常见操作2"></a>字典的常见操作2</h3><ul><li>&lt;1&gt;len()<br>测量字典中，键值对的个数</li><li>&lt;2&gt;keys<br>返回一个包含字典所有KEY的列表</li><li>&lt;3&gt;values<br>返回一个包含字典所有value的列表</li><li>&lt;4&gt;items<br>返回一个包含所有（键，值）元祖的列表</li><li>&lt;5&gt;has_key<br>dict.has_key(key)如果key在字典中，返回True，否则返回Fals</li></ul><h3 id="字典的遍历"><a href="#字典的遍历" class="headerlink" title="字典的遍历"></a>字典的遍历</h3><p>通过for … in …:的语法结构，我们可以遍历字符串、列表、元组、字典等数据结构。</p><p><strong>注意python语法的缩进</strong></p><h4 id="字符串遍历"><a href="#字符串遍历" class="headerlink" title="字符串遍历"></a>字符串遍历</h4><pre class="language-none"><code class="language-none">&gt;&gt;&gt; a_str = "hello itcast"&gt;&gt;&gt; for char in a_str:...     print(char,end=' ')...h e l l o   i t c a s t</code></pre><h4 id="列表遍历"><a href="#列表遍历" class="headerlink" title="列表遍历"></a>列表遍历</h4><pre class="language-none"><code class="language-none">&gt;&gt;&gt; a_list = [1, 2, 3, 4, 5]&gt;&gt;&gt; for num in a_list:...     print(num,end=' ')...1 2 3 4 5</code></pre><h4 id="元组遍历"><a href="#元组遍历" class="headerlink" title="元组遍历"></a>元组遍历</h4><pre class="language-none"><code class="language-none">&gt;&gt;&gt; a_turple = (1, 2, 3, 4, 5)&gt;&gt;&gt; for num in a_turple:...     print(num,end=" ")1 2 3 4 5</code></pre><h4 id="字典遍历"><a href="#字典遍历" class="headerlink" title="字典遍历"></a>字典遍历</h4><ul><li>&lt;1&gt; 遍历字典的key（键）</li><li>&lt;2&gt; 遍历字典的value（值）</li><li>&lt;3&gt; 遍历字典的项（元素）</li><li>&lt;4&gt; 遍历字典的key-value（键值对）</li></ul><h4 id="实现带下标索引的遍历"><a href="#实现带下标索引的遍历" class="headerlink" title="实现带下标索引的遍历"></a>实现带下标索引的遍历</h4><p><strong>enumerate()</strong></p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; chars = ['a', 'b', 'c', 'd']&gt;&gt;&gt; for i, chr in enumerate(chars):...     print i, chr...0 a1 b2 c3 d</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python字符串和列表</title>
      <link href="/2017/10/26/python-zi-fu-chuan-he-lie-biao/"/>
      <url>/2017/10/26/python-zi-fu-chuan-he-lie-biao/</url>
      
        <content type="html"><![CDATA[<h1 id="字符串介绍"><a href="#字符串介绍" class="headerlink" title="字符串介绍"></a>字符串介绍</h1><h3 id="python中字符串的格式"><a href="#python中字符串的格式" class="headerlink" title="python中字符串的格式"></a>python中字符串的格式</h3><ul><li>如下定义的变量a，存储的是数字类型的值<pre class="language-none"><code class="language-none">a = 100</code></pre></li><li>如下定义的变量b，存储的是字符串类型的值<pre class="language-none"><code class="language-none">b = "hello itcast.cn" 或者 b = 'hello itcast.cn'</code></pre></li><li><strong>双引号或者单引号中的数据，就是字符串</strong></li></ul><h3 id="字符串输出"><a href="#字符串输出" class="headerlink" title="字符串输出"></a>字符串输出</h3><p>demo</p><pre class="language-none"><code class="language-none">name = 'xiaoming'    position = '讲师'    address = '北京市昌平区建材城西路金燕龙办公楼1层'    print('--------------------------------------------------')    print("姓名：%s"%name)    print("职位：%s"%position)    print("公司地址：%s"%address)    print('--------------------------------------------------')</code></pre><p>结果:</p><pre class="language-none"><code class="language-none">--------------------------------------------------    姓名： xiaoming    职位： 讲师    公司地址： 北京市昌平区建材城西路金燕龙办公楼1层    --------------------------------------------------</code></pre><h3 id="字符串输入"><a href="#字符串输入" class="headerlink" title="字符串输入"></a>字符串输入</h3><p>之前在学习input的时候，通过它能够完成从键盘获取数据，然后保存到指定的变量中；</p><p><strong>注意：input获取的数据，都以字符串的方式进行保存，即使输入的是数字，那么也是以字符串方式保存</strong></p><ul><li><p>demo:</p><pre class="language-none"><code class="language-none">userName = input('请输入用户名:')  print("用户名为：%s"%userName)  password = input('请输入密码:')  print("密码为：%s"%password)</code></pre></li><li><p>结果：（根据输入的不同结果也不同）</p><pre class="language-none"><code class="language-none">请输入用户名:dongGe  用户名为： dongGe  请输入密码:haohaoxuexitiantianxiangshang  密码为： haohaoxuexitiantianxiangshang</code></pre></li></ul><h3 id="下标和切片"><a href="#下标和切片" class="headerlink" title="下标和切片"></a>下标和切片</h3><ul><li><strong>1. 下标索引</strong><br>所谓“下标”，就是编号，就好比超市中的存储柜的编号，通过这个编号就能找到相应的存储空间<br>生活中的 “下标”:<blockquote><p>超市储物柜<br>高铁二等座<br>高铁一等座<br>绿皮车</p></blockquote></li></ul><p>字符串中”下标”的使用:<br><strong>列表与元组支持下标索引好理解，字符串实际上就是字符的数组，所以也支持下标索引。</strong><br>如果想取出部分字符，那么可以通过下标的方法，（注意python中下标从 0 开始）</p><pre class="language-none"><code class="language-none">name = 'abcdef'   print(name[0])   print(name[1])   print(name[2])</code></pre><ul><li><strong>2. 切片</strong><br>切片是指对操作的对象截取其中一部分的操作。字符串、列表、元组都支持切片操作。</li><li>*切片的语法：[起始:结束:步长]**</li></ul><p>注意：选取的区间属于左闭右开型，即从”起始”位开始，到”结束”位的前一位结束（不包含结束位本身)。</p><p>如果取出一部分，则可以在中括号[]中，使用:</p><pre class="language-none"><code class="language-none">name = 'abcdef'     print(name[0:3]) # 取 下标0~2 的字符      name = 'abcdef'     print(name[0:5]) # 取 下标为0~4 的字符     name = 'abcdef'     print(name[3:5]) # 取 下标为3、4 的字符     name = 'abcdef'     print(name[2:]) # 取 下标为2开始到最后的字符     name = 'abcdef'     print(name[1:-1]) # 取 下标为1开始 到 最后第2个  之间的字符</code></pre><p>demo:</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; a = "abcdef"&gt;&gt;&gt; a[:3]'abc'&gt;&gt;&gt; a[::2]'ace'&gt;&gt;&gt; a[5:1:2] ''&gt;&gt;&gt; a[1:5:2]'bd'&gt;&gt;&gt; a[::-2]'fdb' &gt;&gt;&gt; a[5:1:-2]'fd'</code></pre><h3 id="字符串常见操作"><a href="#字符串常见操作" class="headerlink" title="字符串常见操作"></a>字符串常见操作</h3><p>如有字符串mystr = ‘hello world itcast and itcastcpp’，以下是常见的操作</p><ul><li><p><strong>&lt;1&gt;find</strong><br>检测 str 是否包含在 mystr中，如果是返回开始的索引值，否则返回-1</p><pre class="language-none"><code class="language-none">mystr.find(str, start=0, end=len(mystr))</code></pre></li><li><p><strong>&lt;2&gt;index</strong><br>跟find()方法一样，只不过如果str不在 mystr中会报一个异常.</p><pre class="language-none"><code class="language-none">mystr.index(str, start=0, end=len(mystr)) </code></pre></li><li><p><strong>&lt;3&gt;count</strong><br>返回 str在start和end之间 在 mystr里面出现的次数</p><pre class="language-none"><code class="language-none">mystr.count(str, start=0, end=len(mystr))</code></pre></li><li><p><strong>&lt;4&gt;replace</strong><br>把 mystr 中的 str1 替换成 str2,如果 count 指定，则替换不超过 count 次.</p><pre class="language-none"><code class="language-none">mystr.replace(str1, str2,  mystr.count(str1))</code></pre></li><li><p><strong>&lt;5&gt;split</strong><br>以 str 为分隔符切片 mystr，如果 maxsplit有指定值，则仅分隔 maxsplit 个子字符串</p><pre class="language-none"><code class="language-none">mystr.split(str=" ", 2)   </code></pre></li><li><p><strong>&lt;6&gt;capitalize</strong><br>把字符串的第一个字符大写</p><pre class="language-none"><code class="language-none">mystr.capitalize()</code></pre></li><li><p><strong>&lt;7&gt;title</strong><br>把字符串的每个单词首字母大写</p><pre class="language-none"><code class="language-none">    &gt;&gt;&gt; a = "hello itcast"  &gt;&gt;&gt; a.title()'Hello Itcast'</code></pre></li><li><p><strong>&lt;3&gt;count</strong><br>返回 str在start和end之间 在 mystr里面出现的次数</p><pre class="language-none"><code class="language-none">mystr.count(str, start=0, end=len(mystr))</code></pre></li><li><p><strong>&lt;8&gt;startswith</strong><br>检查字符串是否是以 obj 开头, 是则返回 True，否则返回 False</p><pre class="language-none"><code class="language-none">mystr.startswith(obj)</code></pre></li><li><p><strong>&lt;9&gt;endswith</strong><br>检查字符串是否以obj结束，如果是返回True,否则返回 False.</p><pre class="language-none"><code class="language-none">mystr.endswith(obj)</code></pre></li><li><p><strong>&lt;10&gt;lower</strong><br>转换 mystr 中所有大写字符为小写</p><pre class="language-none"><code class="language-none">mystr.lower()        </code></pre></li><li><p><strong>&lt;11&gt;upper</strong><br>转换 mystr 中的小写字母为大写</p><pre class="language-none"><code class="language-none">mystr.upper()   </code></pre></li><li><p><strong>&lt;12&gt;ljust</strong><br>返回一个原字符串左对齐,并使用空格填充至长度 width 的新字符串</p><pre class="language-none"><code class="language-none">mystr.ljust(width) </code></pre></li><li><p><strong>&lt;13&gt;rjust</strong><br>返回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串</p><pre class="language-none"><code class="language-none">mystr.rjust(width)      </code></pre></li><li><p><strong>&lt;10&gt;lower</strong><br>转换 mystr 中所有大写字符为小写</p><pre class="language-none"><code class="language-none">mystr.lower()        </code></pre></li><li><p><strong>&lt;14&gt;center</strong><br>返回一个原字符串居中,并使用空格填充至长度 width 的新字符串</p><pre class="language-none"><code class="language-none">mystr.center(width)        </code></pre></li><li><p><strong>&lt;15&gt;lstrip</strong><br>删除 mystr 左边的空白字符</p><pre class="language-none"><code class="language-none">mystr.lstrip()</code></pre></li><li><p><strong>&lt;16&gt;rstrip</strong><br>删除 mystr 字符串末尾的空白字符</p><pre class="language-none"><code class="language-none">mystr.rstrip()        </code></pre></li><li><p><strong>&lt;17&gt;strip</strong><br>删除mystr字符串两端的空白字符</p><pre class="language-none"><code class="language-none">    &gt;&gt;&gt; a = "\n\t itcast \t\n"  &gt;&gt;&gt; a.strip()'    itcast'   </code></pre></li><li><p><strong>&lt;18&gt;rfind</strong><br>类似于 find()函数，不过是从右边开始查找.</p><pre class="language-none"><code class="language-none">mystr.rfind(str, start=0,end=len(mystr) )     </code></pre></li><li><p><strong>&lt;19&gt;rindex</strong><br>类似于 index()，不过是从右边开始.</p><pre class="language-none"><code class="language-none">mystr.rindex( str, start=0,end=len(mystr))      </code></pre></li></ul><h1 id="列表介绍"><a href="#列表介绍" class="headerlink" title="列表介绍"></a>列表介绍</h1><h3 id="lt-1-gt-列表的格式"><a href="#lt-1-gt-列表的格式" class="headerlink" title="<1>列表的格式"></a>&lt;1&gt;列表的格式</h3><p>变量A的类型为列表</p><pre class="language-none"><code class="language-none">namesList = ['xiaoWang','xiaoZhang','xiaoHua']</code></pre><p><strong>比C语言的数组强大的地方在于列表中的元素可以是不同类型的</strong></p><pre class="language-none"><code class="language-none">testList = [1, 'a']</code></pre><h3 id="lt-2-gt-打印列表"><a href="#lt-2-gt-打印列表" class="headerlink" title="<2>打印列表"></a>&lt;2&gt;打印列表</h3><p>demo:</p><pre class="language-none"><code class="language-none">namesList = ['xiaoWang','xiaoZhang','xiaoHua']    print(namesList[0])    print(namesList[1])    print(namesList[2])</code></pre><p>结果：</p><pre class="language-none"><code class="language-none">xiaoWang    xiaoZhang    xiaoHua</code></pre><h3 id="列表的循环遍历"><a href="#列表的循环遍历" class="headerlink" title="列表的循环遍历"></a>列表的循环遍历</h3><ul><li><ol><li>使用for循环<br>为了更有效率的输出列表的每个数据，可以使用循环来完成<pre class="language-none"><code class="language-none">namesList = ['xiaoWang','xiaoZhang','xiaoHua']for name in namesList:   print(name)</code></pre></li></ol></li></ul><pre class="language-none"><code class="language-none">xiaoWang    xiaoZhang    xiaoHua</code></pre><ul><li><ol start="2"><li><p>使用while循环<br>为了更有效率的输出列表的每个数据，可以使用循环来完成</p><pre class="language-none"><code class="language-none">namesList = ['xiaoWang','xiaoZhang','xiaoHua']length = len(namesList)i = 0while i&lt;length:   print(namesList[i])   i+=1   </code></pre></li></ol></li></ul><pre class="language-none"><code class="language-none">xiaoWang    xiaoZhang    xiaoHua</code></pre><h3 id="列表的相关操作"><a href="#列表的相关操作" class="headerlink" title="列表的相关操作"></a>列表的相关操作</h3><h4 id="lt-1-gt-添加元素-“增”append-extend-insert"><a href="#lt-1-gt-添加元素-“增”append-extend-insert" class="headerlink" title="<1>添加元素(“增”append, extend, insert)"></a>&lt;1&gt;添加元素(“增”append, extend, insert)</h4><ul><li><p><strong>append</strong><br>通过append可以向列表添加元素</p><pre class="language-none"><code class="language-none">#定义变量A，默认有3个元素  A = ['xiaoWang','xiaoZhang','xiaoHua']  print("-----添加之前，列表A的数据-----")  for tempName in A:      print(tempName)  #提示、并添加元素  temp = input('请输入要添加的学生姓名:')  A.append(temp)  print("-----添加之后，列表A的数据-----")  for tempName in A:      print(tempName)</code></pre></li><li><p><strong>extend</strong><br>通过extend可以将另一个集合中的元素逐一添加到列表中</p><pre class="language-none"><code class="language-none">&gt;&gt;&gt; a = [1, 2]&gt;&gt;&gt; b = [3, 4]&gt;&gt;&gt; a.append(b)&gt;&gt;&gt; a[1, 2, [3, 4]]&gt;&gt;&gt; a.extend(b)&gt;&gt;&gt; a[1, 2, [3, 4], 3, 4]</code></pre></li></ul><ul><li>** insert**<br>insert(index, object) 在指定位置index前插入元素object<pre class="language-none"><code class="language-none">&gt;&gt;&gt; a = [0, 1, 2]&gt;&gt;&gt; a.insert(1, 3)&gt;&gt;&gt; a[0, 3, 1, 2]</code></pre></li></ul><h4 id="lt-2-gt-修改元素-“改”"><a href="#lt-2-gt-修改元素-“改”" class="headerlink" title="<2>修改元素(“改”)"></a>&lt;2&gt;修改元素(“改”)</h4><p>修改元素的时候，要通过下标来确定要修改的是哪个元素，然后才能进行修改</p><pre class="language-none"><code class="language-none">#定义变量A，默认有3个元素    A = ['xiaoWang','xiaoZhang','xiaoHua']    print("-----修改之前，列表A的数据-----")    for tempName in A:        print(tempName)    #修改元素    A[1] = 'xiaoLu'    print("-----修改之后，列表A的数据-----")    for tempName in A:        print(tempName)</code></pre><h4 id="lt-3-gt-查找元素-“查”in-not-in-index-count"><a href="#lt-3-gt-查找元素-“查”in-not-in-index-count" class="headerlink" title="<3>查找元素(“查”in, not in, index, count)"></a>&lt;3&gt;查找元素(“查”in, not in, index, count)</h4><p>所谓的查找，就是看看指定的元素是否存在</p><ul><li><strong>in, not in</strong><br>python中查找的常用方法为：</li></ul><ul><li>in（存在）,如果存在那么结果为true，否则为false</li><li>not in（不存在），如果不存在那么结果为true，否则false</li></ul><pre class="language-none"><code class="language-none">#待查找的列表    nameList = ['xiaoWang','xiaoZhang','xiaoHua']    #获取用户要查找的名字    findName = input('请输入要查找的姓名:')    #查找是否存在    if findName in nameList:        print('在字典中找到了相同的名字')    else:        print('没有找到')</code></pre><p><strong>说明：</strong><br>in的方法只要会用了，那么not in也是同样的用法，只不过not in判断的是不存在</p><ul><li><strong>index, count</strong><br>index和count与字符串中的用法相同<pre class="language-none"><code class="language-none">&gt;&gt;&gt; a = ['a', 'b', 'c', 'a', 'b']&gt;&gt;&gt; a.index('a', 1, 3) # 注意是左闭右开区间Traceback (most recent call last):File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: 'a' is not in list&gt;&gt;&gt; a.index('a', 1, 4)3&gt;&gt;&gt; a.count('b')2&gt;&gt;&gt; a.count('d')0</code></pre></li></ul><h4 id="lt-4-gt-删除元素-“删”del-pop-remove"><a href="#lt-4-gt-删除元素-“删”del-pop-remove" class="headerlink" title="<4>删除元素(“删”del, pop, remove)"></a>&lt;4&gt;删除元素(“删”del, pop, remove)</h4><p>类比现实生活中，如果某位同学调班了，那么就应该把这个条走后的学生的姓名删除掉；在开发中经常会用到删除这种功能。</p><p>列表元素的常用删除方法有：</p><ul><li>del：根据下标进行删除</li><li>pop：删除最后一个元素</li><li>remove：根据元素的值进行删除</li></ul><p>demo:(del)</p><pre class="language-none"><code class="language-none">movieName = ['加勒比海盗','骇客帝国','第一滴血','指环王','霍比特人','速度与激情']    print('------删除之前------')    for tempName in movieName:        print(tempName)    del movieName[2]    print('------删除之后------')    for tempName in movieName:        print(tempName)</code></pre><p>demo:(pop)</p><pre class="language-none"><code class="language-none">movieName = ['加勒比海盗','骇客帝国','第一滴血','指环王','霍比特人','速度与激情']    print('------删除之前------')    for tempName in movieName:        print(tempName)    movieName.pop()    print('------删除之后------')    for tempName in movieName:        print(tempName)</code></pre><p>demo:(remove)</p><pre class="language-none"><code class="language-none">movieName = ['加勒比海盗','骇客帝国','第一滴血','指环王','霍比特人','速度与激情']    print('------删除之前------')    for tempName in movieName:        print(tempName)    movieName.remove('指环王')    print('------删除之后------')    for tempName in movieName:        print(tempName)</code></pre><h4 id="lt-5-gt-排序-sort-reverse"><a href="#lt-5-gt-排序-sort-reverse" class="headerlink" title="<5>排序(sort, reverse)"></a>&lt;5&gt;排序(sort, reverse)</h4><p>sort方法是将list按特定顺序重新排列，默认为由小到大，参数reverse=True可改为倒序，由大到小。</p><p>reverse方法是将list逆置。</p><pre class="language-none"><code class="language-none">    &gt;&gt;&gt; a = [1, 4, 2, 3]    &gt;&gt;&gt; a    [1, 4, 2, 3]    &gt;&gt;&gt; a.reverse()    &gt;&gt;&gt; a    [3, 2, 4, 1]    &gt;&gt;&gt; a.sort()    &gt;&gt;&gt; a    [1, 2, 3, 4]    &gt;&gt;&gt; a.sort(reverse=True)    &gt;&gt;&gt; a    [4, 3, 2, 1]``` ### 列表的嵌套* 1. 列表嵌套类似while循环的嵌套，列表也是支持嵌套的一个列表中的元素又是一个列表，那么这就是列表的嵌套</code></pre><p>schoolNames = [[‘北京大学’,’清华大学’],<br>                    [‘南开大学’,’天津大学’,’天津师范大学’],<br>                    [‘山东大学’,’中国海洋大学’]]</p><pre class="language-none"><code class="language-none">* 2. 应用一个学校，有3个办公室，现在有8位老师等待工位的分配，请编写程序，完成随机的分配</code></pre><p>#encoding=utf-8</p><p>import random</p><h4 id="定义一个列表用来保存3个办公室"><a href="#定义一个列表用来保存3个办公室" class="headerlink" title="定义一个列表用来保存3个办公室"></a>定义一个列表用来保存3个办公室</h4><p>offices = [[],[],[]]</p><h4 id="定义一个列表用来存储8位老师的名字"><a href="#定义一个列表用来存储8位老师的名字" class="headerlink" title="定义一个列表用来存储8位老师的名字"></a>定义一个列表用来存储8位老师的名字</h4><p>names = [‘A’,’B’,’C’,’D’,’E’,’F’,’G’,’H’]</p><p>i = 0<br>for name in names:<br>    index = random.randint(0,2)<br>    offices[index].append(name)</p><p>i = 1<br>for tempNames in offices:<br>    print(‘办公室%d的人数为:%d’%(i,len(tempNames)))<br>    i+=1<br>    for name in tempNames:<br>        print(“%s”%name,end=’’)<br>    print(“\n”)<br>    print(“-“*20)</p><pre><code></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python判断语句和循环语句以及for循环</title>
      <link href="/2017/10/25/python-pan-duan-yu-ju-he-xun-huan-yu-ju-yi-ji-for-xun-huan/"/>
      <url>/2017/10/25/python-pan-duan-yu-ju-he-xun-huan-yu-ju-yi-ji-for-xun-huan/</url>
      
        <content type="html"><![CDATA[<h1 id="判断语句介绍"><a href="#判断语句介绍" class="headerlink" title="判断语句介绍"></a>判断语句介绍</h1><h3 id="生活中的判断场景"><a href="#生活中的判断场景" class="headerlink" title="生活中的判断场景"></a>生活中的判断场景</h3><blockquote><p>火车站安检<br>上网吧</p></blockquote><h3 id="开发中的判断场景"><a href="#开发中的判断场景" class="headerlink" title="开发中的判断场景"></a>开发中的判断场景</h3><blockquote><p>密码判断<br>重要日期判断,譬如说什么时候发工资，什么时候还贷款</p></blockquote><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><blockquote><p>如果某些条件满足，才能做某件事情，而不满足时不允许做，这就是所谓的判断<br>不仅生活中有，在软件开发中“判断”功能也经常会用到</p></blockquote><h1 id="if判断语句"><a href="#if判断语句" class="headerlink" title="if判断语句"></a>if判断语句</h1><h3 id="if判断语句介绍"><a href="#if判断语句介绍" class="headerlink" title="if判断语句介绍"></a>if判断语句介绍</h3><ul><li><p>if语句是用来进行判断的，其使用格式如下：</p><pre class="language-none"><code class="language-none">if 要判断的条件:      条件成立时，要做的事情</code></pre></li><li><p>demo1:</p><pre class="language-none"><code class="language-none">age = 30  print "------if判断开始------"  if age&gt;=18:      print "我已经成年了"  print "------if判断结束------"</code></pre></li><li><p>运行结果:</p><pre class="language-none"><code class="language-none">------if判断开始------  我已经成年了  ------if判断结束------</code></pre></li><li><p>demo2:</p><pre class="language-none"><code class="language-none">age = 16  print "------if判断开始------"  if age&gt;=18:      print "我已经成年了"  print "------if判断结束------"</code></pre></li><li><p>运行结果:</p><pre class="language-none"><code class="language-none">------if判断开始------  ------if判断结束------</code></pre></li><li><p><strong>总结：</strong></p><blockquote><p>以上2个demo仅仅是age变量的值不一样，结果却不同；能够看得出if判断语句的作用：就是当满足一定条件时才会执行那块代码，否则就不执行那块代码<br><strong>代码的缩进为一个tab键，或者4个空格</strong></p></blockquote></li></ul><h3 id="if-else"><a href="#if-else" class="headerlink" title="if-else"></a>if-else</h3><ul><li><p>if-else的使用格式</p><pre class="language-none"><code class="language-none">if 条件:      满足条件时要做的事情1      满足条件时要做的事情2      满足条件时要做的事情3      ...(省略)...  else:      不满足条件时要做的事情1      不满足条件时要做的事情2      不满足条件时要做的事情3      ...(省略)...</code></pre><h3 id="elif"><a href="#elif" class="headerlink" title="elif"></a>elif</h3></li><li><p>elif的使用格式如下:</p><pre class="language-none"><code class="language-none">if xxx1:      事情1  elif xxx2:      事情2  elif xxx3:      事情3</code></pre></li><li><p><strong>说明:</strong></p><blockquote><p>当xxx1满足时，执行事情1，然后整个if结束<br>当xxx1不满足时，那么判断xxx2，如果xxx2满足，则执行事情2，然后整个if结束<br>当xxx1不满足时，xxx2也不满足，如果xxx3满足，则执行事情3，然后整个if结束</p></blockquote></li><li><p><strong>注意点</strong></p><blockquote><p>可以和else一起使用<br>elif必须和if一起使用，否则出错</p></blockquote></li></ul><h3 id="if嵌套"><a href="#if嵌套" class="headerlink" title="if嵌套"></a>if嵌套</h3><ul><li><p>if嵌套的格式</p><pre class="language-none"><code class="language-none">if 条件1:      满足条件1 做的事情1      满足条件1 做的事情2      ...(省略)...      if 条件2:          满足条件2 做的事情1          满足条件2 做的事情2          ...(省略)...</code></pre></li></ul><p><strong>说明:</strong><br>|  外层的if判断，也可以是if-else<br>| 内层的if判断，也可以是if-else<br>| 根据实际开发的情况，进行选择</p><ul><li><p>if嵌套的应用</p><pre class="language-none"><code class="language-none">chePiao = 1     # 用1代表有车票，0代表没有车票  daoLenght = 9     # 刀子的长度，单位为cm  if chePiao == 1:      print("有车票，可以进站")      if daoLenght &lt; 10:          print("通过安检")          print("终于可以见到Ta了，美滋滋~~~")      else:          print("没有通过安检")          print("刀子的长度超过规定，等待警察处理...")  else:      print("没有车票，不能进站")      print("亲爱的，那就下次见了，一票难求啊~~~~(&gt;_&lt;)~~~~")</code></pre><p>结果1：chePiao = 1;daoLenght = 9</p></li></ul><h1 id="循环介绍"><a href="#循环介绍" class="headerlink" title="循环介绍"></a>循环介绍</h1><h3 id="生活中的循环场景"><a href="#生活中的循环场景" class="headerlink" title="生活中的循环场景"></a>生活中的循环场景</h3><blockquote><p>跑道<br>风扇<br>CF加特林</p></blockquote><h3 id="软件开发中循环的使用场景"><a href="#软件开发中循环的使用场景" class="headerlink" title="软件开发中循环的使用场景"></a>软件开发中循环的使用场景</h3><blockquote><p>跟媳妇承认错误，说一万遍”媳妇儿，我错了”</p></blockquote><pre class="language-none"><code class="language-none">print("媳妇儿，我错了")   print("媳妇儿，我错了")   print("媳妇儿，我错了")   ...(还有99997遍)...</code></pre><blockquote><p>使用循环语句一句话搞定</p></blockquote><pre class="language-none"><code class="language-none">i = 0   while i&lt;10000:       print("媳妇儿，我错了")       i+=1</code></pre><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><blockquote><p>一般情况下，需要多次重复执行的代码，都可以用循环的方式来完成<br>循环不是必须要使用的，但是为了提高代码的重复使用率，所以有经验的开发者都会采用循环</p></blockquote><h3 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h3><ul><li>while循环的格式<pre class="language-none"><code class="language-none">while 条件:     条件满足时，做的事情1     条件满足时，做的事情2     条件满足时，做的事情3     ...(省略)...</code></pre></li><li>demo:<pre class="language-none"><code class="language-none">i = 0 while i&lt;5:     print("当前是第%d次执行循环"%(i+1))     print("i=%d"%i)     i+=1</code></pre></li><li>结果:</li></ul><pre class="language-none"><code class="language-none">当前是第1次执行循环    i=0    当前是第2次执行循环    i=1    当前是第3次执行循环    i=2    当前是第4次执行循环    i=3    当前是第5次执行循环    i=4</code></pre><h3 id="while循环应用"><a href="#while循环应用" class="headerlink" title="while循环应用"></a>while循环应用</h3><blockquote><p><strong>1.计算1~100的累积和（包含1和100）</strong></p></blockquote><pre class="language-none"><code class="language-none">#encoding=utf-8i = 1sum = 0while i&lt;=100:    sum = sum + i    i += 1print("1~100的累积和为:%d"%sum)</code></pre><blockquote><p><strong>2.计算1~100之间偶数的累积和（包含1和100）</strong></p></blockquote><pre class="language-none"><code class="language-none">#encoding=utf-8i = 1sum = 0while i&lt;=100:    if i%2 == 0:        sum = sum + i    i+=1print("1~100的累积和为:%d"%sum)</code></pre><h3 id="while循环嵌套"><a href="#while循环嵌套" class="headerlink" title="while循环嵌套"></a>while循环嵌套</h3><ul><li><p>while嵌套的格式</p><pre class="language-none"><code class="language-none">while 条件1:      条件1满足时，做的事情1      条件1满足时，做的事情2      条件1满足时，做的事情3      ...(省略)...      while 条件2:          条件2满足时，做的事情1          条件2满足时，做的事情2          条件2满足时，做的事情3          ...(省略)...</code></pre></li><li><p>while嵌套应用一</p><pre class="language-none"><code class="language-none">要求：打印如下图形：  *  * *  * * *  * * * *  * * * * *参考代码：  i = 1  while i&lt;=5:      j = 1      while j&lt;=i:          print("* ",end='')          j+=1      print("\n")      i+=1</code></pre></li><li><p>while嵌套应用二：九九乘法表</p><pre class="language-none"><code class="language-none">参考代码：  i = 1  while i&lt;=9:      j=1      while j&lt;=i:          print("%d*%d=%-2d "%(j,i,i*j),end='')          j+=1      print('\n')      i+=1</code></pre></li></ul><h3 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h3><p>像while循环一样，for可以完成循环的功能。</p><p>在Python中 for循环可以遍历任何序列的项目，如一个列表或者一个字符串等。</p><ul><li><p>for循环的格式</p><pre class="language-none"><code class="language-none">for 临时变量 in 列表或者字符串等:      循环满足条件时执行的代码  else:      循环不满足条件时执行的代码</code></pre></li><li><p>demo1</p><pre class="language-none"><code class="language-none">name = 'dongGe'  for x in name:      print(x)</code></pre></li><li><p>demo2</p><pre class="language-none"><code class="language-none">name = ''  for x in name:      print(x)  else:      print("没有数据")</code></pre></li></ul><h3 id="break和continue"><a href="#break和continue" class="headerlink" title="break和continue"></a>break和continue</h3><ul><li><ol><li>break<br>break的作用：用来结束整个循环</li></ol></li><li><ol start="2"><li>continue<br>continue的作用：用来结束本次循环，紧接着执行下一次的循环</li></ol></li><li><ol start="3"><li>注意点</li></ol></li><li>break/continue只能用在循环中，除此以外不能单独使用</li><li>break/continue在嵌套循环中，只对最近的一层循环起作用</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python数据类型转换,比较关系运算符</title>
      <link href="/2017/10/25/python-shu-ju-lei-xing-zhuan-huan-bi-jiao-guan-xi-yun-suan-fu/"/>
      <url>/2017/10/25/python-shu-ju-lei-xing-zhuan-huan-bi-jiao-guan-xi-yun-suan-fu/</url>
      
        <content type="html"><![CDATA[<h1 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h1><h3 id="常用的数据类型转换"><a href="#常用的数据类型转换" class="headerlink" title="常用的数据类型转换"></a>常用的数据类型转换</h3><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>int(x [,base ])</td><td>将x转换为一个整数</td></tr><tr><td>long(x [,base ])</td><td>将x转换为一个长整数</td></tr><tr><td>float(x )</td><td>将x转换到一个浮点数</td></tr><tr><td>complex(real [,imag ])</td><td>创建一个复数</td></tr><tr><td>str(x )</td><td>将对象 x 转换为字符串</td></tr><tr><td>repr(x )</td><td>将对象 x 转换为表达式字符串</td></tr><tr><td>eval(str )</td><td>用来计算在字符串中的有效Python表达式,并返回一个对象</td></tr><tr><td>tuple(s )</td><td>将序列 s 转换为一个元组</td></tr><tr><td>list(s )</td><td>将序列 s 转换为一个列表</td></tr><tr><td>chr(x )</td><td>将一个整数转换为一个字符</td></tr><tr><td>unichr(x )</td><td>将一个整数转换为Unicode字符</td></tr><tr><td>ord(x )</td><td>将一个字符转换为它的整数值</td></tr><tr><td>hex(x )</td><td>将一个整数转换为一个十六进制字符串</td></tr><tr><td>oct(x )</td><td>将一个整数转换为一个八进制字符串</td></tr></tbody></table><p>比如说：</p><pre class="language-none"><code class="language-none">a = '100' # 此时a的类型是一个字符串，里面存放了100这3个字符    b = int(a) # 此时b的类型是整型，里面存放的是数字100    print("a=%d"%b)</code></pre><h1 id="比较-即关系-运算符"><a href="#比较-即关系-运算符" class="headerlink" title="比较(即关系)运算符"></a>比较(即关系)运算符</h1><h3 id="python中的比较运算符如下表"><a href="#python中的比较运算符如下表" class="headerlink" title="python中的比较运算符如下表"></a>python中的比较运算符如下表</h3><table><thead><tr><th>运算符</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>==</td><td>检查两个操作数的值是否相等，如果是则条件变为真。</td><td>如a=3,b=3则（a == b) 为 true.</td></tr><tr><td>!=</td><td>检查两个操作数的值是否相等，如果值不相等，则条件变为真。</td><td>如a=1,b=3则(a != b) 为 true.</td></tr><tr><td>&lt;&gt;</td><td>检查两个操作数的值是否相等，如果值不相等，则条件变为真。</td><td>如a=1,b=3则(a &lt;&gt; b) 为 true。这个类似于 != 运算符</td></tr></tbody></table><blockquote><p>   |  检查左操作数的值是否大于右操作数的值，如果是，则条件成立。    |  如a=7,b=3则(a &gt; b) 为 true.<br>&lt;    |  检查左操作数的值是否小于右操作数的值，如果是，则条件成立。    |  如a=7,b=3则(a &lt; b) 为 false.<br>=    |  检查左操作数的值是否大于或等于右操作数的值，如果是，则条件成立。    |  如a=3,b=3则(a &gt;= b) 为 true.<br>&lt;=    |  检查左操作数的值是否小于或等于右操作数的值，如果是，则条件成立。    |  如a=3,b=3则(a &lt;= b) 为 true.</p></blockquote><h3 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h3><table><thead><tr><th>运算符</th><th>逻辑表达式</th><th>描述</th><th>实例</th></tr></thead><tbody><tr><td>and</td><td>x and y</td><td>布尔”与” - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。</td><td>(a and b) 返回 20。</td></tr><tr><td>or</td><td>x or y</td><td>布尔”或” - 如果 x 是 True，它返回 True，否则它返回 y 的计算值。</td><td>(a or b) 返回 10。</td></tr><tr><td>not</td><td>not x</td><td>布尔”非” - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。</td><td>not(a and b) 返回 False</td></tr></tbody></table><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python安装numpy模块</title>
      <link href="/2017/10/25/python-an-zhuang-numpy-mo-kuai/"/>
      <url>/2017/10/25/python-an-zhuang-numpy-mo-kuai/</url>
      
        <content type="html"><![CDATA[<h1 id="numpy简介"><a href="#numpy简介" class="headerlink" title="numpy简介"></a>numpy简介</h1><h3 id="numpy官网"><a href="#numpy官网" class="headerlink" title="numpy官网"></a><a href="http://www.numpy.org/">numpy官网</a></h3><h4 id="NumPy-is-the-fundamental-package-for-scientific-computing-with-Python-It-contains-among-other-things"><a href="#NumPy-is-the-fundamental-package-for-scientific-computing-with-Python-It-contains-among-other-things" class="headerlink" title="NumPy is the fundamental package for scientific computing with Python. It contains among other things:"></a>NumPy is the fundamental package for scientific computing with Python. It contains among other things:</h4><ul><li>a powerful N-dimensional array object</li><li>sophisticated (broadcasting) functions</li><li>tools for integrating C/C++ and Fortran code</li><li>useful linear algebra, Fourier transform, and random number capabilities</li></ul><p>Besides its obvious scientific uses, NumPy can also be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined. This allows NumPy to seamlessly and speedily integrate with a wide variety of databases.</p><h3 id="numpy是什么"><a href="#numpy是什么" class="headerlink" title="numpy是什么"></a>numpy是什么</h3><ul><li>NumPy：N维数组容器</li><li>NumPy（Numerrical Python 的缩写）是一个开源的Python科学计算库。使用NumPy，就可以很自然的使用数组</li><li>NumPy包含很多实用的数学函数，涵盖线性代数运算、傅立叶变换和随机生成等功能</li><li>Numpy是以矩阵为基础的数学计算模块，纯数学</li><li>NumPy的线性代数模块会调用它，否则NumPy将使用自己实现的库函数。LAPACK是一个著名的数值计算库，最初是用Fortran写成的，Matlab同样也需要调用它</li></ul><h3 id="安装numpy"><a href="#安装numpy" class="headerlink" title="安装numpy"></a>安装numpy</h3><h4 id="NumPy函数库是Python开发环境下的一个独立的模块。"><a href="#NumPy函数库是Python开发环境下的一个独立的模块。" class="headerlink" title="NumPy函数库是Python开发环境下的一个独立的模块。"></a>NumPy函数库是Python开发环境下的一个独立的模块。</h4><p>可以使用两种方式进行安装：</p><ul><li><strong>第一种是采用pip方式</strong>：这种方式下载太慢了，放弃了。</li><li><strong>第二种采用源码安装</strong>：步骤如下：<br>|  1.下载源码包：<br> <a href="https://sourceforge.net/projects/numpy/files/NumPy">wget https://sourceforge.net/projects/numpy/files/NumPy</a>  下载zip和.tar.gz包都可以<br>| 2.解压<br> unzip numpy-1.11.2.zip 或者 tar zxvf numpy-1.11.2.tar.gz -C 指定目录<br>| 3.进入解压目录<br> cd numpy-1.11.2<br>| 4.运行解压目录里的setup.py 文件<br> sudo python setup.py install<br>| 5.测试是否安装成功：<br><img src="/images/20171025/1.png"></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python的输出和输入</title>
      <link href="/2017/10/24/python-de-shu-chu-he-shu-ru/"/>
      <url>/2017/10/24/python-de-shu-chu-he-shu-ru/</url>
      
        <content type="html"><![CDATA[<h1 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h1><h3 id="1-普通的输出"><a href="#1-普通的输出" class="headerlink" title="1.普通的输出"></a>1.普通的输出</h3><ul><li>生活中的“输出”： 看电影</li><li>软件中的“输出”</li><li>python中变量的输出<pre class="language-none"><code class="language-none"># 打印提示  print('hello world')  print('给我的卡---印度语，你好的意思')</code></pre></li></ul><h3 id="2-格式化输出"><a href="#2-格式化输出" class="headerlink" title="2.格式化输出"></a>2.格式化输出</h3><ul><li><p>1.格式化操作的目的: 字符串格式化 ,譬如：</p><pre class="language-none"><code class="language-none">pirnt("我今年10岁")pirnt("我今年11岁")pirnt("我今年12岁")</code></pre><blockquote><p>在输出年龄的时候，用了多次”我今年xx岁”，能否简化一下程序呢？？？<br>答：字符串格式化</p></blockquote></li><li><p>2.什么是格式化<br>看如下代码:</p><pre class="language-none"><code class="language-none">age = 10  print("我今年%d岁"%age)  age += 1  print("我今年%d岁"%age)  age += 1  print("我今年%d岁"%age)</code></pre><p>在程序中，看到了%这样的操作符，这就是Python中格式化输出。</p><pre class="language-none"><code class="language-none">age = 18  name = "xiaohua"  print("我的姓名是%s,年龄是%d"%(name,age))</code></pre></li></ul><h3 id="3-常用的格式符号"><a href="#3-常用的格式符号" class="headerlink" title="3.常用的格式符号"></a>3.常用的格式符号</h3><table><thead><tr><th>格式符号</th><th>转换</th></tr></thead><tbody><tr><td>%c</td><td>字符</td></tr><tr><td>%s</td><td>通过str() 字符串转换来格式化</td></tr><tr><td>%i</td><td>有符号十进制整数</td></tr><tr><td>%d</td><td>有符号十进制整数</td></tr><tr><td>%u</td><td>无符号十进制整数</td></tr><tr><td>%o</td><td>八进制整数</td></tr><tr><td>%x</td><td>十六进制整数（小写字母）</td></tr><tr><td>%X</td><td>十六进制整数（大写字母）</td></tr><tr><td>%e</td><td>索引符号（小写’e’）</td></tr><tr><td>%E</td><td>索引符号（大写“E”）</td></tr><tr><td>%f</td><td>浮点实数</td></tr><tr><td>%g</td><td>％f和％e 的简写</td></tr><tr><td>%G</td><td>％f和％E的简写</td></tr></tbody></table><h3 id="4-换行输出"><a href="#4-换行输出" class="headerlink" title="4.换行输出"></a>4.换行输出</h3><p>在输出的时候，如果有\n那么，此时\n后的内容会在另外一行显示</p><pre class="language-none"><code class="language-none">print("1234567890-------") # 会在一行显示    print("1234567890\n-------") # 一行显示1234567890，另外一行显示-------</code></pre><h3 id="5-练一练"><a href="#5-练一练" class="headerlink" title="5.练一练"></a>5.练一练</h3><p>编写代码完成以下名片的显示</p><pre class="language-none"><code class="language-none">==================================    姓名: hello world    QQ:xxxxxxx    手机号:131xxxxxx    公司地址:北京市xxxx    ==================================</code></pre><h1 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h1><h3 id="1-python2版本中"><a href="#1-python2版本中" class="headerlink" title="1.python2版本中"></a>1.python2版本中</h3><ul><li>1.1 raw_input()<br>在Python中，获取键盘输入的数据的方法是采用 raw_input 函数<br>看如下示例:<pre class="language-none"><code class="language-none">password = raw_input("请输入密码:")  print '您刚刚输入的密码是:', password</code></pre></li><li>*注意:**</li></ul><blockquote><p>raw_input()的小括号中放入的是，提示信息，用来在获取数据之前给用户的一个简单提示<br>raw_input()在从键盘获取了数据以后，会存放到等号右边的变量中<br>raw_input()会把用户输入的任何值都作为字符串来对待</p></blockquote><ul><li>1.2 input()<br>input()函数与raw_input()类似，但其接受的输入必须是表达式。</li></ul><h3 id="2-python3版本中"><a href="#2-python3版本中" class="headerlink" title="2. python3版本中"></a>2. python3版本中</h3><p>没有raw_input()函数，只有input()</p><p>并且 python3中的input与python2中的raw_input()功能一样</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python变量和类型,标示符和关键字</title>
      <link href="/2017/10/24/python-bian-liang-he-lei-xing-biao-shi-fu-he-guan-jian-zi/"/>
      <url>/2017/10/24/python-bian-liang-he-lei-xing-biao-shi-fu-he-guan-jian-zi/</url>
      
        <content type="html"><![CDATA[<h1 id="变量以及类型"><a href="#变量以及类型" class="headerlink" title="变量以及类型"></a>变量以及类型</h1><h3 id="1-变量的定义"><a href="#1-变量的定义" class="headerlink" title="1.变量的定义"></a>1.变量的定义</h3><p>在Python中，存储一个数据，需要一个叫做变量的东西，如下示例:</p><pre class="language-none"><code class="language-none">num1 = 100 #num1就是一个变量，就好一个小菜篮子    num2 = 87  #num2也是一个变量    result = num1 + num2 #把num1和num2这两个"菜篮子"中的数据进行累加，然后放到 result变量中</code></pre><p>说明:</p><blockquote><p>1.所谓变量，可以理解为菜篮子，如果需要存储多个数据，最简单的方式是有多个变量，当然了也可以使用一个<br>2.程序就是用来处理数据的，而变量就是用来存储数据的<br>**?: 想一想：我们应该让变量占用多大的空间，保存什么样的数据？**</p></blockquote><h3 id="2-变量的类型"><a href="#2-变量的类型" class="headerlink" title="2.变量的类型"></a>2.变量的类型</h3><ul><li>程序中: 为了更充分的利用内存空间以及更有效率的管理内存，变量是有不同的类型的，如下所示:<br><img src="/images/20171024/1.png"></li><li>怎样知道一个变量的类型呢？</li></ul><ul><li>在python中，只要定义了一个变量，而且它有数据，那么它的类型就已经确定了，不需要咱们开发者主动的去说明它的类型，系统会自动辨别</li><li>可以使用type(变量的名字)，来查看变量的类型</li></ul><hr><h1 id="标示符和关键字"><a href="#标示符和关键字" class="headerlink" title="标示符和关键字"></a>标示符和关键字</h1><h3 id="1-标示符"><a href="#1-标示符" class="headerlink" title="1.标示符"></a>1.标示符</h3><ul><li>什么是标示符<blockquote><p>开发人员在程序中自定义的一些符号和名称标示符是自己定义的,如变量名 、函数名等</p></blockquote></li></ul><h3 id="2-标示符的规则"><a href="#2-标示符的规则" class="headerlink" title="2.标示符的规则"></a>2.标示符的规则</h3><ul><li>2.1标示符由字母、下划线和数字组成，且数字不能开头</li><li>2.2python中的标识符是区分大小写的</li></ul><h3 id="3命名规则"><a href="#3命名规则" class="headerlink" title="3命名规则"></a>3命名规则</h3><ul><li>3.1见名知意<blockquote><p>起一个有意义的名字，尽量做到看一眼就知道是什么意思(提高代码可 读性) 比如: 名字 就定义为 name , 定义学生 用 student</p></blockquote></li><li>3.2驼峰命名法<blockquote><p> 1）小驼峰式命名法（lower camel case）： 第一个单词以小写字母开始；第二个单词的首字母大写，例如：myName、aDog<br>2)大驼峰式命名法（upper camel case）： 每一个单字的首字母都采用大写字母，例如：FirstName、LastName<br>3)不过在程序员中还有一种命名法比较流行，就是用下划线“_”来连接所有的单词，比如send_buf 一般我喜欢用第三种</p></blockquote></li></ul><h3 id="2-关键字"><a href="#2-关键字" class="headerlink" title="2.关键字"></a>2.关键字</h3><ul><li>2.1什么是关键字<blockquote><p>python一些具有特殊功能的标示符，这就是所谓的关键字<br>关键字，是python已经使用的了，所以不允许开发者自己定义和关键字相同的名字的标示符<br>查看关键字:</p></blockquote><pre class="language-none"><code class="language-none">and     as      assert     break     class      continue    def     del    elif    else    except     exec      finally    for         from    global    if      in      import     is        lambda     not         or      pass    print   raise   return     try       while      with        yield</code></pre><blockquote><p>可以通过以下命令进行查看当前系统中python的关键字</p></blockquote><pre class="language-none"><code class="language-none">import keywordkeyword.kwlist</code></pre><blockquote><p>关键字会在以后慢慢介绍</p></blockquote></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python语法基础</title>
      <link href="/2017/10/24/python-yu-fa-ji-chu/"/>
      <url>/2017/10/24/python-yu-fa-ji-chu/</url>
      
        <content type="html"><![CDATA[<h1 id="认识python"><a href="#认识python" class="headerlink" title="认识python"></a>认识python</h1><h2 id="1-python的发展历史"><a href="#1-python的发展历史" class="headerlink" title="1.python的发展历史"></a>1.python的发展历史</h2><h3 id="1-1简单介绍"><a href="#1-1简单介绍" class="headerlink" title="1.1简单介绍"></a>1.1简单介绍</h3><ul><li><strong>起源</strong>： Python的作者，Guido von Rossum，荷兰人。</li><li><strong>一门语言的诞生</strong>： 1991年，第一个Python编译器诞生。它是用C语言实现的，并能够调用C语言的库文件<br> 从一出生，Python已经具有了 ：类，函数，异常处理，包含表和词典在内的核心数据类型，以及模块为基础的拓展系统</li><li><strong>时势造英雄</strong>： Python有强大的标准库。由于标准库的体系已经稳定，所以Python的生态系统开始拓展到第三方包。这些包，如Django、web.py、     wxpython、numpy、matplotlib、PIL，将Python升级成了物种丰富的热带雨林</li><li><strong>启示录</strong>： Python崇尚优美、清晰、简单，是一个优秀并广泛使用的语言。</li></ul><h3 id="1-2关键点常识"><a href="#1-2关键点常识" class="headerlink" title="1.2关键点常识"></a>1.2关键点常识</h3><ul><li>Python的发音与拼写  Python的意思是蟒蛇，源于作者喜欢的一部电视剧</li><li>Python的作者是Guido van Rossum（龟叔）</li><li>Python是龟叔在1989年圣诞节期间，为了打发无聊的圣诞节而用C编写的一个编程语言，Python正式诞生于1991年</li><li>Python的解释器如今有多个语言实现，我们常用的是CPython（官方版本的C语言实现），其他还有Jython（可以运行在Java平台）、IronPython      （    可以    运行在.NET和Mono平台）、PyPy（Python实现的，支持JIT即时编译）</li><li>Python目前有两个版本，Python2和Python3，最新版分别为2.7.12和3.5.2，现阶段大部分公司用的是Python2</li><li><strong>Life is shot, you need Python. 人生苦短，我用Python。</strong></li></ul><h2 id="2-Python优缺点"><a href="#2-Python优缺点" class="headerlink" title="2.Python优缺点"></a>2.Python优缺点</h2><h3 id="2-1优点"><a href="#2-1优点" class="headerlink" title="2.1优点"></a>2.1优点</h3><ol><li>简单————Python是一种代表简单主义思想的语言</li><li>易学————就如同你即将看到的一样，Python极其容易上手。前面已经提到了，Python有极其简单的语法。</li><li>免费、开源————Python是FLOSS（自由/开放源码软件）之一。</li><li>高层语言————当你用Python语言编写程序的时候，你无需考虑诸如如何管理你的程序使用的内存一类的底层细节</li><li>可移植性————由于它的开源本质，Python已经被移植在许多平台上（经过改动使它能够工作在不同平台上），基本什么系统都支持</li><li>解释性———</li><li>面向对象————Python既支持面向过程的编程也支持面向对象的编程</li><li>可扩展性————如果你需要你的一段关键代码运行得更快或者希望某些算法不公开，你可以把你的部分程序用C或C++编写，然后在你的Python程序中使用它们</li><li>丰富的库————Python标准库确实很庞大。它可以帮助你处理各种工作</li><li>规范的代码————Python采用强制缩进的方式使得代码具有极佳的可读性。<h3 id="2-2缺点"><a href="#2-2缺点" class="headerlink" title="2.2缺点"></a>2.2缺点</h3></li><li>运行速度，有速度要求的话，用C++改写关键部分吧。</li><li>国内市场较小（国内以python来做主要开发的，目前只有一些web2.0公司）。但时间推移，目前很多国内软件公司，尤其是游戏公司，也开始规模使用他</li><li>中文资料匮乏（好的python中文资料屈指可数）。托社区的福，有几本优秀的教材已经被翻译了，但入门级教材多，高级内容还是只能看英语版。</li><li>构架选择太多，另一个侧面说明，python比较优秀，吸引的人才多，项目也多。</li></ol><h2 id="3-Python应用场景"><a href="#3-Python应用场景" class="headerlink" title="3.Python应用场景"></a>3.Python应用场景</h2><ul><li><strong>Web应用开发</strong>: Python经常被用于Web开发。比如，通过mod_wsgi模块，Apache可以运行用Python编写的Web程序。如Django,TurboGears,web2py,Zope等，可以让程序员轻松地开发和管理复杂的Web程序。</li><li><strong>操作系统管理、服务器运维的自动化脚本</strong>: 在很多操作系统里，Python是标准的系统组件,一般说来，Python编写的系统管理脚本在可读性、性能、代码重用度、扩展性几方面都优于普通的shell脚本</li><li><strong>科学计算</strong>:NumPy,SciPy,Matplotlib可以让Python程序员编写科学计算程序。</li><li><strong>桌面软件</strong>:PyQt、PySide、wxPython、PyGTK是Python快速开发桌面应用程序的利器。</li><li><strong>服务器软件（网络软件）</strong>:Python对于各种网络协议的支持很完善，因此经常被用于编写服务器软件、网络爬虫。第三方库Twisted支持异步网络编程和多数标准的网络协议(包含客户端和服务器)，并且提供了多种工具，被广泛用于编写高性能的服务器软件。</li><li><strong>构思实现，产品早期原型和迭代</strong>: YouTube、Google、Yahoo!、NASA都在内部大量地使用Python。</li></ul><hr><h1 id="第一个python程序"><a href="#第一个python程序" class="headerlink" title="第一个python程序"></a>第一个python程序</h1><h3 id="1-编写python程序方法1"><a href="#1-编写python程序方法1" class="headerlink" title="1.编写python程序方法1"></a>1.编写python程序方法1</h3><blockquote><p>1.打开ubuntu终端<br>2.输入python3 ，输入python3表示用的python这门编程语言的第3个版本，如果只输入python的话表示用的是python的第2个版本<br>3.输入以下代码</p></blockquote><pre class="language-none"><code class="language-none">print('hello world')</code></pre><h3 id="2-编写python程序方法2"><a href="#2-编写python程序方法2" class="headerlink" title="2.编写python程序方法2"></a>2.编写python程序方法2</h3><blockquote><p>1.打开编辑软件sublime<br>2.编写如下代码：    print(‘hello world’)<br>3.保存代码<br>4.运行程序  在保存的代码路径下运行python代码，如：Python3 hello.py</p></blockquote><h3 id="3-另外一种运行python的程序的方法"><a href="#3-另外一种运行python的程序的方法" class="headerlink" title="3.另外一种运行python的程序的方法"></a>3.另外一种运行python的程序的方法</h3><blockquote><p>在代码第一行写入执行时的python解释器路径，编辑完后需要对此python文件添加’x’权限<br>添加  #! /usr/bin/python</p></blockquote><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>对于编写python程序，上面有3种方法，那到实际开发中哪一种用的比较多呢？一般是用第2或者第3种，即保存在xxx.py文件中，这样可以直接下一次执行运行；而如果用第一种方法的话，每一次运行程序都需要重新进行输入，费时费力</p><hr><h1 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h1><h3 id="1-注释的作用"><a href="#1-注释的作用" class="headerlink" title="1.注释的作用"></a>1.注释的作用</h3><p>通过用自己熟悉的语言，在程序中对某些代码进行标注说明，这就是注释的作用，能够大大增强程序的可读性</p><h3 id="2-注释的分类"><a href="#2-注释的分类" class="headerlink" title="2.注释的分类"></a>2.注释的分类</h3><ul><li><p>单行注释<br>  以#开头，#右边的所有东西当做说明，而不是真正要执行的程序，起辅助说明作用</p>  <pre class="language-none"><code class="language-none"># 我是注释，可以在里写一些功能说明之类的哦     print('hello world')</code></pre></li><li><p>多行注释</p><pre class="language-none"><code class="language-none">'''  我是多行注释，可以写很多很多行的功能说明        这就是我牛X指出        哈哈哈。。。        '''</code></pre></li></ul><h3 id="3-python程序中，中文支持"><a href="#3-python程序中，中文支持" class="headerlink" title="3.python程序中，中文支持"></a>3.python程序中，中文支持</h3><p>如果直接在程序中用到了中文，比如</p><pre class="language-none"><code class="language-none">print('你好')</code></pre><p>如果直接运行输出，程序会出错</p><p>解决的办法为：在程序的开头写入如下代码，这就是中文注释</p><pre class="language-none"><code class="language-none">#coding=utf-8</code></pre><p>修改之后的程序:</p><pre class="language-none"><code class="language-none">#coding=utf-8 print('你好')</code></pre><p>运行结果:</p><pre class="language-none"><code class="language-none">你好</code></pre><p><strong>注意：</strong></p><p>在python的语法规范中推荐使用的方式：</p><pre class="language-none"><code class="language-none"># -*- coding:utf-8 -*-</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04和centos7安装Solr集群</title>
      <link href="/2017/08/20/ubuntu16.04-he-centos7-an-zhuang-solr-ji-qun/"/>
      <url>/2017/08/20/ubuntu16.04-he-centos7-an-zhuang-solr-ji-qun/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-20-Ubuntu16-04LTS和centos7安装Solr集群"><a href="#2017-08-20-Ubuntu16-04LTS和centos7安装Solr集群" class="headerlink" title="2017-08-20 Ubuntu16.04LTS和centos7安装Solr集群"></a><center>2017-08-20 Ubuntu16.04LTS和centos7安装Solr集群</center></h2><p>1、    Solr单机版安装配置</p><pre><code>下载solrSolr和lucene的版本是同步更新的，最新的版本是5.2.1本课程使用的版本：4.10.3下载地址：http://archive.apache.org/dist/lucene/solr/下载版本：4.10.3Linux下需要下载lucene-4.10.3.tgz，windows下需要下载lucene-4.10.3.zip。第一步：安装tomcat第二步：将以下的war包，拷贝到tomcat的webapps目录下    solr-4.10.3/example/webapps下的war包拷贝第三步：解压缩war包    解压缩之后，将war包删掉第四步：添加solr的扩展服务包    solr-4.10.3/example/lib/ext目录中所有jar包拷贝到tomca7.0-solr/webapps/solr/WEB-INF/lib目录下第五步：添加log4j.properties    将以下目录的文件进行拷贝    solr-4.10.3/example/resource目录拷贝到tomca7.0-solr/webapps/solr/WEB-INF/classes    如果没有此目录的话，需要自己手动创建第六步：在web.xml中指定solrhome的目录    在&lt;env-entry&gt;标签中value的值改/usr/local/solr/solrhome</code></pre><p>2、    Solrcore的安装</p><pre><code>1    Solrcore和solrhome    Solrhome是solr服务运行的主目录，一个solrhome目录里面包含多个solrcore目录，一个solrcore目录里面了一个solr实例运行时所需要的配置文件和数据文件。    每一个solrcore都可以单独对外提供搜索和索引服务。    多个solrcore之间没有关系2    Solrcore的安装    安装solrcore需要先安装solrhome    将以下目录的文件进行拷贝    mkdir /usr/local/solr/solr/home    将solr-4.10.3/example/solr/ 目录中的所有文件 拷贝到/usr/local/solr/solrhome中    这样solrhome和solrcore就安装成功了</code></pre><p>3、    Solr集群的架构</p><pre><code>SolrCloud    需要用到solr+zookeeper</code></pre><p>4、    Zookeeper</p><pre><code>1、集群管理    主从的管理、负载均衡、高可用的管理。集群的入口。Zookeeper必须是集群才能保证高可用。    Zookeeper有选举和投票的机制。集群中至少应该有三个节点。2、配置文件的集中管理    搭建solr集群时，需要把Solr的配置文件上传zookeeper，让zookeeper统一管理。每个节点都到zookeeper上取配置文件。3、分布式锁4、忘了</code></pre><p>5、    集群需要的服务器</p><pre><code>Zookeeper：3台Solr：4台伪分布式，zookeeper三个实例、tomcat（solr）需要四个实例。Zookeeper需要安装jdk</code></pre><p>6、    集群搭建步骤</p><pre><code>第一部分：Zookeeper集群搭建    第一步：需要把zookeeper的安装包上传到服务器    第二步：把zookeeper解压    第三步：把zookeeper向/usr/local/solr-cloud目录下复制三份    第四步：配置zookeeper。        1、在zookeeper01目录下创建一个data文件夹        2、在data目录下创建一个myid的文件        3、Myid的内容为1（02对应“2”，03对应“3”）        4、Zookeeper02、03以此类推。        5、进入conf文件，把zoo_sample.cfg文件改名为zoo.cfg        6、修改zoo.cfg，把dataDir=属性指定为刚创建的data文件夹        7、修改zoo.cfg，把clientPort指定为不冲突的端口号（01:2181、02:2182、03:2183）        8、在zoo.cfg中最后一行添加如下内容：  自己主机的IP地址            server.1=192.168.25.154:2881:3881            server.2=192.168.25.154:2882:3882            server.3=192.168.25.154:2883:3883            修改如下内容：            dataDir=/usr/local/solr-could/zookeeper01/data/            clientport=2181    第四步：启动zookeeper。        Zookeeper的目录下有一个bin目录。使用zkServer.sh启动zookeeper服务。        启动：./zkServer.sh start        关闭：./zkServer.sh stop        查看服务状态：./zkServer.sh status第二部分：搭建solr集群    第一步：安装四个tomcat，修改其端口号不能冲突。8080~8083    第二步：向tomcat下部署solr。把单机版的solr工程复制到tomcat下即可。    第三步：为每个solr实例创建一solrhome    第四步：为每个solr实例关联对应的solrhome。修改web.xml    第五步：修改每个solrhome下的solr.xml文件。修改host、hostPort两个属性。分别是对应的ip及端口号            ${host:主机的主机IP}            ${jetty:port:8080}    第六步：把配置文件上传到zookeeper。需要使用        /root/solr-4.10.3/example/scripts/cloud-scripts/zkcli.sh命令上传配置文件。        把/usr/local/solr-cloud/solrhome01/collection1/conf目录上传到zookeeper。        需要zookeeper集群已经启动。        ./zkcli.sh -zkhost 192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183 -cmd upconfig -confdir /usr/local/solr-cloud/solrhome01/collection1/conf -confname myconf    第七步：查看是否上传成功。        使用zookeeper的zkCli.sh命令    第八步：告诉solr实例zookeeper的位置。需要修改tomcat的catalina.sh添加        JAVA_OPTS="-DzkHost=192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183"        每个节点都需要添加。    第九步：启动每个solr实例    第十步：集群分片。        将集群分为两片，每片两个副本。        http://192.168.25.154:8080/solr/admin/collections?action=CREATE&amp;name=collection2&amp;numShards=2&amp;replicationFactor=2    第十一步：删除不用collection1        http://192.168.25.154:8080/solr/admin/collections?action=DELETE&amp;name=collection1</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> mysql </tag>
            
            <tag> jdk8 </tag>
            
            <tag> solr </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04和centos7安装redis集群</title>
      <link href="/2017/08/20/ubuntu16.04-he-centos7-an-zhuang-redis-ji-qun/"/>
      <url>/2017/08/20/ubuntu16.04-he-centos7-an-zhuang-redis-ji-qun/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-20-Ubuntu16-04LTS和centos7安装redis集群"><a href="#2017-08-20-Ubuntu16-04LTS和centos7安装redis集群" class="headerlink" title="2017-08-20 Ubuntu16.04LTS和centos7安装redis集群"></a><center>2017-08-20 Ubuntu16.04LTS和centos7安装redis集群</center></h2><p>1、    Redis 的单机版</p><pre><code>1    安装步骤：    第一步：安装gcc编译环境        yum install gcc-c++    第二步：把redis的源码上传到linux服务器。    第三步：解压缩。        tar -zxvf redis-3.0.0.tar.gz    第四步：make    第五步：make install PREFIX=/usr/local/redis2      启动redis    两种启动方式，前端启动、后台启动。    前端启动：./redis-server    后台启动：    1、复制redis.conf到redis的安装目录    2、修改redis.conf。修改daemonize yes    3、[root@bogon redis]# ./redis-server redis.conf</code></pre><p>2、    Redis集群、3.2.2    集群搭建</p><pre><code>集群中应该至少有三个节点，每个节点有一备份节点。需要6台服务器。搭建伪分布式，需要6个redis实例。搭建集群的步骤：第一步：创建6个redis实例指定端口从7001到7006  在redis.conf文件中修改第二步：修改redis.conf 打开Cluster-enable yes前面的注释第三步：需要一个ruby脚本。在redis源码文件夹下的src目录下。redis-trib.rb第四步：把redis-trib.rb文件复制到到redis-cluster目录下第五步：执行ruby脚本之前，需要安装ruby环境    1、yum install ruby    2、yum install rubygems    3、安装redis-trib.rb运行依赖的ruby的包、自行下载redis-3.0.0.gem         gem install redis-3.0.0.gem第六步：启动所有的redis实例第七步：使用redis-trib.rb创建集群。        填写自己主机的IP地址    ./redis-trib.rb create --replicas 1 192.168.25.153:7001 192.168.25.153:7002 192.168.25.153:7003 192.168.25.153:7004 192.168.25.153:7005  192.168.25.153:7006使用客户端连接集群： redis01/redis-cli -p 7001 -c</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> ubuntu16.04LTS </tag>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04和centos7安装FastDFS</title>
      <link href="/2017/08/20/ubuntu16.04-he-centos7-an-zhuang-fastdfs/"/>
      <url>/2017/08/20/ubuntu16.04-he-centos7-an-zhuang-fastdfs/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-20-Ubuntu16-04LTS和centos7安装nginx"><a href="#2017-08-20-Ubuntu16-04LTS和centos7安装nginx" class="headerlink" title="2017-08-20 Ubuntu16.04LTS和centos7安装nginx"></a><center>2017-08-20 Ubuntu16.04LTS和centos7安装nginx</center></h2><p>1、什么是nginx</p><pre><code>是一个使用c语言开发的高性能的http服务器及反向代理服务器。Nginx是一款高性能的http 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。由俄罗斯的程序设计师Igor Sysoev所开发，官方测试nginx能够支支撑5万并发链接，并且cpu、内存等资源消耗却非常低，运行非常稳定。</code></pre><p>2、Nginx的应用场景</p><pre><code>1、http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。2、虚拟主机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。3、反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，    需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，    不会因为某台服务器负载高宕机而某台服务器闲置的情况</code></pre><p>3、Nginx的安装</p><pre><code>进入http://nginx.org/en/download.html 下载nginx1.8.0版本（当前最新稳定版本）。下载.tar.gz文件3.1、先安装nginx依赖的包：    nginx是C语言开发，建议在linux上运行，本教程使用Centos6.5作为安装环境。3.1.1、gcc    安装nginx需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc：yum install gcc-c++ 3.1.2、PCRE    PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，    所以需要在linux上安装pcre库。    yum install -y pcre pcre-devel    注：pcre-devel是使用pcre开发的一个二次开发库。nginx也需要此库。3.1.3、zlib    zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。    yum install -y zlib zlib-devel3.1.4、openssl    OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，    并提供丰富的应用程序供测试或其它目的使用。    nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。    yum install -y openssl openssl-devel3.2、安装步骤第一步：把nginx的源码上传到linux系统、使用winscp工具上传第二步：把压缩包解压缩。     mkdir /usr/local/nginx    tar zxvf 压缩包 第三步：进行configure    cd 当前目录中的nignx-1.8目录中、进行编译、直接复制下面代码执行            注意：下边将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录    ./configure \    --prefix=/usr/local/nginx \    --pid-path=/var/run/nginx/nginx.pid \    --lock-path=/var/lock/nginx.lock \    --error-log-path=/var/log/nginx/error.log \    --http-log-path=/var/log/nginx/access.log \    --with-http_gzip_static_module \    --http-client-body-temp-path=/var/temp/nginx/client \    --http-proxy-temp-path=/var/temp/nginx/proxy \    --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \    --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \    --http-scgi-temp-path=/var/temp/nginx/scgi第四步：make第五步：make install</code></pre><p>4、Nginx的启动、停止</p><pre><code>1.启动：进入nginx的sbin目录，./nginx就可以启动。 cd  /usr/local/nginx/sbin   ./nginx2.在浏览器中输入主机地址、如果访问不到，首先查看防火墙是否关闭3.关闭nginx        可以使用kill命令，但是不推荐使用        推荐使用：./nginx -s stop4.刷新配置：./nginx -s reload</code></pre><p>5、Nginx的配置</p><pre><code>在/usr/local/nginx/conf目录下nginx.conf文件是nginx的配置文件。</code></pre><p>6、使用nginx配置虚拟机</p><pre><code>6.1 通过端口区分虚拟机    在nginx.conf文件中添加一个Service节点，修改端口号就可以    server {            listen       81;            server_name  localhost;            #charset koi8-r;            #access_log  logs/host.access.log  main;            location / {                root   html81;                index  index.html index.htm;            }       }6.2    通过域名区分虚拟机    可以通过修改host文件指定域名的ip地址。    Host文件的位置：C:\Windows\System32\drivers\etc    添加一条数据,格式如下：  主机IP地址    test.nginx.com    需要修改nginx.conf配置文件。    server {            listen       80;            server_name  test.nginx.com;            location / {                root   html-test3;                index  index.html index.htm;            }       }    修改配置后需要重新加载配置文件。</code></pre><p>7、反向代理的模拟</p><pre><code>3.2.1    反向代理应该有一个nginx服务器有多个应用服务器（可以是tomcat）可以使用一台虚拟机，安装一个nginx，多个tomcat，来模拟。Nginx的配置文件： upstream tomcats{    server 192.168.25.148:8080;    #为2台Tomcat服务器的IP和端口    server 192.168.25.148:8081;   }   server {        listen       80;        server_name  tomcat.nginx.com;        location / {            proxy_pass   http://tomcats;            index  index.html index.htm;        }   }</code></pre><p>8、负载均衡</p><pre><code>只需要在upstream的server后面添加一个weight即可代表权重。权重越高，分配请求的数量就越多。默认权重是1Nginx的配置文件： upstream tomcats{    server 192.168.25.148:8080   weight=6;        server 192.168.25.148:8081;   }   server {        listen       80;        server_name  tomcat.nginx.com;        location / {            proxy_pass   http://tomcats;            index  index.html index.htm;        }   }</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> ubuntu16.04LTS </tag>
            
            <tag> mysql </tag>
            
            <tag> fastdfs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04和centos7安装nginx</title>
      <link href="/2017/08/20/ubuntu16.04-he-centos7-an-zhuang-nginx/"/>
      <url>/2017/08/20/ubuntu16.04-he-centos7-an-zhuang-nginx/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-20-Ubuntu16-04LTS和centos7安装nginx"><a href="#2017-08-20-Ubuntu16-04LTS和centos7安装nginx" class="headerlink" title="2017-08-20 Ubuntu16.04LTS和centos7安装nginx"></a><center>2017-08-20 Ubuntu16.04LTS和centos7安装nginx</center></h2><p>1、什么是nginx</p><pre><code>是一个使用c语言开发的高性能的http服务器及反向代理服务器。Nginx是一款高性能的http 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。由俄罗斯的程序设计师Igor Sysoev所开发，官方测试nginx能够支支撑5万并发链接，并且cpu、内存等资源消耗却非常低，运行非常稳定。</code></pre><p>2、Nginx的应用场景</p><pre><code>1、http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。2、虚拟主机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。3、反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，    需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，    不会因为某台服务器负载高宕机而某台服务器闲置的情况</code></pre><p>3、Nginx的安装</p><pre><code>进入http://nginx.org/en/download.html 下载nginx1.8.0版本（当前最新稳定版本）。下载.tar.gz文件3.1、先安装nginx依赖的包：    nginx是C语言开发，建议在linux上运行，本教程使用Centos6.5作为安装环境。3.1.1、gcc    安装nginx需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc：yum install gcc-c++ 3.1.2、PCRE    PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，    所以需要在linux上安装pcre库。    yum install -y pcre pcre-devel    注：pcre-devel是使用pcre开发的一个二次开发库。nginx也需要此库。3.1.3、zlib    zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。    yum install -y zlib zlib-devel3.1.4、openssl    OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，    并提供丰富的应用程序供测试或其它目的使用。    nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。    yum install -y openssl openssl-devel3.2、安装步骤第一步：把nginx的源码上传到linux系统、使用winscp工具上传第二步：把压缩包解压缩。     mkdir /usr/local/nginx    tar zxvf 压缩包 第三步：进行configure    cd 当前目录中的nignx-1.8目录中、进行编译、直接复制下面代码执行            注意：下边将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录    ./configure \    --prefix=/usr/local/nginx \    --pid-path=/var/run/nginx/nginx.pid \    --lock-path=/var/lock/nginx.lock \    --error-log-path=/var/log/nginx/error.log \    --http-log-path=/var/log/nginx/access.log \    --with-http_gzip_static_module \    --http-client-body-temp-path=/var/temp/nginx/client \    --http-proxy-temp-path=/var/temp/nginx/proxy \    --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \    --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \    --http-scgi-temp-path=/var/temp/nginx/scgi第四步：make第五步：make install</code></pre><p>4、Nginx的启动、停止</p><pre><code>1.启动：进入nginx的sbin目录，./nginx就可以启动。 cd  /usr/local/nginx/sbin   ./nginx2.在浏览器中输入主机地址、如果访问不到，首先查看防火墙是否关闭3.关闭nginx        可以使用kill命令，但是不推荐使用        推荐使用：./nginx -s stop4.刷新配置：./nginx -s reload</code></pre><p>5、Nginx的配置</p><pre><code>在/usr/local/nginx/conf目录下nginx.conf文件是nginx的配置文件。</code></pre><p>6、使用nginx配置虚拟机</p><pre><code>6.1 通过端口区分虚拟机    在nginx.conf文件中添加一个Service节点，修改端口号就可以    server {            listen       81;            server_name  localhost;            #charset koi8-r;            #access_log  logs/host.access.log  main;            location / {                root   html81;                index  index.html index.htm;            }       }6.2    通过域名区分虚拟机    可以通过修改host文件指定域名的ip地址。    Host文件的位置：C:\Windows\System32\drivers\etc    添加一条数据,格式如下：  主机IP地址    test.nginx.com    需要修改nginx.conf配置文件。    server {            listen       80;            server_name  test.nginx.com;            location / {                root   html-test3;                index  index.html index.htm;            }       }    修改配置后需要重新加载配置文件。</code></pre><p>7、反向代理的模拟</p><pre><code>3.2.1    反向代理应该有一个nginx服务器有多个应用服务器（可以是tomcat）可以使用一台虚拟机，安装一个nginx，多个tomcat，来模拟。Nginx的配置文件： upstream tomcats{    server 192.168.25.148:8080;    #为2台Tomcat服务器的IP和端口    server 192.168.25.148:8081;   }   server {        listen       80;        server_name  tomcat.nginx.com;        location / {            proxy_pass   http://tomcats;            index  index.html index.htm;        }   }</code></pre><p>8、负载均衡</p><pre><code>只需要在upstream的server后面添加一个weight即可代表权重。权重越高，分配请求的数量就越多。默认权重是1Nginx的配置文件： upstream tomcats{    server 192.168.25.148:8080   weight=6;        server 192.168.25.148:8081;   }   server {        listen       80;        server_name  tomcat.nginx.com;        location / {            proxy_pass   http://tomcats;            index  index.html index.htm;        }   }</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> ubuntu16.04LTS </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu16.04用源码包安装MySQL5.7</title>
      <link href="/2017/08/17/ubuntu16.04-yong-yuan-ma-bao-an-zhuang-mysql5.7/"/>
      <url>/2017/08/17/ubuntu16.04-yong-yuan-ma-bao-an-zhuang-mysql5.7/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-17-ubuntu16-04用源码包安装MySQL5-7"><a href="#2017-08-17-ubuntu16-04用源码包安装MySQL5-7" class="headerlink" title="2017-08-17 ubuntu16.04用源码包安装MySQL5.7"></a><center>2017-08-17 ubuntu16.04用源码包安装MySQL5.7</center></h2><p>1、使用apt-get全自动安装</p><pre><code>安装命令apt-get install mysql-server# 安装过程中需要输入mysql的root密码</code></pre><p>2、使用dpkg手动安装依赖包</p><pre><code>1.下载安装包# 我测试过程中下载的是：mysql-server_5.7.16-1ubuntu16.04_amd64.deb-bundle.tar# 国内镜像站：http://mirrors.sohu.com/mysql/MySQL-5.7/wget http://mirrors.sohu.com/mysql/MySQL-5.7/mysql-server_5.7.16-1ubuntu16.04_amd64.deb-bundle.tar2.解压安装包tar -xvf ../mysql-server_5.7.16-1ubuntu16.04_amd64.deb-bundle.tar -C ./# 解压后将出现：#  libmysqlclient20_5.7.16-1ubuntu16.04_amd64.deb#  mysql-common_5.7.16-1ubuntu16.04_amd64.deb     #  mysql-community-source_5.7.16-1ubuntu16.04_amd64.deb#  mysql-testsuite_5.7.16-1ubuntu16.04_amd64.deb#  libmysqlclient-dev_5.7.16-1ubuntu16.04_amd64.deb#  mysql-community_5.7.16-1ubuntu16.04_amd64.changes  #  mysql-community-test_5.7.16-1ubuntu16.04_amd64.deb#  libmysqld-dev_5.7.16-1ubuntu16.04_amd64.deb   #  mysql-community-client_5.7.16-1ubuntu16.04_amd64.deb#  mysql-server_5.7.16-1ubuntu16.04_amd64.deb#  mysql-client_5.7.16-1ubuntu16.04_amd64.deb   #  mysql-community-server_5.7.16-1ubuntu16.04_amd64.deb3.使用dpkg安装依赖包dpkg -i mysql-common_5.7.16-1ubuntu16.04_amd64.debdpkg -i libmysqlclient20_5.7.17-1ubuntu16.04_amd64.debdpkg -i libmysqlclient-dev_5.7.17-1ubuntu16.04_amd64.debdpkg -i libmysqld-dev_5.7.17-1ubuntu16.04_amd64.deb# 上面四个包安装应该都没有什么问题，接下来安装的包将会抛出缺少依赖包的错误# 所缺包名当时搞忘了记下来，请仔细看一下错误信息，然后使用apt-get安装一下即可dpkg -i mysql-community-client_5.7.17-1ubuntu16.04_amd64.debdpkg -i mysql-client_5.7.17-1ubuntu16.04_amd64.debdpkg -i mysql-community-source_5.7.17-1ubuntu16.04_amd64.deb# 接下来我们需要安装mysql-community-server包了，安装之前还需要按照一个依赖包：libmecab2apt-get install libmecab2dpkg -i mysql-community-server_5.7.17-1ubuntu16.04_amd64.deb## 安装过程中需要输入mysql的root密码至此，我们已经完成了主程序安装，并可以在本机使用MySQL -u root -p进行登录数据库了。</code></pre><p>3.开放远程访问</p><pre><code>开启root用户的全称访问权限1.修改数据库中user的host# 使用mysql -u root -p登录到数据库，然后依次执行下面语句# xxxxxx表示root用户的密码use mysql;update user set host = '%' where user ='root';grant all privileges on *.* to 'root'@'%' identified by 'xxxxxx';flush privileges;2.修改my.conf的中的ip绑定 # 进入编辑/etc/mysql/mysql.conf.d/mysqld.confvi /etc/mysql/mysql.conf.d/mysqld.conf# 修改ip绑定# 源文件中为：bind-address 127.0.0.1# 将其修改为：bind-address 0.0.0.0# 覆盖保存esc:wq3.重启数据库 # 重启命令service mysql restart</code></pre><p>4.root用户开启远程访问<br>    grant all privileges  on <em>.</em> to root@’%’ identified by “root”;</p><p>5.新增用户并允许远程访问<br>    # 新增用户并允许远程访问只需要在user表中增加一个用户，将host设置为%即可<br>    # 下例默认将所有权限分配给新用户，例如：<br>    grant all privileges on <em>.</em> to ‘lethew’@’%’ identified by ‘abcdef’;<br>    flush privileges;</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> ubuntu16.04LTS </tag>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>centos7用源码包安装MySQL5.7</title>
      <link href="/2017/08/17/centos7-yong-yuan-ma-bao-an-zhuang-mysql5.7/"/>
      <url>/2017/08/17/centos7-yong-yuan-ma-bao-an-zhuang-mysql5.7/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-17-centos7用源码包安装MySQL5-7"><a href="#2017-08-17-centos7用源码包安装MySQL5-7" class="headerlink" title="2017-08-17 centos7用源码包安装MySQL5.7"></a><center>2017-08-17 centos7用源码包安装MySQL5.7</center></h2><p>1、先卸载MySQL5.7，防止重装</p><pre><code>1.yum方式查看安装，查看yum是否安装过mysql    yum list installed mysql*    如或显示了列表，说明系统中有MySQL    yum卸载，根据列表上的名字    yum remove mysql-community-client mysql-community-common mysql-community-libs         mysql-community-libs-compat mysql-community-server mysql57-community-release    rm -rf /var/lib/mysql      rm /etc/my.cnf2.rpm方式查看安装    rpm -qa | grep -i mysql    rpm 卸载        1.        rpm -e mysql57-community-release-el7-9.noarch        rpm -e mysql-community-server-5.7.17-1.el7.x86_64        rpm -e mysql-community-libs-5.7.17-1.el7.x86_64        rpm -e mysql-community-libs-compat-5.7.17-1.el7.x86_64        rpm -e mysql-community-common-5.7.17-1.el7.x86_64        rpm -e mysql-community-client-5.7.17-1.el7.x86_64        cd /var/lib/          rm -rf mysql/        此时可能没有删除干净        2.        whereis mysql        mysql: /usr/bin/mysql /usr/lib64/mysql /usr/local/mysql /usr/share/mysql /usr/share/man/man1/mysql.1.gz        # 删除上面的文件夹        rm -rf /usr/bin/mysql        3、删除配置        rm –rf /usr/my.cnf        rm -rf /root/.mysql_sercret        4.剩余配置检查        chkconfig --list | grep -i mysql        chkconfig --del mysqld        根据上面的列表，删除 ,如：mysqld</code></pre><p>2.安装MySQL5.7</p><pre><code>在此网站https://dev.mysql.com/downloads/repo/yum/ 选择Red Hat Enterprise Linux 7 / Oracle Linux 7 (Architecture Independent), RPM Package 此项下载源码包下载完之后上传到系统，ls 查看 mysql57-community-release-el7-11.noarch.rpm上传成功</code></pre><p>3.解压此RPM包</p><pre><code>sudo rpm -ivh mysql57-community-release-el7-9.noarch.rpm接下来使用yum安装# 更新yum软件包yum check-update  # 更新系统 yum update #安装mysqlyum install mysql mysql-server接下来是漫长的等待。如果中途关机，或者下载挂了，请执行卸载步骤后，再来一次。完成后记住要给root上密码/usr/local/mysql/bin/mysqld_safe --skip-grant-tables --user=mysql &amp;systemctl start mysqldmysql -u rootmysql&gt; update mysql.user set authentication_string=password('new_password') where user='root' and Host ='localhost';mysql&gt; flush privileges;mysql&gt; quit;启动与开放远程访问systemctl start mysqldmysql -u root -p+ 授权远程访问use mysql;grant all privileges  on *.* to root@'%' identified by "root";FLUSH RIVILEGES;建议root不要授权远程访问，请创建新mysql用户</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> mysql </tag>
            
            <tag> jdk8 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu16.04和centos7用源码包安装gradle</title>
      <link href="/2017/08/17/ubuntu16.04-he-centos7-yong-yuan-ma-bao-an-zhuang-gradle/"/>
      <url>/2017/08/17/ubuntu16.04-he-centos7-yong-yuan-ma-bao-an-zhuang-gradle/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-17-ubuntu16-04LTS和centos7-用源码包安装gradle"><a href="#2017-08-17-ubuntu16-04LTS和centos7-用源码包安装gradle" class="headerlink" title="2017-08-17 ubuntu16.04LTS和centos7 用源码包安装gradle"></a><center>2017-08-17 ubuntu16.04LTS和centos7 用源码包安装gradle</center></h2><p>1、下载安装包</p><pre><code>在此网站下https://downloads.gradle.org/distributions/gradle-3.2.1-all.zip也可以使用此命令下载wget https://downloads.gradle.org/distributions/gradle-3.2.1-all.zip</code></pre><p>2、解压安装</p><pre><code>mkdir /usr/local/gradleunzip gradle-3.5-all.zip  -d /usr/local/gradlecd /usr/local/gradlels查看是否解压成功</code></pre><p>3、配置环境变量</p><pre><code>1、centos7下    vi /etc/profile    在最后添加2行        GRADLE_HOME=/usr/local/gradle/gradle-3.5        export PATH=$GRADLE_HOME/bin:$PATH    source /etc/profile2.在ubuntu16.04下    vi /etc/profile  或者 vi ~/.bashrc    在最后添加2行        GRADLE_HOME=/usr/local/gradle/gradle-3.5        export PATH=$GRADLE_HOME/bin:$PATH    source /etc/profile 或者 source ~/.bashrc</code></pre><p>4、检验是否安装成功</p><pre><code>$ gradle -version </code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> ubuntu16.04LTS </tag>
            
            <tag> gradle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu16.04和centos7用源码包安装git</title>
      <link href="/2017/08/16/ubuntu16.04-he-centos7-yong-yuan-ma-bao-an-zhuang-git/"/>
      <url>/2017/08/16/ubuntu16.04-he-centos7-yong-yuan-ma-bao-an-zhuang-git/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-16-ubuntu16-04LTS和centos7-用源码包安装git"><a href="#2017-08-16-ubuntu16-04LTS和centos7-用源码包安装git" class="headerlink" title="2017-08-16 ubuntu16.04LTS和centos7 用源码包安装git"></a><center>2017-08-16 ubuntu16.04LTS和centos7 用源码包安装git</center></h2><p>1.卸载自带的git或者卸载老版本的git</p><pre><code>centos：yum remove gitubuntu：sudo apt-get remove git 使用root权限卸载git，可以保证完全卸载</code></pre><p>2.下载git软件包，在<a href="https://www.kernel.org/pub/software/scm/git/%E8%B7%AF%E5%BE%84%E4%B8%8B%E8%BD%BDgit%E6%BA%90%E7%A0%81%E5%8C%85">https://www.kernel.org/pub/software/scm/git/路径下载git源码包</a></p><pre><code>我下的是git-2.9.5.tar.gz最新版本的</code></pre><p>3.下载到本地、通过工具上传到Linux系统上，我用的是winscp工具，百度就可以下载，当然也可以用wget命令从网上直接下载</p><p>4.在/usr/local/下创建一个目录</p><pre><code>mkdir /usr/local/git</code></pre><p>5.用tar命令解压此文件</p><pre><code>tar zxvf git-2.9.5.tar.gz -C /usr/local/git    -C是指定解压目录</code></pre><p>6.验证是否解压成功、进入到此目录</p><pre><code>cd /usr/local/java ls  只要有git-2.9.5这个目录、说明解压成功</code></pre><p>7.进入此目录</p><pre><code>cd git-2.7.0</code></pre><p>8.编译安装</p><pre><code>8.1 安装插件  yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel 这些插件              yum install gcc perl-ExtUtils-MakeMaker8.2编译安装        make prefix=/usr/local/git all        make prefix=/usr/local/git install</code></pre><p>9.添加环境变量</p><pre><code>9.1在centos中 编辑此文件 vim /etc/profile        在文件最后面添加如下：        export GIT_HOME=/usr/local/git        export PATH=$PATH:$GIT_HOME/bin9.2在ubuntu中 编辑此文件 vim ~/.bashrc，也可以编辑上面那个文件        在文件最后面添加如下：        export GIT_HOME=/usr/local/git        export PATH=$PATH:$GIT_HOME/bin</code></pre><p>10.最后输入此命令</p><pre><code>source /etc/profilesource ~/.bashrc</code></pre><p>11.检查版本</p><pre><code>git --version</code></pre><p>12.执行make prefix=/usr/local/git all时，可能会报错：make: * [git-credential-store] Error 1，此时可以使用以下命令代替</p><pre><code># ./configure --without-iconv# make CFLAGS=-liconv prefix=/usr/local/git all# make CFLAGS=-liconv prefix=/usr/local/git install</code></pre><p>13.初始化git的配置，user.name和user.email,中终端输入如下命令即可设置</p><pre><code>git config --global user.name "Your Name" 名字git config --global user.email "email@example.com" 邮箱然后我们可通过命令 git config --list,查看是否设置成功</code></pre><p>14.查看home目录下是否有.ssh目录，一般情况是没有的，需要我们敲命令生成这个目录，在终端输入</p><pre><code>ssh-keygen -t rsa -C "youremail@example.com"邮箱就是刚刚第二步设置的。然后一路按回车，其实就是不设置密码。然后你就会看到home目录下多了.ssh目录。</code></pre><p>15.进入.ssh目录你会看到两个文件id_rsa和id_rsa.pub,id_rsa是私钥，id_rsa.pub自然就是公钥啦。然后我们需要做的就是把id_rsa.pub文件中的内容拷贝一下。</p><p>16.进入你自己的github，进入Settings-&gt;SSH and GPG keys-&gt;New SSH key,然后在Key那栏下面将第四步拷贝的东西粘贴进去就可以了，最后点击 Add SSH key按钮添加。</p><p>17大功告成，这样你在git push的时候就不需要每次输入用户名和密码了，github作为现在最流行的代码管理工具，对于程序员来说学会使用它还是很有必要的。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> jdk8 </tag>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu16.04用源码包安装jdk8.0</title>
      <link href="/2017/08/16/ubuntu16.04-yong-yuan-ma-bao-an-zhuang-jdk8.0/"/>
      <url>/2017/08/16/ubuntu16.04-yong-yuan-ma-bao-an-zhuang-jdk8.0/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-16-ubuntu16-04LTS-用源码包安装jdk8-0"><a href="#2017-08-16-ubuntu16-04LTS-用源码包安装jdk8-0" class="headerlink" title="2017-08-16 ubuntu16.04LTS 用源码包安装jdk8.0"></a><center>2017-08-16 ubuntu16.04LTS 用源码包安装jdk8.0</center></h2><p>1.安装jdk、在官网下载<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html%E4%B8%8B%E8%BD%BD.tar.gz%E6%96%87%E4%BB%B6">http://www.oracle.com/technetwork/java/javase/downloads/index.html下载.tar.gz文件</a></p><p>2.下载到本地、通过工具上传到ubuntu16.04LTS系统上，我用的是winscp工具，百度就可以下载，当然也可以用wget命令从网上直接下载</p><p>3.在/usr/local/下创建一个目录</p><pre><code>mkdir /usr/local/java</code></pre><p>4.用tar命令解压此文件</p><pre><code>tar zxvf jdk-8u144-linux-x64.tar.gz -C /usr/local/java -C是指定解压目录</code></pre><p>5.验证是否解压成功、进入到此目录</p><pre><code>cd /usr/local/java ls  只要有jdk1.8.0_144这个目录、说明解压成功</code></pre><p>6.配置环境变量</p><pre><code>说明一点：    在ubuntu上、是不允许root用户直接登录的、所以设置环境变量可以在全局变量设置也可以只在当前用户的家目录下设置1.全局变量设置    编辑此文件 vim /etc/profile    在文件最后面添加如下：        export JAVA_HOME=/usr/local/java/jdk1.8.0_144        export PATH=$PATH:$JAVA_HOME/bin2.当前用户变量设置    编辑此文件 vim ~/.bashrc    在文件最后面添加如下：        export JAVA_HOME=/usr/local/java/jdk1.8.0_144        export PATH=$PATH:$JAVA_HOME/bin</code></pre><p>7.最后输入此命令</p><pre><code>source /etc/profilesource ~/.bashrc</code></pre><p>8.检查jdk是否安装成功</p><pre><code>java -version出现以下提示、说明安装成功    java version "1.8.0_144"    Java(TM) SE Runtime Environment (build 1.8.0_144-b01)    Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)</code></pre><p>10.至此已经完成了在ubun16.04上的JDK1.8的安装</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> jdk8 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>centos7用源码包安装jdk8.0</title>
      <link href="/2017/08/16/centos7-yong-yuan-ma-bao-an-zhuang-jdk8.0/"/>
      <url>/2017/08/16/centos7-yong-yuan-ma-bao-an-zhuang-jdk8.0/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-16-centos7-用源码包安装jdk8-0"><a href="#2017-08-16-centos7-用源码包安装jdk8-0" class="headerlink" title="2017-08-16 centos7 用源码包安装jdk8.0"></a><center>2017-08-16 centos7 用源码包安装jdk8.0</center></h2><p>1.新安装的centos7系统会自带openjdk，如不想用自带的，可以用如下方法卸载</p><p>2.查看JDK安装版本</p><pre><code>java -version</code></pre><p>3.查找OpenJDK安装包</p><pre><code>rpm -qa | grep openjdkjava-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64</code></pre><p>4.卸载OpenJDK安装包</p><pre><code>yum -y remove java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64将上面4个包全部删除</code></pre><p>5.查看是否成功删除</p><pre><code>java -version只有出现这个 bash: /usr/bin/java: 没有那个文件或目录 就说明删除成功</code></pre><p>6.安装jdk、在官网下载<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html%E4%B8%8B%E8%BD%BD.tar.gz%E6%96%87%E4%BB%B6">http://www.oracle.com/technetwork/java/javase/downloads/index.html下载.tar.gz文件</a></p><p><img src="/images/20170816/1.png"></p><p><img src="/images/20170816/2.png"></p><pre><code>我下的是这个版本jdk-8u144-linux-x64.tar.gz</code></pre><p>2.下载到本地、通过工具上传到centos7系统上，我用的是winscp工具，百度就可以下载，当然也可以用wget命令从网上直接下载</p><p>3.如下图上传成功,在家目录可以看到此文件</p><p><img src="/images/20170816/3.png"></p><p>4.在/usr/local/下创建一个目录</p><pre><code>mkdir /usr/local/java</code></pre><p>5.用tar命令解压此文件</p><pre><code>tar zxvf jdk-8u144-linux-x64.tar.gz -C /usr/local/java -C是指定解压目录</code></pre><p>6.验证是否解压成功、进入到此目录</p><pre><code>cd /usr/local/java ls  只要有jdk1.8.0_144这个目录、说明解压成功</code></pre><p>7.配置环境变量</p><pre><code>编辑此文件 vim /etc/profile在文件最后面添加如下：    export JAVA_HOME=/usr/local/java/jdk1.8.0_144    export PATH=$PATH:$JAVA_HOME/bin</code></pre><p>8.最后输入此命令</p><pre><code>source /etc/profile</code></pre><p>9.检查jdk是否安装成功</p><pre><code>java -version出现以下提示、说明安装成功java version "1.8.0_144"Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)</code></pre><p>10.至此已经完成了在centos7上的JDK1.8的安装，在centos的5.8、6.8上安装jdk也是如此</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> centos和ubuntu软件包安装 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 </tag>
            
            <tag> jdk8 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 sudo wget</title>
      <link href="/2017/08/16/mei-tian-2-ge-linux-ming-ling-sudo-wget/"/>
      <url>/2017/08/16/mei-tian-2-ge-linux-ming-ling-sudo-wget/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-15-每天2个Linux命令-sudo命令"><a href="#2017-08-15-每天2个Linux命令-sudo命令" class="headerlink" title="2017-08-15 每天2个Linux命令 sudo命令"></a><center>2017-08-15 每天2个Linux命令 sudo命令</center></h2><p>sudo命令用来以其他身份来执行命令，预设的身份为root。</p><p>(1)用法:</p><pre><code>用法:  sudo  [参数]  [命令]</code></pre><p>(2)功能:</p><pre><code>功能:  sudo可以针对单个命令授予临时权限。用户也可以通过su切换到root用户运行命令，su启动一个root shell允许用户运行之后的所有的命令。1)sudo与su的不同之处:sudo仅在需要时授予用户权限，减少了用户因为错误执行命令损坏系统的可能性；sudo也可以用来以其他用户身份执行命令。此外，sudo可以记录用户执行的命令，以及失败的特权获取。2)提醒：在/etc/sudoers中设置了可执行sudo指令的用户。若其未经授权的用户企图使用sudo，则会发出警告的邮件给管理员。用户使用sudo时，必须先输入密码，之后有5分钟的有效期限，超过期限则必须重新输入密码。复制代码[sunmeng@localhost ~]$ yum update mysql　　　　　　　　　　　　　　　　　　　　　　//yum的执行需要root权限已加载插件：fastestmirror, langpacks您需要 root 权限执行此命令。[sunmeng@localhost ~]$ sudo yum update mysql　　　　　　　　　　　　　　　　　　 //默认情况下sudo获得root用户的权限We trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things:    #1) Respect the privacy of others.    #2) Think before you type.    #3) With great power comes great responsibility.[sudo] password for sunmeng: sunmeng 不在 sudoers 文件中。此事将被报告。　　　　　　　　　　　　　　　　　　　　　//此时sunmeng还没有使用sudo的权限</code></pre><p>3)[root@localhost etc]# cat sudoers  查看/etc下的只有root才能打开的文件配置文件sudoers</p><pre><code>复制代码  1 ## Sudoers allows particular users to run various commands as  2 ## the root user, without needing the root password.  3 ## 该文件允许特定用户像root用户一样使用各种各样的命令，而不需要root用户的密码  4 ##  5 ## Examples are provided at the bottom of the file for collections  6 ## of related commands, which can then be delegated out to particular  7 ## users or groups.  8 ## 在文件的底部提供了很多相关命令的示例以供选择，这些示例都可以被特定用户或  9 ## 用户组所使用  10 ## 11 ## This file must be edited with the 'visudo' command. 12 ## 该文件必须使用"visudo"命令编辑 13  14 ## Host Aliases 15 ## Groups of machines. You may prefer to use hostnames (perhaps using  16 ## wildcards for entire domains) or IP addresses instead. 17 ## 对于一组服务器，你可能会更喜欢使用主机名（可能是全域名的通配符） 18 ## 、或IP地址，这时可以配置主机别名 19 # Host_Alias     FILESERVERS = fs1, fs2 20 # Host_Alias     MAILSERVERS = smtp, smtp2 21  22 ## User Aliases 23 ## These aren't often necessary, as you can use regular groups 24 ## (ie, from files, LDAP, NIS, etc) in this file - just use %groupname  25 ## rather than USERALIAS 26 ## 这并不很常用，因为你可以通过使用组来代替一组用户的别名 27 # User_Alias ADMINS = jsmith, mikem 28  29 ## Command Aliases 30 ## These are groups of related commands... 31 ## 指定一系列相互关联的命令（当然可以是一个）的别名，通过赋予该别名sudo权限， 32 ## 可以通过sudo调用所有别名包含的命令，下面是一些示例 33  34 ## Networking 网络操作相关命令别名 35 # Cmnd_Alias NETWORKING = /sbin/route, /sbin/ifconfig, /bin/ping, /sbin/dhclient 36 , /usr/bin/net, /sbin/iptables, /usr/bin/rfcomm, /usr/bin/wvdial, /sbin/iwconfig 37 , /sbin/mii-tool 38  39 ## Installation and management of software 软件安装管理相关命令别名 40 # Cmnd_Alias SOFTWARE = /bin/rpm, /usr/bin/up2date, /usr/bin/yum 41  42 ## Services 服务相关命令别名 43 # Cmnd_Alias SERVICES = /sbin/service, /sbin/chkconfig 44  45 ## Updating the locate database 本地数据库升级命令别名 46 # Cmnd_Alias LOCATE = /usr/bin/updatedb 47  48 ## Storage 磁盘操作相关命令别名 49 # Cmnd_Alias STORAGE = /sbin/fdisk, /sbin/sfdisk, /sbin/parted, /sbin/partprobe 50 , /bin/mount, /bin/umount 51  52 ## Delegating permissions 代理权限相关命令别名 53 # Cmnd_Alias DELEGATING = /usr/sbin/visudo, /bin/chown, /bin/chmod, /bin/chgrp  54  55 ## Processes 进程相关命令别名 56 # Cmnd_Alias PROCESSES = /bin/nice, /bin/kill, /usr/bin/kill, /usr/bin/killall 57  58 ## Drivers 驱动命令别名 59 # Cmnd_Alias DRIVERS = /sbin/modprobe 60  61 # Defaults specification 62  63 # 64 # Disable "ssh hostname sudo &lt;cmd&gt;", because it will show the password in clear.  65 #         You have to run "ssh -t hostname sudo &lt;cmd&gt;". 66 # 一些环境变量的相关配置，具体情况可见man soduers 67 Defaults    requiretty 68 //设为默认的目标用户,69行是系统自带的，是对所有用户的默认，如果设sunmeng为默认目标用户，则语法为:Defaults:foobar runas_default=rene （冒号必不可少） 69 Defaults    env_reset 70 Defaults    env_keep =  "COLORS DISPLAY HOSTNAME HISTSIZE INPUTRC KDEDIR LS_COLORS" 71 Defaults    env_keep += "MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS LC_CTYPE" 72 Defaults    env_keep += "LC_COLLATE LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES" 73 Defaults    env_keep += "LC_MONETARY LC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE" 74 Defaults    env_keep += "LC_TIME LC_ALL LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY" 75  76 Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin 77  78 ## Next comes the main part: which users can run what software on  79 ## which machines (the sudoers file can be shared between multiple 80 ## systems). 81 ## 下面是规则配置：什么用户在哪台服务器上可以执行哪些命令（sudoers文件可以在多个系统上共享） 82 ## Syntax(语法): 83 ## 84 ##     user    MACHINE=COMMANDS 用户 登录的主机=（可以变换的身份） 可以执行的命令 85 ## 86 ## The COMMANDS section may have other options added to it. 87 ## 命令部分可以附带一些其它的选项 88 ## 89 ## Allow root to run any commands anywhere  90 ## 允许root用户执行任意路径下的任意命令 91 root    ALL=(ALL)     ALL 92 //第一个ALL是指网络中的主机，我们后面把它改成了主机名。第二个括号里的ALL是指目标用户，也就是以谁的身份去执行命令。最后一个ALL当然就是指命令名了。 93 ## Allows members of the 'sys' group to run networking, software,  94 ## service management apps and more. 95 ## 允许sys中户组中的用户使用NETWORKING等所有别名中配置的命令 96 # %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE 97 , DRIVERS 98  99 ## Allows people in group wheel to run all commands100 ## 允许wheel用户组中的用户执行所有命令101 %wheel    ALL=(ALL)    ALL102 103 ## Same thing without a password104 ## 允许wheel用户组中的用户在不输入该用户的密码的情况下使用所有命令105 # %wheel    ALL=(ALL)    NOPASSWD: ALL106 107 ## Allows members of the users group to mount and unmount the 108 ## cdrom as root109 ## 允许users用户组中的用户像root用户一样使用mount、unmount、chrom命令110 # %users  ALL=/sbin/mount /mnt/cdrom, /sbin/umount /mnt/cdrom111 112 ## Allows members of the users group to shutdown this system113 ## 允许users用户组中的用户关闭localhost这台服务器114 # %users  localhost=/sbin/shutdown -h now115 116 ## Read drop-in files from /etc/sudoers.d (the # here does not mean a comment)117 ## 读取放置在/etc/sudoers.d/文件夹中的文件（此处的#不意味着这是一个声明）118 #includedir /etc/sudoers.d</code></pre><p>4)给普通用使用sudo命令的授权:</p><pre><code>复制代码visudo后得到的格式为:  账户名                 主机名称=(可切换的身份)              可用的指令  //比如root账户  root                   ALL=(ALL)                                  ALL  对于新增的账户就在下面加上  test                   ALL=(root)                                 ALL  //允许test用sudo命令执行root的所有命令  同理对于组使用者也是一个,但是要加上%  %testgroup   　　　　　 ALL=(root)  　　　　　　　　　　　　　　　　　　 ALL  需要注意的是：每次切换，你都需要密码才可以，使用如下命令可以避免输入密码：  test                   ALL=(root) NOPASSWD: ALL 复制代码复制代码[root@localhost sunmeng]# visudo　　　　　　　　　　　　　　//这里的visudo不需要任何参数，因为它是打开sudoers的专属命令//改过的地方##      user    MACHINE=COMMANDS#### The COMMANDS section may have other options added to it.#### Allow root to run any commands anywhereroot    ALL=(ALL)       ALLsunmeng ALL=(ALL)     ALL</code></pre><p>5)简单的测试:</p><pre><code>复制代码[sunmeng@localhost ~]$ ls　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　//当前身份执行命令Desktop  Documents  Downloads  Music  Pictures  Public  Templates  Videos [sunmeng@localhost ~]$ sudo ls　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　   //利用root身份执行命令Desktop  Documents  Downloads  Music  Pictures    Public    Templates  Videos[sunmeng@localhost ~]$ yum update mysql　　　　　　　　　　　　　　　　　　　　　　　　　　 //当前身份执行命令，提醒需要root身份已加载插件：fastestmirror, langpacks您需要 root 权限执行此命令。[sunmeng@localhost ~]$ sudo yum update mysql　　　　　　　　　　　　　　　　　　　　　　　　//以root身份执行命令（在终端中第一次用这个命令时会提醒输入密码）已加载插件：fastestmirror, langpacksbase                                                     | 3.6 kB     00:00     extras                                                   | 3.4 kB     00:00     updates                                                  | 3.4 kB     00:00     Loading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cnNo packages marked for update</code></pre><p>(3)选项参数:</p><pre><code>  1) -b 　　　　　　在后台运行命令  2) -u user 　　　 以指定用户身份运行命令(或编辑文件)  3) -l　　　　　　  查看当前用户可以执行的命令  4) -v　　　　　　 更新用户的时间戳而不执行命令(注意:在输入密码之后，5分钟内执行sudo不需要再次输入密码。)  5) -V　　　　　　 显示sudo的版本信息  6) -i　　　　　　  以目标用户登录一个shell</code></pre><p>(4)实例:</p><pre><code>  1)[sunmeng@localhost Desktop]$ sudo -u root yum install mysql-devel　　　　　　　　指定用户名复制代码[sunmeng@localhost Desktop]$ sudo -u root yum install mysql-devel　　　　　　　　　　　　　　　　　　-u参数比较有用的地方是在多用户时，可以临时获得权限打开用户独占的文件已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn正在解决依赖关系--&gt; 正在检查事务......--&gt; 解决依赖关系完成依赖关系解决============================================================================================================= Package                        架构              版本                              源                  大小=============================================================================================================正在安装: mariadb-devel                  x86_64            1:5.5.47-1.el7_2                  ......作为依赖被升级:  krb5-libs.x86_64 0:1.13.2-12.el7_2                krb5-workstation.x86_64 0:1.13.2-12.el7_2                 openssl.x86_64 1:1.0.1e-51.el7_2.5                openssl-libs.x86_64 1:1.0.1e-51.el7_2.5                   pcre.x86_64 0:8.32-15.el7_2.1                     zlib.x86_64 0:1.2.7-15.el7                              完毕！</code></pre><p>2)sudo命令与rpm命令结合使用的几个例子</p><pre><code>复制代码[sunmeng@localhost Desktop]$ sudo rpm -q MySQL-embedded-5.5.28-1.linux2.6.i386.rpm[sudo] password for sunmeng: 未安装软件包 MySQL-embedded-5.5.28-1.linux2.6.i386.rpm [sunmeng@localhost Desktop]$ sudo rpm -qpR MySQL-embedded-5.5.28-1.linux2.6.i386.rpmMySQL-devellibaio.so.1libaio.so.1(LIBAIO_0.1)libaio.so.1(LIBAIO_0.4)libc.so.6libc.so.6(GLIBC_2.0)libc.so.6(GLIBC_2.1)libc.so.6(GLIBC_2.1.3)libc.so.6(GLIBC_2.2)libc.so.6(GLIBC_2.3)libc.so.6(GLIBC_2.3.3)libcrypt.so.1libcrypt.so.1(GLIBC_2.0)libdl.so.2libdl.so.2(GLIBC_2.0)libdl.so.2(GLIBC_2.1)libm.so.6libm.so.6(GLIBC_2.0)libm.so.6(GLIBC_2.1)libncurses.so.5libpthread.so.0libpthread.so.0(GLIBC_2.0)libpthread.so.0(GLIBC_2.1)libpthread.so.0(GLIBC_2.2)libpthread.so.0(GLIBC_2.3.2)librt.so.1librt.so.1(GLIBC_2.2)rpmlib(CompressedFileNames) &lt;= 3.0.4-1rpmlib(PayloadFilesHavePrefix) &lt;= 4.0-1</code></pre><p>3)[sunmeng@localhost Desktop]$ sudo -l　　　　　　　　列出用户可以执行的命令</p><pre><code>复制代码[sunmeng@localhost Desktop]$ sudo -l匹配此主机上 sunmeng 的默认条目：    requiretty, !visiblepw, always_set_home, env_reset, env_keep="COLORS DISPLAY HOSTNAME HISTSIZE INPUTRC    KDEDIR LS_COLORS", env_keep+="MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS LC_CTYPE",    env_keep+="LC_COLLATE LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES", env_keep+="LC_MONETARY LC_NAME    LC_NUMERIC LC_PAPER LC_TELEPHONE", env_keep+="LC_TIME LC_ALL LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY",    secure_path=/sbin\:/bin\:/usr/sbin\:/usr/bin用户 sunmeng 可以在该主机上运行以下命令：    (ALL) ALL</code></pre><p>4[root@localhost Desktop]# sudo -i　　　　　　　　　　　以目标身份登录一个shell　　　　　</p><pre><code>[root@localhost Desktop]# sudo -i[root@localhost ~]# sudo -i</code></pre><p>5)[root@localhost ~]# sudo -V　　　　　　　　　　　　　显示详细的sudo的版本信息</p><pre><code>复制代码[root@localhost ~]# sudo -VSudo 版本 1.8.6p7当前选项：--build=x86_64-redhat-linux-gnu --host=x86_64-redhat-linux-gnu --program-prefix= --disable-dependency-tracking --prefix=/usr --exec-prefix=/usr --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --datadir=/usr/share --includedir=/usr/include --libdir=/usr/lib64 --libexecdir=/usr/libexec --localstatedir=/var --sharedstatedir=/var/lib --mandir=/usr/share/man --infodir=/usr/share/info --prefix=/usr --sbindir=/usr/sbin --libdir=/usr/lib64 --docdir=/usr/share/doc/sudo-1.8.6p7 --with-logging=syslog --with-logfac=authpriv --with-pam --with-pam-login --with-editor=/bin/vi --with-env-editor --with-ignore-dot --with-tty-tickets --with-ldap --with-ldap-conf-file=/etc/sudo-ldap.conf --with-selinux --with-passprompt=[sudo] password for %p:  --with-linux-audit --with-sssdSudoers 策略插件版本 1.8.6p7Sudoers 文件语法版本 42Sudoers 路径：/etc/sudoersnsswitch 路径：/etc/nsswitch.confldap.conf 路径：/etc/sudo-ldap.confldap.secret 路径：/etc/ldap.secret认证方法： 'pam'若使用了 syslog，用于记录日志的 syslog 设施：authpriv用户认证成功时使用的 syslog 优先级：notice用户认证不成功时使用的 syslog 优先级：alert忽略 $PATH 中的“.”在用户不在 sudoers 列表中时发送邮件对每个用户/终端组合使用独立的时间戳在用户第一次运行 sudo 时向他致辞默认要求用户认证root 可以运行 sudo总是将 $HOME 设为目标用户的主目录允许收集一些信息，以提供有用的错误消息只允许拥有终端的用户执行 sudoVisudo 将优先考虑 EDITOR 环境变量设置 LOGNAME 和 USER 环境变量日志文件折行的长度(0 则不折行)：80认证时间戳延时：5.0 分钟密码提示延时：5.0 分钟输入密码的尝试次数：3要使用的 umask，或 0777 使用用户的：022邮件程序路径：/usr/sbin/sendmail邮件程序标志：-t发送邮件的地址：root邮件消息的主题行：*** SECURITY information for %h ***密码错误消息：Sorry, try again.认证时间戳文件夹的路径：/var/db/sudo默认密码提示：[sudo] password for %p: 运行命令的默认用户：root覆盖用户的 $PATH 变量的值：/sbin:/bin:/usr/sbin:/usr/binvisudo 所使用的编辑器的路径：/bin/vi何时为“list”伪命令请求密码：any何时为“verify”伪命令请求密码：all&gt;= 3 的文件描述符将会在执行命令前关闭将环境重设为默认的变量集要检查完整性的环境变量：    TERM    LINGUAS    LC_*    LANGUAGE    LANG    COLORTERM要移除的环境变量：    RUBYOPT    RUBYLIB    PYTHONUSERBASE    PYTHONINSPECT    PYTHONPATH    PYTHONHOME    TMPPREFIX    ZDOTDIR    READNULLCMD    NULLCMD    FPATH    PERL5DB    PERL5OPT    PERL5LIB    PERLLIB    PERLIO_DEBUG     JAVA_TOOL_OPTIONS    SHELLOPTS    GLOBIGNORE    PS4    BASH_ENV    ENV    TERMCAP    TERMPATH    TERMINFO_DIRS    TERMINFO    _RLD*    LD_*    PATH_LOCALE    NLSPATH    HOSTALIASES    RES_OPTIONS    LOCALDOMAIN    CDPATH    IFS要保留的环境变量：    XAUTHORITY    _XKB_CHARSET    LINGUAS    LANGUAGE    LC_ALL    LC_TIME    LC_TELEPHONE    LC_PAPER    LC_NUMERIC    LC_NAME    LC_MONETARY    LC_MESSAGES    LC_MEASUREMENT    LC_IDENTIFICATION    LC_COLLATE    LC_CTYPE    LC_ADDRESS    LANG    USERNAME    QTDIR    PS2    PS1    MAIL    LS_COLORS    KDEDIR    INPUTRC    HISTSIZE    HOSTNAME    DISPLAY    COLORS解析 sudoers 时使用的区域设置：C使用 zlib 压缩 I/O 日志用于保存输入/输出日志的目录：/var/log/sudo-io用于保存输入/输出日志的文件：%{seq}在分配伪终端时向 utmp/utmpx 文件中添加一条记录本地 IP 地址和网络掩码对：    192.168.0.15/255.255.255.0    fe80::20c:29ff:fe9f:bf8b/ffff:ffff:ffff:ffff::Sudoers I/O plugin version 1.8.6p7</code></pre><h2 id="2017-08-15-每天2个Linux命令-wget命令"><a href="#2017-08-15-每天2个Linux命令-wget命令" class="headerlink" title="2017-08-15 每天2个Linux命令 wget命令"></a><center>2017-08-15 每天2个Linux命令 wget命令</center></h2><p>wget命令用来从指定的URL下载文件</p><p>(1)用法:</p><pre><code>用法:  wget  [参数]  [URL]</code></pre><p>(2)功能:</p><pre><code>功能:  wget命令用来从指定的URL下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。</code></pre><p>(3)选项参数:</p><pre><code>  1)  -O --output-document=FILE 　　　　　　　　　　　　将文档写入 FILE，等价于给文档指定名称  2) --limit-rate=[n]　　　　　　　　　　　　　　　　　　　限速下载，n为指定下载的速度  3) -c 　　　　　　　　　　　　　　　　　　　　　　　　     支持断点续传  4) -i　　　　　　　　　　　　　　　　　　　　　　　　　　 同时下载多个文件  5) -Q   [n]　　　　　　　　　　　　　　　　　　　　　　　 当下载文件大小超过n时退出下载　　　　　　　　　　　　  6) -o  　　　 　　　　　　　　　　　　　　　　　　　　　  把下载信息存入日志文件　  7) -P　　　　　　　　　　　　　　　　　　　　　　　　　　 指定目录下载  8) --tries=n　　　　　　　　　　　　　　　　　　　　　　  测试下载次数</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost ~]# wget http://files.cnblogs.com/files/MenAngel/GLTools-master.zip　　　直接从网址下载文件复制代码[root@localhost ~]# wget http://files.cnblogs.com/files/MenAngel/GLTools-master.zip--2016-06-23 02:31:01--  http://files.cnblogs.com/files/MenAngel/GLTools-master.zip正在解析主机 files.cnblogs.com (files.cnblogs.com)... 120.26.70.206正在连接 files.cnblogs.com (files.cnblogs.com)|120.26.70.206|:80... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：64789 (63K) [application/x-zip-compressed]正在保存至: “GLTools-master.zip”100%[===================================================================&gt;] 64,789      --.-K/s 用时 0.1s    2016-06-23 02:31:08 (444 KB/s) - 已保存 “GLTools-master.zip” [64789/64789])[root@localhost ~]# find -name "GLTools-master.zip"　　　　　　//查看下载的文件存放的位置　　　　　　./GLTools-master.zip[root@localhost ~]# ls -l　　　　　　　　　　　　　　　　　　　　　//默认存放在当前目录下总用量 68-rw-------. 1 root root  2748 6月  21 11:30 anaconda-ks.cfg-rw-r--r--. 1 root root 64789 6月  22 01:42 GLTools-master.zip</code></pre><p>2)[root@localhost ~]# wget -O GL_O <a href="http://files.cnblogs.com/files/MenAngel/GLTools-master.zip">http://files.cnblogs.com/files/MenAngel/GLTools-master.zip</a>　　为下载的文件指定别名</p><pre><code>复制代码[root@localhost ~]# wget -O GL_O http://files.cnblogs.com/files/MenAngel/GLTools-master.zip--2016-06-23 02:36:33--  http://files.cnblogs.com/files/MenAngel/GLTools-master.zip正在解析主机 files.cnblogs.com (files.cnblogs.com)... 120.26.70.206正在连接 files.cnblogs.com (files.cnblogs.com)|120.26.70.206|:80... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：64789 (63K) [application/x-zip-compressed]正在保存至: “GL_O”100%[===================================================================&gt;] 64,789       364KB/s 用时 0.2s   2016-06-23 02:36:38 (364 KB/s) - 已保存 “GL_O” [64789/64789])[root@localhost ~]# ll总用量 132-rw-------. 1 root root  2748 6月  21 11:30 anaconda-ks.cfg-rw-r--r--. 1 root root 64789 6月  22 01:42 GL_O-rw-r--r--. 1 root root 64789 6月  22 01:42 GLTools-master.zip</code></pre><p>3)[root@localhost ~]# wget –limit-rate=200k <a href="http://files.cnblogs.com/files/MenAngel/GLTools-master.zip">http://files.cnblogs.com/files/MenAngel/GLTools-master.zip</a>　　　　限速下载</p><pre><code>复制代码[root@localhost ~]# wget --limit-rate=200k http://files.cnblogs.com/files/MenAngel/GLTools-master.zip　　　　　　　　//注意速率单位，默认情况下是bit/s--2016-06-23 02:39:34--  http://files.cnblogs.com/files/MenAngel/GLTools-master.zip正在解析主机 files.cnblogs.com (files.cnblogs.com)... 120.26.70.206正在连接 files.cnblogs.com (files.cnblogs.com)|120.26.70.206|:80... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：64789 (63K) [application/x-zip-compressed]正在保存至: “GLTools-master.zip.2”100%[===================================================================&gt;] 64,789      --.-K/s 用时 0.1s    2016-06-23 02:39:40 (435 KB/s) - 已保存 “GLTools-master.zip.2” [64789/64789])</code></pre><p>4)[root@localhost ~]# wget –limit-rate=1k -c <a href="http://files.cnblogs.com/files/MenAngel/GLTools-master.zip">http://files.cnblogs.com/files/MenAngel/GLTools-master.zip</a>　　　　断点续传</p><pre><code>复制代码[root@localhost ~]# wget --limit-rate=1k -c http://files.cnblogs.com/files/MenAngel/GLTools-master.zip--2016-06-23 03:05:43--  http://files.cnblogs.com/files/MenAngel/GLTools-master.zip正在解析主机 files.cnblogs.com (files.cnblogs.com)... 120.26.70.206正在连接 files.cnblogs.com (files.cnblogs.com)|120.26.70.206|:80... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：64789 (63K) [application/x-zip-compressed]正在保存至: “GLTools-master.zip”16% [=========&gt;                                                          ] 10,429      1024B/s 剩余 53s     ^Z[2]+  已停止               wget --limit-rate=1k -c http://files.cnblogs.com/files/MenAngel/GLTools-master.zip[root@localhost ~]# wget --limit-rate=1k -c http://files.cnblogs.com/files/MenAngel/GLTools-master.zip--2016-06-23 03:06:00--  http://files.cnblogs.com/files/MenAngel/GLTools-master.zip正在解析主机 files.cnblogs.com (files.cnblogs.com)... 120.26.70.206正在连接 files.cnblogs.com (files.cnblogs.com)|120.26.70.206|:80... 已连接。已发出 HTTP 请求，正在等待回应... 206 Partial Content长度：64789 (63K)，剩余 54236 (53K) [application/x-zip-compressed]正在保存至: “GLTools-master.zip”17%  [=========&gt;   //直接从先前断的地方开始</code></pre><p>5)[root@localhost ~]# wget -b url　　　　　　　　　在后台下载</p><pre><code>  6)[root@localhost ~]# tail -f wget-log.1　　　　　　查看文件下载的进度（动态的）复制代码[root@localhost ~]# wget -b http://jsdx.down.chinaz.com/201209/MySQL-embedded-5.5.28-1.linux2.6.i386.rpm继续在后台运行，pid 为 50518。将把输出写入至 “wget-log.1”。[root@localhost ~]# tail -f wget-log.1   500K .......... .......... .......... .......... ..........  0%  109K 15m12s   550K .......... .......... .......... .......... ..........  0%  148K 14m29s   600K .......... .......... .......... .......... ..........  1%  137K 13m55s   650K .......... .......... .......... .......... ..........  1%  108K 13m34s   700K .......... .......... .......... .......... ..........  1% 88.4K 13m24s   750K .......... .......... .......... .......... ..........  1%  102K 13m10s   800K .......... .......... .......... .......... ..........  1%  102K 12m57s   850K .......... .......... .......... .......... ..........  1% 81.2K 12m54s   900K .......... .......... .......... .......... ..........  1% 85.3K 12m50s   950K .......... .......... .......... .......... ..........  1% 21.7K 14m28s  1000K .......... .......... .......... .......... ..........  1% 24.1K 15m43s  1050K .......... .......... .......... .......... ..........  1% 80.4K 15m33s  1100K .......... .......... .......... .......... ..........  1% 91.4K 15m20s  1150K .......... .......... .......... .......... ..........  1%  126K 15m0s  1200K .......... .......... .......... .......... ..........  2%  127K 14m42s  1250K .......... .......... .......... .......... ..........  2% 34.4K 15m14s  1300K .......... .....^Z</code></pre><p>7)[root@localhost ~]# wget –spider　　url　　　　　　</p><pre><code>复制代码[root@localhost ~]# wget --spider http://jsdx.down.chinaz.com/201209/MySQL-embedded-5.5.28-1.linux2.6.i386.rpm开启 Spider 模式。检查是否存在远程文件。--2016-06-23 03:20:46--  http://jsdx.down.chinaz.com/201209/MySQL-embedded-5.5.28-1.linux2.6.i386.rpm正在解析主机 jsdx.down.chinaz.com (jsdx.down.chinaz.com)... 182.100.67.10正在连接 jsdx.down.chinaz.com (jsdx.down.chinaz.com)|182.100.67.10|:80... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：61904663 (59M) [audio/x-pn-realaudio-plugin]存在远程文件。复制代码你可以在以下几种情况下使用--spider参数：  定时下载之前进行检查  间隔检测网站是否可用　检查网站页面的死链接</code></pre><p>8)同时下载多个文件</p><pre><code>cat &gt; filelist.txt url1 url2 url3 url4wget -i filelist.txt</code></pre><p>9)[root@localhost ~]# wget -o download.log <a href="ftp://magnet/?xt=urn:btih:211712D">ftp://magnet/?xt=urn:btih:211712D</a>　　　　将下载的输出信息存入日志</p><pre><code>复制代码[root@localhost ~]# wget -o download.log ftp://magnet/?xt=urn:btih:211712D[root@localhost ~]# cat download.log--2016-06-23 03:30:06--  ftp://magnet/?xt=urn:btih:211712D           =&gt; “.listing”正在解析主机 magnet (magnet)... 失败：未知的名称或服务。wget: 无法解析主机地址 “magnet”[root@localhost ~]# </code></pre><p>10)[root@localhost ~]# wegt -P /home/sunmeng <a href="http://files.cnblogs.com/files/MenAngel/GLTools-master.zip">http://files.cnblogs.com/files/MenAngel/GLTools-master.zip</a>　　指定下载目录</p><pre><code>复制代码[root@localhost ~]# wegt -P /home/sunmeng http://files.cnblogs.com/files/MenAngel/GLTools-master.zipbash: wegt: 未找到命令...相似命令是： 'wget'[root@localhost ~]# wget -P /home/sunmeng http://files.cnblogs.com/files/MenAngel/GLTools-master.zip--2016-06-23 03:42:36--  http://files.cnblogs.com/files/MenAngel/GLTools-master.zip正在解析主机 files.cnblogs.com (files.cnblogs.com)... 120.26.70.206正在连接 files.cnblogs.com (files.cnblogs.com)|120.26.70.206|:80... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：64789 (63K) [application/x-zip-compressed]正在保存至: “/home/sunmeng/GLTools-master.zip”100%[======================================&gt;] 64,789      --.-K/s 用时 0.1s    2016-06-23 03:42:42 (456 KB/s) - 已保存 “/home/sunmeng/GLTools-master.zip” [64789/64789])[root@localhost ~]# ls -l /home/sunmeng总用量 64drwxr-xr-x. 2 sunmeng sunmeng     6 6月  23 02:29 Desktopdrwxr-xr-x. 2 sunmeng sunmeng     6 6月  21 03:31 Documentsdrwxr-xr-x. 2 sunmeng sunmeng     6 6月  21 03:31 Downloads-rw-r--r--. 1 root    root    64789 6月  22 01:42 GLTools-master.zipdrwxr-xr-x. 2 sunmeng sunmeng     6 6月  21 03:31 Musicdrwxr-xr-x. 2 sunmeng sunmeng     6 6月  21 03:31 Picturesdrwxr-xr-x. 2 sunmeng sunmeng     6 6月  21 03:31 Publicdrwxr-xr-x. 2 sunmeng sunmeng     6 6月  21 03:31 Templatesdrwxr-xr-x. 2 sunmeng sunmeng     6 6月  21 03:31 Videos</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 yum rpm</title>
      <link href="/2017/08/16/mei-tian-2-ge-linux-ming-ling-yum-rpm/"/>
      <url>/2017/08/16/mei-tian-2-ge-linux-ming-ling-yum-rpm/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-14-每天2个Linux命令-yum命令"><a href="#2017-08-14-每天2个Linux命令-yum命令" class="headerlink" title="2017-08-14 每天2个Linux命令 yum命令"></a><center>2017-08-14 每天2个Linux命令 yum命令</center></h2><p>用于添加/删除/更新RPM包,自动解决包的依赖问题以及系统更新升级。</p><p>(1)用法:</p><pre><code>用法:  yum  [参数] [软件名]</code></pre><p>(2)功能:</p><pre><code>功能:  yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令。简介:  yum命令是在Fedora和RedHat以及SUSE中基于rpm的软件包管理器，它可以使系统管理人员交互和自动化地更细与管理RPM软件包，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。</code></pre><p>(3)选项参数:</p><pre><code>  info,check-update,search,clean  install,remove,update,list  groupinstall,groupremove,groupupdate,grouplist</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# yum check-update | more -15　　　　检查可以更新的软件包复制代码[root@localhost sunjimeng]# yum check-update | more -15已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cnModemManager.x86_64                    1.1.0-8.git20130913.el7         base     ModemManager-glib.x86_64               1.1.0-8.git20130913.el7         base     NetworkManager.x86_64                  1:1.0.6-29.el7_2                updates  NetworkManager-adsl.x86_64             1:1.0.6-29.el7_2                updates  NetworkManager-glib.x86_64             1:1.0.6-29.el7_2                updates  NetworkManager-libnm.x86_64            1:1.0.6-29.el7_2                updates  NetworkManager-libreswan.x86_64        1.0.6-3.el7                     base     NetworkManager-team.x86_64             1:1.0.6-29.el7_2                updates  NetworkManager-tui.x86_64              1:1.0.6-29.el7_2                updates  --More--</code></pre><p>2)[root@localhost sunjimeng]# yum update　　　　　　　　　　　　检查并更新所有软件包，这个命令被用来升级系统</p><pre><code>复制代码[root@localhost sunjimeng]# yum update已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 ModemManager.x86_64.0.1.1.0-6.git20130913.el7 将被 升级---&gt; 软件包 ModemManager.x86_64.0.1.1.0-8.git20130913.el7 将被 更新---&gt; 软件包 ModemManager-glib.x86_64.0.1.1.0-6.git20130913.el7 将被 升级---&gt; 软件包 ModemManager-glib.x86_64.0.1.1.0-8.git20130913.el7 将被 更新......事务概要=====================================================安装   10 软件包 (+48 依赖软件包)升级  697 软件包总计：766 MIs this ok [y/d/N]: nExiting on user command您的事务已保存，请执行： yum load-transaction /tmp/yum_save_tx.2016-06-21.01-02.n0EVjx.yumtx 重新执行该事务</code></pre><p>3)[root@localhost sunjimeng]# yum install yum-fastestmirror　　　自动搜索最快镜像插件并安装</p><pre><code>复制代码[root@localhost sunjimeng]# yum install yum-fastestmirror已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 yum-plugin-fastestmirror.noarch.0.1.1.31-29.el7 将被 升级---&gt; 软件包 yum-plugin-fastestmirror.noarch.0.1.1.31-34.el7 将被 更新--&gt; 解决依赖关系完成依赖关系解决======================================== Package                                   架构                    版本                              源                     大小============================================================正在更新: yum-plugin-fastestmirror                  noarch                  1.1.31-34.el7                     base                   30 k事务概要===========================================升级  1 软件包总计：30 kIs this ok [y/d/N]: yIs this ok [y/d/N]: yDownloading packages:Running transaction checkRunning transaction testTransaction test succeededRunning transaction  正在更新    : yum-plugin-fastestmirror-1.1.31-34.el7.noarch                                                                  清理        : yum-plugin-fastestmirror-1.1.31-29.el7.noarch                                                                  验证中      : yum-plugin-fastestmirror-1.1.31-34.el7.noarch                                                                  验证中      : yum-plugin-fastestmirror-1.1.31-29.el7.noarch                                                                更新完毕:  yum-plugin-fastestmirror.noarch 0:1.1.31-34.el7                                                                                完毕！</code></pre><p>4)[root@localhost sunjimeng]# yum search mysql-server　　　　　　根据名称搜索软件包</p><pre><code>复制代码[root@localhost sunjimeng]# yum list | grep mysql-server[root@localhost sunjimeng]# yum search mysql-server已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn====================================================== 匹配：mysql-server =======================================================akonadi-mysql.x86_64 : Akonadi MySQL backend support[root@localhost sunjimeng]# yum list | grep mysqlakonadi-mysql.x86_64                    1.9.2-4.el7                    base     apr-util-mysql.x86_64                   1.5.2-6.el7                    base     dovecot-mysql.x86_64                    1:2.2.10-5.el7                 base     freeradius-mysql.x86_64                 3.0.4-6.el7                    base     libdbi-dbd-mysql.x86_64                 0.8.3-16.el7                   base     mysql-connector-java.noarch             1:5.1.25-3.el7                 base     mysql-connector-odbc.x86_64             5.2.5-6.el7                    base     pcp-pmda-mysql.x86_64                   3.10.6-2.el7                   base     php-mysql.x86_64                        5.4.16-36.1.el7_2.1            updates  php-mysqlnd.x86_64                      5.4.16-36.1.el7_2.1            updates  qt-mysql.i686                           1:4.8.5-12.el7_2               updates  qt-mysql.x86_64                         1:4.8.5-12.el7_2               updates  redland-mysql.x86_64                    1.0.16-6.el7                   base     rsyslog-mysql.x86_64                    7.4.7-12.el7                   base     [root@localhost sunjimeng]# yum search mysql已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn====================================================== N/S matched: mysql =======================================================MySQL-python.x86_64 : An interface to MySQLakonadi-mysql.x86_64 : Akonadi MySQL backend supportapr-util-mysql.x86_64 : APR utility library MySQL DBD driverdovecot-mysql.x86_64 : MySQL back end for dovecotfreeradius-mysql.x86_64 : MySQL support for freeradiuslibdbi-dbd-mysql.x86_64 : MySQL plugin for libdbimysql-connector-java.noarch : Official JDBC driver for MySQLmysql-connector-odbc.x86_64 : ODBC driver for MySQLpcp-pmda-mysql.x86_64 : Performance Co-Pilot (PCP) metrics for MySQLperl-DBD-MySQL.x86_64 : A MySQL interface for Perlphp-mysql.x86_64 : A module for PHP applications that use MySQL databasesphp-mysqlnd.x86_64 : A module for PHP applications that use MySQL databasesqt-mysql.i686 : MySQL driver for Qt's SQL classesqt-mysql.x86_64 : MySQL driver for Qt's SQL classesqt3-MySQL.i686 : MySQL drivers for Qt 3's SQL classesqt3-MySQL.x86_64 : MySQL drivers for Qt 3's SQL classesredland-mysql.x86_64 : MySQL storage support for Redlandrsyslog-mysql.x86_64 : MySQL support for rsyslogmariadb.x86_64 : A community developed branch of MySQLmariadb-devel.i686 : Files for development of MariaDB/MySQL applicationsmariadb-devel.x86_64 : Files for development of MariaDB/MySQL applicationsmariadb-libs.i686 : The shared libraries required for MariaDB/MySQL clientsmariadb-libs.x86_64 : The shared libraries required for MariaDB/MySQL clients  名称和简介匹配 only，使用“search all”试试。</code></pre><p>5)[root@localhost sunjimeng]# yum install mysql　　　　　　　　安装指定的软件</p><pre><code>复制代码[root@localhost sunjimeng]# yum install mysql已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn软件包 1:mariadb-5.5.47-1.el7_2.x86_64 已安装并且是最新版本无须任何处理[root@localhost sunjimeng]# yum install mysql-devel已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn软件包 1:mariadb-devel-5.5.47-1.el7_2.x86_64 已安装并且是最新版本无须任何处理[root@localhost sunjimeng]# yum install mysql-server已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn没有可用软件包 mysql-server。错误：无须任何处理　　　　　　　　　　　　　　//安装mysql数据库需要三个软件：mysql，mysql-deverl,和mysql-server。</code></pre><p>6)[root@localhost sunjimeng]# yum remove httpd　　　　　　删除指定的软件包</p><pre><code>复制代码[root@localhost sunjimeng]# yum remove httpd已加载插件：fastestmirror, langpacks正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 httpd.x86_64.0.2.4.6-40.el7.centos.1 将被 删除--&gt; 解决依赖关系完成依赖关系解决================================================================================================================================= Package                  架构                      版本                                       源                           大小=================================================================================================================================正在删除: httpd                    x86_64                    2.4.6-40.el7.centos.1                      @updates                    9.4 M事务概要=================================================================================================================================移除  1 软件包安装大小：9.4 M是否继续？[y/N]：yDownloading packages:Running transaction checkRunning transaction testTransaction test succeededRunning transaction  正在删除    : httpd-2.4.6-40.el7.centos.1.x86_64                                                                           1/1   验证中      : httpd-2.4.6-40.el7.centos.1.x86_64                                                                           1/1 删除:  httpd.x86_64 0:2.4.6-40.el7.centos.1                                                                                           完毕！</code></pre><p>7)[root@localhost sunjimeng]# yum -y install httpd　　　　　　　　给指定命令-y参数默认所有的询问都答Y。</p><pre><code>复制代码[root@localhost sunjimeng]# yum -y install httpd已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 httpd.x86_64.0.2.4.6-40.el7.centos.1 将被 安装--&gt; 解决依赖关系完成依赖关系解决================================================================================================================================= Package                  架构                      版本                                        源                          大小=================================================================================================================================正在安装: httpd                    x86_64                    2.4.6-40.el7.centos.1                       updates                    2.7 M事务概要=================================================================================================================================安装  1 软件包总下载量：2.7 M安装大小：9.4 MDownloading packages:httpd-2.4.6-40.el7.centos.1.x86_64.rpm                                                                    | 2.7 MB  00:00:21     Running transaction checkRunning transaction testTransaction test succeededRunning transaction  正在安装    : httpd-2.4.6-40.el7.centos.1.x86_64                                                                           1/1   验证中      : httpd-2.4.6-40.el7.centos.1.x86_64                                                                           1/1 已安装:  httpd.x86_64 0:2.4.6-40.el7.centos.1                                                                                           完毕！</code></pre><p>8)[root@localhost sunjimeng]# yum deplist httpd　　　　　　　　　　获得指定软件包的依赖关系</p><pre><code>复制代码[root@localhost sunjimeng]# yum deplist httpd已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn软件包：httpd.x86_64 2.4.6-40.el7.centos.1   依赖：/bin/sh   provider: bash.x86_64 4.2.46-19.el7   依赖：/etc/mime.types   provider: mailcap.noarch 2.1.41-2.el7   依赖：/usr/sbin/groupadd   provider: shadow-utils.x86_64 2:4.1.5.1-18.el7   依赖：/usr/sbin/useradd   provider: shadow-utils.x86_64 2:4.1.5.1-18.el7   依赖：httpd-tools = 2.4.6-40.el7.centos.1   provider: httpd-tools.x86_64 2.4.6-40.el7.centos.1   依赖：libapr-1.so.0()(64bit)   provider: apr.x86_64 1.4.8-3.el7   依赖：libaprutil-1.so.0()(64bit)   provider: apr-util.x86_64 1.5.2-6.el7   依赖：libc.so.6(GLIBC_2.4)(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libcrypt.so.1()(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libdb-5.3.so()(64bit)   provider: libdb.x86_64 5.3.21-19.el7   依赖：libdl.so.2()(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libexpat.so.1()(64bit)   provider: expat.x86_64 2.1.0-8.el7   依赖：liblua-5.1.so()(64bit)   provider: lua.x86_64 5.1.4-14.el7   依赖：libm.so.6()(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libpcre.so.1()(64bit)   provider: pcre.x86_64 8.32-15.el7_2.1   依赖：libpthread.so.0()(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libpthread.so.0(GLIBC_2.2.5)(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libselinux.so.1()(64bit)   provider: libselinux.x86_64 2.2.2-6.el7   依赖：libsystemd-daemon.so.0()(64bit)   provider: systemd-libs.x86_64 219-19.el7_2.9   依赖：libsystemd-daemon.so.0(LIBSYSTEMD_DAEMON_31)(64bit)   provider: systemd-libs.x86_64 219-19.el7_2.9   依赖：libz.so.1()(64bit)   provider: zlib.x86_64 1.2.7-15.el7   依赖：rtld(GNU_HASH)   provider: glibc.x86_64 2.17-106.el7_2.6   provider: glibc.i686 2.17-106.el7_2.6   依赖：system-logos &gt;= 7.92.1-1   provider: centos-logos.noarch 70.0.6-3.el7.centos   依赖：systemd-units   provider: systemd.x86_64 219-19.el7_2.9</code></pre><p>9)[root@localhost sunjimeng]# yum info httpd　　　　　　　　　　　　查看指定软件包的信息</p><pre><code>复制代码[root@localhost sunjimeng]# yum info httpd已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn已安装的软件包名称    ：httpd架构    ：x86_64版本    ：2.4.6发布    ：40.el7.centos.1大小    ：9.4 M源    ：installed来自源：updates简介    ： Apache HTTP Server网址    ：http://httpd.apache.org/协议    ： ASL 2.0描述    ： The Apache HTTP Server is a powerful, efficient, and extensible         : web server.</code></pre><p>10)[root@localhost sunjimeng]# yum grouplist　　　　　　　　　　<br>    查看系统中已经安装的和可用的软件组，对于可用的软件组，你可以选择安装</p><pre><code>复制代码[root@localhost sunjimeng]# yum grouplist已加载插件：fastestmirror, langpacks没有安装组信息文件Maybe run: yum groups mark convert (see man yum)Loading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cnAvailable environment groups:   最小安装   基础设施服务器   计算节点   文件及打印服务器   基本网页服务器   虚拟化主机   带 GUI 的服务器   GNOME 桌面   KDE Plasma Workspaces   开发及生成工作站可用组：   传统 UNIX 兼容性   兼容性程序库   图形管理工具   安全性工具   开发工具   控制台互联网工具   智能卡支持   科学记数法支持   系统管理   系统管理工具完成</code></pre><p>11)[root@localhost sunjimeng]# yum groupinstall GNOME 桌面　　　　　　安装上一个命令中显示的可用的软件组中的一个软件组</p><pre><code>复制代码[root@localhost sunjimeng]# yum groupinstall GNOME 桌面                  //安装对应的删除和更新分别是groupremove，groupupdate已加载插件：fastestmirror, langpacks没有安装组信息文件Maybe run: yum groups mark convert (see man yum)Loading mirror speeds from cached hostfile * base: mirrors.yun-idc.com * extras: mirrors.yun-idc.com * updates: mirrors.cug.edu.cn正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 NetworkManager-libreswan-gnome.x86_64.0.1.0.6-3.el7 将被 安装......事务概要=================================================================================================================================安装  7 软件包 (+ 24 依赖软件包)升级  3 软件包 (+145 依赖软件包)总计：204 M总下载量：7.7 MIs this ok [y/d/N]: yDownloading packages:......替代:  PackageKit-device-rebind.x86_64 0:0.8.9-11.el7.centos                  adwaita-gtk3-theme.x86_64 0:3.8.4-3.el7                   gnome-settings-daemon-updates.x86_64 0:3.8.6.1-12.el7                  totem-mozplugin.x86_64 1:3.8.2-5.el7                    完毕！</code></pre><ol start="12"><li><p>[root@localhost sunjimeng]# yum clean headers　　　　　　清除命令</p><p>复制代码<br>[root@localhost sunjimeng]# yum clean headers　　　　　　　　　　//清除头文件<br>已加载插件：fastestmirror, langpacks<br>正在清理软件源： base extras updates<br>0 header 文件已移除<br>[root@localhost sunjimeng]# yum clean packages　　　　　　　　　 //清除包文件<br>已加载插件：fastestmirror, langpacks<br>正在清理软件源： base extras updates<br>580 package 文件已移除<br>[root@localhost sunjimeng]# yum clean　　　　　　　　　　　　　　  //必须加上参数<br>已加载插件：fastestmirror, langpacks<br>错误：清理命令需要参数：headers, packages, metadata, dbcache, plugins, expire-cache, rpmdb, all<br>[root@localhost sunjimeng]# yum clean all　　　　　　　　　　　　　//清除所有<br>已加载插件：fastestmirror, langpacks<br>正在清理软件源： base extras updates<br>Cleaning up everything<br>Cleaning up list of fastest mirrors</p></li></ol><h2 id="2017-08-14-每天2个Linux命令-rpm命令"><a href="#2017-08-14-每天2个Linux命令-rpm命令" class="headerlink" title="2017-08-14 每天2个Linux命令 rpm命令"></a><center>2017-08-14 每天2个Linux命令 rpm命令</center></h2><p>rpm是一个功能十分强大的软件包管理系统。</p><p>(1)用法:</p><pre><code>用法:  rpm  [参数]  [包名]</code></pre><p>(2)功能:</p><pre><code>功能:  使得在Linux下安装、升级和删除软件包的工作变得容易，并且具有查询、验证软件包的功能。与图形化工具相比，使用命令行可以获得更大的灵活性。</code></pre><p>(3)选项参数:     </p><pre><code>  1) -l　　　　　　　　　　　　　　　　显示套件的文件列表　　　　　　　　　　　　  2) -h (or --hash) 　　　 　　　　　　安装时输出hash记号 ("#'')，用来显示安装进度  3) -i　　　　　　　　　　　　　　　　显示套件的相关信息  4) -U&lt;套件档&gt; --upgrade&lt;套件档&gt;  升级指定的套件档  5) -p&lt;套件档&gt; 　　　　　　　　　　  查询指定的RPM套件档  6) -q　　　　　　　　　　　　　　　  查看软件包是否被安装  7) -v　　　　　　　　　　　　　　　　显示指令执行过程  8) -a　　　　　　　　　　　　　　　　查询所有套件  9) -R　　　　　　　　　　　　　　　　显示套件的关联性信息</code></pre><p>(4)实例:</p><pre><code>1)[root@localhost sunmeng]rpm -q mariadb-5.5.47-1.el7_2.x86_64　　　　　　查询指定软件包是否被安装[root@localhost sunmeng]rpm -q mariadb-5.5.47-1.el7_2.x86_64mariadb-5.5.47-1.el7_2.x86_64[root@localhost sunmeng]# rpm -q httpd未安装软件包 httpd</code></pre><p>2)[root@localhost packages]# rpm -qa | grep httpd　　　　　　　　　　　　　　 查询所有套件中已经安装的软件包(与httpd有关的软件包)</p><pre><code>复制代码[root@localhost packages]# rpm -qa | grep httpdhttpd-2.4.6-40.el7.centos.1.x86_64httpd-tools-2.4.6-40.el7.centos.1.x86_64[root@localhost packages]# yum search httpd-2.4.6-40.el7.centos.1.x86_64             //在网络软件库并没有这个包已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn警告：没有匹配 httpd-2.4.6-40.el7.centos.1.x86_64 的软件包No matches found[root@localhost packages]# yum info httpd-2.4.6-40.el7.centos.1.x86_64　　　　　　　　//但本地确实已经安装了这个软件包：系统自带已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn已安装的软件包名称    ：httpd架构    ：x86_64版本    ：2.4.6发布    ：40.el7.centos.1大小    ：9.4 M源    ：installed来自源：updates简介    ： Apache HTTP Server网址    ：http://httpd.apache.org/协议    ： ASL 2.0描述    ： The Apache HTTP Server is a powerful, efficient, and extensible         : web server.[root@localhost packages]# yum info httpd-tools-2.4.6-40.el7.centos.1.x86_64已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn已安装的软件包名称    ：httpd-tools架构    ：x86_64版本    ：2.4.6发布    ：40.el7.centos.1大小    ：168 k源    ：installed来自源：updates简介    ： Tools for use with the Apache HTTP Server网址    ：http://httpd.apache.org/协议    ： ASL 2.0描述    ： The httpd-tools package contains tools which can be used with         : the Apache HTTP Server.</code></pre><p>3)[root@localhost packages]# rpm -e mariadb-5.5.47-1.el7_2.x86_64　　　　　　　　卸载指定的安装过的包</p><pre><code>复制代码[root@localhost packages]# yum install mysql　　　　　　　　　　　　　　//已经安装过已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn软件包 1:mariadb-5.5.47-1.el7_2.x86_64 已安装并且是最新版本无须任何处理[root@localhost packages]# rpm -e mariadb-5.5.47-1.el7_2.x86_64　　 //卸载指定安装包　　[root@localhost packages]# yum install mysql　　　　　　　　　　　　　 //重新下载指定安装包已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn正在解决依赖关系--&gt; 正在检查事务---&gt; 软件包 mariadb.x86_64.1.5.5.47-1.el7_2 将被 安装--&gt; 解决依赖关系完成依赖关系解决========================================================================================================================================== Package                       架构                         版本                                      源                             大小==========================================================================================================================================正在安装: mariadb                       x86_64                       1:5.5.47-1.el7_2                          updates                       8.9 M事务概要==========================================================================================================================================安装  1 软件包总下载量：8.9 M安装大小：49 MIs this ok [y/d/N]: yDownloading packages:mariadb-5.5.47-1.el7_2.x86_64. FAILED                                          http://mirrors.cug.edu.cn/centos/7.2.1511/updates/x86_64/Packages/mariadb-5.5.47-1.el7_2.x86_64.rpm: [Errno 12] Timeout on http://mirrors.cug.edu.cn/centos/7.2.1511/updates/x86_64/Packages/mariadb-5.5.47-1.el7_2.x86_64.rpm: (28, 'Resolving timed out after 30419 milliseconds')正在尝试其它镜像。mariadb-5.5.47-1.el7_2.x86_64.rpm                                                                                  | 8.9 MB  00:01:35     Running transaction checkRunning transaction testTransaction test succeededRunning transaction警告：RPM 数据库已被非 yum 程序修改。  正在安装    : 1:mariadb-5.5.47-1.el7_2.x86_64                                                                                       1/1   验证中      : 1:mariadb-5.5.47-1.el7_2.x86_64                                                                                       1/1 已安装:  mariadb.x86_64 1:5.5.47-1.el7_2                                                                                                         完毕！</code></pre><p>4)[root@localhost packages]# rpm -qpR gnome-bluetooth-3.14.1-1.el7.x86_64.rpm　　　　　查看指定软件包的依赖关系</p><pre><code>复制代码[root@localhost packages]# find -name "gnome-bluetooth-3.14.1-1.el7.x86_64.rpm" -exec ls -l {} \;　　　　　　//在当前目录下能够找到指定.rpm包-rw-r--r--. 1 root root 50740 11月 25 2015 ./gnome-bluetooth-3.14.1-1.el7.x86_64.rpm[root@localhost packages]# rpm -qpR gnome-bluetooth-3.14.1-1.el7.x86_64.rpm　　　　　　　　　　　　　　　　　　 //查看它依赖的文件/bin/sh/bin/sh/bin/shbluez &gt;= 5.0desktop-file-utilsdesktop-file-utilsgnome-bluetooth-libs = 1:3.14.1-1.el7libatk-1.0.so.0()(64bit)libc.so.6()(64bit)libc.so.6(GLIBC_2.2.5)(64bit)libc.so.6(GLIBC_2.4)(64bit)libcairo-gobject.so.2()(64bit)libcairo.so.2()(64bit)libgdk-3.so.0()(64bit)libgdk_pixbuf-2.0.so.0()(64bit)libgio-2.0.so.0()(64bit)libglib-2.0.so.0()(64bit)libgmodule-2.0.so.0()(64bit)libgnome-bluetooth.so.13()(64bit)libgobject-2.0.so.0()(64bit)libgtk-3.so.0()(64bit)libm.so.6()(64bit)libpango-1.0.so.0()(64bit)libpangocairo-1.0.so.0()(64bit)libpthread.so.0()(64bit)libudev.so.1()(64bit)pulseaudio-module-bluetoothrpmlib(CompressedFileNames) &lt;= 3.0.4-1rpmlib(FileDigests) &lt;= 4.6.0-1rpmlib(PayloadFilesHavePrefix) &lt;= 4.0-1rtld(GNU_HASH)rpmlib(PayloadIsXz) &lt;= 5.2-1[root@localhost packages]# yum deplist gnome-bluetooth-3.14.1-1.el7.x86_64.rpm　　　　　　　　//yum命令查询依赖关系已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn软件包：gnome-bluetooth.x86_64 1:3.14.1-1.el7   依赖：/bin/sh   provider: bash.x86_64 4.2.46-19.el7   依赖：bluez &gt;= 5.0   provider: bluez.x86_64 5.23-4.el7   依赖：desktop-file-utils   provider: desktop-file-utils.x86_64 0.22-1.el7   依赖：gnome-bluetooth-libs = 1:3.14.1-1.el7   provider: gnome-bluetooth-libs.x86_64 1:3.14.1-1.el7   provider: gnome-bluetooth-libs.i686 1:3.14.1-1.el7   依赖：libatk-1.0.so.0()(64bit)   provider: atk.x86_64 2.14.0-1.el7   依赖：libc.so.6()(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libc.so.6(GLIBC_2.2.5)(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libc.so.6(GLIBC_2.4)(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libcairo-gobject.so.2()(64bit)   provider: cairo-gobject.x86_64 1.14.2-1.el7   依赖：libcairo.so.2()(64bit)   provider: cairo.x86_64 1.14.2-1.el7   依赖：libgdk-3.so.0()(64bit)   provider: gtk3.x86_64 3.14.13-16.el7   依赖：libgdk_pixbuf-2.0.so.0()(64bit)   provider: gdk-pixbuf2.x86_64 2.31.6-3.el7   依赖：libgio-2.0.so.0()(64bit)   provider: glib2.x86_64 2.42.2-5.el7   依赖：libglib-2.0.so.0()(64bit)   provider: glib2.x86_64 2.42.2-5.el7   依赖：libgmodule-2.0.so.0()(64bit)   provider: glib2.x86_64 2.42.2-5.el7   依赖：libgnome-bluetooth.so.13()(64bit)   provider: gnome-bluetooth-libs.x86_64 1:3.14.1-1.el7   依赖：libgobject-2.0.so.0()(64bit)   provider: glib2.x86_64 2.42.2-5.el7   依赖：libgtk-3.so.0()(64bit)   provider: gtk3.x86_64 3.14.13-16.el7   依赖：libm.so.6()(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libpango-1.0.so.0()(64bit)   provider: pango.x86_64 1.36.8-2.el7   依赖：libpangocairo-1.0.so.0()(64bit)   provider: pango.x86_64 1.36.8-2.el7   依赖：libpthread.so.0()(64bit)   provider: glibc.x86_64 2.17-106.el7_2.6   依赖：libudev.so.1()(64bit)   provider: systemd-libs.x86_64 219-19.el7_2.9   依赖：pulseaudio-module-bluetooth   provider: pulseaudio-module-bluetooth.x86_64 6.0-7.el7   依赖：rtld(GNU_HASH)   provider: glibc.x86_64 2.17-106.el7_2.6   provider: glibc.i686 2.17-106.el7_2.6</code></pre><p>5)[root@localhost packages]# rpm -Va　　　　　　　　校验所有的rpm包，查找丢失的文件</p><pre><code>复制代码[root@localhost packages]# rpm -VaS.5....T.  c /etc/hba.conf....L....  c /etc/pam.d/fingerprint-auth....L....  c /etc/pam.d/password-auth....L....  c /etc/pam.d/postlogin....L....  c /etc/pam.d/smartcard-auth....L....  c /etc/pam.d/system-auth遗漏     /var/run/wpa_supplicant遗漏     /var/run/plutoS.5....T.  c /etc/plymouth/plymouthd.confS.5....T.  c /etc/login.defsS.5....T.  c /etc/libuser.confS.5....T.  c /etc/openldap/ldap.conf遗漏     /var/run/gluster.M.......  c /etc/cups/subscriptions.confS.5....T.  c /etc/yum/pluginconf.d/langpacks.conf.M....G..    /var/log/gdmS.5....T.  c /etc/cgrules.confS.5....T.  c /etc/cups/cups-browsed.conf.......T.    /lib/modules/3.10.0-229.el7.x86_64/modules.devname.......T.    /lib/modules/3.10.0-229.el7.x86_64/modules.softdep[root@localhost packages]# which mysql/usr/bin/mysql</code></pre><p>6)[root@localhost packages]# rpm -ql mariadb-5.5.47-1.el7_2.x86_64　　　　查看指定软件包的安装的位置</p><pre><code>复制代码[root@localhost packages]# yum install mysql已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn软件包 1:mariadb-5.5.47-1.el7_2.x86_64 已安装并且是最新版本无须任何处理[root@localhost packages]# rpm -ql mariadb-5.5.47-1.el7_2.x86_64/etc/my.cnf.d/client.cnf/usr/bin/aria_chk/usr/bin/aria_dump_log/usr/bin/aria_ftdump/usr/bin/aria_pack/usr/bin/aria_read_log/usr/bin/msql2mysql/usr/bin/my_print_defaults/usr/bin/mysql/usr/bin/mysql_find_rows/usr/bin/mysql_waitpid/usr/bin/mysqlaccess/usr/bin/mysqladmin/usr/bin/mysqlbinlog/usr/bin/mysqlcheck/usr/bin/mysqldump/usr/bin/mysqlimport/usr/bin/mysqlshow/usr/bin/mysqlslap/usr/share/doc/mariadb-5.5.47/usr/share/doc/mariadb-5.5.47/COPYING/usr/share/doc/mariadb-5.5.47/COPYING.Google/usr/share/doc/mariadb-5.5.47/COPYING.LESSER/usr/share/doc/mariadb-5.5.47/COPYING.Percona/usr/share/doc/mariadb-5.5.47/README/usr/share/doc/mariadb-5.5.47/README.mysql-docs/usr/share/doc/mariadb-5.5.47/README.mysql-license/usr/share/man/man1/aria_chk.1.gz/usr/share/man/man1/aria_dump_log.1.gz/usr/share/man/man1/aria_ftdump.1.gz/usr/share/man/man1/aria_pack.1.gz/usr/share/man/man1/aria_read_log.1.gz/usr/share/man/man1/my_print_defaults.1.gz/usr/share/man/man1/mysql.1.gz/usr/share/man/man1/mysql_find_rows.1.gz/usr/share/man/man1/mysql_waitpid.1.gz/usr/share/man/man1/mysqlaccess.1.gz/usr/share/man/man1/mysqladmin.1.gz/usr/share/man/man1/mysqldump.1.gz/usr/share/man/man1/mysqlshow.1.gz/usr/share/man/man1/mysqlslap.1.gz</code></pre><p>7)[root@localhost packages]# rpm -qi ftp-0.17-66.el7.x86_64　　　　　　　查看指定软件包的信息</p><pre><code>复制代码[root@localhost packages]# yum install ftp已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn软件包 ftp-0.17-66.el7.x86_64 已安装并且是最新版本无须任何处理[root@localhost packages]# rpm -qi ftp-0.17-66.el7.x86_64Name        : ftpVersion     : 0.17Release     : 66.el7Architecture: x86_64Install Date: 2016年06月21日 星期二 11时26分00秒Group       : Applications/InternetSize        : 98691License     : BSD with advertisingSignature   : RSA/SHA256, 2014年07月03日 星期四 18时25分20秒, Key ID 24c6a8a7f4a80eb5Source RPM  : ftp-0.17-66.el7.src.rpmBuild Date  : 2014年06月09日 星期一 13时01分11秒Build Host  : worker1.bsys.centos.orgRelocations : (not relocatable)Packager    : CentOS BuildSystem &lt;http://bugs.centos.org&gt;Vendor      : CentOSURL         : ftp://ftp.linux.org.uk/pub/linux/Networking/netkitSummary     : The standard UNIX FTP (File Transfer Protocol) clientDescription :The ftp package provides the standard UNIX command-line FTP (FileTransfer Protocol) client.  FTP is a widely used protocol fortransferring files over the Internet and for archiving files.If your system is on a network, you should install ftp in order to dofile transfers.复制代码复制代码[root@localhost packages]# yum info ftp-0.17-66.el7.x86_64已加载插件：fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.cqu.edu.cn * extras: mirrors.cqu.edu.cn * updates: mirrors.cqu.edu.cn已安装的软件包名称    ：ftp架构    ：x86_64版本    ：0.17发布    ：66.el7大小    ：96 k源    ：installed来自源：anaconda简介    ： The standard UNIX FTP (File Transfer Protocol) client网址    ：ftp://ftp.linux.org.uk/pub/linux/Networking/netkit协议    ： BSD with advertising描述    ： The ftp package provides the standard UNIX command-line FTP (File         : Transfer Protocol) client.  FTP is a widely used protocol for         : transferring files over the Internet and for archiving files.         :          : If your system is on a network, you should install ftp in order to do         : file transfers.</code></pre><p>8)[root@localhost packages]# rpm -i <a href="ftp://ftp.linux.org.uk/pub/linux/Networking/netkit">ftp://ftp.linux.org.uk/pub/linux/Networking/netkit</a>　　　　　　　　直接从网址下载(-i参数)</p><p>9)[root@localhost packages]# rpm -i -vv <a href="ftp://ftp.linux.org.uk/pub/linux/Networking/netkit">ftp://ftp.linux.org.uk/pub/linux/Networking/netkit</a>　　　　　　显示指令执行的细节(-vvc参数)</p><pre><code>复制代码[root@localhost packages]# rpm -i ftp://ftp.linux.org.uk/pub/linux/Networking/netkitcurl: (78) RETR response: 550错误：跳过 ftp://ftp.linux.org.uk/pub/linux/Networking/netkit - 传输失败[root@localhost packages]# rpm -i -vv ftp://ftp.linux.org.uk/pub/linux/Networking/netkit获取ftp://ftp.linux.org.uk/pub/linux/Networking/netkitcurl: (78) RETR response: 550错误：跳过 ftp://ftp.linux.org.uk/pub/linux/Networking/netkit - 传输失败[root@localhost packages]# rpm -e ftp[root@localhost packages]# rpm -i -vv ftp://ftp.linux.org.uk/pub/linux/Networking/netkit获取ftp://ftp.linux.org.uk/pub/linux/Networking/netkitcurl: (78) RETR response: 550错误：跳过 ftp://ftp.linux.org.uk/pub/linux/Networking/netkit - 传输失败[root@localhost packages]# wget ftp://ftp.linux.org.uk/pub/linux/Networking/netkit　//用wget测试是否能下载时，发现也是不行的，说明是网址的问题。--2016-06-22 08:23:18--  ftp://ftp.linux.org.uk/pub/linux/Networking/netkit           =&gt; “netkit”正在解析主机 ftp.linux.org.uk (ftp.linux.org.uk)... 195.92.253.2, 2002:c35c:fd02::1正在连接 ftp.linux.org.uk (ftp.linux.org.uk)|195.92.253.2|:21... 已连接。正在以 anonymous 登录 ... 登录成功！==&gt; SYST ... 完成。   ==&gt; PWD ... 完成。==&gt; TYPE I ... 完成。 ==&gt; CWD (1) /pub/linux/Networking ... 完成。==&gt; SIZE netkit ... 完成。==&gt; PASV ... 无法连接到 0.0.0.0 端口号 19392: 拒绝连接　　　　　　　　　　　　　　　//指定网站拒绝连接</code></pre><p>(5)其它:</p><pre><code>rpm的详细介绍:1)简介：RPM(Red Hat Package Manager)，是Red Hat 软件包管理器。RPM包里面包含有"可执行的二进制程序"；"程序运行时所需要的文件"。一个RPM 包中的应用程序，有时除了自身所带的附加文件保证其正常以外，还需要其它特定版本文件，这就是软件包的依赖关系。依赖关系并不是Linux特有的， Windows操作系统中也是同样存在的；比如我们在Windows系统中运行3D游戏，在安装的时候，他可能会提示，要安装Direct 9 ；Linux和Windows原理是差不多的。一个软件包安装的流程图:</code></pre><p>2)RPM软件包管理器的全面用途：</p><pre><code>1.可以安装、删除、升级和管理软件；当然也支持在线安装和升级软件；2.通过RPM包管理能知道软件包包含哪些文件，也能知道系统中的某个文件属于哪个软件包；3.可以在查询系统中的软件包是否安装以及其版本；4.作为开发者可以把自己的程序打包为RPM 包发布；5.软件包签名GPG和MD5的导入、验证和签名发布6.依赖性的检查，查看是否有软件包由于不兼容而扰乱了系统；3)RPM 的使用权限：  RPM软件的安装、删除、更新只有root权限才能使用；对于查询功能任何用户都可以操作；如果普通用户拥有安装目录的权限，也可以进行安装。  不是所有的软件包都能通过rpm 命令来安装，只有以.rpm结尾的软件包才可以。4)当rpm系统出了不能安装和查询的问题时:[root@localhost packages]rpm -initdb[root@localhost packages]rpm -rebuilddb            //这个命令需要执行很长时间</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 chkconfig systemctl</title>
      <link href="/2017/08/14/mei-tian-2-ge-linux-ming-ling-chkconfig-systemctl/"/>
      <url>/2017/08/14/mei-tian-2-ge-linux-ming-ling-chkconfig-systemctl/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-13-每天2个Linux命令-chkconfig命令"><a href="#2017-08-13-每天2个Linux命令-chkconfig命令" class="headerlink" title=" 2017-08-13 每天2个Linux命令 chkconfig命令"></a><center> 2017-08-13 每天2个Linux命令 chkconfig命令</center></h2><p>chkconfig命令检查、设置系统的各种服务。</p><p>(1)用法:</p><pre><code>用法:  chkconfig  [必要参数]  [服务]</code></pre><p>(2)功能:</p><pre><code>功能:  chkconfig命令用来安装，查看或修改 services随系统启动的启动选项的设置。是Red Hat公司遵循GPL规则所开发的程序，它可查询操作系统在每一个执行等级中会执行哪些系统服务，其中包括各类常驻服务。注意:  谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接。每一个被chkconfig管理的服务都首先要在/etc/init.d中添加他们。  </code></pre><p>(3)选项参数:</p><pre><code>  1) --add 　　　　　　  开启指定的服务程序  2) --del 　　　　　　　关闭指定的服务程序  3) --list 　　　　　　   列出chkconfig所知道的所有服务  4) --level&lt;代号&gt; 　　  设置服务程序的等级代号，是一串0~7的数字</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# chkconfig --list　　　查看系统程序列表　　　　　复制代码[root@localhost sunjimeng]# chkconfig --list注意：该输出结果只显示 SysV 服务，并不包含原生 systemd 服务。SysV 配置数据可能被原生 systemd 配置覆盖。       如果您想列出 systemd 服务,请执行 'systemctl list-unit-files'。      欲查看对特定 target 启用的服务请执行      'systemctl list-dependencies [target]'。netconsole         0:关    1:关    2:关    3:关    4:关    5:关    6:关network            0:关    1:关    2:开    3:开    4:开    5:开    6:关基于 xinetd 的服务：    chargen-dgram:     关    chargen-stream:    关    daytime-dgram:     关    daytime-stream:    关    discard-dgram:     关    discard-stream:    关    echo-dgram:        关    echo-stream:       关    tcpmux-server:     关    time-dgram:        关    time-stream:       关</code></pre><p>2)在shell脚本中检查service的启动选项的设置</p><pre><code>[root@localhost sunjimeng]# chkconfig network &amp;&amp; echo "Network service is configured"Network service is configured      当你执行chkconfig加service名字，如果service被配置为自动启动，则它将返回true。[root@localhost sunjimeng]# chkconfig xinetd注意：正在将请求转发到“systemctl is-enabled xinetd.service”。enabled[root@localhost sunjimeng]# chkconfig xinetd注意：正在将请求转发到“systemctl is-enabled xinetd.service”。enabled3)添加或删除指定的服务[root@localhost /]# chkconfig --del netconsole[root@localhost /]# chkconfig --add netconsole</code></pre><p>(5)其他:</p><pre><code>  1)等级代号列表：　　等级0表示：表示关机　　等级1表示：单用户模式　　等级2表示：无网络连接的多用户命令行模式　　等级3表示：有网络连接的多用户命令行模式　　等级4表示：不可用　　等级5表示：带图形界面的多用户模式　　等级6表示：重新启动      需要说明的是，level选项可以指定要查看的运行级而不一定是当前运行级。对于每个运行级，只能有一个启动脚本或者停止脚本。当切换运行级时，init不会重新启动已经启动的服务，也不会再次去停止已经停止的服务。       2)运行级文件：　　每个被chkconfig管理的服务需要在对应的init.d下的脚本加上两行或者更多行的注释。第一行告诉chkconfig缺省启动的运行级以及启动和停止的优先级。如果某服务缺省不在任何运行级启动，那么使用-代替运行级。第二行对服务进行描述，可以用\跨行注释。</code></pre><h2 id="2017-08-13-每天2个Linux命令-systemctl命令"><a href="#2017-08-13-每天2个Linux命令-systemctl命令" class="headerlink" title=" 2017-08-13 每天2个Linux命令 systemctl命令"></a><center> 2017-08-13 每天2个Linux命令 systemctl命令</center></h2><p>systemctl命令是系统服务管理器指令，它实际上将 service 和 chkconfig 这两个命令组合到一起。</p><p>(1)用法:</p><pre><code>用法:  systemctl  [参数]  [服务]</code></pre><p>(2)功能:</p><pre><code>功能:  systemd 是 Linux 下的一款系统和服务管理器，兼容 SysV 和 LSB 的启动脚本。</code></pre><p>(3)选项参数：</p><pre><code>  start,stop,restart,status,enable,disable,is-enabled</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# systemctl | more -5　　　　　　   　　显示所有已经激活的服务复制代码[root@localhost sunjimeng]# systemctl | more -5UNIT                                                                                                     LOAD   ACTIVE SUB       DESCRIPTIONproc-sys-fs-binfmt_misc.automount                                                                        loaded active running   Arbitrary Executable File Formats File System Automount Pointsys-devices-pci0000:00-0000:00:07.1-ata2-host1-target1:0:0-1:0:0:0-block-sr0.device                      loaded active plugged   --More--[5]+  已停止               systemctl | more -5[root@localhost sunjimeng]# systemctl list-units |more -5UNIT                                                                                                     LOAD   ACTIVE SUB       DESCRIPTIONproc-sys-fs-binfmt_misc.automount                                                                        loaded active running   Arbitrary Executable File Formats File System Automount Pointsys-devices-pci0000:00-0000:00:07.1-ata2-host1-target1:0:0-1:0:0:0-block-sr0.device                      loaded active plugged   --More--</code></pre><p>2)[root@localhost sunjimeng]# systemctl list-unit-files |more -5　　  显示所有已经安装的服务</p><pre><code>复制代码[root@localhost sunjimeng]# systemctl list-unit-files |more -5UNIT FILE                                   STATE   proc-sys-fs-binfmt_misc.automount           static  dev-hugepages.mount                         static  dev-mqueue.mount                            static  proc-fs-nfsd.mount                          static  --More--</code></pre><p>3)[root@localhost sunjimeng]# systemctl is-enabled telnet.socket　　　查看特定服务是否设定为开机自启　</p><pre><code>[root@localhost sunjimeng]# systemctl is-enabled telnet.socketenabled[root@localhost sunjimeng]# chkconfig telnet.socket　　　　　　　　//这里不需要再加上.socket（加上之后没有反应）[root@localhost sunjimeng]# chkconfig telnet注意：正在将请求转发到“systemctl is-enabled telnet.socket”。enabled</code></pre><p>(5)其他:</p><pre><code>systemd 的特性有:复制代码支持并行化任务；同时采用 socket 式与 D-Bus 总线式激活服务；按需启动守护进程（daemon）；利用 Linux 的 cgroups 监视进程；支持快照和系统恢复；维护挂载点和自动挂载点；各服务间基于依赖关系进行精密控制。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 telnet service</title>
      <link href="/2017/08/14/mei-tian-2-ge-linux-ming-ling-telnet-service/"/>
      <url>/2017/08/14/mei-tian-2-ge-linux-ming-ling-telnet-service/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-12-每天2个Linux命令-telnet命令"><a href="#2017-08-12-每天2个Linux命令-telnet命令" class="headerlink" title=" 2017-08-12 每天2个Linux命令 telnet命令"></a><center> 2017-08-12 每天2个Linux命令 telnet命令</center></h2><p>执行telnet指令开启终端机阶段作业，并登入远端主机。</p><p>(1)用法:</p><pre><code>用法:  telnet [参数] [主机]</code></pre><p>(2)功能:</p><pre><code>功能:  telnet命令通常用来远程登录。原理: Telnet服务虽然也属于客户机/服务器模型的服务，但它更大的意义在于实现了基于Telnet协议的远程登录（远程交互式计算）。telnet实现的远程登录:分时系统允许多个用户同时使用一台计算机，为了保证系统的安全和记帐方便，系统要求每个用户有单独的帐号作为登录标识，系统还为每个用户指定了一个口令。用户在使用该系统之前要输入标识和口令，这个过程被称为'登远程登陆是指用户使用Telnet命令，使自己的计算机暂时成为远程主机的一个仿真终端的过程。仿真终端等效于一个非智能的机器，它只负责把用户输入的每个字符传递给主机，再将主机输出的每个信息回显在屏幕上。telnet的简介:Telnet协议是TCP/IP协议族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。要开始一个 telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。但是，telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。telnet命令还可做别的用途，比如确定远程服务的状态，比如确定远程服务器的某个端口是否能访问。</code></pre><p>(3)选项参数:</p><pre><code>1) -8 　　　　     允许使用8位字符资料，包括输入与输出。 2) -a 　　　　　　 尝试自动登入远端系统。3) -b&lt;主机别名&gt;   使用别名指定远端主机名称。 4) -c 　　　　   　 不读取用户专属目录里的.telnetrc文件。 5) -d 　　　　 　　启动排错模式。 6) -e&lt;脱离字符&gt;   设置脱离字符。 7) -E 　　　　　　 滤除脱离字符。 8) -f 　　　　       此参数的效果和指定"-F"参数相同。 9) -F 　　　　　　 使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机。   10) -k&lt;域名&gt; 　　  使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名。   11) -K 　　　　      不自动登入远端主机。   12) -l&lt;用户名称&gt;    指定要登入远端主机的用户名称。   13) -L 　　　　　　 允许输出8位字符资料。   14) -n&lt;记录文件&gt;   指定文件记录相关信息。   15) -r 　　　　　　  使用类似rlogin指令的用户界面。   16) -S&lt;服务类型&gt;   设置telnet连线所需的IP TOS信息。   17) -x 　　　　　　  假设主机有支持数据加密的功能，就使用它。   18) -X&lt;认证形态&gt;   关闭指定的认证形态。</code></pre><p>(4)实例:</p><pre><code> 1)[root@localhost xinetd.d]# telnet localhost 23　　　　　　连接本地的主机，端口号为23复制代码[root@localhost xinetd.d]# telnet localhost 23Trying ::1...Connected to localhost.Escape character is '^]'.Kernel 3.10.0-229.el7.x86_64 on an x86_64localhost login: sunjimengPassword: Last login: Sat Jun 18 18:29:24 from ::ffff:192.168.142.128[sunjimeng@localhost ~]$ </code></pre><p>2)用真实物理机win10连接虚拟机中的centOS:</p><pre><code>在命令窗口cmd中输入:C:\Users\JMSun&gt;telnet 192.168.0.8弹出另一个页面:(这是在win10下的页面，在这里可以自由操作centos，结果类似直接使用centos的终端。)</code></pre><p>3)用telnet实现win10连接win7：  </p><pre><code>  在用我自己的win10连接别人的win7系统前，我首先将win7的防火墙关闭，打开telnet服务。然后:复制代码C:\Users\JMSun&gt;ping 192.168.0.5    //这是win7机的IP，在这里先测试与它的连通性正在 Ping 192.168.0.5 具有 32 字节的数据:来自 192.168.0.5 的回复: 字节=32 时间=62ms TTL=128来自 192.168.0.5 的回复: 字节=32 时间=6ms TTL=128来自 192.168.0.5 的回复: 字节=32 时间=4ms TTL=128来自 192.168.0.5 的回复: 字节=32 时间=2ms TTL=128192.168.0.5 的 Ping 统计信息:    数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，往返行程的估计时间(以毫秒为单位):    最短 = 2ms，最长 = 62ms，平均 = 18msC:\Users\JMSun&gt;telnet 192.168.0.5复制代码     弹出页面:</code></pre><p>(5)其他:</p><pre><code>1.学习此命令遇到的问题:一.centOS7.0下的shell中出现下面的问题:[root@localhost sunjimeng]# telnetbash: telnet: 未找到命令...解决方案:1)安装telnet-server，telnet，xinted：2)将xinetd、telnet服务加入开机自启动[root@localhost etc]# systemctl enable xinetd.service[root@localhost etc]# systemctl enable telnet.socketln -s '/usr/lib/systemd/system/telnet.socket' '/etc/systemd/system/sockets.target.wants/telnet.socket'3)启动这两个服务：[root@localhost etc]# systemctl start telnet.socket[root@localhost etc]# systemctl start xinetd</code></pre><p>二.我用win10的电脑和虚拟机中的centOS7.0想实现他们之间的通信，但是出现几个问题:</p><pre><code> 1)centOS虚拟机无法ping到物理机win10：  解决方法:关闭win10的防火墙； 2)centOS虚拟机能ping到物理机，物理机win10却无法ping到centOS虚拟机：  解决方法:将虚拟机的网络配置由NAT模式转向桥接模式。这里还涉及到桥接模式下的网络配置问题，以后讨论。（NAT模式下主机与虚机之间不能互相ping通，因为虚拟机是靠主机的真实IP来访问互联网的，而桥接模式下虚拟机有自己独立的动态IP地址。）3)centOS能够用telnet连接自身，却无法连接物理机win10:  解决方法:由于在win10系统中telnet的服务端被删去了（不安全性），只保留了客户端，所以要想达到目的，必须重新下载telnet.server程序并安装配置。在win10的打开或关闭windows功能里启动telnet客户端程序。并同时启动服务端（如果是win7系统则直接在windows功能选项中打开就行。）。  这里存在一个细节:如果你的win10账户不是本地账户而是Microsoft网络账户，则无法连接。需要新建一个本地账户：包括用户名，密码，和域名(domain name)。其中domain name不需要输入，默认为空。  而且在centOS连接到win10后会出现乱码问题，这个问题以后解决。（centOS采用UFT编码方式，而win10采用GB2312编码方式。）4)centOS能够用telnet连接物理机win10，物理机却无法连接centOS，提示:</code></pre><h2 id="2017-08-12-每天2个Linux命令-service命令"><a href="#2017-08-12-每天2个Linux命令-service命令" class="headerlink" title=" 2017-08-12 每天2个Linux命令 service命令"></a><center> 2017-08-12 每天2个Linux命令 service命令</center></h2><p>service命令用于对系统服务进行管理。</p><p>(1)用法:</p><pre><code>用法:  service  [服务]  [操作]</code></pre><p>(2)功能:</p><pre><code>功能:  service命令用于启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。</code></pre><p>3)选项参数:</p><pre><code>  1) status 　　　　　　  2) start  3) stop  4) reload  5) disable  6) force-reload这几个参数顾名思义，不再解释！</code></pre><p>(4)实例:</p><pre><code>  1)[sunjimeng@localhost ~]$ service mysql　　　　　　　　　　　查看service命令的简介　　　　　　　[sunjimeng@localhost ~]$ service mysqlThe service command supports only basic LSB actions (start, stop, restart, try-restart, reload, force-reload, status). For other actions, please try to use systemctl.</code></pre><p>2)[sunjimeng@localhost ~]$ service xinetd status 　　  　　      查看指定服务的状态信息</p><pre><code>复制代码[sunjimeng@localhost ~]$ service xinetd statusRedirecting to /bin/systemctl status  xinetd.servicexinetd.service - Xinetd A Powerful Replacement For Inetd   Loaded: loaded (/usr/lib/systemd/system/xinetd.service; enabled)   Active: active (running) since 日 2016-06-19 23:49:21 PDT; 22min ago  Process: 1395 ExecStart=/usr/sbin/xinetd -stayalive -pidfile /var/run/xinetd.pid $EXTRAOPTIONS (code=exited, status=0/SUCCESS) Main PID: 1426 (xinetd)   CGroup: /system.slice/xinetd.service           └─1426 /usr/sbin/xinetd -stayalive -pidfile /var/run/xinetd.pid复制代码      查看网络连接服务的状态信息:[root@localhost sunjimeng]# service network statusConfigured devices:lo eno16777736 配置_1Currently active devices:lo eno16777736</code></pre><p>3)[sunjimeng@localhost ~]$ service xinetd stop　　　　　　　　停止xinetd服务</p><pre><code>复制代码[sunjimeng@localhost ~]$ service xinetd stopRedirecting to /bin/systemctl stop  xinetd.serviceFailed to issue method call: Access denied                //没有root权限，所以拒绝访问[sunjimeng@localhost ~]$ su root密码：                                                     //登入root[root@localhost sunjimeng]# service xinetd stopRedirecting to /bin/systemctl stop  xinetd.service        [root@localhost sunjimeng]# service xinetd statusRedirecting to /bin/systemctl status  xinetd.servicexinetd.service - Xinetd A Powerful Replacement For Inetd   Loaded: loaded (/usr/lib/systemd/system/xinetd.service; enabled)   Active: inactive (dead) since 一 2016-06-20 00:15:27 PDT; 15s ago  Process: 1395 ExecStart=/usr/sbin/xinetd -stayalive -pidfile /var/run/xinetd.pid $EXTRAOPTIONS (code=exited, status=0/SUCCESS) Main PID: 1426 (code=exited, status=0/SUCCESS)6月 19 23:49:21 localhost.localdomain xinetd[1426]: removing echo6月 19 23:49:21 localhost.localdomain xinetd[1426]: removing tcpmux6月 19 23:49:21 localhost.localdomain xinetd[1426]: removing time6月 19 23:49:21 localhost.localdomain xinetd[1426]: removing time6月 19 23:49:21 localhost.localdomain xinetd[1426]: xinetd Version 2.3.15 st...6月 19 23:49:21 localhost.localdomain xinetd[1426]: Started working: 0 avail...6月 20 00:07:22 localhost.localdomain systemd[1]: Started Xinetd A Powerful ...6月 20 00:08:07 localhost.localdomain systemd[1]: Started Xinetd A Powerful ...6月 20 00:15:27 localhost.localdomain systemd[1]: Stopping Xinetd A Powerful...6月 20 00:15:27 localhost.localdomain systemd[1]: Stopped Xinetd A Powerful ...Hint: Some lines were ellipsized, use -l to show in full.</code></pre><p>4)[root@localhost sunjimeng]# service xinetd restart　　　　　 重启守护进程</p><pre><code>[root@localhost sunjimeng]# service xinetd restartRedirecting to /bin/systemctl restart  xinetd.service</code></pre><p>5)[root@localhost sunjimeng]# service xinetd reload　　　　　 重新加载守护进程xinetd的配置文件</p><pre><code>[root@localhost sunjimeng]# service xinetd reloadRedirecting to /bin/systemctl reload  xinetd.service</code></pre><p>(5)其他:</p><pre><code>1.service程序与一般的程序的区别:  service（也称为daemon）表示后台运行的程序，一般随系统的启动自动地启动且在用户logoff后仍然能够继续运行。该daemon进程一般在启动后需要与父进程断开关系，并使进程没有控制终端（tty）。  因为daemon程序在后台执行，不需要于终端交互，通常就关闭STDIN、STDOUT和STDER。daemon无法输出信息，可以使用syslog或自己的日志系统进行日志处理。  可以使用/etc/rc.d/init.d/functions脚本中的daemon函数来将一般的程序启动为daemon：[root@localhost sunjimeng]# ls /etc/rc.d/init.d/functions/etc/rc.d/init.d/functions2.xinetd:xinetd本身是一个service，他的作用是监听所有的端口，根据配置对不同的端口启动不同的应用。 对于有些需要在后台运行的程序，可以选择设置为service在后台一直运行，也可以选择使用xinetd来配置此程序根据需要激活。对于需要频繁访问的服务，需要在/etc/rc.d/init.d下配置为service；对于不是频繁访问的服务，可以使用xinetd来激活，从而节约服务器的资源；总之service与xinetd，选一即可。3.service命令和chkconfig命令与服务程序的关系:   service的管理工具是:　　　　　　  /sbin/serviceservice的自动启动控制工具是:　　 /sbin/chkconfig 分类: CentOS服务器管理</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 netstat ss</title>
      <link href="/2017/08/14/mei-tian-2-ge-linux-ming-ling-netstat-ss/"/>
      <url>/2017/08/14/mei-tian-2-ge-linux-ming-ling-netstat-ss/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-11-每天2个Linux命令-netstat命令"><a href="#2017-08-11-每天2个Linux命令-netstat命令" class="headerlink" title=" 2017-08-11 每天2个Linux命令 netstat命令"></a><center> 2017-08-11 每天2个Linux命令 netstat命令</center></h2><p>netstat命令用来打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。</p><p>(1)用法:</p><pre><code>用法:  netstat [选项参数]</code></pre><p>(2)功能:</p><pre><code>功能:  netstat用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。</code></pre><p>(3)选项参数:</p><pre><code>  1) -a或–all 　　　　 显示所有连线中的Socket。   2) -n或–numeric     直接使用IP地址，而不通过域名服务器。  3) -t或–tcp 　　　　显示TCP传输协议的连线状况。  4) -u或–udp 　　    显示UDP传输协议的连线状况。  5) -v或–verbose     显示指令执行过程。  6) -p或–programs  显示正在使用Socket的程序识别码和程序名称。  7) -s或–statistice   显示网络工作信息统计表。</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost ~]# netstat　　　　　　　　无参数的使用复制代码[root@localhost ~]# netstatActive Internet connections (w/o servers)                                                   //有源TCP连接Proto Recv-Q Send-Q Local Address               Foreign Address             State      tcp        0    268 192.168.120.204:ssh         10.2.0.68:62420             ESTABLISHED udp        0      0 192.168.120.204:4371        10.58.119.119:domain        ESTABLISHED Active UNIX domain sockets (w/o servers)                                                    //有源Unix域套接口（和网络套接字一样，但是只能用于本机通信，性能可以提高一倍）Proto RefCnt Flags       Type       State         I-Node Pathunix  2      [ ]         DGRAM                    1491   @/org/kernel/udev/udevdunix  4      [ ]         DGRAM                    7337   /dev/logunix  2      [ ]         DGRAM                    708823 unix  2      [ ]         DGRAM                    7539   unix  3      [ ]         STREAM     CONNECTED     7287   unix  3      [ ]         STREAM     CONNECTED     7286   [root@localhost ~]#复制代码  说明:  1."Recv-Q"和"Send-Q"指的是接收队列和发送队列。  2.Proto显示连接使用的协议；RefCnt表示连接到本套接口上的进程号；Types显示套接口的类型；State显示套接口当前的状态；    Path表示连接到套接口的其它进程使用的路径名。  3.套接口类型：    -t ：TCP    -u ：UDP    -raw ：RAW类型    --unix ：UNIX域类型    --ax25 ：AX25类型    --ipx ：ipx类型    --netrom ：netrom类型  4.状态说明：    LISTEN：　　　　 侦听来自远方的TCP端口的连接请求    SYN-SENT：　　  再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了）    SYN-RECEIVED    再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了）    ESTABLISHED：   代表一个打开的连接    FIN-WAIT-1：      等待远程TCP连接中断请求，或先前的连接中断请求的确认    FIN-WAIT-2：      从远程TCP等待连接中断请求    CLOSE-WAIT：    等待从本地用户发来的连接中断请求    CLOSING：          等待远程TCP对连接中断的确认    LAST-ACK：　　   等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击）    TIME-WAIT：       等待足够的时间以确保远程TCP接收到连接中断请求的确认    CLOSED：            没有任何连接状态</code></pre><p>2)[sunjimeng@localhost ~]$ netstat -a　　　　　　显示所有已监听或者没有监听的端口</p><pre><code>复制代码[sunjimeng@localhost ~]$ netstat -aActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State      tcp        0      0 0.0.0.0:ssh             0.0.0.0:*               LISTEN     tcp        0      0 localhost:ipp           0.0.0.0:*               LISTEN     tcp        0      0 localhost:smtp          0.0.0.0:*               LISTEN     tcp        0      0 192.168.142.128:52328   115.28.122.210:http     TIME_WAIT  tcp        0      0 192.168.142.128:52836   112.124.140.210:http    TIME_WAIT  tcp        0      0 192.168.142.128:52334   115.28.122.210:http     TIME_WAIT  tcp        0      0 192.168.142.128:52329   115.28.122.210:http     TIME_WAIT  tcp        0      0 192.168.142.128:52839   112.124.140.210:http    TIME_WAIT  tcp        0      0 192.168.142.128:52336   115.28.122.210:http     TIME_WAIT  tcp        0      0 192.168.142.128:52844   112.124.140.210:http    TIME_WAIT  tcp        0      0 192.168.142.128:54198   202.204.80.77:http      TIME_WAIT  tcp        0      0 192.168.142.128:52326   115.28.122.210:http     TIME_WAIT  tcp        0      0 192.168.142.128:52842   112.124.140.210:http    TIME_WAIT  tcp        0      0 192.168.142.128:44060   ec2-52-27-123-81.:https ESTABLISHEDtcp        0      0 192.168.142.128:52847   112.124.140.210:http    TIME_WAIT  tcp        0      0 192.168.142.128:54204   202.204.80.77:http      TIME_WAIT  tcp        0      0 192.168.142.128:52332   115.28.122.210:http     TIME_WAIT  tcp        0      0 192.168.142.128:54208   202.204.80.77:http      TIME_WAIT  tcp6       0      0 [::]:ssh                [::]:*                  LISTEN     tcp6       0      0 localhost:ipp           [::]:*                  LISTEN     tcp6       0      0 localhost:smtp          [::]:*                  LISTEN     udp        0      0 0.0.0.0:bootpc          0.0.0.0:*                          udp        0      0 0.0.0.0:ntp             0.0.0.0:*                          udp        0      0 localhost:323           0.0.0.0:*                          udp      768      0 192.168.142.128:39404   192.168.142.2:domain    ESTABLISHEDudp        0      0 0.0.0.0:27664           0.0.0.0:*                          udp        0      0 0.0.0.0:mdns            0.0.0.0:*                          udp        0      0 0.0.0.0:52525           0.0.0.0:*                          udp        0      0 0.0.0.0:52525           0.0.0.0:*                          udp6       0      0 [::]:ntp                [::]:*                             udp6       0      0 localhost:323           [::]:*                             udp6       0      0 [::]:14031              [::]:*                             raw6       0      0 [::]:ipv6-icmp          [::]:*                  7          Active UNIX domain sockets (servers and established)Proto RefCnt Flags       Type       State         I-Node   Pathunix  2      [ ACC ]     STREAM     LISTENING     26013    @/tmp/.ICE-unix/2850unix  2      [ ACC ]     STREAM     LISTENING     23031    @/tmp/dbus-XARCfYJ4unix  2      [ ACC ]     STREAM     LISTENING     18194    /var/run/abrt/abrt.socket......unix  3      [ ]         STREAM     CONNECTED     16906    </code></pre><p>3)[sunjimeng@localhost ~]$ netstat -nu　　　　　　显示已建立的UDP连接</p><pre><code>复制代码[sunjimeng@localhost ~]$ netstat -nuActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State      udp      768      0 192.168.142.128:39404   192.168.142.2:53        ESTABLISHED[sunjimeng@localhost ~]$ netstat -anuActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State      udp        0      0 0.0.0.0:68              0.0.0.0:*                          udp        0      0 0.0.0.0:123             0.0.0.0:*                          udp        0      0 127.0.0.1:323           0.0.0.0:*                          udp      768      0 192.168.142.128:39404   192.168.142.2:53        ESTABLISHEDudp        0      0 0.0.0.0:27664           0.0.0.0:*                          udp        0      0 0.0.0.0:5353            0.0.0.0:*                          udp        0      0 0.0.0.0:52525           0.0.0.0:*                          udp6       0      0 :::123                  :::*                               udp6       0      0 ::1:323                 :::*                               udp6       0      0 :::14031                :::* </code></pre><p>4)[sunjimeng@localhost ~]$ netstat -nt　　　　　　 显示所有已建立的TCP连接</p><pre><code>复制代码[sunjimeng@localhost ~]$ netstat -natActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State      tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN     tcp        0      0 192.168.142.128:44060   52.27.123.81:443        ESTABLISHEDtcp        0      0 192.168.142.128:52438   115.28.122.210:80       ESTABLISHEDtcp6       0      0 :::22                   :::*                    LISTEN     tcp6       0      0 ::1:631                 :::*                    LISTEN     tcp6       0      0 ::1:25                  :::*                    LISTEN     [sunjimeng@localhost ~]$ netstat -ntActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State      tcp        0      0 192.168.142.128:44060   52.27.123.81:443        ESTABLISHEDtcp        0      0 192.168.142.128:52438   115.28.122.210:80       ESTABLISHED</code></pre><p>5)[sunjimeng@localhost ~]$ netstat -nupa　　　　　显示UDP端口号的使用情况</p><pre><code>复制代码[sunjimeng@localhost ~]$ netstat -nupa                    //没有root权限(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)Active Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    udp        0      0 0.0.0.0:68              0.0.0.0:*                           -                   udp        0      0 0.0.0.0:123             0.0.0.0:*                           -                   udp        0      0 127.0.0.1:323           0.0.0.0:*                           -                   udp      768      0 192.168.142.128:39404   192.168.142.2:53        ESTABLISHED 18744/netstat       udp        0      0 0.0.0.0:27664           0.0.0.0:*                           -                   udp        0      0 0.0.0.0:5353            0.0.0.0:*                           -                   udp        0      0 0.0.0.0:52525           0.0.0.0:*                           -                   udp6       0      0 :::123                  :::*                                -                   udp6       0      0 ::1:323                 :::*                                -                   udp6       0      0 :::14031                :::*                                -                   [sunjimeng@localhost ~]$ su root密码：[root@localhost sunjimeng]# netstat -aunp   　　　　　　　　 //有root权限Active Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    udp        0      0 0.0.0.0:68              0.0.0.0:*                           14421/dhclient      udp        0      0 0.0.0.0:123             0.0.0.0:*                           781/chronyd         udp        0      0 127.0.0.1:323           0.0.0.0:*                           781/chronyd         udp      768      0 192.168.142.128:39404   192.168.142.2:53        ESTABLISHED 18744/netstat       udp        0      0 0.0.0.0:27664           0.0.0.0:*                           14421/dhclient      udp        0      0 0.0.0.0:5353            0.0.0.0:*                           797/avahi-daemon: r udp        0      0 0.0.0.0:52525           0.0.0.0:*                           797/avahi-daemon: r udp        0      0 192.168.142.128:34639   192.168.142.2:53        ESTABLISHED 20626/python        udp6       0      0 :::123                  :::*                                781/chronyd         udp6       0      0 ::1:323                 :::*                                781/chronyd         udp6       0      0 :::14031                :::*                                14421/dhclient  </code></pre><p>6)[root@localhost sunjimeng]# netstat -i　　　　　　显示网卡列表</p><pre><code>[root@localhost sunjimeng]# netstat -iKernel Interface tableIface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flgeno16777  1500   302197      0      1 0         90150      0      0      0 BMRUlo       65536     2293      0      0 0          2293      0      0      0 LRU</code></pre><p>7)[root@localhost sunjimeng]# netstat -s　　　　　 显示网络统计信息</p><pre><code>复制代码[root@localhost sunjimeng]# netstat -sIp:    132373 total packets received    0 forwarded    0 incoming packets discarded    130636 incoming packets delivered    93212 requests sent out    500 outgoing packets dropped    69 dropped because of missing routeIcmp:    1149 ICMP messages received    0 input ICMP message failed.    ICMP input histogram:        destination unreachable: 1044        timeout in transit: 28        echo requests: 26        echo replies: 51    1283 ICMP messages sent    0 ICMP messages failed    ICMP output histogram:        destination unreachable: 1066        echo request: 191        echo replies: 26IcmpMsg:        InType0: 51        InType3: 1044        InType8: 26        InType11: 28        OutType0: 26        OutType3: 1066        OutType8: 191Tcp:    1330 active connections openings    0 passive connection openings    75 failed connection attempts    9 connection resets received    2 connections established    125542 segments received    86517 segments send out    421 segments retransmited    3 bad segments received.    99 resets sentUdp:    2894 packets received    1053 packets to unknown port received.    0 packet receive errors    4969 packets sent    0 receive buffer errors    0 send buffer errorsUdpLite:TcpExt:    706 TCP sockets finished time wait in fast timer    508 delayed acks sent    9 delayed acks further delayed because of locked socket    Quick ack mode was activated 3 times    94581 packet headers predicted    2447 acknowledgments not containing data payload received    2473 predicted acknowledgments    22 congestion windows recovered without slow start after partial ack    174 other TCP timeouts    1 connections reset due to unexpected data    1 connections reset due to early user close    IPReversePathFilter: 1    TCPRcvCoalesce: 44130    TCPChallengeACK: 3    TCPSYNChallenge: 3IpExt:    InNoRoutes: 382    InMcastPkts: 661    OutMcastPkts: 255    InBcastPkts: 15    OutBcastPkts: 15    InOctets: 420174480    OutOctets: 5078197    InMcastOctets: 101685    OutMcastOctets: 39453    InBcastOctets: 1170    OutBcastOctets: 1170</code></pre><p>8)[root@localhost sunjimeng]# netstat -r　　　　　　　　显示路由表的信息</p><pre><code>复制代码[root@localhost sunjimeng]# netstat -rKernel IP routing tableDestination     Gateway         Genmask         Flags   MSS Window  irtt Ifacedefault         192.168.142.2   0.0.0.0         UG        0 0          0 eno16777736192.168.142.0   0.0.0.0         255.255.255.0   U         0 0          0 eno16777736192.168.142.0   0.0.0.0         255.255.255.0   U         0 0          0 eno16777736[root@localhost sunjimeng]# routeKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Ifacedefault         192.168.142.2   0.0.0.0         UG    100    0        0 eno16777736192.168.142.0   0.0.0.0         255.255.255.0   U     0      0        0 eno16777736192.168.142.0   0.0.0.0         255.255.255.0   U     100    0        0 eno16777736</code></pre><p>(5)其他:</p><pre><code>   Linux网络套接字:   套接字连接的过程如同（客户）打一个电话到一个大公司，接线员（服务器进程）接听电话并把它转接到你要找的部门，然后再从那里转到你要找的人（服务器套接字），然后接线员（服务器进程）再继续转接其它（客户）的电话。  套接字有本地套接字和网络套接字两种。本地套接字的名字是Linux文件系统中的文件名，一般放在/tmp或/usr/tmp目录中；网络套接字的名字是与客户连接的特定网络有关的服务标识符（端口号或访问点）。这个标识符允许Linux将进入的针对特定端口号的连接转到正确的服务器进程。  套接字的连接建立过程:http://blog.chinaunix.net/uid-25829053-id-3015832.html;  Java通信中的套接字连接过程:http://www.cnblogs.com/MenAngel/p/5317082.html;</code></pre><h2 id="2017-08-11-每天2个Linux命令-ss命令"><a href="#2017-08-11-每天2个Linux命令-ss命令" class="headerlink" title=" 2017-08-11 每天2个Linux命令 ss命令"></a><center> 2017-08-11 每天2个Linux命令 ss命令</center></h2><p>ss命令用来显示处于活动状态的套接字信息。</p><p>(1)用法:</p><pre><code>用法:  ss  [参数]    ss  [参数]  [过滤]</code></pre><p>(2)功能:</p><pre><code>功能:  ss是类似netstat的工具。能显示查看网络状态信息，包括TCP、UDP连接，端口。ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。 注意:  当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢。可能你不会有切身的感受，但请相信我，当服务器维持的连接达到上万个的时候，使用netstat等于浪费生命，而用ss才是节省时间。ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效。当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢。</code></pre><p>(3)选项参数</p><pre><code>  1) -t, --tcp 　　　　　　　　仅显示TCP套接字（sockets）  2) -a, --all 　　　　　　　　显示所有套接字（sockets）  3) -s, --summary 　　　　  显示套接字（socket）使用概况   4) -l 　　　　　　　　　　　 显示LISTEN状态的连接(连接打开)  5) -p, --processes 　　       显示使用套接字（socket）的进程  6) -u, --udp 　　　　　　    仅显示 UCP套接字（sockets）  7) -d, --dccp 　　　　　　   仅显示 DCCP套接字（sockets）  8) -w, --raw 　　　　　　　 仅显示 RAW套接字（sockets）  9) -x, --unix 　　　　　　　 仅显示 Unix套接字（sockets）</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# ss -t -a　　　　　　显示TCP连接复制代码[root@localhost sunjimeng]# ss -t -aState      Recv-Q Send-Q      Local Address:Port          Peer Address:Port   LISTEN     0      128                     *:ssh                      *:*       LISTEN     0      128             127.0.0.1:ipp                      *:*       LISTEN     0      100             127.0.0.1:smtp                     *:*       TIME-WAIT  0      0         192.168.142.128:52859       115.28.122.210:http    TIME-WAIT  0      0         192.168.142.128:53367      112.124.140.210:http    LISTEN     0      128                    :::ssh                     :::*       LISTEN     0      128                   ::1:ipp                     :::*       LISTEN     0      100                   ::1:smtp                    :::*       [root@localhost sunjimeng]# netstat -taActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State      tcp        0      0 0.0.0.0:ssh             0.0.0.0:*               LISTEN     tcp        0      0 localhost:ipp           0.0.0.0:*               LISTEN     tcp        0      0 localhost:smtp          0.0.0.0:*               LISTEN     tcp        0      0 192.168.142.128:52926   ec2-52-36-148-12.:https ESTABLISHEDtcp        0      0 192.168.142.128:54577   ec2-52-26-186-108:https ESTABLISHEDtcp        0      0 192.168.142.128:54576   ec2-52-26-186-108:https ESTABLISHEDtcp6       0      0 [::]:ssh                [::]:*                  LISTEN     tcp6       0      0 localhost:ipp           [::]:*                  LISTEN     tcp6       0      0 localhost:smtp          [::]:*                  LISTEN </code></pre><p>2)[root@localhost sunjimeng]# ss -s　显示套接字使用概况(列出当前的established, closed, orphaned and waiting TCP sockets)</p><pre><code>复制代码[root@localhost sunjimeng]# ss -sTotal: 1133 (kernel 1377)TCP:   7 (estab 0, closed 1, orphaned 0, synrecv 0, timewait 0/0), ports 0Transport Total     IP        IPv6*      1377      -         -        RAW      1         0         1        UDP      9         6         3        TCP      6         3         3        INET      16        9         7        FRAG      0         0         0     </code></pre><p>3)[root@localhost sunjimeng]# ss -l　　　　　　　　列出所有打开的网络连接端口，即已经连接的网络端口</p><pre><code>复制代码[root@localhost sunjimeng]# ss -lNetid  State      Recv-Q Send-Q           Local Address:Port               Peer Address:Port   nl     UNCONN     0      0                         rtnl:NetworkManager/929                        *       nl     UNCONN     0      0                         rtnl:gnome-shell/3126                        *       ......u_dgr  UNCONN     0      0                            * 246524                        * 1492   u_dgr  UNCONN     0      0                            * 158303                        * 1492   raw    UNCONN     0      0                           :::ipv6-icmp                      :::*       tcp    UNCONN     0      0                            *:ipproto-68                       *:*       tcp    UNCONN     0      0                            *:ptp                           *:*       tcp    UNCONN     0      0                    127.0.0.1:ipproto-323                       *:*       tcp    UNCONN     0      0                            *:ipproto-5353                       *:*       tcp    UNCONN     0      0                            *:ipproto-52525                       *:*       tcp    UNCONN     0      0                            *:ipproto-16290                       *:*       tcp    UNCONN     0      0                           :::ptp                          :::*       tcp    UNCONN     0      0                          ::1:ipproto-323                      :::*       tcp    UNCONN     0      0                           :::ipproto-44068                      :::*       tcp    LISTEN     0      128                          *:ssh                           *:*       tcp    LISTEN     0      128                  127.0.0.1:ipp                           *:*       tcp    LISTEN     0      100                  127.0.0.1:smtp                          *:*       tcp    LISTEN     0      128                         :::ssh                          :::*       tcp    LISTEN     0      128                        ::1:ipp                          :::*       tcp    LISTEN     0      100                        ::1:smtp                         :::*   复制代码</code></pre><p> 4)[root@localhost sunjimeng]# ss -t -a -p　　　　　　显示使用套接字的进程的信息</p><pre><code>复制代码[root@localhost sunjimeng]# ss -t -aState      Recv-Q Send-Q              Local Address:Port                  Peer Address:Port   LISTEN     0      128                             *:ssh                              *:*       LISTEN     0      128                     127.0.0.1:ipp                              *:*       LISTEN     0      100                     127.0.0.1:smtp                             *:*       LISTEN     0      128                            :::ssh                             :::*       LISTEN     0      128                           ::1:ipp                             :::*       LISTEN     0      100                           ::1:smtp                            :::*       [root@localhost sunjimeng]# ss -t -a -pState      Recv-Q Send-Q              Local Address:Port                  Peer Address:Port   LISTEN     0      128                             *:ssh                              *:*        users:(("sshd",1324,3))LISTEN     0      128                     127.0.0.1:ipp                              *:*        users:(("cupsd",3130,12))LISTEN     0      100                     127.0.0.1:smtp                             *:*        users:(("master",2575,13))LISTEN     0      128                            :::ssh                             :::*        users:(("sshd",1324,4))LISTEN     0      128                           ::1:ipp                             :::*        users:(("cupsd",3130,11))LISTEN     0      100                           ::1:smtp                            :::*        users:(("master",2575,14))</code></pre><p>5)[root@localhost sunjimeng]# ss -pl |grep 1487　　　显示端口号为1487的已连接的套接字的进程信息</p><pre><code>[root@localhost sunjimeng]# ss -pl |grep 1487u_str  LISTEN     0      128    /run/systemd/journal/stdout 1487                  * 0       users:(("systemd-journal",617,3),("systemd",1,25))[root@localhost sunjimeng]# </code></pre><p>6)两个命令的时间对比：</p><pre><code>复制代码[root@localhost sunjimeng]# time ssreal    0m0.081suser    0m0.000ssys    0m0.004s[root@localhost sunjimeng]# time netstatreal    0m0.018suser    0m0.004ssys    0m0.000s[root@localhost sunjimeng]# </code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 ping traceroute</title>
      <link href="/2017/08/10/mei-tian-2-ge-linux-ming-ling-ping-traceroute/"/>
      <url>/2017/08/10/mei-tian-2-ge-linux-ming-ling-ping-traceroute/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-10-每天2个Linux命令-ping命令"><a href="#2017-08-10-每天2个Linux命令-ping命令" class="headerlink" title=" 2017-08-10 每天2个Linux命令 ping命令"></a><center> 2017-08-10 每天2个Linux命令 ping命令</center></h2><p>ping命令用来测试主机之间网络的连通性。</p><p>(1)用法:</p><pre><code>用法:  ping [参数] [主机名或IP地址]</code></pre><p>(2)功能:</p><pre><code>功能:  确定网络和各外部主机的状态；跟踪和隔离硬件和软件问题；测试、评估和管理网络。  细节:  执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。例如:  “ping一下某机器，看是不是开着”、不能打开网页时“先ping网关地址192.168.1.1试试”。ping 命令每秒发送一个数据报并且为每个接收到的响应打印一行输出。ping 命令计算信号往返时间和(信息)包丢失情况的统计信息，并且在完成之后显示一个简要总结。ping 命令在程序超时或当接收到 SIGINT 信号时结束。Host 参数或者是一个有效的主机名或者是因特网地址。注意:  有些服务器为了防止通过ping探测到，通过防火墙设置了禁止ping或者在内核参数中禁止ping，这样就不能通过ping确定该主机是否还处于开启状态。</code></pre><p>(3)选项参数:</p><pre><code>  1) -b  n:　　　 　　　  测试与网关IP的连通性  2) -c  n:　　　　　　   执行指定次数 n的ping命令  3) -i  n：　　　　　　  设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次。  4) -s 字节数：　　　　  指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节。  5) -t 存活数值：　　　　设置存活数值TTL的大小。</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost ~]# ping 192.168.120.205　　　　　　　　　　用ping命令测试与目标站点IP的连通情况复制代码[root@localhost ~]# ping 192.168.120.205PING 192.168.120.205 (192.168.120.205) 56(84) bytes of data.64 bytes from 192.168.120.205: icmp_seq=1 ttl=64 time=0.720 ms64 bytes from 192.168.120.205: icmp_seq=2 ttl=64 time=0.181 ms64 bytes from 192.168.120.205: icmp_seq=3 ttl=64 time=0.191 ms64 bytes from 192.168.120.205: icmp_seq=4 ttl=64 time=0.188 ms64 bytes from 192.168.120.205: icmp_seq=5 ttl=64 time=0.189 ms--- 192.168.120.205 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4000msrtt min/avg/max/mdev = 0.181/0.293/0.720/0.214 ms[root@localhost ~]# </code></pre><p>2)[root@localhost ~]# ping 192.168.120.202　　　　　　　　　　ping命令不连通时</p><pre><code>复制代码[root@localhost ~]# ping 192.168.120.202PING 192.168.120.202 (192.168.120.202) 56(84) bytes of data.From 192.168.120.204 icmp_seq=1 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=2 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=3 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=4 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=5 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=6 Destination Host Unreachable--- 192.168.120.202 ping statistics ---packets transmitted, 0 received, +6 errors, 100% packet loss, time 7005ms, pipe 4[root@localhost ~]#</code></pre><p>3)[root@localhost ~]# ping -b 192.168.120.1　　　　　　　　　　ping命令测试与网关IP的连通性</p><pre><code>复制代码[root@localhost ~]# routeKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface192.168.120.0   *               255.255.255.0   U     0      0        0 eth0192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth010.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0default         192.168.120.240 0.0.0.0         UG    0      0        0 eth0[root@localhost ~]# ping -b 192.168.120.1PING 192.168.120.1 (192.168.120.1) 56(84) bytes of data.bytes from 192.168.120.1: icmp_seq=1 ttl=255 time=2.02 msbytes from 192.168.120.1: icmp_seq=2 ttl=255 time=1.83 msbytes from 192.168.120.1: icmp_seq=3 ttl=255 time=1.68 msbytes from 192.168.120.1: icmp_seq=4 ttl=255 time=1.98 msbytes from 192.168.120.1: icmp_seq=5 ttl=255 time=1.88 ms--- 192.168.120.1 ping statistics ---packets transmitted, 5 received, 0% packet loss, time 4000msrtt min/avg/max/mdev = 1.682/1.880/2.020/0.129 ms</code></pre><p>4)[root@localhost ~]# ping -c 10 192.168.120.206　　　　　　    ping指定的次数</p><pre><code>复制代码[root@localhost ~]# ping -c 10 192.168.120.206PING 192.168.120.206 (192.168.120.206) 56(84) bytes of data.bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=1.25 msbytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.260 msbytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.242 msbytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.271 msbytes from 192.168.120.206: icmp_seq=5 ttl=64 time=0.274 msbytes from 192.168.120.206: icmp_seq=6 ttl=64 time=0.295 msbytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.269 msbytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.270 msbytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.253 msbytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.289 ms--- 192.168.120.206 ping statistics ---packets transmitted, 10 received, 0% packet loss, time 9000msrtt min/avg/max/mdev = 0.242/0.367/1.251/0.295 ms[root@localhost ~]#</code></pre><p>5)[root@localhost ~]# ping -c 10 -i 0.5 192.168.120.206　　　　指定时间间隔和参数限制</p><pre><code>复制代码[root@localhost ~]# ping -c 10 -i 0.5 192.168.120.206PING 192.168.120.206 (192.168.120.206) 56(84) bytes of data.bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=1.24 msbytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.235 msbytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.244 msbytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.300 msbytes from 192.168.120.206: icmp_seq=5 ttl=64 time=0.255 msbytes from 192.168.120.206: icmp_seq=6 ttl=64 time=0.264 msbytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.263 msbytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.331 msbytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.247 msbytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.244 ms--- 192.168.120.206 ping statistics ---packets transmitted, 10 received, 0% packet loss, time 4499msrtt min/avg/max/mdev = 0.235/0.362/1.241/0.294 ms[root@localhost ~]# ping -c 10 -i 0.01 192.168.120.206PING 192.168.120.206 (192.168.120.206) 56(84) bytes of data.bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=0.244 msbytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.195 msbytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.219 msbytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.204 msbytes from 192.168.120.206: icmp_seq=5 ttl=64 time=3.56 msbytes from 192.168.120.206: icmp_seq=6 ttl=64 time=1.93 msbytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.193 msbytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.193 msbytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.202 msbytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.211 ms--- 192.168.120.206 ping statistics ---packets transmitted, 10 received, 0% packet loss, time 90msrtt min/avg/max/mdev = 0.193/0.716/3.564/1.080 ms[root@localhost ~]#参数说明:  什么是TTL？  TTL 指定数据报被路由器丢弃之前允许通过的网段数量。它是为了防止数据包在网络中无限制的循环，而设定的网络数据包在网络传输中最大的转发次数。因为每转发一次在路由器，就会转向下一跳，所以，又通常称为最大跳数。具体的含义是这样的。我们本地机器会发出一个数据包，数据包经过一定数量的路由器传送到目的主机，但是由于很多的原因，一些数据包不能正常传送到目的主机，那如果不给这些数据包一个生存时间的话，这些数据包会一直在网络上传送，导致网络开销的增大。当数据包传送到一个路由器之后，TTL就自动减1，如果减到0了还是没有传送到目的主机，那么就自动丢失。例如:你定义了数据包的TTL为64.那么在你的数据包被转发了64次，也就是经过了63个中间路由器后，还没有到达目的网络，那么，你的电脑就会显示Requet time out （请求超时）了。例如:你定义了数据包的TTL为64.那么在你的数据包被转发了64次，也就是经过了63个中间路由器后，还没有到达目的网络，那么，你的电脑就会显示Requet time out （请求超时）了。这就是TTL的意思了。在此补充一点，由于不同的操作系统所定义的TTL是不同的，一般有如下规则：默认情况下，Linux系统的TTL值为64或255，Windows NT/2000/XP系统的TTL值为128，Windows 98系统的TTL值为32，UNIX主机的TTL值为255。</code></pre><p>(5)其他:</p><pre><code>  1)ICMP协议:  ping 程序使用 ICMP 协议的强制回显请求数据报以使主机或网关发送一份 ICMP 的回显应答。  ICMP是“Internet Control Message Protocol”（Internet控制消息协议）的缩写。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。  2)回显请求数据报:  回显请求数据报(" pings ")含有一个 IP 及 ICMP 的报头，后跟一个时间值关键字，然后是一段任意长度的填充字节用于把保持分组长度为16的整数倍。  3)Linux下的ping和windows下的ping的区别:  linux下的ping和windows下的ping稍有区别,linux下ping不会自动终止,需要按ctrl+c终止或者用参数-c指定要求完成的回应次数。</code></pre><p>4)VMWare网络模式介绍及配置:  </p><pre><code>  4.1VMWare的网络模式:VMWare提供了三种工作模式，它们是bridged(桥接模式)、NAT(网络地址转换模式)和host-only(主机模式)。  桥接模式：在桥接模式下，VMware虚拟机里的系统就像是局域网中的一台独立的主机，它可以访问同一个网段内任何一台机器，即可以相互ping通。在桥接模式下，你需要手工为虚拟系统配置IP地址、子网掩码，而且还要和宿主机器处于同一网段，这样虚拟系统才能和宿主机器进行通信。同时，由于这个虚拟系统是局域网中的一个独立的主机系统，就可以手工配置它的IP，DNS服务器，网关等信息，以实现通过局域网的网关或通过交换机访问外网。让虚拟机具有与宿主机不同的各自独立IP地址，但与宿主机保持在同一网段，最终结果是所有虚拟机都加入宿主主机所在的局域网，这与在该局域网中添加入其他宿主主机在效果上没什么区别。从网络技术上相当于在宿主主机前端加设了一个虚拟交换机，然后宿主主机和所有虚机共享这个交换机；或者干脆理解成在宿主主机上作点增强，使其兼具一个交换机（当然是虚拟的）功能，供该宿主主机和网段内其他虚机使用。图中的局域网，可能由路由器或者交换机建立。本地物理网卡和虚拟网卡通过虚拟交换机进行桥接，物理网卡和虚拟网卡在拓扑图上处于同等地位。Vmware默认给虚拟系统提供了一个虚拟网卡（linux下默认为eth0设备），虚拟系统通过该网卡与外部通信。图中虚拟交换机由vmware提供，其默认设备名为 VMnet0。NAT模式：NAT 即 Network Address Translation 缩写，即网络地址转换，由 NAT服务完成。在vmware里默认为VMnet8虚拟交换机，它将虚拟系统的IP地址转换成宿主机的IP地址，从而借用宿主机访问其他主机。使用NAT模式，也可以让虚拟系统通过宿主机器所在的网络来访问公网。在这种模式下，虚拟系统是不能被LAN内其他PC访问的，只能虚拟机以宿主机的名义访问LAN内的计算机。默认情况下NAT模式的虚拟系统的TCP/IP配置信息由VMnet8(NAT)虚拟网络的DHCP服务器提供，因此采用NAT模式最大的优势是虚拟系统接入互联网非常简单，你不需要进行任何其他的配置，只需要宿主机器能访问互联网即可。使用NAT方式时，宿主机（Windows）网络管理里会多出一块虚拟网卡， 名为VMware Network Adepter VMnet8 如下图：虽然从表面现象看，虚机无自己的IP地址，而是共享宿主主机的IP地址，但技术本质上却是基于Host-only方式的（即，虚机还是有自己独立IP地址的，只不过实际中不投入使用），与Host-only方式一样，宿主主机成为双网卡主机，同时参与现有的宿主局域网和新建的虚拟局域网，但由于加设了一个虚拟的NAT服务器，使得虚拟局域网内的虚机在对外访问时，完全“冒用”宿主主机的IP地址，这样从外部网络来看，只能看到宿主主机，完全看不到新建的虚拟局域网。Host-only(主机模式)：让虚机具有与宿主机不同的各自独立IP地址，但与宿主机位于不同网段，同时为宿主主机新增一个IP地址，且保证该IP地址与各虚机IP地址位于同一网段。最终结果是新建了一个由所有虚机与宿主主机所构成的局域网，但该局域网与宿主主机本身所处的现有局域网是相互独立的，如果不做额外路由设置，这两个局域网之间不会连通，因此新建的局域网可以认为是一个单独从属于当前宿主主机的私有网络，其成员为当前宿主主机和相关的所有虚机，这也是Host-only命名的由来。 从网络技术上相当于为宿主主机增添了一个虚拟网卡，让宿主主机变成一台双网卡主机（宿主网卡+虚拟网卡）。同时在宿主主机后端加设一个虚拟交换机，让宿主主机和所有虚机构成另一个虚拟的局域网。由于具备双网卡，宿主主机可同时参与两个局域网（现有的宿主局域网+新建的虚拟局域网），只不过缺省情况下两个局域网不连通。</code></pre><h2 id="2017-08-10-每天2个Linux命令-traceroute命令"><a href="#2017-08-10-每天2个Linux命令-traceroute命令" class="headerlink" title=" 2017-08-10 每天2个Linux命令 traceroute命令"></a><center> 2017-08-10 每天2个Linux命令 traceroute命令</center></h2><p>traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes。</p><p>(1)用法:</p><pre><code>用法: traceroute [参数] [主机]</code></pre><p>(2)功能:</p><pre><code>功能: 通过traceroute可以知道信息从计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其ip地址。</code></pre><p>(3)选项参数:</p><pre><code>  1) -m 　　　　　　设置检测数据包的最大存活数值TTL的大小。  2) -n 　　　　 　　直接使用IP地址而非主机名称。  3) -w&lt;超时秒数&gt;  设置等待远端主机回报的时间  4) -r 　　　　　　  忽略普通的Routing Table，直接将数据包送到远端主机上。  5) -q　　　　　　　设置发送探测包的个数</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# traceroute www.baidu.com　　　　　　　　查询到百度的站点经过的路径复制代码[root@localhost sunjimeng]# traceroute www.baidu.comtraceroute to www.baidu.com (14.215.177.37), 30 hops max, 60 byte packets 1  192.168.142.2 (192.168.142.2)  0.116 ms  0.071 ms  0.132 ms 2  * * * 3  * * * 4  * * * 5  * * *......30 * * *复制代码注意:  有时我们traceroute一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。     </code></pre><p>2)[root@localhost sunjimeng]# traceroute -q 4 <a href="http://www.baidu.com/">www.baidu.com</a>　　　　　　把探测包的个数设置为值4（默认是三次）</p><pre><code>复制代码[root@localhost sunjimeng]# traceroute -q 4 www.baidu.comtraceroute to www.baidu.com (14.215.177.38), 30 hops max, 60 byte packets 1  192.168.142.2 (192.168.142.2)  0.114 ms  0.143 ms  0.103 ms  0.135 ms 2  * * * * 3  * * * * 4  * * * * 5  * * * *......30 * * * *</code></pre><p>3)[root@localhost sunjimeng]# traceroute -n <a href="http://www.baidu.com/">www.baidu.com</a>　　　　　　   显示IP地址，不查主机名</p><pre><code>复制代码[root@localhost sunjimeng]# traceroute -n www.baidu.comtraceroute to www.baidu.com (14.215.177.38), 30 hops max, 60 byte packets 1  192.168.142.2  0.151 ms  0.107 ms  0.060 ms　　　　　　　　　　　　　　 2  * * * 3  * * * 4  * * * 5  * * *......30 * * *注意：有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n参数来避免DNS解析，以IP格式输出数据。</code></pre><p>4)[root@localhost sunjimeng]# traceroute -m 5 <a href="http://www.baidu.com/">www.baidu.com</a>　　　　　　设置跳数</p><pre><code>复制代码[root@localhost sunjimeng]# traceroute -m 5 www.baidu.comtraceroute to www.baidu.com (14.215.177.38), 5 hops max, 60 byte packets 1  192.168.142.2 (192.168.142.2)  0.100 ms  0.130 ms  0.052 ms 2  * * * 3  * * * 4  * * * 5  * * *[root@localhost sunjimeng]# </code></pre><p>5)[root@localhost sunjimeng]# traceroute -r <a href="http://www.baidu.com/">www.baidu.com</a>　　　　　　　绕过正常的路由表，直接发送到与当前主机相连的IP地址</p><pre><code>[root@localhost sunjimeng]# traceroute -r www.baidu.comtraceroute to www.baidu.com (14.215.177.38), 30 hops max, 60 byte packetsconnect: 网络不可达[root@localhost sunjimeng]# traceroute -r 0.0.0.0traceroute to 0.0.0.0 (0.0.0.0), 30 hops max, 60 byte packets 1  localhost (127.0.0.1)  0.104 ms  0.012 ms  0.009 ms</code></pre><p>(5)其他:</p><pre><code>traceroute的工作原理:  Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）:首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地。当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器......traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？ Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。windows下的tracert:      在大多数情况下，我们会在linux主机系统下，直接执行命令行：　　traceroute hostname。而在Windows系统下是执行tracert的命令：                             tracert hostname。 　　</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 ifconfig route</title>
      <link href="/2017/08/10/mei-tian-2-ge-linux-ming-ling-ifconfig-route/"/>
      <url>/2017/08/10/mei-tian-2-ge-linux-ming-ling-ifconfig-route/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-09-每天2个Linux命令-ifconfig命令"><a href="#2017-08-09-每天2个Linux命令-ifconfig命令" class="headerlink" title=" 2017-08-09 每天2个Linux命令 ifconfig命令"></a><center> 2017-08-09 每天2个Linux命令 ifconfig命令</center></h2><p>在windows系统中，ipconfig命令行工具被用来获取网络接口配置信息并对此进行修改。Linux系统拥有一个类似的工具，也就是ifconfig(interfaces config)。</p><p>(1)用法:</p><pre><code>用法:  ifconfig [网络设备] [参数]</code></pre><p>(2)功能:</p><pre><code>功能:  ifconfig命令用来查看和配置网络设备，当网络环境发生改变时可通过此命令对网络进行相应的配置。注意:  用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在。要想将上述的配置信息永远的存在电脑里，那就要修改网卡的配置文件了。</code></pre><p>(3)选项参数:</p><pre><code>  1)  up 　　　　     　　启动指定网络设备/网卡。  2)  down 　　      　　 关闭指定网络设备/网卡。该参数可以有效地阻止通过指定接口的IP信息流，如果想永久地关闭一个接口，我们还需要从核心路由表中将该接口的路由信息全部删除。  3) -a　　　　　　 　　 无论是否激活，显示所有配置的网络接口。  4) add 　　　　  　　 给指定网卡配置IPv6地址5) del　　　　　　　　  删除指定网卡的IPv6地址  6) arp|-arp　　　 　　  打开或关闭支持ARP协议  7) mtu&lt;字节数&gt;  　　  设置网卡的最大传输单元  8) netmask&lt;子网掩码&gt; 设置网卡的子网掩码</code></pre><p>(4)实例:</p><pre><code>  1)[sunjimeng@localhost ~]$ ifconfig　　　　　　　　复制代码[sunjimeng@localhost ~]$ ifconfig 　　　　　　　　//未联网时的参数eno16777736: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        ether 00:0c:29:4d:a3:cc  txqueuelen 1000  (Ethernet)        RX packets 1914  bytes 174936 (170.8 KiB)        RX errors 0  dropped 36  overruns 0  frame 0        TX packets 0  bytes 0 (0.0 B)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 0  (Local Loopback)        RX packets 3246  bytes 281472 (274.8 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 3246  bytes 281472 (274.8 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0复制代码复制代码[sunjimeng@localhost ~]$ ifconfig                   //连接到有线网时的参数eno16777736: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500                //mtu表示最大传输单元        inet 192.168.117.128  netmask 255.255.255.0  broadcast 192.168.117.255        inet6 fe80::20c:29ff:fe4d:a3cc  prefixlen 64  scopeid 0x20&lt;link&gt;        ether 00:0c:29:4d:a3:cc  txqueuelen 1000  (Ethernet)        RX packets 1969  bytes 181974 (177.7 KiB)        RX errors 0  dropped 36  overruns 0  frame 0        TX packets 48  bytes 6324 (6.1 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 0  (Local Loopback)        RX packets 3590  bytes 310452 (303.1 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 3590  bytes 310452 (303.1 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0复制代码    说明:　　1）etn(Number)指的是网卡，可以看到目前这个网卡的物理地址(MAC地址）是 00:0c:29:4d:a3:cc。      2）inet后表示ip地址，此网卡的ip地址是192.168.117.128，广播地址是192.168.117.255，掩码地址为255.255.255.0。      3）lo是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。　　比如把 http服务器指定到回环地址，在浏览器输入127.0.0.1就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。</code></pre><p>2)[root@localhost sunjimeng]# ifconfig eno16777736 down　　　　打开和关闭指定网卡</p><pre><code>复制代码[sunjimeng@localhost ~]$ ifconfig eno16777736 down　　　　　　//必须是root权限才可以SIOCSIFFLAGS: 不允许的操作[sunjimeng@localhost ~]$ su root密码：[root@localhost sunjimeng]# ifconfig eno16777736 down[root@localhost sunjimeng]# ifconfiglo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 0  (Local Loopback)        RX packets 3598  bytes 311224 (303.9 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 3598  bytes 311224 (303.9 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0[root@localhost sunjimeng]# ifconfig eno16777736 up[root@localhost sunjimeng]# ifconfigeno16777736: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        ether 00:0c:29:4d:a3:cc  txqueuelen 1000  (Ethernet)        RX packets 2013  bytes 185705 (181.3 KiB)        RX errors 0  dropped 36  overruns 0  frame 0        TX packets 88  bytes 9726 (9.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 0  (Local Loopback)        RX packets 3602  bytes 311520 (304.2 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 3602  bytes 311520 (304.2 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0复制代码      注意：ssh登陆linux服务器，关闭了网卡就不能开启了，除非你有多网卡。</code></pre><p>3)[root@localhost sunjimeng]# ifconfig -a　　　　　　无论是否激活，显示所有配置的网络接口，不带参数的只显示已激活的网络接口</p><pre><code>复制代码[root@localhost sunjimeng]# ifconfig -aeno16777736: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        ether 00:0c:29:4d:a3:cc  txqueuelen 1000  (Ethernet)        RX packets 2016  bytes 185981 (181.6 KiB)        RX errors 0  dropped 36  overruns 0  frame 0        TX packets 88  bytes 9726 (9.4 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 0  (Local Loopback)        RX packets 3602  bytes 311520 (304.2 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 3602  bytes 311520 (304.2 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</code></pre><p>4)启用或关闭支持ARP协议</p><pre><code>[root@localhost sunjimeng]# ifconfig eno16777736 arp[root@localhost sunjimeng]# ifconfig eno16777736 -arp</code></pre><p>5)[root@localhost sunjimeng]# ifconfig eno16777736 mtu 2000　　　　设置网络设备传输的最大单元</p><pre><code>复制代码[root@localhost sunjimeng]# ifconfigeno16777736: flags=4291&lt;UP,BROADCAST,RUNNING,NOARP,MULTICAST&gt;  mtu 1500        inet 192.168.117.128  netmask 255.255.255.0  broadcast 192.168.117.255        inet6 fe80::20c:29ff:fe4d:a3cc  prefixlen 64  scopeid 0x20&lt;link&gt;        ether 00:0c:29:4d:a3:cc  txqueuelen 1000  (Ethernet)        RX packets 75518  bytes 108412465 (103.3 MiB)        RX errors 0  dropped 36  overruns 0  frame 0        TX packets 20662  bytes 1263791 (1.2 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 0  (Local Loopback)        RX packets 4381  bytes 364888 (356.3 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 4381  bytes 364888 (356.3 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0[root@localhost sunjimeng]# ifconfig eno16777736 mtu 2000[root@localhost sunjimeng]# ifconfigeno16777736: flags=4291&lt;UP,BROADCAST,RUNNING,NOARP,MULTICAST&gt;  mtu 2000        ether 00:0c:29:4d:a3:cc  txqueuelen 1000  (Ethernet)        RX packets 99762  bytes 145117330 (138.3 MiB)        RX errors 0  dropped 36  overruns 0  frame 0        TX packets 20663  bytes 1263851 (1.2 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 0  (Local Loopback)        RX packets 5243  bytes 424328 (414.3 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 5243  bytes 424328 (414.3 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</code></pre><p>6)[root@localhost sunjimeng]# ifconfig eno16777736 hw ether 00:0c:29:4d:a3:dd　　　　设置网卡的mac地址</p><pre><code>复制代码[root@localhost sunjimeng]# ifconfigeno16777736: flags=4291&lt;UP,BROADCAST,RUNNING,NOARP,MULTICAST&gt;  mtu 2000        inet 0.0.0.64  netmask 0.0.0.0  broadcast 255.255.255.255        ether 00:0c:29:4d:a3:cc  txqueuelen 1000  (Ethernet)        RX packets 109425  bytes 159195954 (151.8 MiB)        RX errors 0  dropped 36  overruns 0  frame 0        TX packets 20668  bytes 1264151 (1.2 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 0  (Local Loopback)        RX packets 33371  bytes 2821752 (2.6 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 33371  bytes 2821752 (2.6 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0[root@localhost sunjimeng]# ifconfig eno16777736 hw ether 00:0c:29:4d:a3:dd[root@localhost sunjimeng]# ifconfigeno16777736: flags=4291&lt;UP,BROADCAST,RUNNING,NOARP,MULTICAST&gt;  mtu 2000        inet 0.0.0.64  netmask 0.0.0.0  broadcast 255.255.255.255        ether 00:0c:29:4d:a3:dd  txqueuelen 1000  (Ethernet)        RX packets 109434  bytes 159196494 (151.8 MiB)        RX errors 0  dropped 36  overruns 0  frame 0        TX packets 20668  bytes 1264151 (1.2 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 0  (Local Loopback)        RX packets 34011  bytes 2876296 (2.7 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 34011  bytes 2876296 (2.7 MiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</code></pre><h2 id="2017-08-09-每天2个Linux命令-route命令"><a href="#2017-08-09-每天2个Linux命令-route命令" class="headerlink" title=" 2017-08-09 每天2个Linux命令 route命令"></a><center> 2017-08-09 每天2个Linux命令 route命令</center></h2><p>Linux系统的route命令用于显示和操作内核IP路由表（show / manipulate the IP routing table）。</p><p>(1)用法:</p><pre><code>用法:  route [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]]</code></pre><p>(2)功能:</p><pre><code>功能:  创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。当使用"add"或者"del"参数时，路由表被修改，如果没有参数，则显示路由表当前的内容。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。在Linux系统中，设置路由通常是为了解决以下问题：该Linux系统在一个局域网中，局域网中有一个网关，能够让机器访问Internet，那么就需要将这台机器的IP地址设置为Linux机器的默认路由。要注意的是，直接在命令行下执行route命令来添加路由，不会永久保存，当网卡重启或者机器重启之后，该路由就失效了；可以在/etc/rc.local中添加route命令来保证该路由设置永久有效。</code></pre><p>(3)选项参数:</p><pre><code>  1) -n:　　　　　　  不执行DNS反向查找，直接显示数字形式的IP地址  2) add:　　　　     添加一条新路由。  3) del:　　　　　　删除一条路由。  4) -net:　　　　　 目标地址是一个网络。  5) -host:　　        目标地址是一个主机。  6) netmask:　　    当添加一个网络路由时，需要使用网络掩码。   7) gw:　　　　　　 路由数据包通过网关。注意，你指定的网关必须能够达到。  8) metric：　　　　设置路由跳数。</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# route　　　　   //显示当前路由，执行DNS反向查找。复制代码[root@localhost sunjimeng]# route　　  //未连接以太网时Kernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface[root@localhost sunjimeng]# route     //连接以太网时Kernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Ifacedefault         192.168.117.2   0.0.0.0         UG    100    0        0 eno16777736192.168.117.0   0.0.0.0         255.255.255.0   U     100    0        0 eno16777736复制代码      主机网络的ip地址是192.168.117.0，若数据传送目标是在本局域网内通信，则可直接通过网卡转发数据包。      若数据传送目的是访问Internet，则由网关接口，将数据包发送到网关192.168.117.2。      参数说明:  　　1)Flags标志说明：　　   U Up表示此路由当前为启动状态；　　   H Host，表示此网关为一主机；　　   G Gateway，表示此网关为一路由器；        R Reinstate Route，使用动态路由重新初始化的路由　　  D Dynamically,此路由是动态性地写入　　  M Modified，此路由是由路由守护程序或导向器动态修改　　  ! 表示此路由当前为关闭状态</code></pre><p>2)[root@localhost sunjimeng]# route -n 　　  //显示当前路由，不执行DNS反向查找</p><pre><code>[root@localhost sunjimeng]# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         192.168.117.2   0.0.0.0         UG    100    0        0 eno16777736192.168.117.0   0.0.0.0         255.255.255.0   U     100    0        0 eno16777736      注意:虽然route -n与route的执行结果是一样的，但是前者执行时要有一个执行DNS反向查找的过程。在显示数字形式的ip地址之前有一个等待过程。route -n (-n 表示不解析名字,列出速度会比route 快)。</code></pre><p>3)[root@localhost sunjimeng]# route add -net 224.0.0.0 netmask 240.0.0.0 dev eno16777736　　　　增加一条到达244.0.0.0的路由</p><pre><code>复制代码[root@localhost sunjimeng]# route add -net 224.0.0.0 netmask 240.0.0.0 dev eno16777736[root@localhost sunjimeng]# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         192.168.117.2   0.0.0.0         UG    100    0        0 eno16777736192.168.117.0   0.0.0.0         255.255.255.0   U     100    0        0 eno16777736224.0.0.0       0.0.0.0         240.0.0.0       U     0      0        0 eno16777736</code></pre><p>4)[root@localhost sunjimeng]# route add -net 224.0.0.0 netmask 240.0.0.0 reject　　　　　　　　　　增加一条用来屏蔽当前已存在路由的路由</p><pre><code>复制代码[root@localhost sunjimeng]# route add -net 224.0.0.0 netmask 240.0.0.0 reject[root@localhost sunjimeng]# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         192.168.117.2   0.0.0.0         UG    100    0        0 eno16777736192.168.117.0   0.0.0.0         255.255.255.0   U     100    0        0 eno16777736224.0.0.0       -               240.0.0.0       !     0      -        0 -          //用来屏蔽下一行的路由224.0.0.0       0.0.0.0         240.0.0.0       U     0      0        0 eno16777736</code></pre><p>5)[root@localhost sunjimeng]# route del -net 224.0.0.0 netmask 240.0.0.0 reject dev eno16777736　　删除一条指定的路由</p><pre><code>复制代码[root@localhost sunjimeng]# route del -net 224.0.0.0 netmask 240.0.0.0 reject dev eno16777736[root@localhost sunjimeng]# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         192.168.117.2   0.0.0.0         UG    100    0        0 eno16777736192.168.117.0   0.0.0.0         255.255.255.0   U     100    0        0 eno16777736224.0.0.0       0.0.0.0         240.0.0.0       U     0      0        0 eno16777736[root@localhost sunjimeng]# route del -net 224.0.0.0 netmask 240.0.0.0 dev eno16777736[root@localhost sunjimeng]# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         192.168.117.2   0.0.0.0         UG    100    0        0 eno16777736192.168.117.0   0.0.0.0         255.255.255.0   U     100    0        0 eno16777736</code></pre><p> 6)[root@localhost sunjimeng]# route del default gw 192.168.117.2　　删除或设置默认网关</p><pre><code>复制代码[root@localhost sunjimeng]# route -del default gw 192.168.117.2　　　　　　//这里不要用-参数route：无效选项 -- droute：无效选项 -- lUsage: route [-nNvee] [-FC] [&lt;AF&gt;]           List kernel routing tables       route [-v] [-FC] {add|del|flush} ...  Modify routing table for AF.       route {-h|--help} [&lt;AF&gt;]              Detailed usage syntax for specified AF.       route {-V|--version}                  Display version/author and exit.        -v, --verbose            be verbose        -n, --numeric            don't resolve names        -e, --extend             display other/more information        -F, --fib                display Forwarding Information Base (default)        -C, --cache              display routing cache instead of FIB  &lt;AF&gt;=Use -4, -6, '-A &lt;af&gt;' or '--&lt;af&gt;'; default: inet  List of possible address families (which support routing):    inet (DARPA Internet) inet6 (IPv6) ax25 (AMPR AX.25)     netrom (AMPR NET/ROM) ipx (Novell IPX) ddp (Appletalk DDP)     x25 (CCITT X.25) [root@localhost sunjimeng]# route del default gw 192.168.117.2　　　　　　//删除默认网关[root@localhost sunjimeng]# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         192.168.117.2   0.0.0.0         UG    100    0        0 eno16777736192.168.117.0   0.0.0.0         255.255.255.0   U     100    0        0 eno16777736[root@localhost sunjimeng]# route add default gw 192.168.117.2　　　　    //设置默认网关[root@localhost sunjimeng]# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         192.168.117.2   0.0.0.0         UG    100    0        0 eno16777736192.168.117.0   0.0.0.0         255.255.255.0   U     100    0        0 eno16777736</code></pre><p>(5)其他:</p><pre><code>  网关，路由器，交换机，网桥的区别:  1)交换机:(switch)意为开关，是一种用于电（光）信号转发的网络设备。它可以为接入交换机的任意两个网络节点提供独享的电信号通路，工作于OSI参考模型的第二层，即数据链路层。  工作原理:交换机内部的CPU会在每个端口成功连接时，通过将MAC地址和端口对应，形成一张MAC表。在今后的通讯中，发往该MAC地址的数据包将仅送往其对应的端口，而不是所有的端口。因此，交换机可用于划分数据链路层广播，即冲突域；但它不能划分网络层广播，即广播域。  最常见的交换机是以太网交换机。其他常见的还有电话语音交换机、光纤交换机等。  2)路由器:  路由器(Router)，是连接因特网中各局域网、广域网的设备，它会根据信道的情况自动选择和设定路由，以最佳路径，按前后顺序发送信号。连接多个逻辑上分开的网络，所谓逻辑网络是代表一个单独的网络或者一个子网。当数据从一个子网传输到另一个子网时，可通过路由器的路由功能来完成。因此，路由器具有判断网络地址和选择IP路径的功能，它能在多网络互联环境中，建立灵活的连接，可用完全不同的数据分组和介质访问方法连接各种子网，路由器只接受源站或其他路由器的信息，属网络层的一种互联设备。  3)网关:  网关(GateWay)又称协议转换器，连接两个或更多个管理上的相异的网络/子网的节点，是一种存储转发设备，主机所发送的数据报将被传送给其他主机。  网关就是为了保证大家同在一个网络的IP， 譬如C网的网关是255.255.255.0 那么在同一个局域网（C类网）的IP只是最后一位不同，任取一台机来说，它的IP与它的网关相与，就得出他的IP前面三位的数值，大家相同，表示在同一个局域网。网关是两个区域间的桥梁，有他来决定你要访问的机器到底在那个小区域里面，并且由它来负责不同协议的转换。大多数网关运行在OSI协议模型的顶层--应用层。  4)网桥:  网桥工作在数据链路层，将两个LAN连起来，根据MAC地址来转发帧，可以看作一个“低层的路由器”（路由器工作在网络层，根据网络地址如IP地址进行转发）。网桥（Bridge）又叫桥接器，它是一种在链路层实现局域网互连的存储转发设备。网桥从一个局域网接收MAC帧，拆封、校对、校验之后，按另一个局域网的格式重新组装，发往它的物理层。 桥提供了一种连接局域网 (LAN) 段的廉价而便捷的方法。LAN 网段是连接计算机的网络媒体的单个部分。 例如，假设您有三台计算机:计算机 A、计算机 B 和计算机 C。计算机 A 有两个以太网络适配器，而计算机 B 和 C 各有一个以太网络适配器。连接 A 和 B 的以太网电缆将创建一个 LAN 网段，连接 A 和 C 的另一个以太网电缆将创建另一个 LAN 网段。 传统做法是，如果您需要网络具有多个段，则您有两个选择:路由和桥接。IP 路由是连接网络段的常用解决方案。但是，如果要安装 IP 路由，则必须购买硬件路由器或在网段之间的交接处安装计算机以用作路由器。对于每个网络段上的每台计算机，IP 路由都要求对 IP 地址进行复杂配置，而且每个网络段都需要配置为独立的子网。IP 路由是适合于大型网络的解决方案，此时可缩放性很重要，而且需要经验丰富的人员配置和维护网络。网桥虽无需进行复杂配置，但是您必须额外购买硬件网桥。如果是家庭或小型办公网络，则这两个选择都不理想，您既不愿意购买昂贵的搭桥硬件，也不愿意请有经验的人员管理 IP 路由网络。   windows计算机上只能存在一个网桥，但可以使用它来桥接该计算机在物理上允许的所有网络连接。  5)路由器和交换机的区别:  交换机发生在OSI参考模型第二层（数据链路层），而路由发生在第三层，即网络层。这一区别决定了路由和交换机在移动信息的过程中需使用不同的控制信息，所以说两者实现各自功能的方式是不同的。交换机最主要的功能就是数据交换，交换机是一种基于MAC地址识别，能完成封装转发数据包功能的网络设备.路由器最主要的功能是选路，指明一个方向。路由器有IP分配、路由寻址、地址映射、访问控制这些功能，普通交换机没有这些功能，只有三层交换机可以有这些功能。  6)数据报:Internet中，所传送的信息被划分为基本的数据单元再进行传送，这些基本的数据单元称为数据报。  7)网关和路由器的区别:  路由可以连接两个网络，网关也可以连接两个网络，那么有什么区别呢？  网关现在通常用来表示一个概念。作为内网和外网的接入点，一般我们称为网关。路由器是实质性的物理介质，我们可以称这个路由器是网关,也可以称某个主机为服务器为网关，跟具体硬件在不同网络之间互联中扮演的角色有关。一般而言:网关是一个IP地址，是一个网络连接到另一个网络的“关口”。路由器是一个物理设备。一般局域网的网关就是路由器的IP地址。  8)网桥和路由器的区别:  网桥和路由的区别在于路由不仅连接两个网络，还在网络路径选择和路径算法中有极大贡献。由于网桥是链路层设备，因此不处理数据链路层以上层次协议所加的报头. 路由器比网桥更加复杂，也具有更大的灵活性。由于路由器具有更强的不同网间的互连能力，所以其连接对象包括局域网和广域网等多种类型网络。从上面可以看出，网桥和路由器的不同主要体现在三个方面。  1.网桥是第二层的设备，而路由器是第三层的设备；  2.网桥只能连接两个相同的网络，而路由器可以连接不同网络；  3.网桥不隔离广播，而路由器可以隔离广播。  9)DNS正向与反向查找:  正向查找就是 知道域名来查找相对应的IP;反向查询就是 知道IP来查找相对应的域名。 </code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 crontab lsof</title>
      <link href="/2017/08/10/mei-tian-2-ge-linux-ming-ling-crontab-lsof/"/>
      <url>/2017/08/10/mei-tian-2-ge-linux-ming-ling-crontab-lsof/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-08-每天2个Linux命令-crontab命令"><a href="#2017-08-08-每天2个Linux命令-crontab命令" class="headerlink" title=" 2017-08-08 每天2个Linux命令 crontab命令"></a><center> 2017-08-08 每天2个Linux命令 crontab命令</center></h2><p>crontab命令被用来提交和管理用户需要周期性执行的任务，与windows下的计划任务类似。</p><p>(1)用法:</p><pre><code>用法: crontab  [-u user]  file    crontab  [-u user]  [ -e | -l | -r ]</code></pre><p>(2)功能:</p><pre><code>功能:  当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。           在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。    这个命令非常设合周期性的日志分析或数据备份等工作。</code></pre><p>(3)选项参数:</p><pre><code>  1) -l 　　　　　　　　列出当前计时器的设置，查看定时运行的程序  2) -e　        　　　　编辑该用户的计时器设置，设置计时器  3) -r　　　　　　　　删除该用户的计时器设置  4) -u&lt;用户名称&gt;　　指定要设定计时器的用户名称</code></pre><p>(4)实例:(此命令用的不常，在此简要介绍)</p><pre><code>  1)每1分钟执行一次command* * * * * command      2)每五分钟执行一次命令 */5 * * * * command     3)在每天的17:00执行这个命令00 17 * * *  command      4)在8:02,11:02,14:02,17:02,20:02 执行，在8点到20点的时间内，每三个小时执行一下命令2 8-20/3 * * * command</code></pre><p>以后会讨论crondtab的几个用法:</p><pre><code> *创建一个新的crontab文件:　　1.进入 /var/spool/cron目录下（目录为空表明当前系统内没有任何Linux计划任务需要执行）[root@localhost /]# cd /var/spool/cron[root@localhost cron]# ll总用量 0</code></pre><p>*列出crontab文件:</p><pre><code> 2.用crontab自带的命令crontab -l 发现也是没有任何东西（）[root@localhost cron]# crontab -lno crontab for root</code></pre><p>*编辑crontab文件;</p><pre><code>    3.如果目录已经存在指定的文件（文件名为当前用户名），则crontab -e 命令编辑它，否则创建新的文件。    cron服务每分钟不仅要读一次/var/spool/cron内的所有文件，还需要读一次 /etc/crontab,    因此我们配置这个文件也能运用cron服务做一些事情。用crontab配置是针对某个用户的，而编辑/etc/crontab是针对系统的任务。*/2 * * * * ls -l /home/sunjimeng/Documents &gt; root.txt*   * * * * echo "I am MenAngel" &gt; root.txt     *删除crontab文件;     恢复丢失的crontab文件;  </code></pre><p>(5)其他:</p><pre><code>    1.什么是Windows的计划任务？  在Windows中，系统有一项重要的“计划任务”功能，通过设置“计划任务”，你可以将每天或某一天的某个时间需要做的事拟成计划，到约定的时间，不管你在电脑上进行什么工作，系统都会提醒你或者启动你设定好的任务程序。    2.crontab的简介:  crontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。该词来源于希腊语 chronos(χρνο)，原意是时间。常，crontab储存的指令被守护进程激活， crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。    3.crontab文件:  crontab文件包含送交cron守护进程的一系列作业和指令。每个用户可以拥有自己的crontab文件；同时，操作系统保存一个针对整个系统的crontab文件，该文件通常存放于/etc或者/etc之下的子目录中，而这个文件只能由系统管理员来修改。crontab文件的每一行均遵守特定的格式，由空格或tab分隔为数个领域，每个领域可以放置单一或多个数值。    4.Linux下的任务调度  Linux下的任务调度分为两类：系统任务调度和用户任务调度。  系统任务调度:  系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件:[root@localhost /]# cat /etc/crontabSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# |  .------------- hour (0 - 23)# |  |  .---------- day of month (1 - 31)# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# |  |  |  |  |# *  *  *  *  * user-name  command to be executed复制代码      前三行是用来配置crond任务运行的环境变量。第一行SHELL变量指定了系统要使用哪个shell，这里是bash；第二行PATH变量指定了系统执行命令的路径；第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户。 *： 表示任何时刻  ,：　表示分割－：表示一个段，如第二端里： 1-5，就表示1到5点 /n : 表示每个n的单位执行一次，如第二段里，*/1, 就表示每隔1个小时执行一次命令。也可以写成1-23/1.      用户任务调度:  用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab文件都被保存在/var/spool/cron目录中。其文件名与用户名一致。[root@localhost /]# cd /var/spool/cron[root@localhost cron]# ll总用量 0/etc/cron.deny 　　　　  该文件中所列用户不允许使用crontab命令 /etc/cron.allow 　　　 　该文件中所列用户允许使用crontab命令 /var/spool/cron/ 　　   所有用户crontab文件存放的目录,以用户名命名</code></pre><p>5.crond服务</p><pre><code> 　 1)安装crontab： 　yum install crontabs      服务操作说明：复制代码/sbin/service crond start //启动服务/sbin/service crond stop //关闭服务/sbin/service crond restart //重启服务/sbin/service crond reload //重新载入配置复制代码　　查看crontab服务状态：　　service crond status复制代码[root@localhost sunjimeng]# service crond statusRedirecting to /bin/systemctl status  crond.servicecrond.service - Command Scheduler   Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled)   Active: active (running) since 五 2016-05-27 23:11:47 PDT; 1 weeks 5 days ago Main PID: 1303 (crond)   CGroup: /system.slice/crond.service           └─1303 /usr/sbin/crond -n5月 27 23:11:47 localhost.localdomain systemd[1]: Started Command Scheduler.5月 27 23:11:47 localhost.localdomain crond[1303]: (CRON) INFO (RANDOM_DELAY...5月 27 23:11:48 localhost.localdomain crond[1303]: (CRON) INFO (running with...Hint: Some lines were ellipsized, use -l to show in full.复制代码　　手动启动crontab服务：　　service crond start[root@localhost sunjimeng]# service crond startRedirecting to /bin/systemctl start  crond.service　   查看crontab服务是否已设置为开机启动，执行命令：　　ntsysv[root@localhost sunjimeng]# ntsysv加入开机自动启动:　　chkconfig –level 35 crond on（以后再介绍）  *要把cron设为在开机的时候自动启动，在 /etc/rc.d/rc.local 脚本中加入 /sbin/service crond start即可。</code></pre><h2 id="2017-08-08-每天2个Linux命令-lsof命令"><a href="#2017-08-08-每天2个Linux命令-lsof命令" class="headerlink" title=" 2017-08-08 每天2个Linux命令 lsof命令"></a><center> 2017-08-08 每天2个Linux命令 lsof命令</center></h2><p> lsof命令用于查看你进程打开的文件，端口(TCP、UDP)，找回/恢复删除的文件，打开文件的进程。</p><p>(1)用法:</p><pre><code>用法:  lsof  [参数]  [文件]</code></pre><p>(2)功能:</p><pre><code>功能:  lsof 命令可显示系统打开的文件.(因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。)在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。 因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。</code></pre><p>(3)选项参数:</p><pre><code>  1) +D&lt;目录&gt;  　　　　递归列出目录下被打开的文件　  2) -u s 　　　　　　　 列出login name或UID为 s的程序3) -c&lt;进程名&gt; 　　　  列出指定进程所打开的文件  4) -i&lt;条件&gt;  　　　　  列出符合条件的进程。（4、6、协议、:端口、 @ip ）  5) -n 　　　　　　　　 -n&lt;目录&gt;  列出使用NFS的文件</code></pre><p> (4)实例:</p><pre><code>  1)[sunjimeng@localhost ~]$ lsof |more -20　　　　　　　　无任何参数，显示当前系统已经打开的正在使用的所有文件复制代码[sunjimeng@localhost ~]$ lsof |more -20COMMAND     PID         TID     USER   FD      TYPE             DEVICE  SIZE/OFF       　　　NODE    NAME进程名称     标志符      线程id  所有者 文件描述符 文件类型           磁盘名称 文件大小             索引节点 文件名称 systemd       1                 root  cwd   unknown                                         /proc/1/cwd (readlink: Permission denied)systemd       1                 root  rtd   unknown                                         /proc/1/root (readlink: Permission denied)systemd       1                 root  txt   unknown                                         /proc/1/exe (readlink: Permission denied)systemd       1                 root NOFD                                                   /proc/1/fd (opendir: Permission denied)kthreadd      2                 root  cwd   unknown                                         /proc/2/cwd (readlink: Permission denied)kthreadd      2                 root  rtd   unknown                                         /proc/2/root (readlink: Permission denied)kthreadd      2                 root  txt   unknown                                         /proc/2/exe (readlink: Permission denied)kthreadd      2                 root NOFD                                                   /proc/2/fd (opendir: Permission denied)ksoftirqd     3                 root  cwd   unknown                                         /proc/3/cwd (readlink: Permission denied)ksoftirqd     3                 root  rtd   unknown                                         /proc/3/root (readlink: Permission denied)ksoftirqd     3                 root  txt   unknown                                         /proc/3/exe (readlink: Permission denied)ksoftirqd     3                 root NOFD                                                   /proc/3/fd (opendir: Permission denied)kworker/0     5                 root  cwd   unknown                                         /proc/5/cwd (readlink: Permission denied)kworker/0     5                 root  rtd   unknown                                         /proc/5/root (readlink: Permission denied)kworker/0     5                 root  txt   unknown                                         /proc/5/exe (readlink: Permission denied)kworker/0     5                 root NOFD                                                   /proc/5/fd (opendir: Permission denied)migration     7                 root  cwd   unknown                                         /proc/7/cwd (readlink: Permission denied)migration     7                 root  rtd   unknown                                         /proc/7/root (readlink: Permission denied)  //是根目录到软连接migration     7                 root  txt   unknown                                         /proc/7/exe (readlink: Permission denied)--More--复制代码      FW的详解:      1)cwd(current work dirctory):　　　 应用程序的当前工作目录，应用程序启动的目录，除非它本身对这个目录进行更改。      2)txt:　　　　　　　　　　　　　　    该类型的文件是程序代码，如应用程序二进制文件本身或共享库      3)rtd:　　　　　　　　　　　　　　　 root directory      4)0:　　　　　　　　　　　　　　      表示标准输出      5)1:　　　　　　　　　　　　　　　　 表示标准输入      6)2:　　　　　　　　　　　　　　　　 表示标准错误      TYPE：文件类型，如DIR、REG等，常见的文件类型:　　（1）DIR：表示目录　　（2）CHR：表示字符类型　　（3）BLK：块设备类型　　（4）UNIX： UNIX 域套接字　　（5）FIFO：先进先出 (FIFO) 队列　　（6）IPv4：网际协议 (IP) 套接字　　  DEVICE：指定磁盘的名称　　  SIZE:　　文件的大小　　  NODE:　索引节点（文件在磁盘上的标识）　　  NAME:   打开文件的确切名称</code></pre><p>2)[root@localhost root]# lsof /bin/bash　　　　　　　　查看与指定文件相关的进程的信息，即找出使用此文件的进程</p><pre><code>复制代码[root@localhost root]# lsof /bin/bashlsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs      Output information may be incomplete.COMMAND    PID      USER  FD   TYPE DEVICE SIZE/OFF     NODE NAMEksmtuned   807      root txt    REG    8,3   960384 34340720 /usr/bin/bashbash     35234 sunjimeng txt    REG    8,3   960384 34340720 /usr/bin/bashbash     38651      root txt    REG    8,3   960384 34340720 /usr/bin/bash</code></pre><p>3)[root@localhost /]# lsof +D /home/sunjimeng/.local/share　　　　递归查看某个目录的文件信息</p><pre><code>复制代码[root@localhost /]# lsof +D /home/sunjimeng/.local/sharelsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs      Output information may be incomplete.COMMAND    PID      USER   FD   TYPE DEVICE SIZE/OFF      NODE NAMEnautilus  3387 sunjimeng  mem    REG    8,3    32768  71239928 /home/sunjimeng/.local/share/gvfs-metadata/home-ddf07f21.lognautilus  3387 sunjimeng  mem    REG    8,3      764  71239927 /home/sunjimeng/.local/share/gvfs-metadata/homenautilus  3387 sunjimeng   15r   REG    8,3      764  71239927 /home/sunjimeng/.local/share/gvfs-metadata/homenautilus  3387 sunjimeng   16r   REG    8,3    32768  71239928 /home/sunjimeng/.local/share/gvfs-metadata/home-ddf07f21.logevolution 3426 sunjimeng   11u   REG    8,3    14336 104003229 /home/sunjimeng/.local/share/evolution/addressbook/system/contacts.dbtracker-s 3447 sunjimeng   15w   REG    8,3   210635  71234252 /home/sunjimeng/.local/share/tracker/data/</code></pre><p>4)[root@localhost dir1]# lsof |grep ‘/home/sunjimeng/Document/dir1’　　不用+D参数得到与某个文件有关的进程信息的方法</p><pre><code>复制代码[root@localhost dir1]# lsof +D /home/sunjimeng/Document/dir1lsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs      Output information may be incomplete.COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF     NODE NAMEbash    38651 root  cwd    DIR    8,3       30 36004773 /home/sunjimeng/Document/dir1lsof    41562 root  cwd    DIR    8,3       30 36004773 /home/sunjimeng/Document/dir1lsof    41563 root  cwd    DIR    8,3       30 36004773 /home/sunjimeng/Document/dir1[root@localhost dir1]# lsof |grep '/home/sunjimeng/Document/dir1'lsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs      Output information may be incomplete.bash      38651                 root  cwd       DIR                8,3        30   36004773 /home/sunjimeng/Document/dir1lsof      41628                 root  cwd       DIR                8,3        30   36004773 /home/sunjimeng/Document/dir1grep      41629                 root  cwd       DIR                8,3        30   36004773 /home/sunjimeng/Document/dir1lsof      41630                 root  cwd       DIR                8,3        30   36004773 /home/sunjimeng/Document/dir1tracker-store.journal</code></pre><p>5)[root@localhost /]# lsof -u sunjimeng |more -20　　　　　　列出某个用户打开的所有文件相关的进程信息</p><pre><code>复制代码[root@localhost /]# lsof -u sunjimeng |more -20lsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs      Output information may be incomplete.COMMAND     PID      USER   FD      TYPE             DEVICE  SIZE/OFF       NODE NAMEgnome-key  2967 sunjimeng  cwd       DIR                8,3         6   71227180 /var/gdmgnome-key  2967 sunjimeng  rtd       DIR                8,3      4096        128 /gnome-key  2967 sunjimeng  txt       REG                8,3   1038688   35649707 /usr/bin/gnome-keyring-daemongnome-key  2967 sunjimeng  mem       REG                8,3     50496   68402049 /usr/lib64/gio/modules/libdconfsettings.sognome-key  2967 sunjimeng  mem       REG                8,3 106065056   34340715 /usr/lib/locale/locale-archivegnome-key  2967 sunjimeng  mem       REG                8,3    153184   67393930 /usr/lib64/liblzma.so.5.0.99gnome-key  2967 sunjimeng  mem       REG                8,3    398272   67393933 /usr/lib64/libpcre.so.1.2.0gnome-key  2967 sunjimeng  mem       REG                8,3     44088   67328582 /usr/lib64/librt-2.17.sognome-key  2967 sunjimeng  mem       REG                8,3    110808   67328580 /usr/lib64/libresolv-2.17.sognome-key  2967 sunjimeng  mem       REG                8,3    147120   67393944 /usr/lib64/libselinux.so.1gnome-key  2967 sunjimeng  mem       REG                8,3     90632   67393947 /usr/lib64/libz.so.1.2.7gnome-key  2967 sunjimeng  mem       REG                8,3     32296   67394691 /usr/lib64/libffi.so.6.0.1gnome-key  2967 sunjimeng  mem       REG                8,3     15616   67394699 /usr/lib64/libgmodule-2.0.so.0.4000.0gnome-key  2967 sunjimeng  mem       REG                8,3   2107760   67328552 /usr/lib64/libc-2.17.sognome-key  2967 sunjimeng  mem       REG                8,3    141616   67328578 /usr/lib64/libpthread-2.17.sognome-key  2967 sunjimeng  mem       REG                8,3     19736   67394316 /usr/lib64/libcap-ng.so.0.0.0gnome-key  2967 sunjimeng  mem       REG                8,3     19384   67394141 /usr/lib64/libgpg-error.so.0.10.0gnome-key  2967 sunjimeng  mem       REG                8,3     19512   67328558 /usr/lib64/libdl-2.17.sognome-key  2967 sunjimeng  mem       REG                8,3    534488   67394280 /usr/lib64/libgcrypt.so.11.8.2--More--</code></pre><p>6)[root@localhost /]# lsof -c sleep　　　　　　　　列出与程序有关的文件</p><pre><code>复制代码[root@localhost /]# lsof -c sleeplsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs      Output information may be incomplete.COMMAND   PID USER   FD   TYPE             DEVICE  SIZE/OFF     NODE NAMEsleep   42253 root  cwd    DIR                8,3      4096      128 /sleep   42253 root  rtd    DIR                8,3      4096      128 /sleep   42253 root  txt    REG                8,3     33088 34268435 /usr/bin/sleepsleep   42253 root  mem    REG                8,3 106065056 34340715 /usr/lib/locale/locale-archivesleep   42253 root  mem    REG                8,3   2107760 67328552 /usr/lib64/libc-2.17.sosleep   42253 root  mem    REG                8,3    164336 67328545 /usr/lib64/ld-2.17.sosleep   42253 root    0r   CHR                1,3       0t0     1045 /dev/nullsleep   42253 root    1u  unix 0xffff880080995a00       0t0    18112 socketsleep   42253 root    2u  unix 0xffff880080995a00       0t0    18112 socket复制代码复制代码[root@localhost /]# lsof |grep sleep                          //等价lsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs      Output information may be incomplete.sleep     42993                 root  cwd       DIR                8,3      4096        128 /sleep     42993                 root  rtd       DIR                8,3      4096        128 /sleep     42993                 root  txt       REG                8,3     33088   34268435 /usr/bin/sleepsleep     42993                 root  mem       REG                8,3 106065056   34340715 /usr/lib/locale/locale-archivesleep     42993                 root  mem       REG                8,3   2107760   67328552 /usr/lib64/libc-2.17.sosleep     42993                 root  mem       REG                8,3    164336   67328545 /usr/lib64/ld-2.17.sosleep     42993                 root    0r      CHR                1,3       0t0       1045 /dev/nullsleep     42993                 root    1u     unix 0xffff880080995a00       0t0      18112 socketsleep     42993                 root    2u     unix 0xffff880080995a00       0t0      18112 socket</code></pre><p>7)[root@localhost /]# lsof -i　　　　　　列出所有的网络连接</p><pre><code>复制代码[root@localhost /]# lsof -iCOMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEchronyd    787 chrony    1u  IPv4  16222      0t0  UDP *:ntp chronyd    787 chrony    2u  IPv6  16223      0t0  UDP *:ntp chronyd    787 chrony    3u  IPv4  16224      0t0  UDP localhost:323 chronyd    787 chrony    5u  IPv6  16225      0t0  UDP localhost:323 avahi-dae  790  avahi   12u  IPv4  17290      0t0  UDP *:mdns avahi-dae  790  avahi   13u  IPv4  17291      0t0  UDP *:44093 sshd      1282   root    3u  IPv4  20803      0t0  TCP *:ssh (LISTEN)sshd      1282   root    4u  IPv6  20805      0t0  TCP *:ssh (LISTEN)master    2527   root   13u  IPv4  22473      0t0  TCP localhost:smtp (LISTEN)master    2527   root   14u  IPv6  22474      0t0  TCP localhost:smtp (LISTEN)cupsd     3269   root   11u  IPv6  27563      0t0  TCP localhost:ipp (LISTEN)cupsd     3269   root   12u  IPv4  27564      0t0  TCP localhost:ipp (LISTEN)列出使用指定协议的网络连接：复制代码[root@localhost /]# lsof -i TCPCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEsshd    1282 root    3u  IPv4  20803      0t0  TCP *:ssh (LISTEN)sshd    1282 root    4u  IPv6  20805      0t0  TCP *:ssh (LISTEN)master  2527 root   13u  IPv4  22473      0t0  TCP localhost:smtp (LISTEN)master  2527 root   14u  IPv6  22474      0t0  TCP localhost:smtp (LISTEN)cupsd   3269 root   11u  IPv6  27563      0t0  TCP localhost:ipp (LISTEN)cupsd   3269 root   12u  IPv4  27564      0t0  TCP localhost:ipp (LISTEN)</code></pre><p>8)[root@localhost /]# lsof -n /home/sunjimeng　　　　　　列出指定目录下使用NFS文件系统的所有文件</p><pre><code>复制代码[root@localhost /]# lsof -n /home/sunjimenglsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs      Output information may be incomplete.COMMAND     PID      USER   FD   TYPE DEVICE SIZE/OFF NODE NAMEgnome-ses  2990 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimenggnome-set  3168 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimenggnome-she  3265 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimenggsd-print  3282 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimengnautilus   3387 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimengvmtoolsd   3435 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimengtracker-m  3442 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimengtracker-s  3447 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimengabrt-appl  3450 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimengtop       15226 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimenggnome-ter 35226 sunjimeng  cwd    DIR    8,3     4096  137 /home/sunjimeng</code></pre><p> (5)其他:</p><pre><code>  lsof可以打开的文件的类型:　　1.普通文件　　2.目录　　3.网络文件系统的文件　　4.字符或设备文件　　5.(函数)共享库　　6.管道，命名管道　　7.符号链接　　8.网络文件（例如：NFS file、网络socket，unix域名socket）　　9.还有其它类型的文件，等等。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 watch at</title>
      <link href="/2017/08/10/mei-tian-2-ge-linux-ming-ling-watch-at/"/>
      <url>/2017/08/10/mei-tian-2-ge-linux-ming-ling-watch-at/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-07-每天2个Linux命令-watch命令"><a href="#2017-08-07-每天2个Linux命令-watch命令" class="headerlink" title=" 2017-08-07 每天2个Linux命令 watch命令"></a><center> 2017-08-07 每天2个Linux命令 watch命令</center></h2><p>watch命令以周期性的方式执行给定的指令，指令输出以全屏方式显示。</p><p>(1)用法:</p><pre><code>用法:  watch  [参数]  [命令]</code></pre><p>(2)功能:</p><pre><code>功能:  可以将命令的输出结果输出到标准输出设备，多用于周期性执行命令/定时执行命令。FreeBSD和Linux下watch命令的不同，在Linux下，watch是周期性的执行下个程序，并全屏显示执行结果，如：watch -n 1 -d netstat -ant，而在FreeBSD下的watch命令是查看其它用户的正在运行的操作，watch允许你偷看其它terminal正在做什么，该命令只能让超级用户使用。</code></pre><p>(3)选项参数:</p><pre><code>1)  -d:　　　　　　　　高亮显示指令输出信息不同之处;2)  -n --interval  　　  可以用-n或-interval来指定间隔的时间。3)  -t:　　　　　　　   不显示标题。</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# watch ls -l　　　　　　　　以全屏的方式显示watch后的命令的查询结果（默认每2秒更新一次）复制代码Every 2.0s: ls -l                                                                             Tue Jun  7 23:36:39 2016总用量 4drwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Desktopdrwxrwxr-x. 4 sunjimeng users     4096 5月  28 00:24 Documentdrwxr-xr-x. 4 root    sunjimeng   48 6月   7 23:34 Documentsdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Downloadsdrwxrwxr-x. 2 sunjimeng sunjimeng    6 5月  17 04:55 findTextDirdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Musicdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Picturesdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Publicdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Templatesdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Videos</code></pre><p>2)[root@localhost sunjimeng]# watch -n 5 netstat -ntlp　　　　　　以每5秒执行一次的方式全屏显示命令执行的结果</p><pre><code>复制代码Every 5.0s: netstat -ntlp          Tue Jun  7 23:40:28 2016Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State    PID/Program nametcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN    1282/sshdtcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN    3269/cupsdtcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN    2527/mastertcp6       0      0 :::22                   :::*                    LISTEN    1282/sshdtcp6       0      0 ::1:631                 :::*                    LISTEN    3269/cupsdtcp6       0      0 ::1:25                  :::*                    LISTEN    2527/master netstat显示网络链接数的变化情况。</code></pre><p>3)[root@localhost Documents]# watch -t ls -l　　　　　　　　　不显示标题</p><pre><code>Every 2.0s: ls -l                                                                             Tue Jun  7 23:46:54 2016总用量 0drwxr-xr-x. 2 root root 72 5月  31 18:25 grepDir-rw-r--r--. 1 root root  0 6月   7 23:34 myfiledrwxr-xr-x. 2 root root  6 6月   7 23:33 newWatch总用量 0drwxr-xr-x. 2 root root 72 5月  31 18:25 grepDir-rw-r--r--. 1 root root  0 6月   7 23:34 myfiledrwxr-xr-x. 2 root root  6 6月   7 23:33 newWatch</code></pre><p>4)[root@localhost Documents]# watch ‘ps aux|grep httpd’　　　　　　　　查看某个进程，定时刷新，比较常用。</p><pre><code>Every 2.0s: ps aux|grep httpd   \ Tue Jun  7 23:50:35 2016root      21479  0.0  0.0 125424  1740 pts/2    S+   23:50   0:00 watch ps aux|grep httpdroot      21514  0.0  0.0 125420   460 pts/2    S+   23:50   0:00 watch ps aux|grep httpdroot      21515  0.0  0.0 113116  1384 pts/2    S+   23:50   0:00 sh -c ps aux|grep httpdroot      21517  0.0  0.0 112656   952 pts/2    S+   23:50   0:00 grep httpd</code></pre><h2 id="2017-08-07-每天2个Linux命令-at命令"><a href="#2017-08-07-每天2个Linux命令-at命令" class="headerlink" title=" 2017-08-07 每天2个Linux命令 at命令"></a><center> 2017-08-07 每天2个Linux命令 at命令</center></h2><p>at命令用于在指定时间执行命令。at允许使用一套相当复杂的指定时间的方法。可以用相对时间法指定，也可以用绝对时间法指定。</p><p>(1)用法:</p><pre><code>用法:  at  [选项参数]  [时间]</code></pre><p>(2)功能:</p><pre><code>功能:  在指定的时间执行命令。</code></pre><p>(3)选项参数:</p><pre><code>  1) -c　　　　　　　　　　显示即将执行任务的细节  2) -d　　　　　　　　　  用任务id号删除指定的任务  3) -l    　　　　　　　　  等同于atq，用job的id号显示指定的未删除而待执行的任务</code></pre><p>(4)实例: </p><pre><code>  1)[root@localhost sunjimeng]# at now + 1 minutes　　　　　  用相对时间，在一分钟之后执行命令[root@localhost sunjimeng]# at now + 2 minutesat&gt; echo "I'm MenAngel!,I'm study at order!"at&gt; &lt;EOT&gt;job 11 at Wed Jun 8 17:46:00 2016  at&gt; &lt;EOT&gt;   &lt;这里输入 [ctrl] + d 就会出现 &lt;EOF&gt; 的字样代表结束!   当你输入下一个命令时，系统会自动提醒你，您在 /var/spool/mail/sunjimeng 中有邮件。此邮件中就包含这个命令执行的结果。</code></pre><p>2)[root@localhost sunjimeng]# at 17:47　　　　　　　　　　　在一个绝对时间执行一个命令</p><pre><code>[root@localhost sunjimeng]# at 17:47at&gt; ls -l /home/sunjimeng/Documentsat&gt; &lt;EOT&gt;job 13 at Wed Jun  8 17:47:00 2016您在 /var/spool/mail/sunjimeng 中有新邮件这里在语句的末尾提醒你有新邮件，可以用cat命令查看文件:/var/spool/mail/sunjimeng。</code></pre><p>3)[root@localhost sunjimeng]# atq　　计划任务设定后，在没有执行之前我们可以用atq命令来查看系统没有执行工作任务　　　　　　　　　　　</p><pre><code>复制代码[root@localhost sunjimeng]# atq1    Wed Jun  8 17:21:00 2016 a root2    Wed Jun  8 17:23:00 2016 a root3    Wed Jun  8 17:23:00 2016 a root4    Wed Jun  8 17:26:00 2016 a root5    Sat Jun 11 17:00:00 2016 a root6    Wed Jun  8 17:31:00 2016 a root</code></pre><p>4)[root@localhost sunjimeng]# atq　　　　　　　　　　　　　　删除已经设置的任务</p><pre><code>复制代码[root@localhost sunjimeng]# atq1    Wed Jun  8 17:21:00 2016 a root2    Wed Jun  8 17:23:00 2016 a root3    Wed Jun  8 17:23:00 2016 a root4    Wed Jun  8 17:26:00 2016 a root5    Sat Jun 11 17:00:00 2016 a root6    Wed Jun  8 17:31:00 2016 a root[root@localhost sunjimeng]# atrm 1 2 3 4 5[root@localhost sunjimeng]# atq6    Wed Jun  8 17:31:00 2016 a root</code></pre><p>5)[root@localhost sunjimeng]# cat /var/spool/mail/sunjimeng　　　　　　显示at命令的执行结果　　</p><pre><code>复制代码[root@localhost sunjimeng]# cat /var/spool/mail/sunjimengFrom root@localhost.localdomain  Wed Jun  8 17:46:01 2016Return-Path: &lt;root@localhost.localdomain&gt;X-Original-To: sunjimengDelivered-To: sunjimeng@localhost.localdomainReceived: by localhost.localdomain (Postfix, from userid 0)    id 24622632F338; Wed,  8 Jun 2016 17:46:01 -0700 (PDT)Subject: Output from your job       11To: sunjimeng@localhost.localdomainMessage-Id: &lt;20160609004601.24622632F338@localhost.localdomain&gt;Date: Wed,  8 Jun 2016 17:46:01 -0700 (PDT)From: root@localhost.localdomain (root)I'm MenAngel!,I'm study at order!From root@localhost.localdomain  Wed Jun  8 17:47:00 2016Return-Path: &lt;root@localhost.localdomain&gt;X-Original-To: sunjimengDelivered-To: sunjimeng@localhost.localdomainReceived: by localhost.localdomain (Postfix, from userid 0)    id C83A5632F338; Wed,  8 Jun 2016 17:47:00 -0700 (PDT)Subject: Output from your job       13To: sunjimeng@localhost.localdomainMessage-Id: &lt;20160609004700.C83A5632F338@localhost.localdomain&gt;Date: Wed,  8 Jun 2016 17:47:00 -0700 (PDT)From: root@localhost.localdomain (root)总用量 0drwxr-xr-x. 2 root root 72 5月  31 18:25 grepDir-rw-r--r--. 1 root root  0 6月   7 23:34 myfiledrwxr-xr-x. 2 root root  6 6月   7 23:33 newWatchFrom root@localhost.localdomain  Wed Jun  8 17:47:00 2016Return-Path: &lt;root@localhost.localdomain&gt;X-Original-To: sunjimengDelivered-To: sunjimeng@localhost.localdomainReceived: by localhost.localdomain (Postfix, from userid 0)    id C9EA3632F33A; Wed,  8 Jun 2016 17:47:00 -0700 (PDT)Subject: Output from your job       12To: sunjimeng@localhost.localdomainMessage-Id: &lt;20160609004700.C9EA3632F33A@localhost.localdomain&gt;Date: Wed,  8 Jun 2016 17:47:00 -0700 (PDT)From: root@localhost.localdomain (root)总用量 0drwxr-xr-x. 2 root root 72 5月  31 18:25 grepDir-rw-r--r--. 1 root root  0 6月   7 23:34 myfiledrwxr-xr-x. 2 root root  6 6月   7 23:33 newWatchFrom root@localhost.localdomain  Wed Jun  8 17:52:01 2016Return-Path: &lt;root@localhost.localdomain&gt;X-Original-To: sunjimengDelivered-To: sunjimeng@localhost.localdomainReceived: by localhost.localdomain (Postfix, from userid 0)    id F3239632F338; Wed,  8 Jun 2016 17:52:00 -0700 (PDT)Subject: Output from your job       14To: sunjimeng@localhost.localdomainMessage-Id: &lt;20160609005200.F3239632F338@localhost.localdomain&gt;Date: Wed,  8 Jun 2016 17:52:00 -0700 (PDT)From: root@localhost.localdomain (root)I'm MenAngelFrom root@localhost.localdomain  Wed Jun  8 17:54:00 2016Return-Path: &lt;root@localhost.localdomain&gt;X-Original-To: sunjimengDelivered-To: sunjimeng@localhost.localdomainReceived: by localhost.localdomain (Postfix, from userid 0)    id 4B264632F338; Wed,  8 Jun 2016 17:54:00 -0700 (PDT)Subject: Output from your job       15To: sunjimeng@localhost.localdomainMessage-Id: &lt;20160609005400.4B264632F338@localhost.localdomain&gt;Date: Wed,  8 Jun 2016 17:54:00 -0700 (PDT)From: root@localhost.localdomain (root)总用量 4drwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Desktopdrwxrwxr-x. 4 sunjimeng users     4096 5月  28 00:24 Documentdrwxr-xr-x. 4 root      sunjimeng   48 6月   7 23:34 Documentsdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Downloadsdrwxrwxr-x. 2 sunjimeng sunjimeng    6 5月  17 04:55 findTextDirdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Musicdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Picturesdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Publicdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 Templatesdrwxr-xr-x. 2 sunjimeng sunjimeng    6 5月   1 01:23 VideosFrom root@localhost.localdomain  Wed Jun  8 17:54:00 2016Return-Path: &lt;root@localhost.localdomain&gt;X-Original-To: sunjimengDelivered-To: sunjimeng@localhost.localdomainReceived: by localhost.localdomain (Postfix, from userid 0)    id 4E5D2632F33A; Wed,  8 Jun 2016 17:54:00 -0700 (PDT)Subject: Output from your job       16To: sunjimeng@localhost.localdomainMessage-Id: &lt;20160609005400.4E5D2632F33A@localhost.localdomain&gt;Date: Wed,  8 Jun 2016 17:54:00 -0700 (PDT)From: root@localhost.localdomain (root)总用量 0drwxr-xr-x. 2 root root 72 5月  31 18:25 grepDir-rw-r--r--. 1 root root  0 6月   7 23:34 myfiledrwxr-xr-x. 2 root root  6 6月   7 23:33 newWatch</code></pre><p> 6)[sunjimeng@localhost ~]$ at -c 18　　　　　　　　　　根据id号查看即将要执行命令的细节</p><pre><code>复制代码[sunjimeng@localhost ~]$ atq                      //显示结果表明没有即将要执行的任务[sunjimeng@localhost ~]$ at now + 1 minutes       //新建一个要执行的任务at&gt; ls -lat&gt; &lt;EOT&gt;job 18 at Wed Jun  8 18:09:00 2016[sunjimeng@localhost ~]$ atq                      //查看18    Wed Jun  8 18:09:00 2016 a sunjimeng[sunjimeng@localhost ~]$ at -c 18                //根据id号查看，它的即将执行的细节#!/bin/sh# atrun uid=1000 gid=1000# mail sunjimeng 0umask 2XDG_VTNR=1; export XDG_VTNRSSH_AGENT_PID=3132; export SSH_AGENT_PIDXDG_SESSION_ID=2; export XDG_SESSION_IDHOSTNAME=localhost.localdomain; export HOSTNAMEIMSETTINGS_INTEGRATE_DESKTOP=yes; export IMSETTINGS_INTEGRATE_DESKTOPGPG_AGENT_INFO=/run/user/1000/keyring-CchymL/gpg:0:1; export GPG_AGENT_INFOVTE_VERSION=3406; export VTE_VERSIONSHELL=/bin/bash; export SHELLXDG_MENU_PREFIX=gnome-; export XDG_MENU_PREFIXHISTSIZE=1000; export HISTSIZEGJS_DEBUG_OUTPUT=stderr; export GJS_DEBUG_OUTPUTWINDOWID=25197065; export WINDOWIDGNOME_KEYRING_CONTROL=/run/user/1000/keyring-CchymL; export GNOME_KEYRING_CONTROLGJS_DEBUG_TOPICS=JS\ ERROR\;JS\ LOG; export GJS_DEBUG_TOPICSIMSETTINGS_MODULE=IBus; export IMSETTINGS_MODULEUSER=sunjimeng; export USERLS_COLORS=rs=0:di=38\;5\;27:ln=38\;5\;51:mh=44\;38\;5\;15:pi=40\;38\;5\;11:so=38\;5\;13:do=38\;5\;5:bd=48\;5\;232\;38\;5\;11:cd=48\;5\;232\;38\;5\;3:or=48\;5\;232\;38\;5\;9:mi=05\;48\;5\;232\;38\;5\;15:su=48\;5\;196\;38\;5\;15:sg=48\;5\;11\;38\;5\;16:ca=48\;5\;196\;38\;5\;226:tw=48\;5\;10\;38\;5\;16:ow=48\;5\;10\;38\;5\;21:st=48\;5\;21\;38\;5\;15:ex=38\;5\;34:\*.tar=38\;5\;9:\*.tgz=38\;5\;9:\*.arc=38\;5\;9:\*.arj=38\;5\;9:\*.taz=38\;5\;9:\*.lha=38\;5\;9:\*.lz4=38\;5\;9:\*.lzh=38\;5\;9:\*.lzma=38\;5\;9:\*.tlz=38\;5\;9:\*.txz=38\;5\;9:\*.tzo=38\;5\;9:\*.t7z=38\;5\;9:\*.zip=38\;5\;9:\*.z=38\;5\;9:\*.Z=38\;5\;9:\*.dz=38\;5\;9:\*.gz=38\;5\;9:\*.lrz=38\;5\;9:\*.lz=38\;5\;9:\*.lzo=38\;5\;9:\*.xz=38\;5\;9:\*.bz2=38\;5\;9:\*.bz=38\;5\;9:\*.tbz=38\;5\;9:\*.tbz2=38\;5\;9:\*.tz=38\;5\;9:\*.deb=38\;5\;9:\*.rpm=38\;5\;9:\*.jar=38\;5\;9:\*.war=38\;5\;9:\*.ear=38\;5\;9:\*.sar=38\;5\;9:\*.rar=38\;5\;9:\*.alz=38\;5\;9:\*.ace=38\;5\;9:\*.zoo=38\;5\;9:\*.cpio=38\;5\;9:\*.7z=38\;5\;9:\*.rz=38\;5\;9:\*.cab=38\;5\;9:\*.jpg=38\;5\;13:\*.jpeg=38\;5\;13:\*.gif=38\;5\;13:\*.bmp=38\;5\;13:\*.pbm=38\;5\;13:\*.pgm=38\;5\;13:\*.ppm=38\;5\;13:\*.tga=38\;5\;13:\*.xbm=38\;5\;13:\*.xpm=38\;5\;13:\*.tif=38\;5\;13:\*.tiff=38\;5\;13:\*.png=38\;5\;13:\*.svg=38\;5\;13:\*.svgz=38\;5\;13:\*.mng=38\;5\;13:\*.pcx=38\;5\;13:\*.mov=38\;5\;13:\*.mpg=38\;5\;13:\*.mpeg=38\;5\;13:\*.m2v=38\;5\;13:\*.mkv=38\;5\;13:\*.webm=38\;5\;13:\*.ogm=38\;5\;13:\*.mp4=38\;5\;13:\*.m4v=38\;5\;13:\*.mp4v=38\;5\;13:\*.vob=38\;5\;13:\*.qt=38\;5\;13:\*.nuv=38\;5\;13:\*.wmv=38\;5\;13:\*.asf=38\;5\;13:\*.rm=38\;5\;13:\*.rmvb=38\;5\;13:\*.flc=38\;5\;13:\*.avi=38\;5\;13:\*.fli=38\;5\;13:\*.flv=38\;5\;13:\*.gl=38\;5\;13:\*.dl=38\;5\;13:\*.xcf=38\;5\;13:\*.xwd=38\;5\;13:\*.yuv=38\;5\;13:\*.cgm=38\;5\;13:\*.emf=38\;5\;13:\*.axv=38\;5\;13:\*.anx=38\;5\;13:\*.ogv=38\;5\;13:\*.ogx=38\;5\;13:\*.aac=38\;5\;45:\*.au=38\;5\;45:\*.flac=38\;5\;45:\*.mid=38\;5\;45:\*.midi=38\;5\;45:\*.mka=38\;5\;45:\*.mp3=38\;5\;45:\*.mpc=38\;5\;45:\*.ogg=38\;5\;45:\*.ra=38\;5\;45:\*.wav=38\;5\;45:\*.axa=38\;5\;45:\*.oga=38\;5\;45:\*.spx=38\;5\;45:\*.xspf=38\;5\;45:; export LS_COLORSSSH_AUTH_SOCK=/run/user/1000/keyring-CchymL/ssh; export SSH_AUTH_SOCKSESSION_MANAGER=local/unix:@/tmp/.ICE-unix/2990,unix/unix:/tmp/.ICE-unix/2990; export SESSION_MANAGERUSERNAME=sunjimeng; export USERNAMEGNOME_SHELL_SESSION_MODE=classic; export GNOME_SHELL_SESSION_MODEPATH=/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/bin:/sbin:/home/sunjimeng/.local/bin:/home/sunjimeng/bin; export PATHMAIL=/var/spool/mail/sunjimeng; export MAILDESKTOP_SESSION=gnome-classic; export DESKTOP_SESSIONQT_IM_MODULE=ibus; export QT_IM_MODULEPWD=/home/sunjimeng; export PWDXMODIFIERS=@im=ibus; export XMODIFIERSGNOME_KEYRING_PID=2967; export GNOME_KEYRING_PIDLANG=zh_CN.utf8; export LANGGDM_LANG=zh_CN.utf8; export GDM_LANGGDMSESSION=gnome-classic; export GDMSESSIONHISTCONTROL=ignoredups; export HISTCONTROLXDG_SEAT=seat0; export XDG_SEATHOME=/home/sunjimeng; export HOMESHLVL=2; export SHLVLGNOME_DESKTOP_SESSION_ID=this-is-deprecated; export GNOME_DESKTOP_SESSION_IDLOGNAME=sunjimeng; export LOGNAMEDBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-O0naLUCbYg,guid=ad8d9a1bab9eccd8c11d0a6257493a83; export DBUS_SESSION_BUS_ADDRESSLESSOPEN=\|\|/usr/bin/lesspipe.sh\ %s; export LESSOPENWINDOWPATH=1; export WINDOWPATHXDG_RUNTIME_DIR=/run/user/1000; export XDG_RUNTIME_DIRCOLORTERM=gnome-terminal; export COLORTERMXAUTHORITY=/run/gdm/auth-for-sunjimeng-Bcg9Bg/database; export XAUTHORITYcd /home/sunjimeng || {     echo 'Execution directory inaccessible' &gt;&amp;2     exit 1}${SHELL:-/bin/sh} &lt;&lt; 'marcinDELIMITER7e20521d'ls -lmarcinDELIMITER7e20521d[sunjimeng@localhost ~]$ </code></pre><p>7)[sunjimeng@localhost ~]$ at -d 21　　　　　　　　取消指向执行id号为21的任务</p><pre><code>复制代码[sunjimeng@localhost ~]$ atq20    Wed Jun  8 18:15:00 2016 a sunjimeng21    Wed Jun  8 18:16:00 2016 a sunjimeng[sunjimeng@localhost ~]$ atrm 20[sunjimeng@localhost ~]$ atq21    Wed Jun  8 18:16:00 2016 a sunjimeng[sunjimeng@localhost ~]$ at -d 21[sunjimeng@localhost ~]$ atq</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 vmstat iostat</title>
      <link href="/2017/08/08/mei-tian-2-ge-linux-ming-ling-vmstat-iostat/"/>
      <url>/2017/08/08/mei-tian-2-ge-linux-ming-ling-vmstat-iostat/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-06-每天2个Linux命令-vmstat命令"><a href="#2017-08-06-每天2个Linux命令-vmstat命令" class="headerlink" title=" 2017-08-06 每天2个Linux命令 vmstat命令"></a><center> 2017-08-06 每天2个Linux命令 vmstat命令</center></h2><p>vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。</p><p>它能够对系统的整体情况进行统计，无法对某个进程进行深入分析。vmstat 工具提供了一种低开销的系统性能观察方式。</p><p> (1)用法</p><pre><code>用法:  vmstat  [选项参数]   或   vmstat  [选项参数]   [数字]   [数字]</code></pre><p>(2)功能:</p><pre><code>功能:  报告虚拟内存的统计信息,关于进程、内存、I/O等系统整体运行状态。</code></pre><p>(3)选项参数:</p><pre><code>  1) -d:　　　　　　　　显示磁盘相关统计信息。  2) -a：　　　　　　    显示活跃和非活跃内存  3) -f：　　　　　　　  显示从系统启动至今的fork数量。  4) -p：　　　　　　    显示指定磁盘分区统计信息  5) -s：　　　　　　    显示内存相关统计信息及多种系统活动数量。  6) -m：　　　　　　  显示slabinfo</code></pre><p>(4)实例:</p><pre><code>  1)[sunjimeng@localhost ~]$ vmstat　　　　　　　　　　显示虚拟内存使用情况[sunjimeng@localhost ~]$ vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 5  0      0 858580    752 506988    0    0     7     1   81  120  2  1 97  0  0[sunjimeng@localhost ~]$       字段说明:   1.Procs（进程）     r: 运行队列中进程数量，这个值也可以判断是否需要增加CPU。（长期大于1）     b: 等待IO的进程数量。   2.Memory（内存）    swpd: 使用虚拟内存大小，如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能。    free: 空闲物理内存大小。    buff: 用作缓冲的内存大小。    cache: 用作缓存的内存大小，如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小。  3.Swap    si: 每秒从交换区写到内存的大小，由磁盘调入内存。    so: 每秒写入交换区的内存大小，由内存调入磁盘。  注意:  内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。  4.IO（现在的Linux版本块的大小为1kb）    bi: 每秒读取的块数    bo: 每秒写入的块数  注意:  随机磁盘读写的时候，这2个值越大（如超出1024k)，能看到CPU在IO等待的值也会越大。  5.system（系统）    in: 每秒中断数，包括时钟中断。    cs: 每秒上下文切换数。  注意：  上面2个值越大，会看到由内核消耗的CPU时间会越大。  6.CPU（以百分比表示）　　us: 用户进程执行时间百分比(user time) us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。　　sy: 内核系统进程执行时间百分比(system time) sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。　　wa: IO等待时间百分比 wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。　　id: 空闲时间百分比</code></pre><p>2)[sunjimeng@localhost ~]$ vmstat 2　　　　　　　　每二秒显示一次系统内存的统计信息</p><pre><code>[sunjimeng@localhost ~]$ vmstat 2procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 1  0      0 853508    752 507144    0    0     7     1   80  119  2  1 97  0  0 0  0      0 853508    752 507144    0    0     0     0  376  466  3  2 96  0  0......</code></pre><p>3)[sunjimeng@localhost ~]$ vmstat 2 5　　　　　　　每二秒显示一次系统内存的统计信息,总共5次　</p><pre><code>复制代码[sunjimeng@localhost ~]$ vmstat 2 5procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 1  0      0 853888    752 507152    0    0     7     1   81  119  2  1 97  0  0 0  0      0 853888    752 507152    0    0     0     0  609  763  5  2 92  0  0 1  0      0 853888    752 507152    0    0     0     0  582  626  5  2 93  0  0 0  0      0 853888    752 507152    0    0     0     0  399  464  3  2 95  0  0 0  0      0 853888    752 507152    0    0     0     0  263  365  3  1 96  0  0[sunjimeng@localhost ~]$ </code></pre><p>4)[sunjimeng@localhost ~]$ vmstat -d　　　　　　　显示磁盘的信息</p><pre><code>[sunjimeng@localhost ~]$ vmstat -ddisk- ------------reads------------ ------------writes----------- -----IO------       total merged sectors      ms  total merged sectors      ms    cur    secsda    11582    610  838780  116523   7805   1068  133502  564406      0     73sr0        0      0       0       0      0      0       0       0      0      0[sunjimeng@localhost ~]$        merged:表示一次来自于合并的写/读请求,一般系统会把多个连接/邻近的读/写请求合并到一起来操作。</code></pre><p>5)[sunjimeng@localhost ~]$ vmstat -a　　　　　　 显示活跃内存与非活跃内存</p><pre><code>  使用-a选项显示活跃和非活跃内存时，所显示的内容除增加inact和active外，其他显示内容与例子1相同。[sunjimeng@localhost ~]$ vmstat -aprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free  inact active   si   so    bi    bo   in   cs us sy id wa st 1  0      0 854904 316268 604280    0    0     7     1   81  119  2  1 97  0  0[sunjimeng@localhost ~]$ </code></pre><p>6)[sunjimeng@localhost ~]$ vmstat -f　　　　　　查看系统已经被fork多少次</p><pre><code>[sunjimeng@localhost ~]$ vmstat -f        17873 forks[sunjimeng@localhost ~]$ </code></pre><p>7)[sunjimeng@localhost ~]$ vmstat -p devtmpfs　　查看特定磁盘设备的</p><pre><code>复制代码[sunjimeng@localhost ~]$ df文件系统          1K-块    已用     可用 已用% 挂载点/dev/sda3      18555904 3583564 14972340   20% /devtmpfs         997908       0   997908    0% /devtmpfs           1006936     148  1006788    1% /dev/shmtmpfs           1006936    9080   997856    1% /runtmpfs           1006936       0  1006936    0% /sys/fs/cgroup/dev/sda1        303788  113264   190524   38% /boot[sunjimeng@localhost ~]$ vmstat -p devtmpfspartition was not found[sunjimeng@localhost ~]$ vmstat -p /dev/sda1sda1          reads   read sectors  writes    requested writes                1151      51564       1034       4138   复制代码　　说明：　　这些信息主要来自于/proc/diskstats。　　reads:　　　　　　　 　来自于这个分区的读的次数。　　read sectors:　　　　  来自于这个分区的读扇区的次数。　　writes:　　　　　　　  来自于这个分区的写的次数。　　requested writes:　   来自于这个分区的写请求次数。      8)[root@localhost sunjimeng]# vmstat -m　　　　　　　　显示slabinfo复制代码[sunjimeng@localhost ~]$ vmstat -mvmstat: your kernel does not support slabinfo or your permissions are insufficient[sunjimeng@localhost ~]$ su root密码：[root@localhost sunjimeng]# vmstat -mCache                       Num  Total   Size  Pagesfuse_inode                   42     42    768     42nf_conntrack_ffff880080950000      0      0    320     51nf_conntrack_ffffffff819e07c0    102    102    320     51kcopyd_job                    0      0   3312      9dm_uevent                     0      0   2608     12dm_rq_target_io               0      0    424     38xfs_icr                       0      0    144     56xfs_ili                    3922   3922    152     53xfs_inode                 26816  26816   1024     32xfs_efd_item                 80     80    400     40xfs_da_state                134    134    488     67xfs_btree_cur                78     78    208     39xfs_log_ticket               88     88    184     44scsi_cmd_cache               72     72    448     36UDPLITEv6                     0      0   1152     28UDPv6                        56     56   1152     28tw_sock_TCPv6                 0      0    256     64TCPv6                        32     32   2048     16Cache                       Num  Total   Size  Pagescfq_queue                   140    140    232     70bsg_cmd                       0      0    312     52mqueue_inode_cache           36     36    896     36hugetlbfs_inode_cache       106    106    608     53configfs_dir_cache            0      0     88     46dquot                         0      0    256     64kioctx                        0      0    576     56pid_namespace                 0      0   2176     15posix_timers_cache            0      0    248     66UDP-Lite                      0      0   1024     32ip_fib_trie                 146    146     56     73RAW                         884    884    960     34UDP                          64     64   1024     32tw_sock_TCP                   0      0    256     64TCP                          34     34   1920     17blkdev_queue                 32     32   2016     16blkdev_requests            4578   4578    384     42blkdev_ioc                  156    156    104     39Cache                       Num  Total   Size  Pagesfsnotify_event_holder    128180 128180     24    170fsnotify_event              909   1632    120     68sock_inode_cache           1224   1224    640     51net_namespace                 7      7   4224      7shmem_inode_cache          1008   1008    680     48Acpi-ParseExt              6720   6720     72     56Acpi-Namespace             4692   4692     40    102taskstats                    98     98    328     49proc_inode_cache           5638   5978    656     49sigqueue                    102    102    160     51bdev_cache                   78     78    832     39sysfs_dir_cache           29688  30168    112     36inode_cache               15675  15675    592     55dentry                    57213  57498    192     42iint_cache                    0      0     80     51selinux_inode_security    50139  50439     80     51buffer_head                3588   3588    104     39vm_area_struct            18198  18463    216     37Cache                       Num  Total   Size  Pagesmm_struct                   140    140   1600     20files_cache                 306    306    640     51signal_cache                857    952   1152     28sighand_cache               575    585   2112     15task_xstate                 858    858    832     39task_struct                 721    781   2912     11anon_vma                   6502   7040     64     64shared_policy_node         2295   2295     48     85numa_policy                 186    186    264     62radix_tree_node            5988   6048    584     56idr_layer_cache             210    210   2112     15dma-kmalloc-8192              0      0   8192      4dma-kmalloc-4096              0      0   4096      8dma-kmalloc-2048              0      0   2048     16dma-kmalloc-1024              0      0   1024     32dma-kmalloc-512              64     64    512     64dma-kmalloc-256               0      0    256     64dma-kmalloc-128               0      0    128     64Cache                       Num  Total   Size  Pagesdma-kmalloc-64                0      0     64     64dma-kmalloc-32                0      0     32    128dma-kmalloc-16                0      0     16    256dma-kmalloc-8                 0      0      8    512dma-kmalloc-192               0      0    192     42dma-kmalloc-96                0      0     96     42kmalloc-8192                 40     44   8192      4kmalloc-4096                581    648   4096      8kmalloc-2048               1472   1584   2048     16kmalloc-1024               3353   3424   1024     32kmalloc-512                7808   7808    512     64kmalloc-256                8046   9216    256     64kmalloc-192                9976   9996    192     42kmalloc-128                5696   5696    128     64kmalloc-96                 5586   5586     96     42kmalloc-64               112568 113152     64     64kmalloc-32               123831 124416     32    128kmalloc-16                58869  60672     16    256Cache                       Num  Total   Size  Pageskmalloc-8                 84992  84992      8    512kmem_cache_node             192    192     64     64kmem_cache                  192    192    256     64</code></pre><p>(5)其他:</p><pre><code>1.物理内存和虚拟内存区别:  物理内存读写数据要比从硬盘读写数据要快的多，因此，我们希望所有数据的读取和写入都在内存完成，而内存是有限的，这样就引出了物理内存与虚拟内存的概念。  物理内存就是系统硬件提供的内存大小，是真正的内存；在Linux系统下，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。作为物理内存的扩展，linux会在物理内存不足时，使用交换分区的虚拟内存。（更详细的说，就是内核会将暂时不用的内存块信息写到交换空间，这样以来，物理内存得到了释放，这块内存就可以用于其它目的，当需要用到原始的内容时，这些信息会被重新从交换空间读入物理内存。）2.linux内存运行机制:  linux的内存管理采取的是分页存取机制，为了保证物理内存能得到充分的利用，内核会在适当的时候将物理内存中不经常使用的数据块自动交换到虚拟内存中，而将经常使用的信息保留到物理内存。  1)首先，Linux系统会不时的进行页面交换操作，以保持尽可能多的空闲物理内存，即使并没有什么事情需要内存，Linux也会交换出暂时不用的内存页面。这可以避免等待交换所需的时间。   2)其次，linux进行页面交换是有条件的，不是所有页面在不用时都交换到虚拟内存，linux内核根据”最近最经常使用“算法，仅仅将一些不经常使用的页面文件交换到虚拟内存，有时我们会看到这么一个现象：linux物理内存还有很多，但是交换空间也使用了很多。其实，这并不奇怪，例如，一个占用很大内存的进程运行时，需要耗费很多内存资源，此时就会有一些不常用页面文件被交换到虚拟内存中，但后来这个占用很多内存资源的进程结束并释放了很多内存时，刚才被交换出去的页面文件并不会自动的交换进物理内存，除非有这个必要，那么此刻系统物理内存就会空闲很多，同时交换空间也在被使用，就出现了刚才所说的现象了。关于这点，不用担心什么，只要知道是怎么一回事就可以了。  3)最后，交换空间的页面在使用时会首先被交换到物理内存，如果此时没有足够的物理内存来容纳这些页面，它们又会被马上交换出去，如此以来，虚拟内存中可能没有足够空间来存储这些交换页面，最终会导致linux出现假死机、服务异常等问题，linux虽然可以在一段时间内自行恢复，但是恢复后的系统已经基本不可用了。  4)因此，合理规划和设计linux内存的使用，是非常重要的。3.虚拟内存原理:  在系统中运行的每个进程都需要使用到内存，但不是每个进程都需要每时每刻使用系统分配的内存空间。当系统运行所需内存超过实际的物理内存，内核会释放某些进程所占用但未使用的部分或所有物理内存，将这部分资料存储在磁盘上直到进程下一次调用，并将释放出的内存提供给有需要的进程使用。  在Linux内存管理中，主要是通过“调页Paging”和“交换Swapping”来完成上述的内存调度。调页算法是将内存中最近不常使用的页面换到磁盘上，把活动页面保留在内存中供进程使用。交换技术是将整个进程，而不是部分页面，全部交换到磁盘上。 分页(Page)写入磁盘的过程被称作Page-Out，分页(Page)从磁盘重新回到内存的过程被称作Page-In。当内核需要一个分页时，但发现此分页不在物理内存中(因为已经被Page-Out了)，此时就发生了分页错误（Page Fault）。 当系统内核发现可运行内存变少时，就会通过Page-Out来释放一部分物理内存。经管Page-Out不是经常发生，但是如果Page-out频繁不断的发生，直到当内核管理分页的时间超过运行程式的时间时，系统效能会急剧下降。这时的系统已经运行非常慢或进入暂停状态，这种状态亦被称作thrashing(颠簸)。4.buffer与cache的区别buff和cache的主要区别是在控制和速度上。buff的控制相对简单，是对数据流缓冲，将需要的数据流临时缓冲在buff里，以降低低速设备对整体的影响。一般都是对大量的数据交换进行缓冲；cache是对高速交换进行缓冲，需要一些额外的算法来提高效率，比如读取命中之类的，一般相对较小，速度很快，大多是对指令的临时存储。</code></pre><h2 id="2017-08-06-每天2个Linux命令-iostat命令"><a href="#2017-08-06-每天2个Linux命令-iostat命令" class="headerlink" title=" 2017-08-06 每天2个Linux命令 iostat命令"></a><center> 2017-08-06 每天2个Linux命令 iostat命令</center></h2><p>iostat是I/O statistics（输入/输出统计）的缩写，对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，<br>同时也会汇报出CPU使用情况。</p><p>(1)用法:</p><pre><code>用法:  iostat  [参数]  [时间]  [次数]</code></pre><p>(2)功能:</p><pre><code>功能: 可以提供更丰富的IO性能状态数据，        通过iostat方便查看CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况, 负载信息。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。iostat属于sysstat软件包。可以用yum install sysstat 直接安装。</code></pre><p>(3)选项参数:</p><pre><code>  1) -c  　　　　　　　　　　　　　　显示CPU使用情况  2) -d 　　　　　　　　　　　　      显示磁盘使用情况  3) -k 　　　　　　　　　　　　　　 以 KB 为单位显示  4) -m 　　　　　　　　　　　　　　以 M 为单位显示  5) -N 　　　　　　　　　　　　　　 显示磁盘阵列(LVM) 信息  6) -x 　　　　　　　　　　　　　　  显示详细信息</code></pre><p>4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# iostat　　　　　　　　　　　　显示所有设备负载情况复制代码[root@localhost sunjimeng]# iostatLinux 3.10.0-229.el7.x86_64 (localhost.localdomain)     2016年06月07日     _x86_64_    (2 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           1.58    0.00    0.92    0.04    0.00   97.47Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnsda               0.57        11.80         2.13     419482      75552复制代码      等价于:复制代码[root@localhost sunjimeng]# iostat -c -dLinux 3.10.0-229.el7.x86_64 (localhost.localdomain)     2016年06月07日     _x86_64_    (2 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           1.55    0.00    0.89    0.04    0.00   97.52Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnsda               0.53        10.92         2.00     419506      76803复制代码  参数说明:  1.cpu值属性说明:  %user：CPU处在用户模式下的时间百分比。  %nice：CPU处在带NICE值的用户模式下的时间百分比。  %system：CPU处在系统模式下的时间百分比。  %iowait：CPU等待输入输出完成时间的百分比。  %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。  %idle：CPU空闲时间百分比。  备注:  如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。  2.disk值属性说明:  tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。“一次传输”请求的大小是未知的。  kB_read/s：每秒从设备（drive expressed）读取的数据量；  kB_wrtn/s：每秒向设备（drive expressed）写入的数据量；  kB_read：读取的总数据量；  kB_wrtn：写入的总数量数据量；  这些单位都为kb。</code></pre><p>2)[root@localhost sunjimeng]# iostat 1 3　　　　　　　　每秒一次，共显示3次</p><pre><code>复制代码[root@localhost sunjimeng]# iostat 1 3Linux 3.10.0-229.el7.x86_64 (localhost.localdomain)     2016年06月07日     _x86_64_    (2 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           1.56    0.00    0.89    0.04    0.00   97.51Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnsda               0.55        11.25         2.05     419502      76249avg-cpu:  %user   %nice %system %iowait  %steal   %idle           4.10    0.00    2.05    0.00    0.00   93.85Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnsda               3.96         0.00        13.37          0         13avg-cpu:  %user   %nice %system %iowait  %steal   %idle           7.10    0.00    2.19    0.00    0.00   90.71Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnsda               0.00         0.00         0.00          0          0</code></pre><p>3)[root@localhost sunjimeng]# iostat -x　　　　　　　　　　　显示更多更详细的信息　　　</p><pre><code>复制代码[root@localhost sunjimeng]# iostat -xLinux 3.10.0-229.el7.x86_64 (localhost.localdomain)     2016年06月07日     _x86_64_    (2 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           1.55    0.00    0.89    0.04    0.00   97.53Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %utilsda               0.02     0.03    0.31    0.23    11.16     2.03    48.66     0.02   40.03   10.06   79.52   3.87   0.21     复制代码      rrqm/s：每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，    如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge）；　　wrqm/s：每秒这个设备相关的写入请求有多少被Merge了。　　rsec/s：每秒读取的扇区数；wsec/：每秒写入的扇区数。      r/s：The number of read requests that were issued to the device per second；      w/s：The number of write requests that were issued to the device per second；　　await：每一个IO请求的处理的平均时间（单位是毫秒）。这里可以理解为IO的响应时间，一般地系统IO响应时间应该低于5ms，    如果大于10ms就比较大了。　　%util：在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，    那么该设备的%util = 0.8/1 = 80%，所以该参数暗示了设备的繁忙程度。一般地，    如果该参数是100%表示设备已经接近满负荷运行了（当然如果是多磁盘，即使%util是100%，因为磁盘的并发能力，    所以磁盘使用未必就到了瓶颈）。</code></pre><p>4)[root@localhost sunjimeng]# iostat -c　　　　　　　　　　显示部分cpu的状态值</p><pre><code>[root@localhost sunjimeng]# iostat -cLinux 3.10.0-229.el7.x86_64 (localhost.localdomain)     2016年06月07日     _x86_64_    (2 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           1.54    0.00    0.89    0.04    0.00   97.53</code></pre><p>5)[root@localhost sunjimeng]# iostat -d　　　　　　　　　　显示部分disk的状态值</p><pre><code>[root@localhost sunjimeng]# iostat -dLinux 3.10.0-229.el7.x86_64 (localhost.localdomain)     2016年06月07日     _x86_64_    (2 CPU)Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnsda               0.54        11.00         2.01     419502      76703</code></pre><p>6)[root@localhost sunjimeng]# iostat -t　　　　　　　　　　 显示tty和cpu信息</p><pre><code>复制代码[root@localhost sunjimeng]# iostat -tLinux 3.10.0-229.el7.x86_64 (localhost.localdomain)     2016年06月07日     _x86_64_    (2 CPU)2016年06月07日 02时20分31秒avg-cpu:  %user   %nice %system %iowait  %steal   %idle           1.55    0.00    0.89    0.04    0.00   97.52Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnsda               0.53        10.88         2.01     419506      77323</code></pre><p>(5)其他:</p><pre><code>  Linux终端TTY:  终端是一种字符型设备，它有多种类型，通常使用tty来简称各种类型的终端设备。tty是Teletype的缩写。    Teletype是最早出现的一种终端设备，很象电传打字机（或者说就是），是由Teletype公司生产的。设备名放在特殊文件目录/dev/下，终端特殊设备文件一般有以下几种：　　1.串行端口终端（/dev/ttySn）　　串行端口终端（Serial Port Terminal）是使用计算机串行端口连接的终端设备。计算机把每个串行端口都看作是一个字符设备。有段时间这些串行端口设备通常被称为终端设备，因为那时它的最大用途就是用来连接终端。这些串行端口所对应的设备名称是/dev/tts/0（或/dev/ttyS0）、/dev/tts/1（或/dev/ttyS1）等，设备号分别是（4,0）、（4,1）等，分别对应于DOS系统下的COM1、COM2等。若要向一个端口发送数据，可以在命令行上把标准输出重定向到这些特殊文件名上即可。例如，在命令行提示符下键入：echo test &gt; /dev/ttyS1会把单词”test”发送到连接在ttyS1（COM2）端口的设备上。　　2.伪终端（/dev/pty/）　　伪终端（Pseudo Terminal）是成对的逻辑终端设备，例如/dev/ptyp3和/dev/ttyp3（或着在设备文件系统中分别是/dev/pty/m3和/dev/pty/s3）。它们与实际物理设备并不直接相关。如果一个程序把ttyp3看作是一个串行端口设备，则它对该端口的读/写操作会反映在该逻辑终端设备对的另一个上面（ttyp3）。而ttyp3则是另一个程序用于读写操作的逻辑设备。这样，两个程序就可以通过这种逻辑设备进行互相交流，而其中一个使用ttyp3的程序则认为自己正在与一个串行端口进行通信。这很象是逻辑设备对之间的管道操作。对于ttyp3（s3），任何设计成使用一个串行端口设备的程序都可以使用该逻辑设备。但对于使用ptyp3的程序，则需要专门设计来使用ptyp3（m3）逻辑设备。　　例如，如果某人在网上使用telnet程序连接到你的计算机上，则telnet程序就可能会开始连接到设备ptyp2（m2）上（一个伪终端端口上）。此时一个getty程序就应该运行在对应的ttyp2（s2）端口上。当telnet从远端获取了一个字符时，该字符就会通过m2、s2传递给getty程序，而getty程序就会通过s2、m2和telnet程序往网络上返回”login:”字符串信息。这样，登录程序与telnet程序就通过“伪终端”进行通信。通过使用适当的软件，就可以把两个甚至多个伪终端设备连接到同一个物理串行端口上。在使用设备文件系统（device filesystem）之前，为了得到大量的伪终端设备特殊文件，HP-UX AIX等使用了比较复杂的文件名命名方式。　　3.控制终端（/dev/tty）如果当前进程有控制终端（Controlling Terminal）的话，那么/dev/tty就是当前进程的控制终端的设备特殊文件。可以使用命令”ps –ax”来查看进程与哪个控制终端相连。对于你登录的shell，/dev/tty就是你使用的终端，设备号是（5,0）。使用命令”tty”可以查看它具体对应哪个实际终端设备。/dev/tty有些类似于到实际所使用终端设备的一个联接。　　4.控制台终端（/dev/ttyn, /dev/console）在UNIX系统中，计算机显示器通常被称为控制台终端（Console）。它仿真了类型为Linux的一种终端（TERM=Linux），并且有一些设备特殊文件与之相关联：tty0、tty1、tty2等。当你在控制台上登录时，使用的是tty1。使用Alt+[F1—F6]组合键时，我们就可以切换到tty2、tty3等上面去。tty1 –tty6等称为虚拟终端，而tty0则是当前所使用虚拟终端的一个别名，系统所产生的信息会发送到该终端上。因此不管当前正在使用哪个虚拟终端，系统信息都会发送到控制台终端上。你可以登录到不同的虚拟终端上去，因而可以让系统同时有几个不同的会话期存在。只有系统或超级用户root可以向/dev/tty0进行写操作，　　5.其它类型还针对很多不同的字符设备存在有很多其它种类的终端设备特殊文件。例如针对ISDN设备的/dev/ttyIn终端设备等。这里不再赘述。      2.LVM:　　 LVM是 Logical Volume Manager(逻辑卷管理)的简写，它是Linux环境下对磁盘分区进行管理的一种机制。  建了一个VG,有3个逻辑卷，其中一个我分了100m，但是我往上拷了一个300m的文件，为什么能成功？  lvm有点像windows下的动态磁盘，因为LVM能够动态调整逻辑卷的大小。实际上LVM卷按照通常分区的概念是在同一个分区上，每个LVM卷都能动态扩展到整个分区的大小，只要三个逻辑卷已用空间之和小于这个分区的大小，那么你可以向任何LVM卷上继续拷贝文件。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 top free</title>
      <link href="/2017/08/08/mei-tian-2-ge-linux-ming-ling-top-free/"/>
      <url>/2017/08/08/mei-tian-2-ge-linux-ming-ling-top-free/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-05-每天2个Linux命令-top命令"><a href="#2017-08-05-每天2个Linux命令-top命令" class="headerlink" title=" 2017-08-05 每天2个Linux命令 top命令"></a><center> 2017-08-05 每天2个Linux命令 top命令</center></h2><p>top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。</p><p>(1)用法:</p><pre><code>  用法:  top  [参数]  top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态。如果在前台执行该命令,它将独占前台,直到用户终止该程序为止。比较准确的说,top命令提供了实时的对系统处理器的状态监视。它将显示系统中CPU最“敏感”的任务列表。该命令可以按CPU使用。内存使用和执行时间对任务进行排序，而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定。</code></pre><p>(2)功能:</p><pre><code>  功能:  top命令可以实时动态地查看系统的整体运行情况，是一个综合了多方信息监测系统性能和运行信息的实用工具。通过top命令所提供的互动式界面，用热键可以管理。</code></pre><p>(3)选项参数:</p><pre><code>  1)  -b 　　　　　　 批处理  2)  -c　　 　　　　 显示完整的治命令         3)  -I 　　　　　　 忽略失效过程  4)  -s　　 　　　　 保密模式  5)  -S 　　　　　　累积模式  6)  -i&lt;时间&gt; 　  　设置间隔时间  7)  -p&lt;进程号&gt;     指定进程  8)  -n&lt;次数&gt;       循环显示的次数</code></pre><p>(4)实例:</p><pre><code>  1)[sunjimeng@localhost ~]$ top复制代码[sunjimeng@localhost ~]$ toptop - 18:05:44 up  6:49,  2 users,  load average: 0.00, 0.01, 0.05Tasks: 417 total,   1 running, 416 sleeping,   0 stopped,   0 zombie%Cpu(s):  4.8 us,  1.9 sy,  0.0 ni, 93.2 id,  0.0 wa,  0.0 hi,  0.2 si,  0.0 stKiB Mem :  2013872 total,   894192 free,   612372 used,   507308 buff/cacheKiB Swap:  2097148 total,  2097148 free,        0 used.  1193280 avail Mem    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                   3265 sunjime+  20   0 1823060 301072  44248 S  59.8 14.9  29:14.18 gnome-shell                               2004 root      20   0  205212  34256   8036 S  13.0  1.7   6:01.59 Xorg                                     13378 sunjime+  20   0  796120  22176  14180 S   4.0  1.1   0:01.98 gnome-terminal-                          14386 sunjime+  20   0  130288   2096   1268 R   0.7  0.1   0:00.29 top                                       3302 sunjime+  20   0  461684   6024   3552 S   0.3  0.3   1:09.70 ibus-daemon                              12151 root      20   0       0      0      0 S   0.3  0.0   0:01.40 kworker/0:0                              1 root      20   0   60052   7796   2656 S   0.0  0.4   0:06.50 systemd                                  2 root      20   0       0      0      0 S   0.0  0.0   0:00.14 kthreadd                                 3 root      20   0       0      0      0 S   0.0  0.0   0:05.55 ksoftirqd/0                              5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H                             7 root      rt   0       0      0      0 S   0.0  0.0   0:00.74 migration/0                              8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh                                   9 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/0                                 10 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/1                                 11 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/2                                 12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/3                                 13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/4                                 14 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/5                                 15 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/6                                 16 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/7     复制代码  显示结果的解释:  1.第一行，任务队列信息，同 uptime 命令的执行结果    【top - 18:05:44】   　　　　　　　　　　当前系统的时间    【up     6:49      】   　　　　　　　　　　从6:49分开始运行，如果已经运行3天，则会显示 up  3 days。    【2  users          】   　　　　　　　　　　两个用户    【load average: 0.00, 0.01, 0.05】　　　系统负载，即任务队列的平均长度  2.第二行，Tasks — 任务（进程）    【Tasks: 417 total】　　　　　　　　　　 总进程数    【1 running】　　　　　　　　　　　　　  正在运行的进程数    【416 sleeping】　　　　　　　　　　　　 睡眠的进程数    【0 stopped】　　　　　　　　　　　　　  停止的进程数    【0 zombie】　　　　　　　　　　　　　　冻结的进程数  3.第三行，cpu状态信息    【%Cpu(s): 4.8 us】 　　　　　　　　　  用户空间占用CPU百分比    【1.9 sy】　　　　　　　　　　　　　　　  内核空间占用CPU的百分比    【KiB Mem : 2013872 total】　　　　　　物理内存总量    【0.0% ni】　　　　　　　　　　　　　　  用户进程空间内改变过优先级的进程占用CPU百分比    【93.2 id】　　　　　　　　　　　　　　　 空闲CPU百分比  4.第四行,内存状态    【KiB Mem : 2013872 total】　　　　　　物理内存总量，2G    【612372 used】　　　　　　　　　　　　 已使用内存总量    【894192 free】　　　　　　　　　　　　  空闲内存总量    【507308 buff/cache】　　　　　　　　　 缓存的内存量  5.第五行，swap交换分区信息    【KiB Swap: 2097148 total】　　　　　　交换区总量    【2097148 free】　　　　　　　　　　　　空闲的交换区总量    【0 used】　　　　　　　　　　　　　　　 使用的交换区总量    【1193280 avail Mem】　　　　　　　　  缓冲的交换区总量，即可用交换区内存  6.空行  7.各个标题的意思:    PID — 进程idUSER — 进程所有者PR — 进程优先级NI — nice值。负值表示高优先级，正值表示低优先级VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESRES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATASHR — 共享内存大小，单位kbS — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程　　%CPU — 上次更新到现在的CPU时间占用百分比%MEM — 进程使用的物理内存百分比TIME+ — 进程使用的CPU时间总计，单位1/100秒COMMAND — 进程名称（命令名/命令行）</code></pre><p>2)[sunjimeng@localhost ~]$ uptime　　　　　　　　同top命令第一行的任务队列信息执行结果</p><pre><code>[sunjimeng@localhost ~]$ uptime 18:25:18 up  7:09,  2 users,  load average: 0.04, 0.06, 0.05 </code></pre><p>3)[sunjimeng@localhost ~]$ top -p 2004　　　　　 显示特定进程号的所有进程信息　</p><pre><code>复制代码[sunjimeng@localhost ~]$ top -p 2004top - 18:55:18 up  7:39,  2 users,  load average: 0.40, 0.21, 0.12Tasks:   1 total,   0 running,   1 sleeping,   0 stopped,   0 zombie%Cpu(s): 11.2 us,  3.4 sy,  0.0 ni, 85.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem :  2013872 total,   874012 free,   632484 used,   507376 buff/cacheKiB Swap:  2097148 total,  2097148 free,        0 used.  1173212 avail Mem    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                               2004 root      20   0  203712  32824   8084 S   6.7  1.6   6:16.16 Xorg  </code></pre><p>(5)其他的一些范例:</p><pre><code>  [sunjimeng@localhost ~]# top -b #　　　　   以批处理模式显示程序信息  [sunjimeng@localhost ~]# top -S #　　　　   以累积模式显示程序信息  [sunjimeng@localhost ~]# top -n -2 #　　　  设置信息更新次数,表示更新2次后终止更新显示  [sunjimeng@localhost ~]# top -d -3 #　　　  设置信息更新时间,表示更新周期为3秒</code></pre><h2 id="2017-08-05-每天2个Linux命令-free命令"><a href="#2017-08-05-每天2个Linux命令-free命令" class="headerlink" title=" 2017-08-05 每天2个Linux命令 free命令"></a><center> 2017-08-05 每天2个Linux命令 free命令</center></h2><p>free命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。</p><p>(1)用法:</p><pre><code>  用法:  free  [选项参数]</code></pre><p>(2)功能:</p><pre><code>  功能:  free 命令显示系统使用和空闲的内存情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。共享内存将被忽略。</code></pre><p>(3)选项参数:</p><pre><code>  1) -b 　　　　　　　　　　 以Byte为单位显示内存使用情况。   2) -k 　　　　　　　　       以KB为单位显示内存使用情况。  3) -m 　　　　　　　　　　以MB为单位显示内存使用情况。   4) -g 　　　　　　　　　　 以GB为单位显示内存使用情况。   5) -s　　　　　　　　　　  每3秒执行一次free操作</code></pre><p>(4)实例:</p><pre><code>  1)[sunjimeng@localhost ~]$ free　　　　　　　　　　显示内存使用情况复制代码[sunjimeng@localhost ~]$ free                                     //以kn为单位显示              total        used        free      shared  buff/cache   availableMem:        2013872      641564      864800       10132      507508     1164056Swap:       2097148           0     2097148[sunjimeng@localhost ~]$ free -m                                 //以MB为单位显示              total        used        free      shared  buff/cache   availableMem:           1966         626         844           9         495        1136Swap:          2047           0        2047[sunjimeng@localhost ~]$ free -g　　　　　　　　　　　　　　　　　　  //以GB为单位进行显示              total        used        free      shared  buff/cache   availableMem:              1           0           0           0           0           1Swap:             1           0           1[sunjimeng@localhost ~]$ 复制代码  第一部分Mem行解释：    total：　　　　　　　　   内存总数； 　　   used：　　　　　　　　  已经使用的内存数；   free：　　　　　　　　   空闲的内存数；   Buffers/cached:　　      磁盘缓存的大小。   关系:  total = used + free +Buffers/cached  第二部分Swap指的是交换分区，也就是我们通常所说的虚拟内存。</code></pre><p>2)[sunjimeng@localhost ~]$ free -t　　　　　　　　　　　以总的形式显示内存的使用情况</p><pre><code>[sunjimeng@localhost ~]$ free -t              total        used        free      shared  buff/cache   availableMem:        2013872      640344      865772       10132      507756     1165108Swap:       2097148           0     2097148Total:      4111020      640344     2962920</code></pre><p>3)[sunjimeng@localhost ~]$ free -s 3　　　　　　　　　每三秒执行一次free操作</p><pre><code>复制代码[sunjimeng@localhost ~]$ free -s 3              total        used        free      shared  buff/cache   availableMem:        2013872      642136      863972       10132      507764     1163300Swap:       2097148           0     2097148              total        used        free      shared  buff/cache   availableMem:        2013872      642148      863960       10132      507764     1163288Swap:       2097148           0     2097148......</code></pre><p>(5)其他:</p><pre><code>  buffers和cached都是缓存，两者的区别：  为了提高磁盘存取效率, Linux做了一些精心的设计, 除了对dentry进行缓存(用于VFS,加速文件路径名到inode的转换), 还采取了两种主要Cache方式：Buffer Cache和Page Cache。前者针对磁盘块的读写，后者针对文件inode的读写。这些Cache有效缩短了 I/O系统调用(比如read,write,getdents)的时间。   简单说来，page cache用来缓存文件数据，buffer cache用来缓存磁盘数据。在有文件系统的情况下，对文件操作，那么数据会缓存到page cache，如果直接采用dd等工具对磁盘进行读写，那么数据会缓存到buffer cache。  所以我们看linux,只要不用swap的交换空间,就不用担心自己的内存太少.如果常常swap用很多,可能你就要考虑加物理内存了.这也是linux看内存是否够用的标准。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis学习</title>
      <link href="/2017/08/07/redis-xue-xi/"/>
      <url>/2017/08/07/redis-xue-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-08-07-redis学习笔记"><a href="#2017-08-07-redis学习笔记" class="headerlink" title="2017-08-07 redis学习笔记"></a><center>2017-08-07 redis学习笔记</center></h2><p>1    课程计划</p><pre><code>1、    redis介绍    a)    什么是NoSql    b)    NoSql的分类    c)    什么是redis    d)    Redis应用场景2、    redis安装（重点）3、    redis客户端    a)    redis自带客户端    b)    图形界面的客户端（了解）    c)    Java客户端jedis（重点）4、    Redis数据类型（重点）    a)    String类型    b)    Map类型    c)    List类型    d)    Set类型    e)    SortedSet5、    Keys命令（了解）6、    Redis的持久化方案    a)    Rbd方式    b)    Aof方式7、    Redis的主从复制8、    Redis的集群（重点）9、    Jedis连接redis集群</code></pre><p>2    Redis介绍</p><pre><code>2.1    什么是NoSql为了解决高并发、高可用、高可扩展，大数据存储等一系列问题而产生的数据库解决方案，就是NoSql。NoSql，叫非关系型数据库，它的全名Not only sql。它不能替代关系型数据库，只能作为关系型数据库的一个良好补充。2.2    NoSql的分类1    键值(Key-Value)存储数据库相关产品： Tokyo Cabinet/Tyrant、Redis、Voldemort、Berkeley DB典型应用： 内容缓存，主要用于处理大量数据的高访问负载。 数据模型： 一系列键值对优势： 快速查询劣势： 存储的数据缺少结构化2    列存储数据库相关产品：Cassandra, HBase, Riak典型应用：分布式的文件系统数据模型：以列簇式存储，将同一列数据存在一起优势：查找速度快，可扩展性强，更容易进行分布式扩展 劣势：功能相对局限3    文档型数据库相关产品：CouchDB、MongoDB典型应用：Web应用（与Key-Value类似，Value是结构化的）数据模型： 一系列键值对 优势：数据结构要求不严格 劣势： 查询性能不高，而且缺乏统一的查询语法4    图形(Graph)数据库相关数据库：Neo4J、InfoGrid、Infinite Graph典型应用：社交网络数据模型：图结构优势：利用图结构相关算法。劣势：需要对整个图做计算才能得出结果，不容易做分布式的集群方案。2.3    什么是redisRedis是使用c语言开发的一个高性能键值数据库。Redis可以通过一些键值类型来存储数据。键值类型：String字符类型map散列类型list列表类型set集合类型sortedset有序集合类型2.4    redis历史发展2008年，意大利的一家创业公司Merzia推出了一款基于MySQL的网站实时统计系统LLOOGG，然而没过多久该公司的创始人 Salvatore Sanfilippo便 对MySQL的性能感到失望，于是他决定亲自为LLOOGG量身定做一个数据库，并于2009年开发完成，这个数据库就是Redis。 不过Salvatore Sanfilippo并不满足只将Redis用于LLOOGG这一款产品，而是希望更多的人使用它，于是在同一年Salvatore Sanfilippo将Redis开源发布，并开始和Redis的另一名主要的代码贡献者Pieter Noordhuis一起继续着Redis的开发，直到今天。Salvatore Sanfilippo自己也没有想到，短短的几年时间，Redis就拥有了庞大的用户群体。Hacker News在2012年发布了一份数据库的使用情况调查，结果显示有近12%的公司在使用Redis。国内如新浪微博、街旁网、知乎网，国外如GitHub、Stack Overflow、Flickr等都是Redis的用户。VMware公司从2010年开始赞助Redis的开发， Salvatore Sanfilippo和Pieter Noordhuis也分别在3月和5月加入VMware，全职开发Redis。2.5    redis的应用场景缓存（数据查询、短连接、新闻内容、商品内容等等）。（最多使用）分布式集群架构中的session分离。聊天室的在线好友列表。任务队列。（秒杀、抢购、12306等等）应用排行榜。网站访问统计。数据过期处理（可以精确到毫秒）</code></pre><p>3    redis安装</p><pre><code>3.1    redis下载官网地址：http://redis.io/下载地址：http://download.redis.io/releases/redis-3.0.0.tar.gz</code></pre><p><img src="/images/20170807/1.png"></p><pre><code>3.2    redis的安装redis的安装环境会安装到linux系统中。第一步：安装VMware，并且在VMware中安装centos系统（参考linux教程）。第二步：将redis的压缩包，上传到linux系统第三步：对redis的压缩包进行解压缩Redis解压缩之后的文件是用c语言写的源码文件[root@itheima ~]# tar -zxf redis-3.0.0.tar.gz第四步：安装c语言环境（安装centos之后，自带c语言环境）[root@itheima ~]# yum install gcc-c++第五步：编译redis源码[root@itheima ~]# cd redis-3.0.0[root@itheima redis-3.0.0]# make第六步：安装redis[root@itheima redis-3.0.0]# make install PREFIX=/usr/local/redis19第七步：查看是否安装成功</code></pre><p><img src="/images/20170807/2.png"></p><pre><code>3.3    redis启动    3.3.1    前端启动    前端启动的命令：        [root@itheima bin]# ./redis-server    前端启动的关闭：        强制关闭：Ctrl+c        正常关闭：[root@itheima bin]# ./redis-cli shutdown    启动界面：    前端启动的问题：    一旦客户端关闭，则redis服务也停掉。</code></pre><p><img src="/images/20170807/3.png"></p><pre><code>    3.3.2    后端启动    第一步：需要将redis解压之后的源码包中的redis.conf文件拷贝到bin目录下    [root@itheima bin]# cp /root/redis-3.0.0/redis.conf ./    第二步：修改redis.conf文件，将daemonize改为yes    先要使用vim redis.conf</code></pre><p><img src="/images/20170807/4.png"></p><pre><code>    第三步：使用命令后端启动redis    [root@itheima bin]# ./redis-server redis.conf    第四步：查看是否启动成功</code></pre><p><img src="/images/20170807/5.png"></p><pre><code>    关闭后端启动的方式：    强制关闭：[root@itheima bin]# kill -9 5071    正常关闭：[root@itheima bin]# ./redis-cli shutdown    在项目中，建议使用正常关闭。    因为redis作为缓存来使用的话，将数据存储到内存中，如果使用正常关闭，则会将内存数据持久化到本地之后，再关闭。    如果是强制关闭，则不会进行持久化操作，可能会造成部分数据的丢失。</code></pre><p>4    Redis客户端</p><pre><code>4.1    Redis自带的客户端1    启动启动客户端命令：[root@itheima bin]# ./redis-cli -h 127.0.0.1 -p 6379-h：指定访问的redis服务器的ip地址-p：指定访问的redis服务器的port端口还可以写成：[root@itheima bin]# ./redis-cli使用默认配置：默认的ip【127.0.0.1】，默认的port【6379】2    关闭Ctrl+c127.0.0.1:6379&gt; quit4.2    图形界面客户端安装文件位置：</code></pre><p><img src="/images/20170807/6.png"></p><pre><code>安装之后，打开如下：</code></pre><p><img src="/images/20170807/7.png"></p><pre><code>防火墙设置：[root@itheima redis-3.0.0]# vim /etc/sysconfig/iptables# Firewall configuration written by system-config-firewall# Manual customization of this file is not recommended.*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 6379 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j REJECT --reject-with icmp-host-prohibitedCOMMIT~                                                                                                     ~                                                                                                     ~                                                                                                     ~                                                                                                     ~                                                                                                     ~                                                                                                     ~                                                                                                     ~                                                                                                     ~                                                                                                     ~                                                                                                     ~                                                                                                     "/etc/sysconfig/iptables" 16L, 677C 已写入                                          [root@itheima redis-3.0.0]# service iptables restartiptables：清除防火墙规则：                                 [确定]iptables：将链设置为政策 ACCEPT：filter                    [确定]iptables：正在卸载模块：                                   [确定]iptables：应用防火墙规则：                                 [确定][root@itheima redis-3.0.0]#</code></pre><p><img src="/images/20170807/8.png"></p><pre><code>Redis.conf中的数据库数量的设置：</code></pre><p><img src="/images/20170807/9.png"></p><pre><code>选择数据库的方式：使用select 加上数据库的下标 就可以选择指定的数据库来使用，下标从0开始127.0.0.1:6379&gt; select 15OK127.0.0.1:6379[15]&gt;4.3    Jedis客户端    4.3.1    jedis介绍        Redis不仅是使用命令来操作，现在基本上主流的语言都有客户端支持，比如java、C、C#、C++、php、Node.js、Go等。         在官方网站里列一些Java的客户端，有Jedis、Redisson、Jredis、JDBC-Redis、等其中官方推荐使用Jedis和Redisson。         在企业中用的最多的就是Jedis，下面我们就重点学习下Jedis。         Jedis同样也是托管在github上，地址：https://github.com/xetorthio/jedis    4.3.2    工程搭建        添加jar包</code></pre><p><img src="/images/20170807/10.png"></p><pre><code>    4.3.3    单实例连接redis</code></pre><p><img src="/images/20170807/11.png"></p><pre><code>    4.3.4    使用jedis连接池连接redis服务器</code></pre><p><img src="/images/20170807/12.png"></p><pre><code>    4.3.5    Spring整合jedisPool（自学）    1    添加spring的jar包    2    配置spring配置文件applicationContext.xml    &lt;?xml version="1.0" encoding="UTF-8"?&gt;    &lt;beans xmlns="http://www.springframework.org/schema/beans"        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc"        xmlns:context="http://www.springframework.org/schema/context"        xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx"        xsi:schemaLocation="http://www.springframework.org/schema/beans             http://www.springframework.org/schema/beans/spring-beans-3.2.xsd             http://www.springframework.org/schema/mvc             http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd             http://www.springframework.org/schema/context             http://www.springframework.org/schema/context/spring-context-3.2.xsd             http://www.springframework.org/schema/aop             http://www.springframework.org/schema/aop/spring-aop-3.2.xsd             http://www.springframework.org/schema/tx             http://www.springframework.org/schema/tx/spring-tx-3.2.xsd "&gt;        &lt;!-- 连接池配置 --&gt;        &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt;            &lt;!-- 最大连接数 --&gt;            &lt;property name="maxTotal" value="30" /&gt;            &lt;!-- 最大空闲连接数 --&gt;            &lt;property name="maxIdle" value="10" /&gt;            &lt;!-- 每次释放连接的最大数目 --&gt;            &lt;property name="numTestsPerEvictionRun" value="1024" /&gt;            &lt;!-- 释放连接的扫描间隔（毫秒） --&gt;            &lt;property name="timeBetweenEvictionRunsMillis" value="30000" /&gt;            &lt;!-- 连接最小空闲时间 --&gt;            &lt;property name="minEvictableIdleTimeMillis" value="1800000" /&gt;            &lt;!-- 连接空闲多久后释放, 当空闲时间&gt;该值 且 空闲连接&gt;最大空闲连接数 时直接释放 --&gt;            &lt;property name="softMinEvictableIdleTimeMillis" value="10000" /&gt;            &lt;!-- 获取连接时的最大等待毫秒数,小于零:阻塞不确定的时间,默认-1 --&gt;            &lt;property name="maxWaitMillis" value="1500" /&gt;            &lt;!-- 在获取连接的时候检查有效性, 默认false --&gt;            &lt;property name="testOnBorrow" value="false" /&gt;            &lt;!-- 在空闲时检查有效性, 默认false --&gt;            &lt;property name="testWhileIdle" value="true" /&gt;            &lt;!-- 连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认true --&gt;            &lt;property name="blockWhenExhausted" value="false" /&gt;        &lt;/bean&gt;        &lt;!-- redis单机 通过连接池 --&gt;        &lt;bean id="jedisPool" class="redis.clients.jedis.JedisPool"            destroy-method="close"&gt;            &lt;constructor-arg name="poolConfig" ref="jedisPoolConfig" /&gt;            &lt;constructor-arg name="host" value="192.168.242.130" /&gt;            &lt;constructor-arg name="port" value="6379" /&gt;        &lt;/bean&gt;    &lt;/beans&gt;    3    测试代码    @Test        public void testJedisPool() {            JedisPool pool = (JedisPool) applicationContext.getBean("jedisPool");            Jedis jedis = null;            try {                jedis = pool.getResource();                jedis.set("name", "lisi");                String name = jedis.get("name");                System.out.println(name);            } catch (Exception ex) {                ex.printStackTrace();            } finally {                if (jedis != null) {                    // 关闭连接                    jedis.close();                }            }        }</code></pre><p>5    Redis数据类型</p><pre><code>5.1    String    5.1.1.1    命令    5.1.1.2    赋值        语法：SET key value        127.0.0.1:6379&gt; set test 123        OK    5.1.1.3    取值        语法：GET key        127.0.0.1:6379&gt; get test        "123“    5.1.1.4    取值并赋值        语法：GETSET key value        127.0.0.1:6379&gt; getset s2 222        "111"        127.0.0.1:6379&gt; get s2        "222"    5.1.1.5    设置/获取多个键值         语法：        MSET key value [key value …]        MGET key [key …]        127.0.0.1:6379&gt; mset k1 v1 k2 v2 k3 v3        OK        127.0.0.1:6379&gt; get k1        "v1"        127.0.0.1:6379&gt; mget k1 k3        1) "v1"        2) "v3"    5.1.1.6    删除        语法：DEL key        127.0.0.1:6379&gt; del test        (integer) 1    5.1.1.7    数值增减        1    递增数字         当存储的字符串是整数时，Redis提供了一个实用的命令INCR，其作用是让当前键值递增，并返回递增后的值。        语法：INCR key        127.0.0.1:6379&gt; incr num        (integer) 1        127.0.0.1:6379&gt; incr num        (integer) 2        127.0.0.1:6379&gt; incr num        (integer) 3        2    增加指定的整数        语法：INCRBY key increment        127.0.0.1:6379&gt; incrby num 2        (integer) 5        127.0.0.1:6379&gt; incrby num 2        (integer) 7        127.0.0.1:6379&gt; incrby num 2        (integer) 9        3    递减数值        语法：DECR key        127.0.0.1:6379&gt; decr num        (integer) 9        127.0.0.1:6379&gt; decr num        (integer) 8        4    减少指定的整数         语法：DECRBY key decrement        127.0.0.1:6379&gt; decr num        (integer) 6        127.0.0.1:6379&gt; decr num        (integer) 5        127.0.0.1:6379&gt; decrby num 3        (integer) 2        127.0.0.1:6379&gt; decrby num 3        (integer) -1    5.1.1.8    其它命令(自学)        5.1.1.8.1    向尾部追加值             APPEND的作用是向键值的末尾追加value。如果键不存在则将该键的值设置为value，            即相当于 SET key value。返回值是追加后字符串的总长度。             语法：APPEND key value            127.0.0.1:6379&gt; set str hello            OK            127.0.0.1:6379&gt; append str " world!"            (integer) 12            127.0.0.1:6379&gt; get str             "hello world!"        5.1.1.8.2    获取字符串长度             STRLEN命令返回键值的长度，如果键不存在则返回0。            语法：STRLEN key            127.0.0.1:6379&gt; strlen str             (integer) 0            127.0.0.1:6379&gt; set str hello            OK            127.0.0.1:6379&gt; strlen str             (integer) 5    5.1.2    应用        5.1.2.1    自增主键        商品编号、订单号采用string的递增数字特性生成。        定义商品编号key：items:id        192.168.101.3:7003&gt; INCR items:id        (integer) 2        192.168.101.3:7003&gt; INCR items:id        (integer) 35.2    Hash    散列类型    5.2.1    使用string的问题        假设有User对象以JSON序列化的形式存储到Redis中，User对象有id，username、password、age、name等属性，        存储的过程如下：         保存、更新：         User对象 à json(string) à redis         如果在业务上只是更新age属性，其他的属性并不做更新我应该怎么做呢？         如果仍然采用上边的方法在传输、处理时会造成资源浪费，下边讲的hash可以很好的解决这个问题。    5.2.2    redis hash介绍        hash叫散列类型，它提供了字段和字段值的映射。字段值只能是字符串类型，不支持散列类型、集合类型等其它类型。如下：</code></pre><p><img src="/images/20170807/13.png"></p><pre><code>    5.2.3    命令        5.2.3.1    赋值            HSET命令不区分插入和更新操作，当执行插入操作时HSET命令返回1，当执行更新操作时返回0。            1    一次只能设置一个字段值            语法：HSET key field value                127.0.0.1:6379&gt; hset user username zhangsan             (integer) 1            2    一次可以设置多个字段值            语法：HMSET key field value [field value ...]                    127.0.0.1:6379&gt; hmset user age 20 username lisi             OK            3    当字段不存在时赋值，类似HSET，区别在于如果字段存在，该命令不执行任何操作            语法：HSETNX key field value            127.0.0.1:6379&gt; hsetnx user age 30    如果user中没有age字段则设置age值为30，否则不做任何操作            (integer) 0        5.2.3.2    取值             1    一次只能获取一个字段值            语法：HGET key field                        127.0.0.1:6379&gt; hget user username            "zhangsan“            2    一次可以获取多个字段值            语法：HMGET key field [field ...]                            127.0.0.1:6379&gt; hmget user age username            1) "20"            2) "lisi"            3    获取所有字段值            语法：HGETALL key            127.0.0.1:6379&gt; hgetall user            1) "age"            2) "20"            3) "username"            4) "lisi"        5.2.3.3    删除字段            可以删除一个或多个字段，返回值是被删除的字段个数             语法：HDEL key field [field ...]            127.0.0.1:6379&gt; hdel user age            (integer) 1            127.0.0.1:6379&gt; hdel user age name            (integer) 0            127.0.0.1:6379&gt; hdel user age username            (integer) 1         5.2.3.4    增加数字             语法：HINCRBY key field increment            127.0.0.1:6379&gt; hincrby user age 2    将用户的年龄加2            (integer) 22            127.0.0.1:6379&gt; hget user age        获取用户的年龄            "22“        5.2.3.5    其它命令(自学)            5.2.3.5.1    判断字段是否存在            语法：HEXISTS key field            127.0.0.1:6379&gt; hexists user age        查看user中是否有age字段            (integer) 1            127.0.0.1:6379&gt; hexists user name    查看user中是否有name字段            (integer) 0            5.2.3.5.2    只获取字段名或字段值            语法：            HKEYS key            HVALS key            127.0.0.1:6379&gt; hmset user age 20 name lisi             OK            127.0.0.1:6379&gt; hkeys user            1) "age"            2) "name"            127.0.0.1:6379&gt; hvals user            1) "20"            2) "lisi"        5.2.3.5.3    获取字段数量             语法：HLEN key            127.0.0.1:6379&gt; hlen user            (integer) 2    5.2.4    应用        5.2.4.1    存储商品信息        1    商品字段        【商品id、商品名称、商品描述、商品库存、商品好评】        2    定义商品信息的key        商品1001的信息在 Redis中的key为：[items:1001]        3    存储商品信息        192.168.101.3:7003&gt; HMSET items:1001 id 3 name apple price 999.9        OK        4    获取商品信息        192.168.101.3:7003&gt; HGET items:1001 id        "3"        192.168.101.3:7003&gt; HGETALL items:1001        1) "id"        2) "3"        3) "name"        4) "apple"        5) "price"        6) "999.9"5.3    List    5.3.1    Arraylist和linkedlist的区别    Arraylist是使用数组来存储数据，特点：查询快、增删慢    Linkedlist是使用双向链表存储数据，特点：增删快、查询慢，但是查询链表两端的数据也很快。    Redis的list是采用来链表来存储的，所以对于redis的list数据类型的操作，是操作list的两端数据来操作的。    5.3.2    命令        5.3.2.1    向列表两端增加元素        1    向列表左边增加元素         语法：LPUSH key value [value ...]        127.0.0.1:6379&gt; lpush list:1 1 2 3        (integer) 3        2    向列表右边增加元素         语法：RPUSH key value [value ...]        127.0.0.1:6379&gt; rpush list:1 4 5 6        (integer) 3        5.3.2.2    查看列表         LRANGE命令是列表类型最常用的命令之一，获取列表中的某一片段，将返回start、stop之间的所有元素（包含两端的元素），        索引从0开始。索引可以是负数，如：“-1”代表最后边的一个元素。        语法：LRANGE key start stop        127.0.0.1:6379&gt; lrange list:1 0 2        1) "2"        2) "1"        3) "4"        127.0.0.1:6379&gt; lrange list1 0 -1        5.3.2.3    从列表两端弹出元素         LPOP命令从列表左边弹出一个元素，会分两步完成：        第一步是将列表左边的元素从列表中移除        第二步是返回被移除的元素值。        语法：        LPOP key        RPOP key        127.0.0.1:6379&gt; lpop list:1        "3“        127.0.0.1:6379&gt; rpop list:1        "6“        5.3.2.4    获取列表中元素的个数         语法：LLEN key        127.0.0.1:6379&gt; llen list:1        (integer) 2        5.3.2.5    其它命令(自学)            5.3.2.5.1    删除列表中指定的值             LREM命令会删除列表中前count个值为value的元素，返回实际删除的元素个数。根据count值的不同，            该命令的执行方式会有所不同：             1    当count&gt;0时， LREM会从列表左边开始删除。             2    当count&lt;0时， LREM会从列表后边开始删除。             3    当count=0时， LREM删除所有值为value的元素。             语法：LREM key count value            5.3.2.5.2    获得/设置指定索引的元素值             1    获得指定索引的元素值            语法：LINDEX key index            127.0.0.1:6379&gt; lindex l:list 2            "1"            2    设置指定索引的元素值            语法：LSET key index value            127.0.0.1:6379&gt; lset l:list 2 2            OK            127.0.0.1:6379&gt; lrange l:list 0 -1            1) "6"            2) "5"            3) "2"            4) "2"            5.3.2.5.3    只保留列表指定片段            指定范围和LRANGE一致             语法：LTRIM key start stop            127.0.0.1:6379&gt; lrange l:list 0 -1            1) "6"            2) "5"            3) "0"            4) "2"            127.0.0.1:6379&gt; ltrim l:list 0 2            OK            127.0.0.1:6379&gt; lrange l:list 0 -1            1) "6"            2) "5"            3) "0"            5.3.2.5.4    向列表中插入元素             该命令首先会在列表中从左到右查找值为pivot的元素，            然后根据第二个参数是BEFORE还是AFTER来决定将value插入到该元素的前面还是后面。             语法：LINSERT key BEFORE|AFTER pivot value            127.0.0.1:6379&gt; lrange list 0 -1            1) "3"            2) "2"            3) "1"            127.0.0.1:6379&gt; linsert list after 3 4            (integer) 4            127.0.0.1:6379&gt; lrange list 0 -1            1) "3"            2) "4"            3) "2"            4) "1"            5.3.2.5.5    将元素从一个列表转移到另一个列表中             语法：RPOPLPUSH source destination            127.0.0.1:6379&gt; rpoplpush list newlist             "1"            127.0.0.1:6379&gt; lrange newlist 0 -1            1) "1"            127.0.0.1:6379&gt; lrange list 0 -1            1) "3"            2) "4"            3) "2"    5.3.3    应用        5.3.3.1    商品评论列表        思路：        在Redis中创建商品评论列表        用户发布商品评论，将评论信息转成json存储到list中。        用户在页面查询评论列表，从redis中取出json数据展示到页面。        定义商品评论列表key：        商品编号为1001的商品评论key【items: comment:1001】        192.168.101.3:7001&gt; LPUSH items:comment:1001 '{"id":1,"name":"商品不错，很好！！","date":1430295077289}'5.4    Set    集合类型    集合类型：无序、不可重复    列表类型：有序、可重复    5.4.1    命令        5.4.1.1    增加/删除元素         语法：SADD key member [member ...]        127.0.0.1:6379&gt; sadd set a b c        (integer) 3        127.0.0.1:6379&gt; sadd set a        (integer) 0        语法：SREM key member [member ...]        127.0.0.1:6379&gt; srem set c d        (integer) 1        5.4.1.2    获得集合中的所有元素         语法：SMEMBERS key        127.0.0.1:6379&gt; smembers set        1) "b"        2) "a”        5.4.1.3    判断元素是否在集合中        语法：SISMEMBER key member        127.0.0.1:6379&gt; sismember set a        (integer) 1        127.0.0.1:6379&gt; sismember set h        (integer) 0    5.4.2    运算命令        5.4.2.1    集合的差集运算 A-B        属于A并且不属于B的元素构成的集合。        语法：SDIFF key [key ...]        127.0.0.1:6379&gt; sadd setA 1 2 3        (integer) 3        127.0.0.1:6379&gt; sadd setB 2 3 4        (integer) 3        127.0.0.1:6379&gt; sdiff setA setB         1) "1"        127.0.0.1:6379&gt; sdiff setB setA         1) "4"        5.4.2.2    集合的交集运算 A ∩ B        属于A且属于B的元素构成的集合。        语法：SINTER key [key ...]        127.0.0.1:6379&gt; sinter setA setB         1) "2"        2) "3"        5.4.2.3    集合的并集运算 A ∪ B        属于A或者属于B的元素构成的集合        语法：SUNION key [key ...]        127.0.0.1:6379&gt; sunion setA setB        1) "1"        2) "2"        3) "3"        4) "4"    5.4.3    其它命令(自学)        5.4.3.1    获得集合中元素的个数         语法：SCARD key        127.0.0.1:6379&gt; smembers setA         1) "1"        2) "2"        3) "3"        127.0.0.1:6379&gt; scard setA         (integer) 3        5.4.3.2    从集合中弹出一个元素        注意：由于集合是无序的，所有SPOP命令会从集合中随机选择一个元素弹出         语法：SPOP key        127.0.0.1:6379&gt; spop setA         "1“5.5    Sortedset    Sortedset又叫zset    Sortedset是有序集合，可排序的，但是唯一。    Sortedset和set的不同之处，是会给set中的元素添加一个分数，然后通过这个分数进行排    5.5.1    命令        5.5.1.1    增加元素        向有序集合中加入一个元素和该元素的分数，如果该元素已经存在则会用新的分数替换原有的分数。        返回值是新加入到集合中的元素个数，不包含之前已经存在的元素。         语法：ZADD key score member [score member ...]        127.0.0.1:6379&gt; zadd scoreboard 80 zhangsan 89 lisi 94 wangwu         (integer) 3        127.0.0.1:6379&gt; zadd scoreboard 97 lisi         (integer) 0        5.5.1.2    获取元素的分数         语法：ZSCORE key member        127.0.0.1:6379&gt; zscore scoreboard lisi         "97"        5.5.1.3    删除元素        移除有序集key中的一个或多个成员，不存在的成员将被忽略。        当key存在但不是有序集类型时，返回一个错误。        语法：ZREM key member [member ...]        127.0.0.1:6379&gt; zrem scoreboard lisi        (integer) 1        5.5.1.4    获得排名在某个范围的元素列表        获得排名在某个范围的元素列表         1    按照元素分数从小到大的顺序返回索引从start到stop之间的所有元素（包含两端的元素）        语法：ZRANGE key start stop [WITHSCORES]                    127.0.0.1:6379&gt; zrange scoreboard 0 2        1) "zhangsan"        2) "wangwu"        3) "lisi“        2    按照元素分数从大到小的顺序返回索引从start到stop之间的所有元素（包含两端的元素）        语法：ZREVRANGE key start stop [WITHSCORES]                127.0.0.1:6379&gt; zrevrange scoreboard 0 2        1) " lisi "        2) "wangwu"        3) " zhangsan “        如果需要获得元素的分数的可以在命令尾部加上WITHSCORES参数         127.0.0.1:6379&gt; zrange scoreboard 0 1 WITHSCORES        1) "zhangsan"        2) "80"        3) "wangwu"        4) "94"        5.5.1.5    获取元素的排名         1    从小到大        语法：ZRANK key member        127.0.0.1:6379&gt; ZRANK scoreboard lisi         (integer) 0        2    从大到小        语法：ZREVRANK key member        127.0.0.1:6379&gt; ZREVRANK scoreboard zhangsan         (integer) 1        5.5.1.6    其它命令(自学)            5.5.1.6.1    获得指定分数范围的元素             语法：ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]            127.0.0.1:6379&gt; ZRANGEBYSCORE scoreboard 90 97 WITHSCORES            1) "wangwu"            2) "94"            3) "lisi"            4) "97"            127.0.0.1:6379&gt; ZRANGEBYSCORE scoreboard 70 100 limit 1 2            1) "wangwu"            2) "lisi"            5.5.1.6.2    增加某个元素的分数            返回值是更改后的分数             语法：ZINCRBY  key increment member            127.0.0.1:6379&gt; ZINCRBY scoreboard 4 lisi             "101“            5.5.1.6.3    获得集合中元素的数量             语法：ZCARD key            127.0.0.1:6379&gt; ZCARD scoreboard            (integer) 3            5.5.1.6.4    获得指定分数范围内的元素个数             语法：ZCOUNT key min max            127.0.0.1:6379&gt; ZCOUNT scoreboard 80 90            (integer) 1            5.5.1.6.5    按照排名范围删除元素             语法：ZREMRANGEBYRANK key start stop            127.0.0.1:6379&gt; ZREMRANGEBYRANK scoreboard 0 1            (integer) 2             127.0.0.1:6379&gt; ZRANGE scoreboard 0 -1            1) "lisi"            5.5.1.6.6    按照分数范围删除元素             语法：ZREMRANGEBYSCORE key min max            127.0.0.1:6379&gt; zadd scoreboard 84 zhangsan                (integer) 1            127.0.0.1:6379&gt; ZREMRANGEBYSCORE scoreboard 80 100            (integer) 1    5.5.2    应用        5.5.2.1    商品销售排行榜        需求：根据商品销售量对商品进行排行显示        思路：定义商品销售排行榜（sorted set集合），Key为items:sellsort，分数为商品销售量。        写入商品销售量：            商品编号1001的销量是9，商品编号1002的销量是10        192.168.101.3:7007&gt; ZADD items:sellsort 9 1001 10 1002            商品编号1001的销量加1        192.168.101.3:7001&gt; ZINCRBY items:sellsort 1 1001            商品销量前10名：        192.168.101.3:7001&gt; ZRANGE items:sellsort 0 9 withscores</code></pre><p>6    Keys命令</p><pre><code>6.1    常用命令    6.1.1    keys    返回满足给定pattern 的所有key    redis 127.0.0.1:6379&gt; keys mylist*    1) "mylist"    2) "mylist5"    3) "mylist6"    4) "mylist7"    5) "mylist8"    6.1.2    exists    确认一个key 是否存在    示例：从结果来看，数据库中不存在HongWan 这个key，但是age 这个key 是存在的    redis 127.0.0.1:6379&gt; exists HongWan    (integer) 0    redis 127.0.0.1:6379&gt; exists age    (integer) 1    redis 127.0.0.1:6379&gt;    6.1.3    del    删除一个key    redis 127.0.0.1:6379&gt; del age    (integer) 1    redis 127.0.0.1:6379&gt; exists age    (integer) 0    6.1.4    rename    重命名key    示例：age 成功的被我们改名为age_new 了    redis 127.0.0.1:6379[1]&gt; keys *    1) "age"    redis 127.0.0.1:6379[1]&gt; rename age age_new    OK    redis 127.0.0.1:6379[1]&gt; keys *    1) "age_new"    redis 127.0.0.1:6379[1]&gt;    6.1.5    type    返回值的类型    示例：这个方法可以非常简单的判断出值的类型    redis 127.0.0.1:6379&gt; type addr    string    redis 127.0.0.1:6379&gt; type myzset2    zset    redis 127.0.0.1:6379&gt; type mylist    list    redis 127.0.0.1:6379&gt;6.2    设置key的生存时间    Redis在实际使用过程中更多的用作缓存，然而缓存的数据一般都是需要设置生存时间的，即：到期后数据销毁。    EXPIRE key seconds             设置key的生存时间（单位：秒）key在多少秒后会自动删除    TTL key                     查看key生于的生存时间    PERSIST key                清除生存时间     PEXPIRE key milliseconds    生存时间设置单位为：毫秒    例子：    192.168.101.3:7002&gt; set test 1        设置test的值为1    OK    192.168.101.3:7002&gt; get test            获取test的值    "1"    192.168.101.3:7002&gt; EXPIRE test 5    设置test的生存时间为5秒    (integer) 1    192.168.101.3:7002&gt; TTL test            查看test的生于生成时间还有1秒删除    (integer) 1    192.168.101.3:7002&gt; TTL test    (integer) -2    192.168.101.3:7002&gt; get test            获取test的值，已经删除    (nil)</code></pre><p>7    Redis持久化方案</p><pre><code>7.1    Rdb方式    Redis默认的方式，redis通过快照来将数据持久化到磁盘中。    7.1.1    设置持久化快照的条件        在redis.conf中修改持久化快照的条件，如下：</code></pre><p><img src="/images/20170807/14.png"></p><pre><code>    7.1.2    持久化文件存储的目录    在redis.conf中可以指定持久化文件存储的目录</code></pre><p><img src="/images/20170807/15.png"></p><pre><code>    7.1.3    Rdb问题    一旦redis非法关闭，那么会丢失最后一次持久化之后的数据。    如果数据不重要，则不必要关心。    如果数据不能允许丢失，那么要使用aof方式7.2    Aof方式    Redis默认是不使用该方式持久化的。Aof方式的持久化，是操作一次redis数据库，则将操作的记录存储到aof持久化文件中。    第一步：开启aof方式的持久化方案    将redis.conf中的appendonly改为yes，即开启aof方式的持久化方案。</code></pre><p><img src="/images/20170807/16.png"></p><pre><code>    Aof文件存储的目录和rdb方式的一样。    Aof文件存储的名称</code></pre><p><img src="/images/20170807/17.png"></p><pre><code>    7.2.1    结论    在使用aof和rdb方式时，如果redis重启，则数据从aof文件加载。</code></pre><p>8    Redis的主从复制</p><pre><code>8.1    什么是主从复制持久化保证了即使redis服务重启也不会丢失数据，因为redis服务重启后会将硬盘上持久化的数据恢复到内存中，但是当redis服务器的硬盘损坏了可能会导致数据丢失，如果通过redis的主从复制机制就可以避免这种单点故障，如下图：</code></pre><p><img src="/images/20170807/18.png"></p><pre><code>说明：1    主redis中的数据有两个副本（replication）即从redis1和从redis2，即使一台redis服务器宕机其它两台redis服务也可以继续提供服务。2    主redis中的数据和从redis上的数据保持实时同步，当主redis写入数据时通过主从复制机制会复制到两个从redis服务上。3    只有一个主redis，可以有多个从redis。4    主从复制不会阻塞master，在同步数据时，master 可以继续处理client 请求5    一个redis可以即是主又是从，如下图：</code></pre><p><img src="/images/20170807/19.png"></p><pre><code>8.2    主从复制设置    8.2.1    主机配置        无需配置    8.2.2    从机配置        第一步：复制出一个从机        [root@itheima redis19]# cp bin/ bin2 –r        第二步：修改从机的redis.conf        语法：Slaveof masterip masterport        slaveof 192.168.242.137 6379</code></pre><p><img src="/images/20170807/20.png"></p><pre><code>        第三步：修改从机的port地址为6380        在redis.conf中修改</code></pre><p><img src="/images/20170807/21.png"></p><pre><code>        第四步：清除从机中的持久化文件        [root@itheima bin2]# rm -rf appendonly.aof dump.rdb        第五步：启动从机        [root@itheima bin2]# ./redis-server redis.conf        第六步：启动6380的客户端        [root@itheima bin2]# ./redis-cli -p 6380          注意：            主机一旦发生增删改操作，那么从机会将数据同步到从机中            从机不能执行写操作        127.0.0.1:6380&gt; set s2 222        (error) READONLY You can't write against a read only slave.</code></pre><p>9    Redis集群</p><pre><code>9.1    redis-cluster架构图</code></pre><p><img src="/images/20170807/22.png"></p><pre><code>架构细节:(1)所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.(2)节点的fail是通过集群中超过半数的节点检测失效时才生效.(3)客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可(4)redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护node&lt;-&gt;slot&lt;-&gt;valueRedis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点示例如下：</code></pre><p><img src="/images/20170807/23.png"></p><pre><code>9.2    redis-cluster投票:容错</code></pre><p><img src="/images/20170807/24.png"></p><pre><code>集群中所有master参与投票,如果半数以上master节点与其中一个master节点通信超过(cluster-node-timeout),认为该master节点挂掉.(2):什么时候整个集群不可用(cluster_state:fail)?     如果集群任意master挂掉,且当前master没有slave，则集群进入fail状态。也可以理解成集群的[0-16383]slot映射不完全时进入fail状态。    如果集群超过半数以上master挂掉，无论是否有slave，集群进入fail状态。9.3    安装ruby集群管理工具（redis-trib.rb）是使用ruby脚本语言编写的。第一步：安装ruby[root@itheima bin2]# yum install ruby[root@itheima bin2]# yum install rubygems第二步：将以下文件上传到linux系统</code></pre><p><img src="/images/20170807/25.png"></p><pre><code>第三步：安装ruby和redis接口[root@itheima ~]# gem install redis-3.0.0.gem第四步：将redis-3.0.0包下src目录中的以下文件拷贝到redis19/redis-cluster/</code></pre><p><img src="/images/20170807/26.png"></p><pre><code>[root@itheima src]# cd /usr/local/redis19/[root@itheima redis19]# mkdir redis-cluster[root@itheima redis19]# cd /root/redis-3.0.0/src/[root@itheima src]# cp redis-trib.rb  /usr/local/redis19/redis-cluster第五步：查看是否拷贝成功</code></pre><p><img src="/images/20170807/27.png"></p><pre><code>9.4    搭建集群搭建集群最少也得需要3台主机，如果每台主机再配置一台从机的话，则最少需要6台机器。端口设计如下：7001-7006第一步：复制出一个7001机器[root@itheima redis19]# cp bin ./redis-cluster/7001 –r第二步：如果存在持久化文件，则删除[root@itheima 7001]# rm -rf appendonly.aof dump.rdb第三步：设置集群参数</code></pre><p><img src="/images/20170807/28.png"></p><pre><code>第四步：修改端口</code></pre><p><img src="/images/20170807/29.png"></p><pre><code>第五步：复制出7002-7006机器[root@itheima redis-cluster]# cp 7001/ 7002 -r[root@itheima redis-cluster]# cp 7001/ 7003 -r[root@itheima redis-cluster]# cp 7001/ 7004 -r[root@itheima redis-cluster]# cp 7001/ 7005 -r[root@itheima redis-cluster]# cp 7001/ 7006 –r第六步：修改7002-7006机器的端口第七步：启动7001-7006这六台机器</code></pre><p><img src="/images/20170807/30.png"></p><pre><code>第八步：修改start-all.sh文件的权限[root@itheima redis-cluster]# chmod u+x start-all.sh[root@itheima redis-cluster]# ./start-all.sh第九步：创建集群[root@itheima redis-cluster]# ./redis-trib.rb create --replicas 1 192.168.242.137:7001 192.168.242.137:7002 192.168.242.137:7003 192.168.242.137:7004 192.168.242.137:7005  192.168.242.137:7006&gt;&gt;&gt; Creating clusterConnecting to node 192.168.242.137:7001: OKConnecting to node 192.168.242.137:7002: OKConnecting to node 192.168.242.137:7003: OKConnecting to node 192.168.242.137:7004: OKConnecting to node 192.168.242.137:7005: OKConnecting to node 192.168.242.137:7006: OK&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:192.168.242.137:7001192.168.242.137:7002192.168.242.137:7003Adding replica 192.168.242.137:7004 to 192.168.242.137:7001Adding replica 192.168.242.137:7005 to 192.168.242.137:7002Adding replica 192.168.242.137:7006 to 192.168.242.137:7003M: 8240cd0fe6d6f842faa42b0174fe7c5ddcf7ae24 192.168.242.137:7001   slots:0-5460 (5461 slots) masterM: 4f52a974f64343fd9f1ee0388490b3c0647a4db7 192.168.242.137:7002   slots:5461-10922 (5462 slots) masterM: cb7c5def8f61df2016b38972396a8d1f349208c2 192.168.242.137:7003   slots:10923-16383 (5461 slots) masterS: 66adf006fed43b3b5e499ce2ff1949a756504a16 192.168.242.137:7004   replicates 8240cd0fe6d6f842faa42b0174fe7c5ddcf7ae24S: cbb0c9bc4b27dd85511a7ef2d01bec90e692793b 192.168.242.137:7005   replicates 4f52a974f64343fd9f1ee0388490b3c0647a4db7S: a908736eadd1cd06e86fdff8b2749a6f46b38c00 192.168.242.137:7006   replicates cb7c5def8f61df2016b38972396a8d1f349208c2Can I set the above configuration? (type 'yes' to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join..&gt;&gt;&gt; Performing Cluster Check (using node 192.168.242.137:7001)M: 8240cd0fe6d6f842faa42b0174fe7c5ddcf7ae24 192.168.242.137:7001   slots:0-5460 (5461 slots) masterM: 4f52a974f64343fd9f1ee0388490b3c0647a4db7 192.168.242.137:7002   slots:5461-10922 (5462 slots) masterM: cb7c5def8f61df2016b38972396a8d1f349208c2 192.168.242.137:7003   slots:10923-16383 (5461 slots) masterM: 66adf006fed43b3b5e499ce2ff1949a756504a16 192.168.242.137:7004   slots: (0 slots) master   replicates 8240cd0fe6d6f842faa42b0174fe7c5ddcf7ae24M: cbb0c9bc4b27dd85511a7ef2d01bec90e692793b 192.168.242.137:7005   slots: (0 slots) master   replicates 4f52a974f64343fd9f1ee0388490b3c0647a4db7M: a908736eadd1cd06e86fdff8b2749a6f46b38c00 192.168.242.137:7006   slots: (0 slots) master   replicates cb7c5def8f61df2016b38972396a8d1f349208c2[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.[root@itheima redis-cluster]#9.5    连接集群[root@itheima 7001]# ./redis-cli -h 192.168.242.137 -p 7001 –c-c：指定是集群连接</code></pre><p><img src="/images/20170807/31.png"></p><pre><code>9.6    查看集群信息    查看集群信息    192.168.242.137:7002&gt; cluster info    cluster_state:ok    cluster_slots_assigned:16384    cluster_slots_ok:16384    cluster_slots_pfail:0    cluster_slots_fail:0    cluster_known_nodes:6    cluster_size:3    cluster_current_epoch:6    cluster_my_epoch:2    cluster_stats_messages_sent:2372    cluster_stats_messages_received:2372    192.168.242.137:7002&gt;    查看集群节点    192.168.242.137:7002&gt; cluster nodes    8240cd0fe6d6f842faa42b0174fe7c5ddcf7ae24 192.168.242.137:7001 master - 0 1451581348093 1 connected 0-5460    cb7c5def8f61df2016b38972396a8d1f349208c2 192.168.242.137:7003 master - 0 1451581344062 3 connected 10923-16383    66adf006fed43b3b5e499ce2ff1949a756504a16 192.168.242.137:7004 slave 8240cd0fe6d6f842faa42b0174fe7c5ddcf7ae24 0 1451581351115 1 connected    a908736eadd1cd06e86fdff8b2749a6f46b38c00 192.168.242.137:7006 slave cb7c5def8f61df2016b38972396a8d1f349208c2 0 1451581349101 3 connected    4f52a974f64343fd9f1ee0388490b3c0647a4db7 192.168.242.137:7002 myself,master - 0 0 2 connected 5461-10922    cbb0c9bc4b27dd85511a7ef2d01bec90e692793b 192.168.242.137:7005 slave 4f52a974f64343fd9f1ee0388490b3c0647a4db7 0 1451581350108 5 connected</code></pre><p>10    jedis连接集群</p><pre><code>10.1    设置防火墙[root@itheima redis-cluster]# vim /etc/sysconfig/iptables-A INPUT -m state --state NEW -m tcp -p tcp --dport 6379 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 6379 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 6379 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 6379 -j ACCEPT# Firewall configuration written by system-config-firewall# Manual customization of this file is not recommended.*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 6379 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7001 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7002 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7003 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7004 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7005 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7006 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7007 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j REJECT --reject-with icmp-host-prohibitedCOMMIT~                                                                                                     ~                                                                                                     ~                                                                                                     ~                                                                                                     "/etc/sysconfig/iptables" 23L, 1146C 已写入                                         [root@itheima redis-cluster]# service iptables restartiptables：清除防火墙规则：                                 [确定]iptables：将链设置为政策 ACCEPT：filter                    [确定]iptables：正在卸载模块：                                   [确定]iptables：应用防火墙规则：                                 [确定][root@itheima redis-cluster]#10.2    代码</code></pre><p><img src="/images/20170807/32.png"></p><pre><code>10.3    使用spring    配置applicationContext.xml&lt;!-- 连接池配置 --&gt;&lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt;    &lt;!-- 最大连接数 --&gt;    &lt;property name="maxTotal" value="30" /&gt;    &lt;!-- 最大空闲连接数 --&gt;    &lt;property name="maxIdle" value="10" /&gt;    &lt;!-- 每次释放连接的最大数目 --&gt;    &lt;property name="numTestsPerEvictionRun" value="1024" /&gt;    &lt;!-- 释放连接的扫描间隔（毫秒） --&gt;    &lt;property name="timeBetweenEvictionRunsMillis" value="30000" /&gt;    &lt;!-- 连接最小空闲时间 --&gt;    &lt;property name="minEvictableIdleTimeMillis" value="1800000" /&gt;    &lt;!-- 连接空闲多久后释放, 当空闲时间&gt;该值 且 空闲连接&gt;最大空闲连接数 时直接释放 --&gt;    &lt;property name="softMinEvictableIdleTimeMillis" value="10000" /&gt;    &lt;!-- 获取连接时的最大等待毫秒数,小于零:阻塞不确定的时间,默认-1 --&gt;    &lt;property name="maxWaitMillis" value="1500" /&gt;    &lt;!-- 在获取连接的时候检查有效性, 默认false --&gt;    &lt;property name="testOnBorrow" value="true" /&gt;    &lt;!-- 在空闲时检查有效性, 默认false --&gt;    &lt;property name="testWhileIdle" value="true" /&gt;    &lt;!-- 连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认true --&gt;    &lt;property name="blockWhenExhausted" value="false" /&gt;&lt;/bean&gt;&lt;!-- redis集群 --&gt;&lt;bean id="jedisCluster" class="redis.clients.jedis.JedisCluster"&gt;    &lt;constructor-arg index="0"&gt;        &lt;set&gt;            &lt;bean class="redis.clients.jedis.HostAndPort"&gt;                &lt;constructor-arg index="0" value="192.168.101.3"&gt;&lt;/constructor-arg&gt;                &lt;constructor-arg index="1" value="7001"&gt;&lt;/constructor-arg&gt;            &lt;/bean&gt;            &lt;bean class="redis.clients.jedis.HostAndPort"&gt;                &lt;constructor-arg index="0" value="192.168.101.3"&gt;&lt;/constructor-arg&gt;                &lt;constructor-arg index="1" value="7002"&gt;&lt;/constructor-arg&gt;            &lt;/bean&gt;            &lt;bean class="redis.clients.jedis.HostAndPort"&gt;                &lt;constructor-arg index="0" value="192.168.101.3"&gt;&lt;/constructor-arg&gt;                &lt;constructor-arg index="1" value="7003"&gt;&lt;/constructor-arg&gt;            &lt;/bean&gt;            &lt;bean class="redis.clients.jedis.HostAndPort"&gt;                &lt;constructor-arg index="0" value="192.168.101.3"&gt;&lt;/constructor-arg&gt;                &lt;constructor-arg index="1" value="7004"&gt;&lt;/constructor-arg&gt;            &lt;/bean&gt;            &lt;bean class="redis.clients.jedis.HostAndPort"&gt;                &lt;constructor-arg index="0" value="192.168.101.3"&gt;&lt;/constructor-arg&gt;                &lt;constructor-arg index="1" value="7005"&gt;&lt;/constructor-arg&gt;            &lt;/bean&gt;            &lt;bean class="redis.clients.jedis.HostAndPort"&gt;                &lt;constructor-arg index="0" value="192.168.101.3"&gt;&lt;/constructor-arg&gt;                &lt;constructor-arg index="1" value="7006"&gt;&lt;/constructor-arg&gt;            &lt;/bean&gt;        &lt;/set&gt;    &lt;/constructor-arg&gt;    &lt;constructor-arg index="1" ref="jedisPoolConfig"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;    测试代码private ApplicationContext applicationContext;    @Before    public void init() {        applicationContext = new ClassPathXmlApplicationContext(                "classpath:applicationContext.xml");    }    // redis集群    @Test    public void testJedisCluster() {        JedisCluster jedisCluster = (JedisCluster) applicationContext                .getBean("jedisCluster");        jedisCluster.set("name", "zhangsan");        String value = jedisCluster.get("name");        System.out.println(value);    }</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
            <tag> spring </tag>
            
            <tag> spring-boot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 ps kill</title>
      <link href="/2017/07/31/mei-tian-2-ge-linux-ming-ling-ps-kill/"/>
      <url>/2017/07/31/mei-tian-2-ge-linux-ming-ling-ps-kill/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-31-每天2个Linux命令-ps命令"><a href="#2017-07-31-每天2个Linux命令-ps命令" class="headerlink" title=" 2017-07-31 每天2个Linux命令 ps命令"></a><center> 2017-07-31 每天2个Linux命令 ps命令</center></h2><pre><code> Linux中的ps命令是Process Status的缩写。  ps命令用于报告当前系统的进程状态。可以搭配kill指令随时中断、删除不必要的程序。</code></pre><p> (1)用法:</p><pre><code>  用法:  ps  [选项参数]  [用户名]（可选）</code></pre><p>(2)功能:</p><pre><code>  功能:  用来显示当前进程的状态。  ps命令可以搭配kill指令随时中断、删除不必要的程序。ps命令是最基本同时也是非常强大的进程查看命令，使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等，总之大部分信息都是可以通过执行该命令得到的。</code></pre><p>(3)选项参数:</p><pre><code>  1) -A 　　　　　　　　　　　　　　　　　　显示所有的进程  2) -e　　　　　　　　　　　　　　　　　　 显示所有的进程，与-A参数一样  3) -u　　　　　　　　　　　　　　　　　　 显示指定用户的信息  4) -a 　　　　　　　　　　　　　　　　　　显示所有终端机下执行的进程，除了阶段作业领导者之外。  5)  a 　　　　　　　　　　　　　　　　　　显示现行终端机下的所有进程，包括其他用户的进程。  6) -H　　　　　　　　　　　　　　　　　　显示树状结构，表示程序间的相互关系。 -j或j：采用工作控制的格式显示程序状况。</code></pre><p> (4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# ps -e|more -20　　　　　　　　　　显示所有的进程复制代码[root@localhost sunjimeng]# ps -e|more -20   PID TTY          TIME CMD     1 ?        00:00:05 systemd     2 ?        00:00:00 kthreadd     3 ?        00:00:05 ksoftirqd/0     5 ?        00:00:00 kworker/0:0H     7 ?        00:00:00 migration/0     8 ?        00:00:00 rcu_bh     9 ?        00:00:00 rcuob/0    10 ?        00:00:00 rcuob/1    11 ?        00:00:00 rcuob/2    12 ?        00:00:00 rcuob/3    13 ?        00:00:00 rcuob/4    14 ?        00:00:00 rcuob/5    15 ?        00:00:00 rcuob/6    16 ?        00:00:00 rcuob/7    17 ?        00:00:00 rcuob/8    18 ?        00:00:00 rcuob/9    19 ?        00:00:00 rcuob/10    20 ?        00:00:00 rcuob/11    21 ?        00:00:00 rcuob/12复制代码      -A命令与-e命令相同，都可以显示所有进程复制代码[root@localhost sunjimeng]# ps -A|more -10   PID TTY          TIME CMD     1 ?        00:00:06 systemd     2 ?        00:00:00 kthreadd     3 ?        00:00:05 ksoftirqd/0     5 ?        00:00:00 kworker/0:0H     7 ?        00:00:00 migration/0     8 ?        00:00:00 rcu_bh     9 ?        00:00:00 rcuob/0    10 ?        00:00:00 rcuob/1    11 ?        00:00:00 rcuob/2--More--</code></pre><p>2)[root@localhost sunjimeng]# ps -u root|more -10　　　　　　　　　　显示指定用户的进程信息</p><pre><code>复制代码[root@localhost sunjimeng]# ps -u root|more -10   PID TTY          TIME CMD     1 ?        00:00:06 systemd     2 ?        00:00:00 kthreadd     3 ?        00:00:05 ksoftirqd/0     5 ?        00:00:00 kworker/0:0H     7 ?        00:00:00 migration/0     8 ?        00:00:00 rcu_bh     9 ?        00:00:00 rcuob/0    10 ?        00:00:00 rcuob/1    11 ?        00:00:00 rcuob/2</code></pre><p>3)[root@localhost sunjimeng]# ps a　　　　　　　　　　　　　　　　　　ps a命令与ps -a命令</p><pre><code>复制代码[root@localhost sunjimeng]# ps a   PID TTY      STAT   TIME COMMAND  2004 tty1     Ssl+   5:13 /usr/bin/Xorg :0 -background none -verbose -auth /run/gdm/auth-for-gdm-8E54kT/database -seat seat0 -nolisten tcp 11465 pts/0    Ss     0:00 bash 11498 pts/0    S      0:00 su root 11504 pts/0    S      0:00 bash 11757 pts/0    R+     0:00 ps a[root@localhost sunjimeng]# ps -a   PID TTY          TIME CMD 11498 pts/0    00:00:00 su 11504 pts/0    00:00:00 bash 11761 pts/0    00:00:00 ps</code></pre><p>4)[root@localhost sunjimeng]# ps -ef|more -10　　　　　　　　　　　　显示所有进程信息，连同命令行</p><pre><code>复制代码[root@localhost sunjimeng]# ps -ef|more -10UID         PID   PPID  C STIME TTY          TIME CMDroot          1      0  0 12:15 ?        00:00:06 /usr/lib/systemd/systemd --switched-root --system --deserialize 24root          2      0  0 12:15 ?        00:00:00 [kthreadd]root          3      2  0 12:15 ?        00:00:05 [ksoftirqd/0]root          5      2  0 12:15 ?        00:00:00 [kworker/0:0H]root          7      2  0 12:15 ?        00:00:00 [migration/0]root          8      2  0 12:15 ?        00:00:00 [rcu_bh]root          9      2  0 12:15 ?        00:00:00 [rcuob/0]root         10      2  0 12:15 ?        00:00:00 [rcuob/1]root         11      2  0 12:15 ?        00:00:00 [rcuob/2]--More--</code></pre><p>5)[root@localhost sunjimeng]# ps -ef|more -5　　　　　　　　　　　　ps命令与grep命令结合起来查找指定的进程</p><pre><code>复制代码[root@localhost sunjimeng]# ps -ef|more -5UID         PID   PPID  C STIME TTY          TIME CMDroot          1      0  0 12:15 ?        00:00:06 /usr/lib/systemd/systemd --switched-root --system --deserialize 24root          2      0  0 12:15 ?        00:00:00 [kthreadd]root          3      2  0 12:15 ?        00:00:05 [ksoftirqd/0]root          5      2  0 12:15 ?        00:00:00 [kworker/0:0H][root@localhost sunjimeng]# ps -ef|grep kworker/0:0Hroot          5      2  0 12:15 ?        00:00:00 [kworker/0:0H]root      11981  11504  0 17:33 pts/0    00:00:00 grep --color=auto kworker/0:0H</code></pre><p>6)[root@localhost sunjimeng]# ps -l　　　　　　　　　　　　　　　　　将目前属于您自己这次登入的 PID 与相关信息列示出来</p><pre><code>[root@localhost sunjimeng]# ps -lF S   UID    PID   PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD4 S     0  11498  11465  0  80   0 - 45979 wait   pts/0    00:00:00 su4 S     0  11504  11498  0  80   0 - 29064 wait   pts/0    00:00:00 bash0 R     0  11993  11504  0  80   0 - 30319 -      pts/0    00:00:00 ps说明：各相关信息的意义：F 代表这个程序的旗标 (flag)， 4 代表使用者为 super userS 代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍UID 程序被该 UID 所拥有PID 就是这个程序的 ID ！</code></pre><p>　　PPID 则是其上级父程序的ID</p><p>　　C CPU 使用的资源百分比</p><p>　　PRI 这个是 Priority (优先执行序) 的缩写</p><p>　　NI 这个是 Nice 值</p><p>　　ADDR 这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-“</p><p>　　SZ 使用掉的内存大小</p><p>　　WCHAN 目前这个程序是否正在运作当中，若为 - 表示正在运作</p><p>　　TTY 登入者的终端机位置</p><p>　　TIME 使用掉的 CPU 时间。</p><p>　　CMD 所下达的指令为何</p><p>　　在预设的情况下， ps 仅会列出与目前所在的 bash shell 有关的 PID 而已，所以， 当我使用 ps -l 的时候，只有三个 PID。</p><p>7)[root@localhost sunjimeng]# ps f　　　　　　　　　　　　　　　　显示进程间的关系</p><pre><code>复制代码UID         PID   PPID  C STIME TTY          TIME CMDroot      11498  11465  0 17:17 pts/0    00:00:00 su rootroot      11504  11498  0 17:17 pts/0    00:00:00 bashroot      12311  11504  0 17:52 pts/0    00:00:00 ps -f[root@localhost sunjimeng]# ps f   PID TTY      STAT   TIME COMMAND 11498 pts/0    S      0:00 su root 11504 pts/0    S      0:00  \_ bash 12315 pts/0    R+     0:00      \_ ps f  2004 tty1     Ssl+   5:25 /usr/bin/Xorg :0 -background none -verbose -auth /run/gdm/auth-for-gdm-8E54kT/database -seat seat0 -nolisten tcp[root@localhost sunjimeng]# </code></pre><p>8)root@localhost sunjimeng]# ps aux |more -10　　　　　　　　　列出目前所有的正在内存当中的程序</p><pre><code>复制代码root@localhost sunjimeng]# ps aux |more -10USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDroot          1  0.0  0.3  60052  7796 ?        Ss   12:15   0:06 /usr/lib/systemd/systemd --switched-root --system --deserialize 24root          2  0.0  0.0      0     0 ?        S    12:15   0:00 [kthreadd]root          3  0.0  0.0      0     0 ?        S    12:15   0:05 [ksoftirqd/0]root          5  0.0  0.0      0     0 ?        S&lt;   12:15   0:00 [kworker/0:0H]root          7  0.0  0.0      0     0 ?        S    12:15   0:00 [migration/0]root          8  0.0  0.0      0     0 ?        S    12:15   0:00 [rcu_bh]root          9  0.0  0.0      0     0 ?        S    12:15   0:00 [rcuob/0]root         10  0.0  0.0      0     0 ?        S    12:15   0:00 [rcuob/1]root         11  0.0  0.0      0     0 ?        S    12:15   0:00 [rcuob/2]    说明：  USER：该 process 属于哪一个个使用者账号的  PID ：该 process 的号码   %CPU：该 process 使用掉的 CPU 资源百分比   %MEM：该 process 所占用的物理内存百分比  VSZ ：该 process 使用掉的虚拟内存量 (Kbytes)  RSS ：该 process 占用的固定的内存量 (Kbytes)  TTY ：该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。  STAT：该程序目前的状态，主要的状态有  R ：该程序目前正在运作，或者是可被运作  S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。  T ：该程序目前正在侦测或者是停止了  Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态  START：该 process 被触发启动的时间  TIME ：该 process 实际使用 CPU 运作的时间  COMMAND：该程序的实际指令</code></pre><p>9)[root@localhost sunjimeng]# ps -axjf|more -10　　　　　　　　　　　　　　列出类似程序树的程序显示</p><pre><code>复制代码[root@localhost sunjimeng]# ps -axjf|more -10  PPID    PID   PGID    SID TTY       TPGID STAT   UID   TIME COMMAND     0      2      0      0 ?            -1 S        0   0:00 [kthreadd]     2      3      0      0 ?            -1 S        0   0:05  \_ [ksoftirqd/0]     2      5      0      0 ?            -1 S&lt;       0   0:00  \_ [kworker/0:0H]     2      7      0      0 ?            -1 S        0   0:00  \_ [migration/0]     2      8      0      0 ?            -1 S        0   0:00  \_ [rcu_bh]     2      9      0      0 ?            -1 S        0   0:00  \_ [rcuob/0]     2     10      0      0 ?            -1 S        0   0:00  \_ [rcuob/1]     2     11      0      0 ?            -1 S        0   0:00  \_ [rcuob/2]     2     12      0      0 ?            -1 S        0   0:00  \_ [rcuob/3]</code></pre><h2 id="2017-07-31-每天2个Linux命令-kill命令"><a href="#2017-07-31-每天2个Linux命令-kill命令" class="headerlink" title=" 2017-07-31 每天2个Linux命令 kill命令"></a><center> 2017-07-31 每天2个Linux命令 kill命令</center></h2><p>Linux中的kill命令用来终止指定的进程（terminate a process）的运行。 kill可将指定的信息送至程序。预设的信息为SIGTERM(15),可将指定程序终止。</p><p>(1)用法:</p><pre><code>  用法:  kill  [选项]  参数  参数指的是进程或作业识别号，指定要删除的进程或作业。</code></pre><p> (2)功能:</p><pre><code>  功能:  发送指定的信号到相应进程。不指定型号将发送SIGTERM（15）终止指定进程 。  若仍无法终止该程序，可使用SIGKILL(9)信息尝试强制删除程序。程序或工作的编号可利用ps指令或job指令查看。  root用户将影响用户的进程，非root用户只能影响自己的进程。</code></pre><p> (3)选项参数:</p><pre><code>  1) -a: 　　　　　　　　　　当处理当前进程时，不限制命令名和进程号的对应关系  2) -l &lt;信息编号&gt;:　　　　  若不加&lt;信息编号&gt;选项，则-l参数会列出全部的信息名称  3) -p: 　　　　　　　　　　指定kill 命令只打印相关进程的进程号，而不发送任何信号  4) -s &lt;信息名称或编号&gt;:   指定要送出的信息</code></pre><p> (4)实例:</p><pre><code>  1)[sunjimeng@localhost ~]$ kill -l　　　　　　　　　　　　列出所有的信号复制代码[sunjimeng@localhost ~]$ kill -l 1) SIGHUP       2) SIGINT        3) SIGQUIT       4) SIGILL         5) SIGTRAP 6) SIGABRT      7) SIGBUS        8) SIGFPE        9) SIGKILL       10) SIGUSR111) SIGSEGV     12) SIGUSR2      13) SIGPIPE      14) SIGALRM       15) SIGTERM16) SIGSTKFLT   17) SIGCHLD      18) SIGCONT      19) SIGSTOP       20) SIGTSTP21) SIGTTIN     22) SIGTTOU      23) SIGURG       24) SIGXCPU       25) SIGXFSZ26) SIGVTALRM   27) SIGPROF      28) SIGWINCH     29) SIGIO         30) SIGPWR31) SIGSYS      34) SIGRTMIN     35) SIGRTMIN+1   36) SIGRTMIN+2    37) SIGRTMIN+338) SIGRTMIN+4  39) SIGRTMIN+5   40) SIGRTMIN+6   41) SIGRTMIN+7    42) SIGRTMIN+843) SIGRTMIN+9  44) SIGRTMIN+10  45) SIGRTMIN+11  46) SIGRTMIN+12   47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15  50) SIGRTMAX-14  51) SIGRTMAX-13   52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10  55) SIGRTMAX-9   56) SIGRTMAX-8    57) SIGRTMAX-758) SIGRTMAX-6  59) SIGRTMAX-5   60) SIGRTMAX-4   61) SIGRTMAX-3    62) SIGRTMAX-263) SIGRTMAX-1  64) SIGRTMAX    复制代码      只有第9种信号(SIGKILL)才可以无条件终止进程，其他信号进程都有权利忽略，下面是常用的信号：复制代码HUP      1 终端断线 INT      2 中断（同 Ctrl + C） QUIT     3 退出（同 Ctrl + \） TERM    15 终止 KILL     9 强制终止 CONT    18 继续（与STOP相反， fg/bg命令） STOP    19 暂停（同 Ctrl + Z）</code></pre><p>2)[sunjimeng@localhost ~]$ kill 3429　　　　　　　　　　　　　　查找并删除命令</p><pre><code>复制代码[sunjimeng@localhost ~]$ ps -ef |grep "/usr/bin/seapplet"sunjime+   3429   2990  0 16:36 ?        00:00:00 /usr/bin/seappletsunjime+  12918  11465  0 22:16 pts/0    00:00:00 grep --color=auto /usr/bin/seapplet[sunjimeng@localhost ~]$ kill 3429[sunjimeng@localhost ~]$ kill 12918bash: kill: (12918) - 没有那个进程[sunjimeng@localhost ~]$ kill 3429bash: kill: (3429) - 没有那个进程[sunjimeng@localhost ~]$ ps -ef |grep "/usr/bin/seapplet"sunjime+  12932  11465  0 22:17 pts/0    00:00:00 grep --color=auto /usr/bin/seapplet注意在测试时尽量不要删除root的进程。</code></pre><p>3)[sunjimeng@localhost ~]$ kill -l KILL　　　　　　　　　　　　　显示指定信号的数值</p><pre><code>[sunjimeng@localhost ~]$ kill -l KILL9[sunjimeng@localhost ~]$ kill -l TERM15</code></pre><p>4)[sunjimeng@localhost ~]$ kill -9 $(ps -ef |grep sunjimeng)　删除指定用户的所有进程</p><pre><code>[sunjimeng@localhost ~]$ kill -u sunjimengbash: kill: u: 无效的信号声明      -u参数不能用了。删除指定用户的所有进程用下面的命令:　　　　 [sunjimeng@localhost ~]$ kill -9 $(ps -ef |grep sunjimeng)</code></pre><p>5)[sunjimeng@localhost ~]$ kill -9 1　　　　　　　　　　　　　　杀死init进程</p><pre><code>[sunjimeng@localhost ~]$ kill -9 1bash: kill: (1) - 不允许的操作[sunjimeng@localhost ~]$       init是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。    内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结构等）之后，    就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。     其它所有进程都是init进程的子孙。init进程是不可杀的！</code></pre><p>(5)其他:</p><pre><code>  Linux进程的管理:  进程是Linux系统中一个非常重要的概念。Linux是一个多任务的操作系统，系统上经常同时运行着多个进程。我们不关心这些进程究竟是如何分配的，或者是内核如何管理分配时间片的，所关心的是如何去控制这些进程，让它们能够很好地为用户服务。 Linux操作系统包括三种不同类型的进程，每种进程都有自己的特点和属性。  1)交互进程是由一个Shell启动的进程。交互进程既可以在前台运行，也可以在后台运行。  2)批处理进程和终端没有联系，是一个进程序列。  3)监控进程（也称系统守护进程）时Linux系统启动时启动的进程，并在后台运行。例如，httpd是著名的Apache服务器的监控进程。 kill命令的工作原理是:  向Linux系统的内核发送一个系统操作信号和某个程序的进程标识号，然后系统内核就可以对进程标识号指定的进程进行操作。比如在top命令中，我们看到系统运行许多进程，有时就需要使用kill中止某些进程来提高系统资源。在讲解安装和登陆命令时，曾提到系统多个虚拟控制台的作用是当一个程序出错造成系统死锁时，可以切换到其它虚拟控制台工作关闭这个程序。此时使用的命令就是kill，因为kill是大多数Shell内部命令可以直接调用的。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 grep wc</title>
      <link href="/2017/07/31/mei-tian-2-ge-linux-ming-ling-grep-wc/"/>
      <url>/2017/07/31/mei-tian-2-ge-linux-ming-ling-grep-wc/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-30-每天2个Linux命令-grep命令"><a href="#2017-07-30-每天2个Linux命令-grep命令" class="headerlink" title=" 2017-07-30 每天2个Linux命令 grep命令"></a><center> 2017-07-30 每天2个Linux命令 grep命令</center></h2><p>grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）<br><br>是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。</p><p>(1)用法:</p><pre><code>  用法:  grep [选项]... PATTERN [FILE]...</code></pre><p>(2)功能:</p><pre><code>  功能:  在每个 FILE 或是标准输入中查找 PATTERN。</code></pre><p>(3)选项参数:</p><pre><code>  1) -V, --version 　　　　　　　　　　显示版本号  2) -i　　　　　　　　　　　　　　　　在匹配过程中忽略大小写  3) -v, --invert-match 　　　　　　　 显示不匹配的行   4) -f　　　　　　　　　　　　　　　　指定文件中存的每行字符串作为匹配字符串  5) -c　　　　　　　　　　　　　　　　统计每个文件中包含指定字符串的行数  6) --color=auto　　　　　　　　　　  标记匹配颜色  7) -E 　　　　　　　　　　　　　　　  将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式  8) -q　　　　　　　　　　　　　　　　 grep静默输出，常用来测试。</code></pre><p> (4)实例:</p><pre><code>  1)[root@localhost grepDir]# grep "MenAngel" t1.txt t2.txt t3.txt　　　　　　　　　　在特定的文本集中查找特定字符串复制代码[root@localhost grepDir]# cat &gt;t1.txtI'm MenAngel!Although I'm still a poor student right now,I believe that someday I will be one of the successful man in the world!^Z[3]+  已停止               cat &gt; t1.txt[root@localhost grepDir]# cat &gt;t2.txtEvery one fights for a better future,but I fight for freedom!                     ^Z[4]+  已停止               cat &gt; t2.txt[root@localhost grepDir]# cat &gt;t3.txt &lt;&lt;EOF&gt; There is no one hoping that you will succeed when you are been looking down upon,but&gt;  if you succeeded,they will look down upon themselves!&gt; When you get an important thing,you will find that it is not so precious as you &gt; like,but when you lose it after that,it will become so precious as you liked.&gt; EOF[root@localhost grepDir]# grep "MenAngel" t1.txt t2.txt t3.txtt1.txt:I'm MenAngel!</code></pre><p>2)[root@localhost grepDir]# grep -v “MenAngel” t1.txt t2.txt t3.txt　　　　　　　　输出指定字符串所在行之外的所有文件的行内容</p><pre><code>[root@localhost grepDir]# grep -v "MenAngel" t1.txt t2.txt t3.txtt1.txt:Although I'm still a poor student right now,I believe that someday I will be one of the successful man in the world!t2.txt:Every one fights for a better future,but I fight for freedom!t3.txt:There is no one hoping that you will succeed when you are been looking down upon,but if you succeeded,they will look down upon themselves!t3.txt:When you get an important thing,you will find that it is not so precious as you like,but when you lose it after that,it will become so precious as you liked.</code></pre><p>3)[root@localhost grepDir]# grep “fight” t1.txt t2.txt t3.txt –color=auto　　　　　 将查找的字符串用特定的颜色标记出来</p><pre><code>[root@localhost grepDir]# grep "fight" t1.txt t2.txt t3.txt --color=autot2.txt:Every one fights for a better future,but I fight for freedom!</code></pre><p>4)[root@localhost grepDir]# grep -c “that” t1.txt t2.txt t3.txt　　　　　　　　　　　 统计每个文件中包含指定字符串的行数</p><pre><code>[root@localhost grepDir]# grep -c "that" t1.txt t2.txt t3.txtt1.txt:1t2.txt:0t3.txt:2</code></pre><p>5)[root@localhost grepDir]# grep -n “that” t1.txt t2.txt t3.txt　　　　　　　　　　   默认情况，输出包含特定字符串所在的行</p><pre><code>复制代码[root@localhost grepDir]# grep -n "that" t1.txt t2.txt t3.txtt1.txt:2:Although I'm still a poor student right now,I believe that someday I will be one of the successful man in the world!t3.txt:1:There is no one hoping that you will succeed when you are been looking down upon,but if you succeeded,they will look down upon themselves!t3.txt:2:When you get an important thing,you will find that it is not so precious as you like,but when you lose it after that,it will become so precious as you liked.[root@localhost grepDir]# grep "that" t1.txt t2.txt t3.txtt1.txt:Although I'm still a poor student right now,I believe that someday I will be one of the successful man in the world!t3.txt:There is no one hoping that you will succeed when you are been looking down upon,but if you succeeded,they will look down upon themselves!t3.txt:When you get an important thing,you will find that it is not so precious as you like,but when you lose it after that,it will become so precious as you liked.</code></pre><p>6)[root@localhost grepDir]# cat t1.txt t2.txt t3.txt|grep “MenAngel”　　　　　　　　配合cat命令查看文件中指定字符串所在行的内容</p><pre><code>[root@localhost grepDir]# cat t1.txt t2.txt t3.txt|grep "MenAngel"I'm MenAngel![root@localhost grepDir]# grep "MenAngel" t1.txt t2.txt t3.txtt1.txt:I'm MenAngel!</code></pre><p> 7)[root@localhost grepDir]# cat t1.txt t2.txt t3.txt|grep ^I　　　　　　　　　　　　　查找以指定字符串开头的文本行并输出</p><pre><code>[root@localhost grepDir]# cat t1.txt t2.txt t3.txt|grep ^II'm MenAngel![root@localhost grepDir]# cat t1.txt t2.txt t3.txt|grep ^M  //没有以M开头的[root@localhost grepDir]# </code></pre><p>8)[root@localhost grepDir]# cat t1.txt t2.txt t3.txt|grep ^[^I]　　　　　　　　　　　<br>    经不以指定字符串开头的文本所在行的内容输出</p><pre><code>[root@localhost grepDir]# cat t1.txt t2.txt t3.txt|grep ^[^I]Although I'm still a poor student right now,I believe that someday I will be one of the successful man in the world!Every one fights for a better future,but I fight for freedom!There is no one hoping that you will succeed when you are been looking down upon,but if you succeeded,they will look down upon themselves!When you get an important thing,you will find that it is not so precious as you like,but when you lose it after that,it will become so precious as you liked.[root@localhost grepDir]# </code></pre><p> 9)[root@localhost grepDir]# seq 10|grep “5” -C|-A|-B 3　　　　　　　　　　　　　    显示特定行的前面或后面的内容　　　　　</p><pre><code>复制代码[root@localhost grepDir]# seq 10|grep "5" -C 32345678[root@localhost grepDir]# seq 10|grep "5" -A 35678[root@localhost grepDir]# seq 10|grep "5" -B 32345复制代码</code></pre><p> 10)[root@localhost grepDir]# grep -C 3 “MenAngel” t1.txt t2.txt t3.txt　　　　　　无论用不用通道，参数都是可用的</p><pre><code>[root@localhost grepDir]# grep -C 3 "MenAngel" t1.txt t2.txt t3.txtt1.txt:I'm MenAngel!t1.txt-Although I'm still a poor student right now,I believe that someday I will be one of the successful man in the world!</code></pre><p>11)[root@localhost grepDir]# echo -e “a\nb\nc\na\nb\nc” | grep a -A 1　　　　<br>    　　如果匹配结果有多个，会用“–”作为各匹配结果之间的分隔符</p><pre><code>复制代码[root@localhost grepDir]# echo -e "a\nb\nc\na\nb\nc" | grep a -A 1ab--ab[root@localhost grepDir]# [root@localhost grepDir]# echo -e "a\nb\nc\nd\na\nb\nc\nd" | grep a -A 1ab--ab[root@localhost grepDir]# echo -e "a\nb\nc\nd\na\nb\nc\nd" | grep a -A 2abc--abc</code></pre><p>12)[root@localhost grepDir]# echo this is a text line | grep -e “is” -e “line” -o　　　　　　　　　 制动多个匹配样式</p><pre><code>[root@localhost grepDir]# echo this is a text line | grep -e "is" -e "line" -o   //grep这里处理的是前面的echo输出的内容isisline</code></pre><p>13)[root@localhost grepDir]# echo MenAngel is sunjimeng|grep -f patfile　　　　　　　　　　　 指定在文件中每行存的多个字符串</p><pre><code>复制代码[root@localhost grepDir]# cat &gt;patfile &lt;&lt;EOF&gt; MenAngel&gt; sunjimeng&gt; EOF[root@localhost grepDir]# echo MenAngel is sunjimeng|grep -f patfileMenAngel is sunjimeng[root@localhost grepDir]# </code></pre><p>14)[root@localhost grepDir]# grep –help</p><pre><code>复制代码[root@localhost grepDir]# grep --help用法: grep [选项]... PATTERN [FILE]...在每个 FILE 或是标准输入中查找 PATTERN。默认的 PATTERN 是一个基本正则表达式(缩写为 BRE)。例如: grep -i 'hello world' menu.h main.c正则表达式选择与解释:  -E, --extended-regexp     PATTERN 是一个可扩展的正则表达式(缩写为 ERE)  -F, --fixed-strings       PATTERN 是一组由断行符分隔的定长字符串。  -G, --basic-regexp        PATTERN 是一个基本正则表达式(缩写为 BRE)  -P, --perl-regexp         PATTERN 是一个 Perl 正则表达式  -e, --regexp=PATTERN      用 PATTERN 来进行匹配操作  -f, --file=FILE           从 FILE 中取得 PATTERN  -i, --ignore-case         忽略大小写  -w, --word-regexp         强制 PATTERN 仅完全匹配字词  -x, --line-regexp         强制 PATTERN 仅完全匹配一行  -z, --null-data           一个 0 字节的数据行，但不是空行Miscellaneous:  -s, --no-messages         suppress error messages  -v, --invert-match        select non-matching lines  -V, --version             display version information and exit      --help                display this help text and exit输出控制:  -m, --max-count=NUM       NUM 次匹配后停止  -b, --byte-offset         输出的同时打印字节偏移  -n, --line-number         输出的同时打印行号      --line-buffered       每行输出清空  -H, --with-filename       为每一匹配项打印文件名  -h, --no-filename         输出时不显示文件名前缀      --label=LABEL         将LABEL 作为标准输入文件名前缀  -o, --only-matching       show only the part of a line matching PATTERN  -q, --quiet, --silent     suppress all normal output      --binary-files=TYPE   assume that binary files are TYPE;                            TYPE is 'binary', 'text', or 'without-match'  -a, --text                equivalent to --binary-files=text  -I                        equivalent to --binary-files=without-match  -d, --directories=ACTION  how to handle directories;                            ACTION is 'read', 'recurse', or 'skip'  -D, --devices=ACTION      how to handle devices, FIFOs and sockets;                            ACTION is 'read' or 'skip'  -r, --recursive           like --directories=recurse  -R, --dereference-recursive                            likewise, but follow all symlinks      --include=FILE_PATTERN                            search only files that match FILE_PATTERN      --exclude=FILE_PATTERN                            skip files and directories matching FILE_PATTERN      --exclude-from=FILE   skip files matching any file pattern from FILE      --exclude-dir=PATTERN directories that match PATTERN will be skipped.  -L, --files-without-match print only names of FILEs containing no match  -l, --files-with-matches  print only names of FILEs containing matches  -c, --count               print only a count of matching lines per FILE  -T, --initial-tab         make tabs line up (if needed)  -Z, --null                print 0 byte after FILE name文件控制:  -B, --before-context=NUM  打印以文本起始的NUM 行  -A, --after-context=NUM   打印以文本结尾的NUM 行  -C, --context=NUM         打印输出文本NUM 行  -NUM                      same as --context=NUM      --group-separator=SEP use SEP as a group separator      --no-group-separator  use empty string as a group separator      --color[=WHEN],      --colour[=WHEN]       use markers to highlight the matching strings;                            WHEN is 'always', 'never', or 'auto'  -U, --binary              do not strip CR characters at EOL (MSDOS/Windows)  -u, --unix-byte-offsets   report offsets as if CRs were not there                            (MSDOS/Windows)‘egrep’即‘grep -E’。‘fgrep’即‘grep -F’。直接使用‘egrep’或是‘fgrep’均已不可行了。若FILE 为 -，将读取标准输入。不带FILE，读取当前目录，除非命令行中指定了-r 选项。如果少于两个FILE 参数，就要默认使用-h 参数。如果有任意行被匹配，那退出状态为 0，否则为 1；如果有错误产生，且未指定 -q 参数，那退出状态为 2。</code></pre><h2 id="2017-07-30-每天2个Linux命令-wc命令"><a href="#2017-07-30-每天2个Linux命令-wc命令" class="headerlink" title=" 2017-07-30 每天2个Linux命令 wc命令"></a><center> 2017-07-30 每天2个Linux命令 wc命令</center></h2><p>Linux系统中的wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。</p><p>(1)用法:</p><pre><code>  用法:  wc [选项] [文件]......</code></pre><p>(2)功能:</p><pre><code>  功能:  wc命令用来计算数字。利用wc指令我们可以计算文件的Byte数、字数或是列数，若不指定文件名称，或是所给予的文件名为“-”，则wc指令会从标准输入设备读取数据。</code></pre><p>(3)选项参数</p><pre><code>  1)  -c  --bytes　　　　　　　　　　　　打印字节数  2)  -m --chars 　　　　　　　　　　　  打印字符数，这个标志不能与 -c 标志一起使用。  3)  -l  --lines 　　　　　　　　　　　　 打印行数  4)  -L --max-line-length 　　　　　　  打印最长行的长度  5) -w --words 　　　　　　　　　　　  打印单词数，一个单词被定义为由空白、跳格或换行字符分隔的字符串。</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost grepDir]# cat patfile|wc -l　　　　　　　　　　　　统计指定文件的行数[root@localhost grepDir]# cat patfileMenAngelsunjimeng[root@localhost grepDir]# cat patfile|wc -l2</code></pre><p>2)[root@localhost grepDir]# cat patfile|wc -c　　　　　　　　　　　　统计文件中的字节数</p><pre><code>[root@localhost grepDir]# cat patfile|wc -c                   //这里回车应该算2个字符，2+8+919</code></pre><p>3)[root@localhost grepDir]# cat patfile|wc -m　　　　　　　　　　　统计文件中的字符数</p><pre><code>[root@localhost grepDir]# cat patfile|wc -m　　19</code></pre><p>4)-c参数与-m参数的区别</p><pre><code>复制代码[root@localhost grepDir]# cat t2.txtEvery one fights for a better future,but I fight for freedom![root@localhost grepDir]# cat t2.txt|wc -c62[root@localhost grepDir]# cat t2.txt|wc -m62[root@localhost grepDir]# cat &gt;wcText &lt;&lt;EOF&gt; wc命令的功能为统计指定文件中的字节数、单词数、行数, 并将统计结果显示输出&gt; I'm MenAngel&gt; EOF[root@localhost grepDir]# cat wcText|wc -c120[root@localhost grepDir]# cat wcText|wc -m52</code></pre><p> 5)[root@localhost grepDir]# cat t1.txt|wc -L　　　　　　　　　　　　　　显示文件中最长的一行的长度，是字节长度</p><pre><code>[root@localhost grepDir]# cat t1.txtI'm MenAngel!Although I'm still a poor student right now,I believe that someday I will be one of the successful man in the world![root@localhost grepDir]# cat t1.txt|wc -L116</code></pre><p>6)[root@localhost grepDir]# ls -l|wc -l　　　　　　　　　　　　　　　　　统计当前目录下的文件的总数</p><pre><code>复制代码[root@localhost grepDir]# ls -l|wc -l6[root@localhost grepDir]# ll总用量 20-rw-r--r--. 1 root root  19 5月  31 04:44 patfile-rw-r--r--. 1 root root 131 5月  31 03:56 t1.txt-rw-r--r--. 1 root root  62 5月  31 03:58 t2.txt-rw-r--r--. 1 root root 297 5月  31 04:04 t3.txt-rw-r--r--. 1 root root 120 5月  31 18:25 wcText</code></pre><p>7)[root@localhost grepDir]# cat wcText|wc -l　　　　　　　　　　　　　只显示统计数字而不显示文件名</p><pre><code>[root@localhost grepDir]# wc -l wcText2 wcText[root@localhost grepDir]# cat wcText|wc -l</code></pre><p>8)[root@localhost grepDir]# echo “I’m MenAngel”|wc -c　　　　　　　用wc命令处理echo输出的字符串</p><pre><code>[root@localhost grepDir]# echo "I'm MenAngel"|wc -c13[root@localhost grepDir]# echo "I'm MenAngel"|wc -m13[root@localhost grepDir]# echo "I'm MenAngel"|wc -l</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 date cal</title>
      <link href="/2017/07/31/mei-tian-2-ge-linux-ming-ling-date-cal/"/>
      <url>/2017/07/31/mei-tian-2-ge-linux-ming-ling-date-cal/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-29-每天2个Linux命令-date命令"><a href="#2017-07-29-每天2个Linux命令-date命令" class="headerlink" title=" 2017-07-29 每天2个Linux命令 date命令"></a><center> 2017-07-29 每天2个Linux命令 date命令</center></h2><p>date命令是显示或设置系统时间与日期。</p><p>(1)用法:</p><pre><code>  用法:  date [选项]  [参数]</code></pre><p>(2)功能:</p><pre><code>  功能:  根据指定格式显示当前时间或设置系统时间   很多shell脚本里面需要打印不同格式的时间或日期，以及要根据时间和日期执行操作。延时通常用于脚本执行过程中提供一段等待的时间。日期可以以多种格式去打印，也可以使用命令设置固定的格式。在类UNIX系统中，日期被存储为一个整数，其大小为自世界标准时间（UTC）1970年1月1日0时0分0秒起流逝的秒数。</code></pre><p>(3)选项参数:</p><pre><code>  1) &lt;+时间日期格式&gt;：　　　　　　　　指定显示时使用的日期时间格式；  2) -d&lt;字符串&gt;：　　　　　　　　　　  显示字符串所指的日期与时间，字符串前后必须加上双引号；  3) -s&lt;字符串&gt;：　　　　　　　　　　  根据字符串来设置日期与时间；（不用加引号）</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost Document]# date -s 20160530　　　　　　　　　　　设置日期和时间(只有root权限才能设置，其他只能查看)[root@localhost Document]# date -s 201605302016年 05月 30日 星期一 00:00:00 PDT[root@localhost Document]# date -s 09:00:002016年 05月 30日 星期一 09:00:00 PDT</code></pre><p>2)[root@localhost Document]# date　　　　　　　　　　　　　　　　　　查看当前时间</p><pre><code>[root@localhost Document]# date2016年 05月 30日 星期一 09:01:05 PDT</code></pre><p>3)[root@localhost Document]# date 0819150511　　　　　　　　　　　 第二种设置日期和时间的方式</p><pre><code>[root@localhost Document]# date 08191505112011年 08月 19日 星期五 15:05:00 PDT[root@localhost Document]# date 05300800162016年 05月 30日 星期一 08:00:00 PDT</code></pre><p>4)[root@localhost Document]# date +%m%d%H%M%S　　　　　　　　第二种显示日期的方式</p><pre><code>[root@localhost Document]# date +%m%d%H%M%S0530080137[root@localhost Document]# date +%y%m%d%H%M%S160530080158</code></pre><p>5)[root@localhost Document]# date -d “+1 day” +”%y/%m/%d”　　　　　　　　显示经过加减法过后的日期</p><pre><code>复制代码[root@localhost Document]# date -d "1 day ago" +"%Y-%m-%d"                  //等价于date -d "-1 day ago" +"%Y-%m-%d"2016-05-29[root@localhost Document]# date -d "1 day ago" +"%y-%m-%d"16-05-29[root@localhost Document]# date -d "1 month ago" +"%y/%m/%d"16/04/30[root@localhost Document]# date -d "+1 day" +"%y/%m/%d"16/05/31[root@localhost Document]# date -d "+1 month" +"%y-%m-%d"16-06-30</code></pre><p>6)[root@localhost Document]# date -s “2016-05-30 09:10:10”　　　　　　　　　同时设置日期和时间</p><pre><code>复制代码[root@localhost Document]# date -s "2016-05-30 09:10:10"2016年 05月 30日 星期一 09:10:10 PDT[root@localhost Document]# date -s "20160530 09:10:10"2016年 05月 30日 星期一 09:10:10 PDT[root@localhost Document]# date -s "09:00:00 20160530"2016年 05月 30日 星期一 09:00:00 PDT[root@localhost Document]# date -s "09:00:00 2016/05/30"2016年 05月 30日 星期一 09:00:00 PDT[root@localhost Document]# date -s "09:00:00 2016-05-30"2016年 05月 30日 星期一 09:00:00 PDT</code></pre><p>7)格式转换后时间游走：</p><pre><code>[root@localhost Document]# date -d "Nov 5, 2018 09:00:00 AM 2 year ago" +"%Y-%m-%d %H:%M.%S"2016-11-05 09:00.00[root@localhost Document]# date -d "Oct 30, 2018 09:10:00 AM 2 month ago" +"5Y-%m-%d %H:%M"5Y-08-30 09:10[root@localhost Document]# date -d "Oct 30, 2018 09:10:00 AM 2 month ago" +"%Y-%m-%d %H:%M"2018-08-30 09:10</code></pre><p>8)[root@localhost Document]# echo $diff seconds　　　　　　　　记录命令花费的时间</p><pre><code>复制代码[root@localhost Document]# start=$(date +%s)[root@localhost Document]# ls /home |more -10sunjimeng[root@localhost Document]# end=$(date +%s)[root@localhost Document]# diff=$((end-start))[root@localhost Document]# echo $diff seconds40 seconds</code></pre><p>(5)日期格式字符串列表</p><pre><code>  %H 小时，24小时制（00~23）</code></pre><p>　　%I 小时，12小时制（01~12）</p><p>　　%k 小时，24小时制（0~23）</p><p>　　%l 小时，12小时制（1~12）</p><p>　　%M 分钟（00~59）</p><p>　　%p 显示出AM或PM</p><p>　　%r 显示时间，12小时制（hh:mm:ss %p）</p><p>　　%s 从1970年1月1日00:00:00到目前经历的秒数</p><p>　　%S 显示秒（00~59）</p><p>　　%T 显示时间，24小时制（hh:mm:ss）</p><p>　　%X 显示时间的格式（%H:%M:%S）</p><p>　　%Z 显示时区，日期域（CST）</p><p>　　%a 星期的简称（Sun~Sat）</p><p>　　%A 星期的全称（Sunday~Saturday）</p><p>　　%h,%b 月的简称（Jan~Dec）</p><p>　　%B 月的全称（January~December）</p><p>　　%c 日期和时间（Tue Nov 20 14:12:58 2012）</p><p>　　%d 一个月的第几天（01~31）</p><p>　　%x,%D 日期（mm/dd/yy）</p><p>　　%j 一年的第几天（001~366）</p><p>　　%m 月份（01~12）</p><p>　　%w 一个星期的第几天（0代表星期天）</p><p>　　%W 一年的第几个星期（00~53，星期一为第一天）</p><p>　　%y 年的最后两个数字（1999则是99）</p><pre><code>  月份的英文表示:【January】 　【February】  【March】  【April】   【May】   【June】   【July】  【August】  【September】  【October】  【November】  【December 】</code></pre><h2 id="2017-07-29-每天2个Linux命令-cal命令"><a href="#2017-07-29-每天2个Linux命令-cal命令" class="headerlink" title=" 2017-07-29 每天2个Linux命令 cal命令"></a><center> 2017-07-29 每天2个Linux命令 cal命令</center></h2><p> cal命令用于显示当前日历，或者指定日期的日历。</p><p> (1)用法:</p><pre><code>  用法： cal [选项]  [[[日] 月] 年]</code></pre><p>(2)功能:</p><pre><code>  功能:  用于查看日历等时间信息，如只有一个参数，则表示年份(1-9999)，如有两个参数，则表示月份和年份</code></pre><p>(3)选项参数:</p><pre><code>  1) -1  --one 　　　　　　　　　　　　只显示当前月份(默认)2) -3  --three 　　　　　　　　　　　 显示上个月、当月和下个月  3) -s  --sunday 　　　　　　　　　　 周日作为一周第一天  4) -m --monday 　　　　　　　　　  周一用为一周第一天  5) -j   --julian 　　　　　　　　　　　输出儒略日  6)-y   --year 　　　　　　　　　　　  输出整年</code></pre><p>(4)实例:</p><pre><code>  1)[sunjimeng@localhost ~]$ cal　　　　　　　　　　　　显示当前月份的日历复制代码[sunjimeng@localhost ~]$ cal      五月 2016     日 一 二 三 四 五 六 1  2  3  4  5  6  7 8  9 10 11 12 13 1415 16 17 18 19 20 2122 23 24 25 26 27 2829 30 31[sunjimeng@localhost ~]$ 复制代码</code></pre><p> 2)[sunjimeng@localhost ~]$ cal -1　　　　　　　　　　 显示当前月份的日历，与cal -1的参数一样</p><pre><code>复制代码[sunjimeng@localhost ~]$ cal -1      五月 2016     日 一 二 三 四 五 六 1  2  3  4  5  6  7 8  9 10 11 12 13 1415 16 17 18 19 20 2122 23 24 25 26 27 2829 30 31[sunjimeng@localhost ~]$ </code></pre><p> 3)[sunjimeng@localhost ~]$ cal -3　　　　　　　　　　显示着这个月，上个月和下个月的日历</p><pre><code>复制代码[sunjimeng@localhost ~]$ cal -3      四月 2016             五月 2016             六月 2016     日 一 二 三 四 五 六  日 一 二 三 四 五 六  日 一 二 三 四 五 六                1  2   1  2  3  4  5  6  7            1  2  3  4 3  4  5  6  7  8  9   8  9 10 11 12 13 14   5  6  7  8  9 10 1110 11 12 13 14 15 16  15 16 17 18 19 20 21  12 13 14 15 16 17 1817 18 19 20 21 22 23  22 23 24 25 26 27 28  19 20 21 22 23 24 2524 25 26 27 28 29 30  29 30 31              26 27 28 29 30      [sunjimeng@localhost ~]$ </code></pre><p>4)[sunjimeng@localhost ~]$ cal -j　　　　　　　　　　显示某日是今年的第多少天</p><pre><code>复制代码[sunjimeng@localhost ~]$ cal -j         五月 2016          日  一  二  三  四  五  六122 123 124 125 126 127 128129 130 131 132 133 134 135136 137 138 139 140 141 142143 144 145 146 147 148 149150 151 152复制代码</code></pre><p>5)[sunjimeng@localhost ~]$ cal -s　　　　　　　　　　将周日作为显示的日历的第一天</p><pre><code>复制代码[sunjimeng@localhost ~]$ cal -s      五月 2016     日 一 二 三 四 五 六 1  2  3  4  5  6  7 8  9 10 11 12 13 1415 16 17 18 19 20 2122 23 24 25 26 27 2829 30 31[sunjimeng@localhost ~]$ 复制代码</code></pre><p> 6)[sunjimeng@localhost ~]$ cal 11 2099      　　　　 显示特定某天的日历</p><pre><code>复制代码[sunjimeng@localhost ~]$ cal 11 2099     十一月 2099    日 一 二 三 四 五 六 1  2  3  4  5  6  7 8  9 10 11 12 13 1415 16 17 18 19 20 2122 23 24 25 26 27 2829 30[sunjimeng@localhost ~]$ cal 11 11 1111     十一月 1111    日 一 二 三 四 五 六          1  2  3  4 5  6  7  8  9 10 1112 13 14 15 16 17 1819 20 21 22 23 24 2526 27 28 29 30复制代码</code></pre><p>7)[sunjimeng@localhost ~]$ cal -m　　　　　　　　　以星期一作为一周的开始显示当前月份的日历</p><pre><code>复制代码[sunjimeng@localhost ~]$ cal -m      五月 2016     一 二 三 四 五 六 日                   1 2  3  4  5  6  7  8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 31复制代码</code></pre><p>8)[sunjimeng@localhost ~]$ cal 2016　　　　　　　　也可以显示某个特定年份的日历</p><pre><code>复制代码[sunjimeng@localhost ~]$ cal 2016                               2016                                       一月                   二月                   三月        日 一 二 三 四 五 六   日 一 二 三 四 五 六   日 一 二 三 四 五 六                1  2       1  2  3  4  5  6          1  2  3  4  5 3  4  5  6  7  8  9    7  8  9 10 11 12 13    6  7  8  9 10 11 1210 11 12 13 14 15 16   14 15 16 17 18 19 20   13 14 15 16 17 18 1917 18 19 20 21 22 23   21 22 23 24 25 26 27   20 21 22 23 24 25 2624 25 26 27 28 29 30   28 29                  27 28 29 30 3131        四月                   五月                   六月        日 一 二 三 四 五 六   日 一 二 三 四 五 六   日 一 二 三 四 五 六                1  2    1  2  3  4  5  6  7             1  2  3  4 3  4  5  6  7  8  9    8  9 10 11 12 13 14    5  6  7  8  9 10 1110 11 12 13 14 15 16   15 16 17 18 19 20 21   12 13 14 15 16 17 1817 18 19 20 21 22 23   22 23 24 25 26 27 28   19 20 21 22 23 24 2524 25 26 27 28 29 30   29 30 31               26 27 28 29 30        七月                   八月                   九月        日 一 二 三 四 五 六   日 一 二 三 四 五 六   日 一 二 三 四 五 六                1  2       1  2  3  4  5  6                1  2  3 3  4  5  6  7  8  9    7  8  9 10 11 12 13    4  5  6  7  8  9 1010 11 12 13 14 15 16   14 15 16 17 18 19 20   11 12 13 14 15 16 1717 18 19 20 21 22 23   21 22 23 24 25 26 27   18 19 20 21 22 23 2424 25 26 27 28 29 30   28 29 30 31            25 26 27 28 29 3031        十月                  十一月                 十二月       日 一 二 三 四 五 六   日 一 二 三 四 五 六   日 一 二 三 四 五 六                   1          1  2  3  4  5                1  2  3 2  3  4  5  6  7  8    6  7  8  9 10 11 12    4  5  6  7  8  9 10 9 10 11 12 13 14 15   13 14 15 16 17 18 19   11 12 13 14 15 16 1716 17 18 19 20 21 22   20 21 22 23 24 25 26   18 19 20 21 22 23 2423 24 25 26 27 28 29   27 28 29 30            25 26 27 28 29 30 31</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 ln diff</title>
      <link href="/2017/07/28/mei-tian-2-ge-linux-ming-ling-ln-diff/"/>
      <url>/2017/07/28/mei-tian-2-ge-linux-ming-ling-ln-diff/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-28-每天2个Linux命令-ln命令"><a href="#2017-07-28-每天2个Linux命令-ln命令" class="headerlink" title=" 2017-07-28 每天2个Linux命令 ln命令"></a><center> 2017-07-28 每天2个Linux命令 ln命令</center></h2><p>ln命令用来为文件创建链接，连接类型分为硬链接和符号链接两种，默认的连接类型是硬连接。如果要创建符号连接必须使用”-s”选项。</p><p>(1)用法:</p><pre><code>  用法:  ln  [options]  source  dist</code></pre><p>(2)功能:</p><pre><code>  功能:  在文件之间建立连接   注意: 符号链接文件不是一个独立的文件，它的许多属性依赖于源文件，所以给符号链接文件设置存取权限是没有意义的。</code></pre><p>(3)选项参数:</p><pre><code>  1) -s 　　　　　　　　 软链接(符号链接)  2) -v 　　　　　　　　 显示详细的处理过程  3) -d 　　　　　　　　 允许超级用户制作目录的硬链接</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost Documents]# ln -s findDir finDir_link　　　　　　　　为目录创建软连接    复制代码    [root@localhost Documents]# ll    总用量 0    dr--r--r--. 3 root sunjimeng 16 5月  24 07:52 findDir    drwxr-xr-x. 2 root root      51 5月  21 07:10 NoPdir    drwxr-xr-x. 2 root root      51 5月  21 07:09 Pdir    [root@localhost Documents]# ln -s findDir finDir_link    [root@localhost Documents]# ll    总用量 0    dr--r--r--. 3 root sunjimeng 16 5月  24 07:52 findDir    lrwxrwxrwx. 1 root root       7 5月  27 06:04 finDir_link -&gt; findDir    drwxr-xr-x. 2 root root      51 5月  21 07:10 NoPdir    drwxr-xr-x. 2 root root      51 5月  21 07:09 Pdir    复制代码          当源文件失效后，链接文件将失效。    复制代码    [root@localhost Documents]# ll    总用量 0    dr--r--r--. 3 root sunjimeng 16 5月  24 07:52 findDir    lrwxrwxrwx. 1 root root       7 5月  27 06:04 finDir_link -&gt; findDir    //有效时的颜色    drwxr-xr-x. 2 root root      51 5月  21 07:10 NoPdir    drwxr-xr-x. 2 root root      51 5月  21 07:09 Pdir    [root@localhost Documents]# cd finDir_link    [root@localhost finDir_link]# ll    总用量 0    dr-xr-xr-x. 3 root sunjimeng 60 5月  24 08:01 Dir    [root@localhost findDir]# rmdir Dir    [root@localhost findDir]# cd ../    [root@localhost Documents]# rmdir findDir    [root@localhost Documents]# ll    总用量 0                                   //无效时的颜色    lrwxrwxrwx. 1 root root  7 5月  27 06:04 finDir_link -&gt; findDir     drwxr-xr-x. 2 root root 51 5月  21 07:10 NoPdir    drwxr-xr-x. 2 root root 51 5月  21 07:09 Pdir    [root@localhost Documents]# cd finDir_link    bash: cd: finDir_link: 没有那个文件或目录</code></pre><p>2)[root@localhost Documents]# ln newFile newLink　　　　　　　　　　给文件创建硬链接</p><pre><code>复制代码[root@localhost Documents]# ll总用量 0drwxr-xr-x. 2 root root 51 5月  21 07:10 NoPdirdrwxr-xr-x. 2 root root 51 5月  21 07:09 Pdir[root@localhost Documents]# touch newFile             //创建文件[root@localhost Documents]# ln -s newFile newLink_s   //创建文件符号链接[root@localhost Documents]# ln newFile newLink        //创建文件硬链接[root@localhost Documents]# ln -s Pdir PdirLink_s     //创建目录符号链接[root@localhost Documents]# ln Pdir PdirLink          //不允许创建目录硬链接ln: "Pdir": 不允许将硬链接指向目录[root@localhost Documents]# ll总用量 0-rw-r--r--. 2 root root  0 5月  27 06:18 newFile-rw-r--r--. 2 root root  0 5月  27 06:18 newLink          lrwxrwxrwx. 1 root root  7 5月  27 06:19 newLink_s -&gt; newFiledrwxr-xr-x. 2 root root 51 5月  21 07:10 NoPdirdrwxr-xr-x. 2 root root 51 5月  21 07:09 Pdirlrwxrwxrwx. 1 root root  4 5月  27 06:19 PdirLink_s -&gt; Pdir创建的文件硬链接newLink与源文件newFile具有相同的权限，并且没有箭头。而文件软链接newLink_s的权限要多得多，而且有指向符号。</code></pre><p>3)综合实例，比较硬链接与符号链接的差别</p><pre><code>复制代码[root@localhost Documents]# cat &gt;newFile &lt;&lt;EOF&gt; This is original file!&gt; &gt; I'm test the hard link and the symbol link!&gt; EOF                                                     //到这里新建一个文件总用量 4[root@localhost Documents]# ln -s newFile newFile_link_s[root@localhost Documents]# ln newFile newFile_link[root@localhost Documents]# rm newFile                   //删除源文件rm：是否删除普通文件 "newFile"？y[root@localhost Documents]# ll总用量 4-rw-r--r--. 1 root root 68 5月  27 06:30 newFile_link    lrwxrwxrwx. 1 root root  7 5月  27 06:31 newFile_link_s -&gt; newFiledrwxr-xr-x. 2 root root 51 5月  21 07:10 NoPdirdrwxr-xr-x. 2 root root 51 5月  21 07:09 Pdir[root@localhost Documents]# cat newFile_link              //查看硬链接，完全不受影响，但符号链接已经失效This is original file!I'm test the hard link and the symbol link![root@localhost Documents]# cat &gt;newFile &lt;&lt;EOF            再新建一个文件newFile   &gt; The Second Test!&gt; &gt; EOF[root@localhost Documents]# ll总用量 8-rw-r--r--. 1 root root 18 5月  27 06:33 newFile-rw-r--r--. 1 root root 68 5月  27 06:30 newFile_linklrwxrwxrwx. 1 root root  7 5月  27 06:31 newFile_link_s -&gt; newFile   //符号链接已经恢复drwxr-xr-x. 2 root root 51 5月  21 07:10 NoPdirdrwxr-xr-x. 2 root root 51 5月  21 07:09 Pdir[root@localhost Documents]# cat newFile_link            //分别查看符号链接和硬链接发现硬链接内容不变，符号链接内容变为新建的文件内容了。This is original file!I'm test the hard link and the symbol link![root@localhost Documents]# cat newFile_link_sThe Second Test!</code></pre><p>4)[root@localhost Documents]# ln newFile ln_dir　　　　　　　　　　在另一个目录创建同名硬链接</p><pre><code>[root@localhost Documents]# mkdir ln_dir[root@localhost Documents]# ln newFile ln_dir[root@localhost Documents]# cd ln_dir[root@localhost ln_dir]# ll总用量 4-rw-r--r--. 2 root root 18 5月  27 06:33 newFile</code></pre><p>5)[root@localhost Documents]# ln -sv a.c ./Pdir　　　　　　　　　　　在指定目录创建链接</p><pre><code>复制代码[root@localhost Documents]# touch a.c[root@localhost Documents]# ll总用量 0-rw-r--r--. 1 root root  0 5月  27 07:03 a.clrwxrwxrwx. 1 root root  6 5月  27 06:58 No_link -&gt; NoPdirdrwxr-xr-x. 2 root root 51 5月  21 07:10 NoPdirdrwxr-xr-x. 2 root root 51 5月  21 07:09 Pdir[root@localhost Documents]# ln -sv a.c ./Pdir"./Pdir/a.c" -&gt; "a.c"[root@localhost Documents]# ln -sv a.c ./Pdir/b.c"./Pdir/b.c" -&gt; "a.c"[root@localhost Documents]# ln -v a.c ./Pdir/c.c"./Pdir/c.c" =&gt; "a.c"[root@localhost Documents]# ls -l Pdir总用量 8lrwxrwxrwx. 1 root root   3 5月  27 07:04 a.c -&gt; a.clrwxrwxrwx. 1 root root   3 5月  27 07:04 b.c -&gt; a.c-rw-r--r--. 2 root root   0 5月  27 07:03 c.c-r--r--r--. 1 root root   0 5月  19 04:16 find-rw-r--r--. 1 root root  85 5月  19 04:25 t3.txt--w-------. 1 root root   0 5月  15 18:34 uText-rw-r--r--. 1 root root 105 5月  21 06:35 vf</code></pre><p>(5)其他:</p><pre><code>  扩展知识:  Linux具有为一个文件起多个名字的功能，称为链接。被链接的文件可以存放在相同的目录下，    但是必须有不同的文件名，而不用在硬盘上为同样的数据重复备份。另外，被链接的文件也可以有相同的文件名，    但是存放在不同的目录下，这样只要对一个目录下的该文件进行修改，就可以完成对所有目录下同名链接文件的修改。    对于某个文件的各链接文件，我们可以给它们指定不同的存取权限，以控制对信息的共享和增强安全性。     文件链接有两种形式，即硬链接和符号链接。  硬链接:  建立硬链接时，在另外的目录或本目录中增加目标文件的一个目录项，这样，一个文件就登记在多个目录中。  创建硬链接后，己经存在的文件的I节点号（Inode）会被多个目录文件项使用。    一个文件的硬链接数可以在目录的长列表格式的第二列中看到，无额外链接的文件的链接数为l。 在默认情况下，ln命令创建硬链接。ln命令会增加链接数，rm命令会减少链接数。一个文件除非链接数为0，否则不会从文件系统中被物理地删除。  对硬链接有如下限制：  1.不能对目录文件做硬链接。  2.不能在不同的文件系统之间做硬链接。就是说，链接文件和被链接文件必须位于同一个文件系统中。  软链接:  符号链接也称为软链接，是将一个路径名链接到一个文件。这些文件是一种特别类型的文件。    事实上，它只是一个文本文件，其中包含它提供链接的另一个文件的路径名，如图中虚线箭头所示。另一个文件是实际包含所有数据的文件。所有读、写文件内容的命令被用于符号链接时，将沿着链接方向前进来访问实际的文件。  与硬链接不同的是，符号链接确实是一个新文件，当然它具有不同的I节点号；而硬链接并没有建立新文件。 符号链接没有硬链接的限制，可以对目录文件做符号链接，也可以在不同文件系统之间做符号链接。  用ln -s命令建立符号链接时，源文件最好用绝对路径名。这样可以在任何工作目录下进行符号链接。而当源文件用相对路径时，如果当前的工作路径与要创建的符号链接文件所在路径不同，就不能进行链接。 符号链接保持了链接与源文件或目录之间的区别： 删除源文件或目录，只删除了数据，不会删除链接。一旦以同样文件名创建了源文件，链接将继续指向该文件的新数据。 在目录长列表中，符号链接作为一种特殊的文件类型显示出来，其第一个字母是l。 符号链接的大小是其链接文件的路径名中的字节数。</code></pre><h2 id="2017-07-28-每天2个Linux命令-diff命令"><a href="#2017-07-28-每天2个Linux命令-diff命令" class="headerlink" title=" 2017-07-28 每天2个Linux命令 diff命令"></a><center> 2017-07-28 每天2个Linux命令 diff命令</center></h2><p>diff命令在最简单的情况下，比较给定的两个文件的不同。如果使用“-”代替“文件”参数，则要比较的内容将来自标准输入。<br>diff命令是以逐行的方式，比较文本文件的异同处。如果该命令指定进行目录的比较，<br>则将会比较该目录中具有相同文件名的文件，而不会对其子目录文件进行任何比较操作。</p><p>(1)用法:</p><pre><code>用法:  diff  [选项参数]  [文件1或目录1] [文件2或目录2]</code></pre><p> (2)功能:</p><pre><code>功能:  diff命令能比较单个文件或者目录内容。如果指定比较的是文件，则只有当输入为文本文件时才有效。以逐行的方式，比较文本文件的异同处。如果指定比较的是目录的的时候，diff 命令会比较两个目录下名字相同的文本文件。列出不同的二进制文件、公共子目录和只在一个目录出现的文件。</code></pre><p>(3)选项参数:</p><pre><code>  1) -y  --side-by-side 　　　　　　　　　　　以并列的方式显示文件的异同之处。  2) -W --width 　　　　　　　　　　　　　　 在使用-y参数时，指定栏宽。  3) -c 　　　　　　　　　　　　　　　　　　　显示全部内文，并标出不同之处。  4) -u -U --unified　　　　　　　　　　　　  以合并的方式来显示文件内容的不同。  5) -r --recursive 　　　　　　　　　　　　　比较子目录中的文件  6) -n --rcs 　　　　　　　　　　　　　　　　将比较结果以RCS的格式来显示。</code></pre><p> (4)实例:</p><pre><code>  1)[root@localhost Document]# diff t1.txt t2.txt　　　　　　　　比较两个文档的区别复制代码[root@localhost Document]# cat &gt;t1.txt &lt;&lt;EOF   //第一种新建文档的方式&gt; this is a text!&gt; &gt; Name is t1.txt!&gt; The extra content!&gt; I am MenAngel!&gt; EOF[root@localhost Document]# cat &gt;t2.txt        //第二种新建文档的方式this is a text!Name is t2.txt!^Z[2]+  已停止               cat &gt; t2.txt       //按ctrl+z键停止[root@localhost Document]# diff ../Document/t1.txt ../Document/t2.txt    diff后的两个文件参数可以跟相对路径也可以跟绝对路径3,5c3                                  &lt; Name is t1.txt!&lt; The extra content!&lt; I am MenAngel!---&gt; Name is t2.txt![root@localhost Document]# diff t1.txt t2.txt3,5c3&lt; Name is t1.txt!&lt; The extra content!&lt; I am MenAngel!---&gt; Name is t2.txt!复制代码      第一个3表示两个文档第3行不同，第二个5c3表示第一个文档有5行，而第2个文档有三行。</code></pre><p>2)[root@localhost Document]# diff -y t1.txt t2.txt　　　　　　　　以并排显示比较两个文档的区别</p><pre><code>[root@localhost Document]# diff -y t1.txt t2.txtthis is a text!                            this is a text!Name is t1.txt!                              |    Name is t2.txt!The extra content!                          &lt;I am MenAngel!                              &lt;</code></pre><p>3)[root@localhost Document]# diff -y -W 40 t1.txt t2.txt　　　　在（2）的基础上自定义显示的宽度</p><pre><code>[root@localhost Document]# diff -y -W 40 t1.txt t2.txtthis is a text!        this is a text!Name is t1.txt!       |    Name is t2.txt!The extra conten   &lt;I am MenAngel!     &lt;</code></pre><p>4)[root@localhost Document]# diff -y -W 40 t1.txt t2.txt 或者 t2.txt t1.txt　　　　文档顺序对结果的影响</p><pre><code>复制代码[root@localhost Document]# diff -y -W 40 t1.txt t2.txtthis is a text!        this is a text!Name is t1.txt!       |    Name is t2.txt!The extra conten   &lt;I am MenAngel!       &lt;[root@localhost Document]# diff -y -W 40 t2.txt t1.txtthis is a text!        this is a text!Name is t2.txt!       |    Name is t1.txt!           &gt;    The extra conten           &gt;    I am MenAngel!复制代码　　说明：　　“|”表示前后2个文件内容有不同　　“&lt;”表示后面文件比前面文件少了1行内容　　“&gt;”表示后面文件比前面文件多了1行内容</code></pre><p>5)[root@localhost Document]# diff -c t1.txt t2.txt　　　　　　　<br>    将进行比较的两个文档的内容全部显示出来标明行数，标出不同点</p><pre><code>复制代码[root@localhost Document]# diff -c t1.txt t2.txt*** t1.txt    2016-05-27 23:31:25.949100752 -0700--- t2.txt    2016-05-27 23:31:54.287100555 -0700****************** 1,5 ****           //从1到5行  this is a text!! Name is t1.txt!     //第3.4.5行不同! The extra content!  //由于t2.txt没有第4和第5行，所以第4和第5行表明是比t2.txt多的! I am MenAngel!--- 1,3 ----          //从1到3行  this is a text!! Name is t2.txt!     //第三行不同 复制代码　　说明：　　这种方式在开头两行作了比较文件的说明，这里有三中特殊字符：　　　 （“＋” 比较的文件的后者比前着多一行　　　　“－” 比较的文件的后者比前着少一行）  //-u参数用的　　　　“！” 比较的文件两者有差别的行</code></pre><p>6)[root@localhost Document]# diff -u t1.txt t2.txt　　　　　　　　以合并的方式显示文本的不同　　　　　　</p><pre><code>复制代码[root@localhost Document]# diff -u t1.txt t2.txt                        //它的第一部分，也是文件的基本信息--- t1.txt    2016-05-27 23:31:25.949100752 -0700                       //-号表示第一个文件+++ t2.txt    2016-05-27 23:31:54.287100555 -0700                       //+号表示第二个文件@@ -1,5 +1,3 @@ this is a text!-Name is t1.txt!-The extra content!-I am MenAngel!+Name is t2.txt!   //每个减号对应一个加号，如果没有对应则表明在另一个文件中没有此行</code></pre><p>7)[root@localhost Document]# diff dir1 dir2　　　　　　　　　　　　比较两个目录</p><pre><code>复制代码[root@localhost Document]# mkdir dir1 dir2                                 //创建两个目录[root@localhost Document]# cd dir1[root@localhost dir1]# cat &gt;text1 &lt;&lt;EOF    //在dir1中创建text1,text2在dir2中创建text1,text3&gt; dir:      dir1&gt; name:     text1&gt; &gt; Total 4!&gt; EOF[root@localhost dir1]# cat &gt;text2 &lt;&lt;EOF&gt; I am MenAngel!&gt; I am studying the order of Linux!&gt; EOF[root@localhost dir1]# cd ../dir2[root@localhost dir2]# cat &gt;text1 &lt;&lt;EOF&gt; dir:      dir2&gt; name:     text1&gt; &gt; &gt; Total 5!&gt; EOF[root@localhost dir2]# cat &gt;text3 &lt;&lt;EOF&gt; Working hard makes success!&gt; I am MenAngel!&gt; EOF[root@localhost dir2]# cd ../[root@localhost Document]# diff dir1 dir2只在 dir2 存在：text3diff dir1/text1 dir2/text1       //遇到同名文件自动比较1c1&lt; dir:      dir1---&gt; dir:      dir24c4,5&lt; Total 4!---&gt; &gt; Total 5!只在 dir1 存在：text2</code></pre><p>8)[root@localhost Document]# diff dir1 dir2 &gt;dir.log　　　　　　<br>    产生补丁，其实就是把原本要输出到标准输出的内容输出到自定义文件中</p><pre><code>复制代码[root@localhost Document]# diff dir1 dir2 &gt;dir.log[root@localhost Document]# cat dir.log只在 dir2 存在：textdiff dir1/text1 dir2/text11c1&lt; dir:      dir1---&gt; dir:      dir24c4,5&lt; Total 4!---&gt; &gt; Total 5!只在 dir1 存在：text2</code></pre><p>9)[root@localhost Document]# diff t1.txt t2.txt&gt;t12.log　　　　　　　　产生补丁，并用此补丁更新文件</p><pre><code>复制代码[root@localhost Document]# cat t1.txt t2.txtthis is a text!Name is t1.txt!The extra content!I am MenAngel!      //到这是t1.txt的内容this is a text!Name is t2.txt!    //到这是t2.txt的内容[root@localhost Document]# diff t1.txt t2.txt&gt;t12.log       //产生补丁[root@localhost Document]# patch t1.txt t12.log             //给t1.txt打补丁，让它的内容变为t2.txt的内容patching file t1.txt[root@localhost Document]# cat t1.txtthis is a text!Name is t2.txt![root@localhost Document]# patch t2.txt t12.log             //给t2.txt打补丁，不过好像有点差别patching file t2.txtReversed (or previously applied) patch detected!  Assume -R? [n] y    //还不知道是为什么？[root@localhost Document]# cat t2.txtthis is a text!Name is t1.txt!The extra content!I am MenAngel!复制代码</code></pre><p>(5)其他:</p><pre><code>  扩展知识:  diff 命令是 linux上非常重要的工具，用于比较文件的内容，特别是比较两个版本不同的文件以找到改动的地方。diff在命令行中打印每一个行的改动。最新版本的diff还支持二进制文件。diff程序的输出被称为补丁 (patch)，因为Linux系统中还有一个patch程序，可以根据diff的输出将a.c的文件内容更新为b.c。diff是svn、cvs、git等版本控制工具不可或缺的一部分。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 df du</title>
      <link href="/2017/07/27/mei-tian-2-ge-linux-ming-ling-df-du/"/>
      <url>/2017/07/27/mei-tian-2-ge-linux-ming-ling-df-du/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-27-每天2个Linux命令-df命令"><a href="#2017-07-27-每天2个Linux命令-df命令" class="headerlink" title=" 2017-07-27 每天2个Linux命令 df命令"></a><center> 2017-07-27 每天2个Linux命令 df命令</center></h2><p>报告文件系统磁盘空间的使用情况。获取硬盘被占用了多少空间，目前还剩下多少空间等信息。</p><p>(1)用法:</p><pre><code>  用法:  df [选项] [文件]</code></pre><p> (2)功能:</p><pre><code>  功能:  显示指定磁盘文件的可用空间。如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示。           默认情况下，磁盘空间将以 1KB 为单位进行显示，除非环境变量 POSIXLY_CORRECT 被指定，那样将以512字节为单位进行显示。</code></pre><p> (3)选项参数:</p><pre><code>  1) -a 　　　　　　　　　　　　    全部文件系统列表  2) -h 　　　　　　　　　　　　    方便阅读方式显示 3) -H 　　　　　　　　　　　　　 等于“-h”，但是计算式，1K=1000，而不是1K=1024  4) -i 　　　　　　　　 　　　　    显示inode信息  5) -k 　　　　　　　　 　　　　    区块为1024字节  6) -l 　　　　　　　　 　　　　    只显示本地文件系统  7) -m 　　　　　　　  　　　　　 区块为1048576字节  8) --no-sync 　　      　　　　     忽略 sync 命令  9) -P 　　　　　　　　　　　　　  输出格式为POSIX10) --sync 　　　　　  　　　　     在取得磁盘信息前，先执行sync命令11) -T 　　　　　　　　　　　　　  文件系统类型选择参数：12) --block-size=&lt;区块大小&gt; 　　指定区块大小13) -t&lt;文件系统类型&gt; 　　　　　　只显示选定文件系统的磁盘信息14) -x&lt;文件系统类型&gt; 　　　　　  不显示选定文件系统的磁盘信息</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost /]# df　　　　　　　　　　　 列出各文件系统的磁盘空间使用情况复制代码[root@localhost /]# df文件系统          1K-块    已用     可用 已用% 挂载点/dev/sda3      18555904 3582444 14973460   20% /devtmpfs         997908       0   997908    0% /devtmpfs           1006936     148  1006788    1% /dev/shmtmpfs           1006936    9072   997864    1% /runtmpfs           1006936       0  1006936    0% /sys/fs/cgroup/dev/sda1        303788  113264   190524   38% /boot</code></pre><hr><pre><code>2)[root@localhost /]# df -i　　　　　　　　　　　　列出各文件系统inode使用情况　　复制代码[root@localhost /]# df -i文件系统          Inode 已用(I)  可用(I) 已用(I)% 挂载点/dev/sda3      18566144  127865 18438279       1% /devtmpfs         249477     370   249107       1% /devtmpfs            251734       8   251726       1% /dev/shmtmpfs            251734     489   251245       1% /runtmpfs            251734      13   251721       1% /sys/fs/cgroup/dev/sda1        307200     330   306870       1% /boot</code></pre><hr><pre><code>3)[root@localhost /]# df -ia |more -10　　   　　列出所有文件系统的的inode使用情况,用more命令分隔只显示前10条复制代码[root@localhost /]# df -ia |more -10文件系统          Inode 已用(I)  可用(I) 已用(I)% 挂载点rootfs         18566144  127865 18438279       1% /proc                  0       0        0        - /procsysfs                 0       0        0        - /sysdevtmpfs         249477     370   249107       1% /devsecurityfs            0       0        0        - /sys/kernel/securitytmpfs            251734       8   251726       1% /dev/shmdevpts                0       0        0        - /dev/ptstmpfs            251734     489   251245       1% /runtmpfs            251734      13   251721       1% /sys/fs/cgroup--More--</code></pre><hr><pre><code>4)[root@localhost /]# df -T　　　　　　　　　　显示各文件系统类型复制代码[root@localhost /]# df -T文件系统       类型        1K-块    已用     可用 已用% 挂载点/dev/sda3      xfs      18555904 3582964 14972940   20% /　　　　　　　　　　　　//这里貌似没显示ext*文件系统devtmpfs       devtmpfs   997908       0   997908    0% /devtmpfs          tmpfs     1006936     148  1006788    1% /dev/shmtmpfs          tmpfs     1006936    9072   997864    1% /runtmpfs          tmpfs     1006936       0  1006936    0% /sys/fs/cgroup/dev/sda1      xfs        303788  113264   190524   38% /boot</code></pre><hr><pre><code>5)[root@localhost /]# df -h　　　　　　　　　 以便于阅读的方式显示信息复制代码[root@localhost /]# df -h文件系统        容量  已用  可用 已用% 挂载点/dev/sda3        18G  3.5G   15G   20% /devtmpfs        975M     0  975M    0% /devtmpfs           984M  148K  984M    1% /dev/shmtmpfs           984M  8.9M  975M    1% /runtmpfs           984M     0  984M    0% /sys/fs/cgroup/dev/sda1       297M  111M  187M   38% /boot[root@localhost /]# df -ih文件系统       Inode 已用(I) 可用(I) 已用(I)% 挂载点/dev/sda3        18M    125K     18M       1% /devtmpfs        244K     370    244K       1% /devtmpfs           246K       8    246K       1% /dev/shmtmpfs           246K     489    246K       1% /runtmpfs           246K      13    246K       1% /sys/fs/cgroup/dev/sda1       300K     330    300K       1% /boot</code></pre><hr><pre><code>6)[root@localhost /]# df -k　　　　　　　　以单位显示磁盘的使用情况(默认)复制代码[root@localhost /]# df -kh文件系统        容量  已用  可用 已用% 挂载点/dev/sda3        18G  3.5G   15G   20% /devtmpfs        975M     0  975M    0% /devtmpfs           984M  148K  984M    1% /dev/shmtmpfs           984M  8.9M  975M    1% /runtmpfs           984M     0  984M    0% /sys/fs/cgroup/dev/sda1       297M  111M  187M   38% /boot[root@localhost /]# df -k文件系统          1K-块    已用     可用 已用% 挂载点/dev/sda3      18555904 3582484 14973420   20% /devtmpfs         997908       0   997908    0% /devtmpfs           1006936     148  1006788    1% /dev/shmtmpfs           1006936    9076   997860    1% /runtmpfs           1006936       0  1006936    0% /sys/fs/cgroup/dev/sda1        303788  113264   190524   38% /boot[root@localhost /]# df文件系统          1K-块    已用     可用 已用% 挂载点/dev/sda3      18555904 3582484 14973420   20% /devtmpfs         997908       0   997908    0% /devtmpfs           1006936     148  1006788    1% /dev/shmtmpfs           1006936    9076   997860    1% /runtmpfs           1006936       0  1006936    0% /sys/fs/cgroup/dev/sda1        303788  113264   190524   38% /boot复制代码</code></pre><hr><pre><code>  7)[root@localhost /]# df -t tmpfs　　　　　　　显示指定类型的文件系统复制代码[root@localhost /]# df -k文件系统          1K-块    已用     可用 已用% 挂载点/dev/sda3      18555904 3582508 14973396   20% /devtmpfs         997908       0   997908    0% /devtmpfs           1006936     148  1006788    1% /dev/shmtmpfs           1006936    9076   997860    1% /runtmpfs           1006936       0  1006936    0% /sys/fs/cgroup/dev/sda1        303788  113264   190524   38% /boot[root@localhost /]# df -t tmpfs文件系统         1K-块  已用    可用 已用% 挂载点tmpfs          1006936   148 1006788    1% /dev/shmtmpfs          1006936  9076  997860    1% /runtmpfs          1006936     0 1006936    0% /sys/fs/cgroup</code></pre><h2 id="2017-07-27-每天2个Linux命令-du命令"><a href="#2017-07-27-每天2个Linux命令-du命令" class="headerlink" title=" 2017-07-27 每天2个Linux命令 du命令"></a><center> 2017-07-27 每天2个Linux命令 du命令</center></h2><p>du命令是对文件和目录磁盘使用的空间的查看。</p><p>(1)用法:</p><pre><code>用法:  du  [选项]  [文件]</code></pre><p>(2)功能:</p><pre><code>功能:  报告磁盘空间使用情况</code></pre><p>(3)选项参数:</p><pre><code>  1) -a  --all 　　　　　　　　　　　　　　显示对所有文件的统计，而不只是包含子目录。  2) -b  --bytes 　　　　　　　　　　　　 输出以字节为单位的大小，替代缺省时1024字节的计数单位。   3) -h --human-readable  　　　　　　  以K，M，G为单位，提高信息的可读性。  4) -s --summarize 　　　　　　　　　　对每个参数只显示总和    5) --max-depth=n 　　　　　　　　　　只输出命令行参数的小于等于第 n 层的目录的总计。 --max-depth=0的作用同于-s选项。  6) -m --megabytes 　　　　　　　　　  输出以兆字节的块为计数单位的大小(就是 1,048,576 字节)  7) -X file --exclude-from=file 　　　　  除了从指定的文件中得到模式之外与 --exclude 一样。 模式以行的形式列出。如果指定的文件是'-',那么从标准输 入中读出模式。  8) -k --kilobytes 　　　　　　　　　　   以KB(1024bytes)为单位输出</code></pre><p>(4)实例:</p><pre><code>  默认是1024个字节为单位  1)[root@localhost sunjimeng]# du Documents　　　　　　　　显示目录或文件的空间使用情况复制代码[root@localhost sunjimeng]# du Documents               //只显示目录0    Documents/findDir/Dir/CDir12    Documents/findDir/Dir12    Documents/findDir8    Documents/Pdir8    Documents/NoPdir28    Documents显示文件的空间使用情况[root@localhost sunjimeng]# du Documents/findDir/Dir/head_text4    Documents/findDir/Dir/head_text     </code></pre><hr><pre><code>2)[root@localhost sunjimeng]# du -a Documents　　　　　　详细查看当前目录，子目录下的，所有文件和目录　　复制代码[root@localhost sunjimeng]# du -a Documents4    Documents/findDir/Dir/head_text4    Documents/findDir/Dir/less20    Documents/findDir/Dir/CDir4    Documents/findDir/Dir/less1.gz12    Documents/findDir/Dir12    Documents/findDir0    Documents/Pdir/find4    Documents/Pdir/t3.txt4    Documents/Pdir/vf0    Documents/Pdir/uText8    Documents/Pdir0    Documents/NoPdir/find4    Documents/NoPdir/t3.txt4    Documents/NoPdir/vf0    Documents/NoPdir/uText8    Documents/NoPdir28    Documents 复制代码</code></pre><hr><pre><code>3)[root@localhost Document]# du　　　　　　　　　　默认显示当前目录的文件夹的空间使用情况复制代码[root@localhost Document]# du0    ./newDir12    .[root@localhost Document]# ll总用量 12-rw-r--r--. 1 root      users 85 5月  18 02:58 all.txt-rw-rw-r--. 1 sunjimeng users  0 5月  19 22:27 B.text3-rw-rw-r--. 1 sunjimeng users  0 5月  19 22:27 C.text6-rw-rw-r--. 1 sunjimeng users  0 5月  19 22:28 D.textdrwxr-xr-x. 2 root      users 51 5月  18 02:47 newDir-rw-r--r--. 1 root      users 42 5月  18 02:53 t1.txt-rw-r--r--. 1 root      users 43 5月  18 02:54 t2.txt[root@localhost Document]# cd ../[root@localhost sunjimeng]# du Document0    Document/newDir12    Document</code></pre><hr><pre><code>4)[root@localhost sunjimeng]# du -ah Documents　　　　　　以易于阅读的方式显示复制代码[root@localhost sunjimeng]# du -ah Documents4.0K    Documents/findDir/Dir/head_text4.0K    Documents/findDir/Dir/less20    Documents/findDir/Dir/CDir4.0K    Documents/findDir/Dir/less1.gz12K    Documents/findDir/Dir12K    Documents/findDir0    Documents/Pdir/find4.0K    Documents/Pdir/t3.txt4.0K    Documents/Pdir/vf0    Documents/Pdir/uText8.0K    Documents/Pdir0    Documents/NoPdir/find4.0K    Documents/NoPdir/t3.txt4.0K    Documents/NoPdir/vf0    Documents/NoPdir/uText8.0K    Documents/NoPdir28K    Documents</code></pre><hr><pre><code>5)[root@localhost sunjimeng]# du -hba Documents　　　　　　以一个字节为单位显示复制代码[root@localhost sunjimeng]# du -hba Documents664    Documents/findDir/Dir/head_text57    Documents/findDir/Dir/less26    Documents/findDir/Dir/CDir67    Documents/findDir/Dir/less1.gz854    Documents/findDir/Dir870    Documents/findDir0    Documents/Pdir/find85    Documents/Pdir/t3.txt105    Documents/Pdir/vf0    Documents/Pdir/uText241    Documents/Pdir0    Documents/NoPdir/find85    Documents/NoPdir/t3.txt105    Documents/NoPdir/vf0    Documents/NoPdir/uText241    Documents/NoPdir1396    Documents</code></pre><hr><pre><code>6)[root@localhost sunjimeng]# du -s *　　　　　　　　　　只以总数显示子文件夹的空间使用情况复制代码[root@localhost sunjimeng]# du -s *0    Desktop12    Document28    Documents0    Downloads0    findTextDir0    Music0    Pictures0    Public0    Templates0    Videos[root@localhost sunjimeng]# du -s　　　　　　　　//默认显示当前的文件夹sunjimeng5328    </code></pre><hr><pre><code>7)[root@localhost sunjimeng]# du -bh * |sort -n　　　　　根据目录的大小进行排序，包括目录的子目录复制代码[root@localhost sunjimeng]# du -bh * |sort -n1.4K    Documents6    Desktop6    Documents/findDir/Dir/CDir6    Downloads6    findTextDir6    Music6    Pictures6    Public6    Templates6    Videos51    Document/newDir241    Documents/NoPdir241    Documents/Pdir321    Document854    Documents/findDir/Dir870    Documents/findDir</code></pre><hr><pre><code>8)[root@localhost /]# du -ahm --max-depth=0　　　　　　以M为单位显示文件夹的大小，并且可以指定显示的深度复制代码[root@localhost /]# du -ahm --max-depth=0　　　//深度为0表示只显示当前文件夹/的大小du: 无法访问"./proc/4599/task/4599/fd/4": 没有那个文件或目录  //但必须将整个磁盘全部查询才知道结果du: 无法访问"./proc/4599/task/4599/fdinfo/4": 没有那个文件或目录du: 无法访问"./proc/4599/fd/4": 没有那个文件或目录du: 无法访问"./proc/4599/fdinfo/4": 没有那个文件或目录du: 无法访问"./run/user/1000/gvfs": 权限不够3540    .[root@localhost /]# du -ahm --max-depth=196    ./boot1    ./devdu: 无法访问"./proc/4670/task/4670/fd/4": 没有那个文件或目录du: 无法访问"./proc/4670/task/4670/fdinfo/4": 没有那个文件或目录du: 无法访问"./proc/4670/fd/4": 没有那个文件或目录du: 无法访问"./proc/4670/fdinfo/4": 没有那个文件或目录0    ./procdu: 无法访问"./run/user/1000/gvfs": 权限不够9    ./run0    ./sys28    ./etc1    ./root1    ./tmp100    ./var3304    ./usr0    ./bin0    ./sbin0    ./lib0    ./lib646    ./home0    ./media0    ./mnt0    ./opt0    ./srv0    ./touch_test0    ./touch_text3540    .     //可知整个ext文件系统的空间使用情况是3540M左右</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>solr学习</title>
      <link href="/2017/07/26/solr-xue-xi/"/>
      <url>/2017/07/26/solr-xue-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-22-solr"><a href="#2017-07-22-solr" class="headerlink" title=" 2017-07-22 solr"></a><center> 2017-07-22 solr</center></h2><p>1    课程计划</p><pre><code>1、    solr介绍    a)    什么是solr    b)    Solr和lucene的区别2、    Solr的安装配置（重点）3、    Solr的基本使用（重点）4、    Solrj的使用（重点）5、    京东案例（重点）</code></pre><p>2    Solr介绍</p><pre><code>2.1    什么是solr    Solr是apache的顶级开源项目，它是使用java开发 ，基于lucene的全文检索服务器。    Solr比lucene提供了更多的查询语句，而且它可扩展、可配置，同时它对lucene的性能进行了优化。    Solr是如何实现全文检索的呢？    索引流程：solr客户端（浏览器、java程序）可以向solr服务端发送POST请求，    请求内容是包含Field等信息的一个xml文档，通过该文档，solr实现对索引的维护（增删改）    搜索流程：solr客户端（浏览器、java程序）可以向solr服务端发送GET请求，solr服务器返回一个xml文档。    Solr同样没有视图渲染的功能。2.2    Solr和lucene的区别    Lucene是一个全文检索引擎工具包，它只是一个jar包，不能独立运行，对外提供服务。    Solr是一个全文检索服务器，它可以单独运行在servlet容器，    可以单独对外提供搜索和索引功能。Solr比lucene在开发全文检索功能时，更快捷、更方便。</code></pre><p><img src="/images/20170722/1.png"></p><p>3    Solr安装配置</p><pre><code>3.1    下载solr    Solr和lucene的版本是同步更新的，最新的版本是5.2.1    本课程使用的版本：4.10.3    下载地址：http://archive.apache.org/dist/lucene/solr/    下载版本：4.10.3    Linux下需要下载lucene-4.10.3.tgz，windows下需要下载lucene-4.10.3.zip。</code></pre><p><img src="/images/20170722/2.png"></p><p><img src="/images/20170722/3.png"></p><p><img src="/images/20170722/4.png"></p><pre><code>3.2    运行环境        Jdk：1.7及以上        Solr：4.10.3        Mysql：5X        Web服务器：tomcat 7    3.2.1    初始化数据库脚本</code></pre><p><img src="/images/20170722/5.png"></p><pre><code>3.3    Solr安装配置    3.3.1    Solr的安装部署        第一步：安装tomcat        第二步：将以下的war包，拷贝到tomcat的webapps目录下</code></pre><p><img src="/images/20170722/6.png"></p><pre><code>        第三步：解压缩war包            解压缩之后，将war包删掉</code></pre><p><img src="/images/20170722/7.png"></p><pre><code>        第四步：添加solr的扩展服务包</code></pre><p><img src="/images/20170722/8.png"></p><pre><code>        将以上jar包，添加到以下目录</code></pre><p><img src="/images/20170722/9.png"></p><pre><code>        第五步：添加log4j.properties            将以下目录的文件进行拷贝</code></pre><p><img src="/images/20170722/10.png"></p><pre><code>        复制到以下目录</code></pre><p><img src="/images/20170722/11.png"></p><pre><code>        第六步：在web.xml中指定solrhome的目录</code></pre><p><img src="/images/20170722/12.png"></p><p><img src="/images/20170722/13.png"></p><pre><code>    3.3.2    Solrcore的安装        3.3.2.1    Solrcore和solrhome            Solrhome是solr服务运行的主目录，一个solrhome目录里面包含多个solrcore目录，            一个solrcore目录里面了一个solr实例运行时所需要的配置文件和数据文件。            每一个solrcore都可以单独对外提供搜索和索引服务。            多个solrcore之间没有关系。        3.3.2.2    Solrcore和solrhome的目录结构                Solrhome的目录结构</code></pre><p><img src="/images/20170722/14.png"></p><pre><code>                Solrcore目录</code></pre><p><img src="/images/20170722/15.png"></p><pre><code>    3.3.2.3    Solrcore的安装            安装solrcore需要先安装solrhome            将以下目录的文件进行拷贝</code></pre><p><img src="/images/20170722/16.png"></p><pre><code>            复制到以下目录</code></pre><p><img src="/images/20170722/17.png"></p><pre><code>            这样solrhome和solrcore就安装成功了。    3.3.2.4    Solrcore配置            在solrcore的conf目录下，有一个solrconfig.xml的配置文件，该配置文件，配置来solrcor的运行信息</code></pre><p><img src="/images/20170722/18.png"></p><pre><code>            在该文件中，主要配置三个标签：lib标签、datadir标签、requestHandler标签            如果对该文件不进行配置也可以，即使用默认的配置项。            3.3.2.4.1    Lib 标签                Solrcore需要添加一个扩展依赖包，通过lib标签来指定依赖包的地址                solr.install.dir：表示solrcore的安装目录                将以下目录的文件进行拷贝</code></pre><p><img src="/images/20170722/19.png"></p><pre><code>                复制到以下目录</code></pre><p><img src="/images/20170722/20.png"></p><pre><code>                修改lib标签</code></pre><p><img src="/images/20170722/21.png"></p><pre><code>            3.3.2.4.2    datadir标签                每个SolrCore都有自己的索引文件目录 ，默认在SolrCore目录下的data中。</code></pre><p><img src="/images/20170722/22.png"></p><pre><code>                data数据目录下包括了index索引目录 和tlog日志文件目录。                如果不想使用默认的目录也可以通过solrConfig.xml更改索引目录 ，如下：</code></pre><p><img src="/images/20170722/23.png"></p><pre><code>            3.3.2.4.3    requestHandler标签                    requestHandler请求处理器，定义了索引和搜索的访问方式。                    通过/update维护索引，可以完成索引的添加、修改、删除操作。</code></pre><p><img src="/images/20170722/24.png"></p><pre><code>                    提交xml、json数据完成索引维护，索引维护小节详细介绍。                    通过/select搜索索引。</code></pre><p><img src="/images/20170722/25.png"></p><pre><code>                    设置搜索参数完成搜索，搜索参数也可以设置一些默认值，如下：                    &lt;requestHandler name="/select" class="solr.SearchHandler"&gt;                        &lt;!-- 设置默认的参数值，可以在请求地址中修改这些参数--&gt;                        &lt;lst name="defaults"&gt;                            &lt;str name="echoParams"&gt;explicit&lt;/str&gt;                            &lt;int name="rows"&gt;10&lt;/int&gt;&lt;!--显示数量--&gt;                            &lt;str name="wt"&gt;json&lt;/str&gt;&lt;!--显示格式--&gt;                            &lt;str name="df"&gt;text&lt;/str&gt;&lt;!--默认搜索字段--&gt;                        &lt;/lst&gt;                    &lt;/requestHandler&gt;3.4    solr界面介绍        启动solr服务        http://localhost:8080/solr</code></pre><p><img src="/images/20170722/26.png"></p><pre><code>    3.4.1    Dashboard            仪表盘，显示了该Solr实例开始启动运行的时间、版本、系统资源、jvm等信息。    3.4.2    Logging            Solr运行日志信息    3.4.3    Cloud            Cloud即SolrCloud，即Solr云（集群），当使用Solr Cloud模式运行时会显示此菜单，该部分功能在第二个项目，即电商项目会讲解。    3.4.4    Core Admin            Solr Core的管理界面。在这里可以添加SolrCore实例。    3.4.5    java properties            Solr在JVM 运行环境中的属性信息，包括类路径、文件编码、jvm内存设置等信息。    3.4.6    Tread Dump            显示Solr Server中当前活跃线程信息，同时也可以跟踪线程运行栈信息。    3.4.7    Core selector（重点）            选择一个SolrCore进行详细操作，如下：</code></pre><p><img src="/images/20170722/27.png"></p><pre><code>        3.4.7.1    Analysis（重点）</code></pre><p><img src="/images/20170722/28.png"></p><pre><code>                通过此界面可以测试索引分析器和搜索分析器的执行情况。                注：solr中，分析器是绑定在域的类型中的。        3.4.7.2    dataimport                可以定义数据导入处理器，从关系数据库将数据导入到Solr索引库中。                默认没有配置，需要手工配置        3.4.7.3    Document（重点）                通过/update表示更新索引，solr默认根据id（唯一约束）域来更新Document的内容，                如果根据id值搜索不到id域则会执行添加操作，如果找到则更新。                通过此菜单可以创建索引、更新索引、删除索引等操作，界面如下：</code></pre><p><img src="/images/20170722/29.png"></p><pre><code>                    overwrite="true" ： solr在做索引的时候，如果文档已经存在，就用xml中的文档进行替换                    commitWithin="1000" ： solr 在做索引的时候，每个1000（1秒）毫秒，做一次文档提交。                    为了方便测试也可以在Document中立即提交，&lt;/doc&gt;后添加“&lt;commit/&gt;”        3.4.7.4    Query（重点）                通过/select执行搜索索引，必须指定“q”查询条件方可搜索。</code></pre><p><img src="/images/20170722/30.png"></p><pre><code>3.5    多solrcore的配置        配置多solrcore的好处：            1、    在进行solrcloud的时候，必须配置多solrcore            2、    每个solrcore之间是独立的，都可以单独对外提供服务。                不同的业务模块可以使用不同的solrcore来提供搜索和索引服务。            添加            第一步：复制solrhome下的collection1目录到本目录下，修改名称为collection2</code></pre><p><img src="/images/20170722/31.png"></p><pre><code>            第二步：修改solrcore目录下的core.properties</code></pre><p><img src="/images/20170722/32.png"></p><pre><code>            这样多solrcore就配置完成了</code></pre><p>4    Solr的基本使用</p><pre><code>    4.1    Schema.xml    在schema.xml文件中，主要配置了solrcore的一些数据信息，包括Field和FieldType的定义等信息，    在solr中，Field和FieldType都需要先定义后使用。</code></pre><p><img src="/images/20170722/33.png"></p><pre><code>        4.1.1    Filed            定义Field域            &lt;field name="id" type="string" indexed="true" stored="true" required="true" multiValued="false" /&gt;             Name：指定域的名称            Type：指定域的类型            Indexed：是否索引            Stored：是否存储            Required：是否必须            multiValued：是否多值，比如商品信息中，一个商品有多张图片，            一个Field像存储多个值的话，必须将multiValued设置为true。        4.1.2    dynamicField                动态域                &lt;dynamicField name="*_i"  type="int"    indexed="true"  stored="true"/&gt;                Name：指定动态域的命名规则        4.1.3    uniqueKey                指定唯一键                &lt;uniqueKey&gt;id&lt;/uniqueKey&gt;                其中的id是在Field标签中已经定义好的域名，而且该域要设置为required为true。                一个schema.xml文件中必须有且仅有一个唯一键        4.1.4    copyField                复制域                &lt;copyField source="cat" dest="text"/&gt;                Source：要复制的源域的域名                Dest：目标域的域名                由dest指的的目标域，必须设置multiValued为true。</code></pre><p><img src="/images/20170722/34.png"></p><pre><code>        4.1.5    FieldType        定义域的类型        &lt;fieldType name="text_general" class="solr.TextField" positionIncrementGap="100"&gt;              &lt;analyzer type="index"&gt;                &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;                &lt;filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" /&gt;                &lt;!-- in this example, we will only use synonyms at query time                &lt;filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/&gt;                --&gt;                &lt;filter class="solr.LowerCaseFilterFactory"/&gt;              &lt;/analyzer&gt;              &lt;analyzer type="query"&gt;                &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;                &lt;filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" /&gt;                &lt;filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/&gt;                &lt;filter class="solr.LowerCaseFilterFactory"/&gt;              &lt;/analyzer&gt;            &lt;/fieldType&gt;        Name：指定域类型的名称        Class：指定该域类型对应的solr的类型        Analyzer：指定分析器        Type：index、query，分别指定搜索和索引时的分析器        Tokenizer：指定分词器        Filter：指定过滤器    4.2    中文分词器        使用ikanalyzer进行中文分词        第一步：将ikanalyzer的jar包拷贝到以下目录</code></pre><p><img src="/images/20170722/35.png"></p><pre><code>        第二步：将ikanalyzer的扩展词库的配置文件拷贝到 目录</code></pre><p><img src="/images/20170722/36.png"></p><pre><code>        第三步：配置FieldType</code></pre><p><img src="/images/20170722/37.png"></p><pre><code>        第四步：配置使用中文分词的Field</code></pre><p><img src="/images/20170722/38.png"></p><pre><code>        第五步：重启tomcat</code></pre><p><img src="/images/20170722/39.png"></p><pre><code>    4.3    配置业务Field        4.3.1    需求            对京东案例中的products表的数据进行索引，所以需要先定义对应的Field域。        4.3.2    分析配置                Products的表结构</code></pre><p><img src="/images/20170722/40.png"></p><pre><code>                需要往索引库添加的字段有：                pid、name、catalog、catalog_name、price、description、picture                FieldType：                经分析，由于中文分词器已经配置完FieldType，所以目前FieldType已经满足需要，无需配置。                Field：                Pid：                由于pid在products表中是唯一键，而且在solr的shema.xml中已有一个id的唯一键配置，所以不需要再重新定义pid域。                Name：                &lt;!-- 商品名称 --&gt;                &lt;field name="product_name" type="text_ik" indexed="true" stored="true"/&gt;                Catalog、catalog_name：                &lt;!-- 商品分类ID --&gt;                    &lt;field name="product_catalog" type="string" indexed="true" stored="true"/&gt;                     &lt;!-- 商品分类名称 --&gt;                    &lt;field name="product_catalog_name" type="string" indexed="true" stored="false"/&gt;                Price：                &lt;!-- 商品价格 --&gt;                    &lt;field name="product_price" type="float" indexed="true" stored="true"/&gt;                Description：                &lt;!-- 商品描述 --&gt;                    &lt;field name="product_description" type="text_ik" indexed="true" stored="false"/&gt;                Picture：                &lt;!-- 商品图片地址 --&gt;                    &lt;field name="product_picture" type="string" indexed="false" stored="true"/&gt; </code></pre><p><img src="/images/20170722/41.png"></p><pre><code>    4.4    Dataimport        该插件可以将数据库中指定的sql语句的结果导入到solr索引库中。        4.4.1    第一步：添加jar包                    Dataimport的jar包                复制以下目录的jar包</code></pre><p><img src="/images/20170722/42.png"></p><pre><code>                添加到以下目录</code></pre><p><img src="/images/20170722/43.png"></p><pre><code>        修改solrconfig.xml文件，添加lib标签        &lt;lib dir="${solr.install.dir:../..}/contrib/dataimporthandler/lib" regex=".*\.jar" /&gt;            MySQL数据库驱动包        将mysql的驱动包，复制到以下目录</code></pre><p><img src="/images/20170722/44.png"></p><pre><code>        修改solrconfig.xml文件，添加lib标签        &lt;lib dir="${solr.install.dir:../..}/contrib/db/lib" regex=".*\.jar" /&gt;        4.4.2    第二步：配置requestHandler                在solrconfig.xml中，添加一个dataimport的requestHandler</code></pre><p><img src="/images/20170722/45.png"></p><pre><code>        4.4.3    第三步：创建data-config.xml                在solrconfig.xml同级目录下，创建data-config.xml</code></pre><p><img src="/images/20170722/46.png"></p><pre><code>        4.4.4    重启tomcat</code></pre><p><img src="/images/20170722/47.png"></p><p>5    Solrj的使用</p><pre><code>    5.1    什么是solrj        Solrj就是solr服务器的java客户端。</code></pre><p><img src="/images/20170722/48.png"></p><pre><code>    5.2    环境准备            Jdk            Ide            Tomcat            Solrj    5.3    搭建工程            Solrj的依赖包和核心包</code></pre><p><img src="/images/20170722/49.png"></p><pre><code>            Solr的扩展服务包</code></pre><p><img src="/images/20170722/50.png"></p><p><img src="/images/20170722/51.png"></p><pre><code>    5.4    使用solrj完成索引维护        5.4.1    添加/修改索引                在solr中，索引库中都会存在一个唯一键，如果一个Document的id存在，则执行修改操作，                如果不存在，则执行添加操作。</code></pre><p><img src="/images/20170722/52.png"></p><pre><code>        5.4.2    删除索引                5.4.2.1    根据指定ID来删除</code></pre><p><img src="/images/20170722/53.png"></p><pre><code>                5.4.2.2    根据条件删除</code></pre><p><img src="/images/20170722/54.png"></p><pre><code>        5.4.3    查询索引                5.4.3.1    简单查询</code></pre><p><img src="/images/20170722/55.png"></p><pre><code>                5.4.3.2    复杂查询                        5.4.3.2.1    solr的查询语法                                1.    q - 查询关键字，必须的，如果查询所有使用*:*。                                    请求的q是字符串</code></pre><p><img src="/images/20170722/56.png"></p><pre><code>                                2.    fq - （filter query）过虑查询，                                作用：在q查询符合结果中同时是fq查询符合的，例如：：                                请求fq是一个数组（多个值）</code></pre><p><img src="/images/20170722/57.png"></p><pre><code>                                过滤查询价格从1到20的记录。                                也可以在“q”查询条件中使用product_price:[1 TO 20]，如下：</code></pre><p><img src="/images/20170722/58.png"></p><pre><code>                                也可以使用“*”表示无限，例如：                                20以上：product_price:[20 TO *]                                20以下：product_price:[* TO 20]                                3.    sort - 排序，格式：sort=&lt;field name&gt;+&lt;desc|asc&gt;[,&lt;field name&gt;+&lt;desc|asc&gt;]… 。示例：  按价格降序</code></pre><p><img src="/images/20170722/59.png"></p><pre><code>                                4.    start - 分页显示使用，开始记录下标，从0开始                                 5.    rows - 指定返回结果最多有多少条记录，配合start来实现分页。                                    实际开发时，知道当前页码和每页显示的个数最后求出开始下标。                                6.    fl - 指定返回那些字段内容，用逗号或空格分隔多个。                                    显示商品图片、商品名称、商品价格</code></pre><p><img src="/images/20170722/60.png"></p><pre><code>                                7.    df-指定一个搜索Field                                    也可以在SolrCore目录 中conf/solrconfig.xml文件中指定默认搜索Field，                                    指定后就可以直接在“q”查询条件中输入关键字。</code></pre><p><img src="/images/20170722/61.png"></p><p><img src="/images/20170722/62.png"></p><pre><code>                                8.    wt - (writer type)指定输出格式，可以有 xml, json, php, phps,                                     后面 solr 1.3增加的，要用通知我们，因为默认没有打开。                                9.    hl 是否高亮 ,设置高亮Field，设置格式前缀和后缀。</code></pre><p><img src="/images/20170722/63.png"></p><pre><code>                        5.4.3.2.2    代码                                @Test                            public void search02() throws Exception {                                // 创建HttpSolrServer                                HttpSolrServer server = new HttpSolrServer("http://localhost:8080/solr");                                // 创建SolrQuery对象                                SolrQuery query = new SolrQuery();                                // 输入查询条件                                query.setQuery("product_name:小黄人");                                // query.set("q", "product_name:小黄人");                                // 设置过滤条件                                // 如果设置多个过滤条件的话，需要使用query.addFilterQuery(fq)                                query.setFilterQueries("product_price:[1 TO 10]");                                // 设置排序                                query.setSort("product_price", ORDER.asc);                                // 设置分页信息（使用默认的）                                query.setStart(0);                                query.setRows(10);                                // 设置显示的Field的域集合                                query.setFields("id,product_name,product_catalog,product_price,product_picture");                                // 设置默认域                                query.set("df", "product_keywords");                                // 设置高亮信息                                query.setHighlight(true);                                query.addHighlightField("product_name");                                query.setHighlightSimplePre("&lt;em&gt;");                                query.setHighlightSimplePost("&lt;/em&gt;");                                // 执行查询并返回结果                                QueryResponse response = server.query(query);                                // 获取匹配的所有结果                                SolrDocumentList list = response.getResults();                                // 匹配结果总数                                long count = list.getNumFound();                                System.out.println("匹配结果总数:" + count);                                // 获取高亮显示信息                                Map&lt;String, Map&lt;String, List&lt;String&gt;&gt;&gt; highlighting = response                                        .getHighlighting();                                for (SolrDocument doc : list) {                                    System.out.println(doc.get("id"));                                    List&lt;String&gt; list2 = highlighting.get(doc.get("id")).get(                                            "product_name");                                    if (list2 != null)                                        System.out.println("高亮显示的商品名称：" + list2.get(0));                                    else {                                        System.out.println(doc.get("product_name"));                                    }                                    System.out.println(doc.get("product_catalog"));                                    System.out.println(doc.get("product_price"));                                    System.out.println(doc.get("product_picture"));                                    System.out.println("=====================");                                }</code></pre><p>6    京东案例</p><pre><code>6.1    需求    使用Solr实现电商网站中商品信息搜索功能，可以根据关键字、分类、价格搜索商品信息，也可以根据价格进行排序，同时还可以分页。    界面如下：</code></pre><p><img src="/images/20170722/64.png"></p><pre><code>6.2    分析    6.2.1    UI分析</code></pre><p><img src="/images/20170722/65.png"></p><pre><code>    6.2.2    架构分析        应用服务器服务端：            表现层：使用springmvc接收前台搜索页面的查询条件等信息            业务层：调用dao层完成数据库持久化                    如果数据库数据发生变化，调用solrj的客户端同步索引库。            Dao层：使用mybatis完成数据库持久化        Solrj服务器：            提供搜索和索引服务        数据库服务器：            提供数据库服务</code></pre><p><img src="/images/20170722/66.png"></p><pre><code>6.3    工程搭建        Solrj的jar包        Solr的扩展包        Springmvc的包</code></pre><p><img src="/images/20170722/67.png"></p><pre><code>6.4    代码实现    6.4.1    Pojo</code></pre><p><img src="/images/20170722/68.png"></p><p><img src="/images/20170722/69.png"></p><pre><code>    6.4.2    Service Service接口</code></pre><p><img src="/images/20170722/70.png"></p><pre><code>            Service实现类            @Service            public class ProductServiceImpl implements ProductService {                // 依赖注入HttpSolrServer                @Autowired                private HttpSolrServer server;                @Override                public ResultModel getProducts(String queryString, String catalogName,                        String price, String sort, Integer page) throws Exception {                    // 创建SolrQuery对象                    SolrQuery query = new SolrQuery();                    // 输入关键字                    if (StringUtils.isNotEmpty(queryString)) {                        query.setQuery(queryString);                    } else {                        query.setQuery("*:*");                    }                    // 输入商品分类过滤条件                    if (StringUtils.isNotEmpty(catalogName)) {                        query.addFilterQuery("product_catalog_name:" + catalogName);                    }                    // 输入价格区间过滤条件                    // price的值：0-9 10-19                    if (StringUtils.isNotEmpty(price)) {                        String[] ss = price.split("-");                        if (ss.length == 2) {                            query.addFilterQuery("product_price:[" + ss[0] + " TO " + ss[1]                                    + "]");                        }                    }                    // 设置排序                    if ("1".equals(sort)) {                        query.setSort("product_price", ORDER.desc);                    } else {                        query.setSort("product_price", ORDER.asc);                    }                    // 设置分页信息                    if (page == null)                        page = 1;                    query.setStart((page - 1) * 20);                    query.setRows(20);                    // 设置默认域                    query.set("df", "product_keywords");                    // 设置高亮信息                    query.setHighlight(true);                    query.addHighlightField("product_name");                    query.setHighlightSimplePre("&lt;font style=\"color:red\" &gt;");                    query.setHighlightSimplePost("&lt;/font&gt;");                    QueryResponse response = server.query(query);                    // 查询出的结果                    SolrDocumentList results = response.getResults();                    // 记录总数                    long count = results.getNumFound();                    List&lt;Products&gt; products = new ArrayList&lt;&gt;();                    Products prod;                    // 获取高亮信息                    Map&lt;String, Map&lt;String, List&lt;String&gt;&gt;&gt; highlighting = response                            .getHighlighting();                    for (SolrDocument doc : results) {                        prod = new Products();                        // 商品ID                        prod.setPid(doc.get("id").toString());                        List&lt;String&gt; list = highlighting.get(doc.get("id")).get(                                "product_name");                        // 商品名称                        if (list != null)                            prod.setName(list.get(0));                        else {                            prod.setName(doc.get("product_name").toString());                        }                        // 商品价格                        prod.setPrice(Float.parseFloat(doc.get("product_price").toString()));                        // 商品图片地址                        prod.setPicture(doc.get("product_picture").toString());                        products.add(prod);                    }                    // 封装ResultModel对象                    ResultModel rm = new ResultModel();                    rm.setProductList(products);                    rm.setCurPage(page);                    rm.setRecordCount(count);                    int pageCount = (int) (count / 20);                    if (count % 20 &gt; 0)                        pageCount++;                    // 设置总页数                    rm.setPageCount(pageCount);                    return rm;                }            }    6.4.3    Controller        6.4.3.1    代码</code></pre><p><img src="/images/20170722/71.png"></p><pre><code>        6.4.3.2    Jsp和静态资源                从资料中拷贝</code></pre><p><img src="/images/20170722/72.png"></p><p><img src="/images/20170722/73.png"></p><pre><code>                图片信息放到以下目录</code></pre><p><img src="/images/20170722/74.png"></p><p><img src="/images/20170722/75.png"></p><pre><code>        6.4.3.3    Web.xml</code></pre><p><img src="/images/20170722/76.png"></p><pre><code>        6.4.3.4    配置springmvc.xml</code></pre><p><img src="/images/20170722/77.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> solr </category>
          
      </categories>
      
      
        <tags>
            
            <tag> solr </tag>
            
            <tag> spring </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 chown gzip</title>
      <link href="/2017/07/26/mei-tian-2-ge-linux-ming-ling-chown-gzip/"/>
      <url>/2017/07/26/mei-tian-2-ge-linux-ming-ling-chown-gzip/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-26-linux每天2个命令-chown命令"><a href="#2017-07-26-linux每天2个命令-chown命令" class="headerlink" title=" 2017-07-26 linux每天2个命令 chown命令"></a><center> 2017-07-26 linux每天2个命令 chown命令</center></h2><p>chown命令改变某个文件或目录的所有者和所属的组，该命令可以向某个用户授权，使该用户变成指定文件的所有者或者改变文件所属的组。</p><p>(1)用法:</p><pre><code>用法:  chown [选项]... [所有者][:[组]] 文件...   或   chown [选项]... --reference=参考文件 文件...</code></pre><p>(2)功能:</p><pre><code>功能:  更改每个文件的所有者和/或所属组。当使用 --referebce 参数时，将文件的所有者和所属组更改为与指定参考文件相同。用户可以是用户或者是用户D，用户组可以是组名或组id。文件名可以使由空格分开的文件列表，在文件名中可以包含通配符。</code></pre><p>(3)选项参数:</p><pre><code>1) -R --recursive　　　　　　　　　　　　递归处理，将指定目录下的所有文件及子目录一并处理2) -f 　　　　　　　　　　　　　　　　　　忽略错误信息3) -v 　　　　　　　　　　　　　　　　　  显示详细的处理信息4) -c 　　　　　　　　　　　　　　　　　  显示更改的部分的信息5) --reference=&lt;参考文件或目录&gt;　　　　把指定文件或目录的拥有者与所属群组全部设成和参考文件或目录的拥有者与所属群组相同</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost Documents]# chown -v sunjimeng findDir/Dir/{head_text,less1,less2}        改变文件的拥有者(指名多个文件时还可以用空格隔开)复制代码[root@localhost Documents]# ls -l findDir/Dir总用量 12-r-xr-xr-x. 1 root root 664 5月   9 07:59 head_text-r-xr-xr-x. 1 root root  45 5月   9 08:15 less1-r-xr-xr-x. 1 root root  57 5月   9 08:16 less2[root@localhost Documents]# chown -v sunjimeng findDir/Dir/{head_text,less1,less2}    在指明路径时，findDir在当前目录Documents下，所以不能带/。changed ownership of "findDir/Dir/head_text" from root to sunjimengchanged ownership of "findDir/Dir/less1" from root to sunjimengchanged ownership of "findDir/Dir/less2" from root to sunjimeng[root@localhost Documents]# ls -l findDir/Dir总用量 12-r-xr-xr-x. 1 sunjimeng root 664 5月   9 07:59 head_text-r-xr-xr-x. 1 sunjimeng root  45 5月   9 08:15 less1-r-xr-xr-x. 1 sunjimeng root  57 5月   9 08:16 less2</code></pre><hr><pre><code>2)[root@localhost Documents]# chown -vR sunjimeng findDir/Dir　　　　　　　　</code></pre><p>　　递归地将文件夹下的所有文件的所属组改变</p><pre><code>复制代码[root@localhost Documents]# ls -l findDir/Dir总用量 12-r-xr-xr-x. 1 sunjimeng root 664 5月   9 07:59 head_text-r-xr-xr-x. 1 sunjimeng root  45 5月   9 08:15 less1-r-xr-xr-x. 1 sunjimeng root  57 5月   9 08:16 less2[root@localhost Documents]# ls -l findDir总用量 0dr-xr-xr-x. 2 root root 46 5月  21 06:58 Dir            //在实例1中并没有改变文件夹的所有者[root@localhost Documents]# chown -v root findDir/Dir/{head_text,less1,less2}     //先把所有者复原为rootchanged ownership of "findDir/Dir/head_text" from sunjimeng to rootchanged ownership of "findDir/Dir/less1" from sunjimeng to rootchanged ownership of "findDir/Dir/less2" from sunjimeng to root[root@localhost Documents]# chown -vR sunjimeng findDir/Dir                   //再递归地把Dir文件夹和其下的文件所有者更改changed ownership of "findDir/Dir/head_text" from root to sunjimengchanged ownership of "findDir/Dir/less2" from root to sunjimengchanged ownership of "findDir/Dir/less1" from root to sunjimengchanged ownership of "findDir/Dir" from root to sunjimeng[root@localhost Documents]# ls -l findDir　　　　　　　　　　　　　　//在这里查看，文件夹Dir及其下文件的所有者都已经改变为sunjimeng总用量 0dr-xr-xr-x. 2 sunjimeng root 46 5月  21 06:58 Dir[root@localhost Documents]# ls -l findDir/Dir总用量 12-r-xr-xr-x. 1 sunjimeng root 664 5月   9 07:59 head_text-r-xr-xr-x. 1 sunjimeng root  45 5月   9 08:15 less1-r-xr-xr-x. 1 sunjimeng root  57 5月   9 08:16 less2</code></pre><hr><pre><code>3[root@localhost Documents]# chown -vR root:sunjimeng findDir　　　　　　　　　　　　　　改变所有者的同时改变所属组复制代码[root@localhost Documents]# chown -vR root:sunjimeng findDirchanged ownership of "findDir/Dir/head_text" from sunjimeng:root to root:sunjimengchanged ownership of "findDir/Dir/less2" from sunjimeng:root to root:sunjimengchanged ownership of "findDir/Dir/less1" from sunjimeng:root to root:sunjimengchanged ownership of "findDir/Dir" from sunjimeng:root to root:sunjimengchanged ownership of "findDir" from root:root to root:sunjimeng[root@localhost Documents]# ll findDir总用量 0dr-xr-xr-x. 2 root sunjimeng 46 5月  21 06:58 Dir[root@localhost Documents]# ll findDir/Dir总用量 12-r-xr-xr-x. 1 root sunjimeng 664 5月   9 07:59 head_text-r-xr-xr-x. 1 root sunjimeng  45 5月   9 08:15 less1-r-xr-xr-x. 1 root sunjimeng  57 5月   9 08:16 less2复制代码</code></pre><hr><pre><code>4)[root@localhost Dir]# chown -c .root head_text less1　　　　　　　　　　　</code></pre><p>　　　　　　只改变文件的所属组(-c参数与-v类似)</p><pre><code>复制代码[root@localhost Dir]# ll总用量 12-r-xr-xr-x. 1 root sunjimeng 664 5月   9 07:59 head_text-r-xr-xr-x. 1 root sunjimeng  45 5月   9 08:15 less1-r-xr-xr-x. 1 root sunjimeng  57 5月   9 08:16 less2[root@localhost Dir]# chown -c .root head_text less1changed ownership of "head_text" from root:sunjimeng to :rootchanged ownership of "less1" from root:sunjimeng to :root[root@localhost Dir]# chgrp -v root head_text less2"head_text" 的所属组已保留为root                      //因为文件的所属组已经为root了，所以这里显示保留为rootchanged group of "less2" from sunjimeng to root[root@localhost Dir]# ll总用量 12-r-xr-xr-x. 1 root root 664 5月   9 07:59 head_text-r-xr-xr-x. 1 root root  45 5月   9 08:15 less1-r-xr-xr-x. 1 root root  57 5月   9 08:16 less2</code></pre><hr><pre><code>5)[root@localhost Dir]# chown -v :sunjimeng less1  和[root@localhost Dir]# chown -v :sunjimeng less1 和[root@localhost Dir]# chown -v sunjimeng head_text     复制代码[root@localhost Dir]# ll总用量 12-r-xr-xr-x. 1 root root 664 5月   9 07:59 head_text-r-xr-xr-x. 1 root root  45 5月   9 08:15 less1-r-xr-xr-x. 1 root root  57 5月   9 08:16 less2[root@localhost Dir]# chown -v :sunjimeng less1changed ownership of "less1" from root:root to :sunjimeng[root@localhost Dir]# chown -v .sunjimeng less2changed ownership of "less2" from root:root to :sunjimeng[root@localhost Dir]# chown -v sunjimeng head_textchanged ownership of "head_text" from root to sunjimeng[root@localhost Dir]# ll总用量 12-r-xr-xr-x. 1 sunjimeng root      664 5月   9 07:59 head_text-r-xr-xr-x. 1 root      sunjimeng  45 5月   9 08:15 less1-r-xr-xr-x. 1 root      sunjimeng  57 5月   9 08:16 less2</code></pre><hr><p>(5)其他:</p><pre><code>  在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。  以下选项是在指定了 -R 选项时被用于设置如何穿越目录结构体系。 如果您指定了多于一个选项，那么只有最后一个会生效。    -H 如果命令行参数是一个通到目录的符号链接，则遍历符号链接 -L 遍历每一个遇到的通到目录的符号链接    -P 不遍历任何符号链接(默认)    --help 显示此帮助信息并退出    --version 显示版本信息并退出 如果没有指定所有者，则不会更改。所属组若没有指定也不会更改，但当加上 ":"时 GROUP 会更改为指定所有者的主要组。所有者和所属组可以是数字或名称。</code></pre><h2 id="2017-07-26-linux每天2个命令-gzip命令"><a href="#2017-07-26-linux每天2个命令-gzip命令" class="headerlink" title=" 2017-07-26 linux每天2个命令 gzip命令"></a><center> 2017-07-26 linux每天2个命令 gzip命令</center></h2><p>zip命令用来压缩文件。gzip是个使用广泛的压缩程序，文件经它压缩过后，其名称后面会多处“.gz”扩展名。</p><p>(1)用法:</p><pre><code>用法:  gzip [选项参数][-s &lt;压缩字尾字符串&gt;]   [文件...]     或 gzip [选项参数][-s &lt;压缩字尾字符串&gt;]   [目录]</code></pre><p>(2)功能:</p><pre><code>功能:  gzip是个使用广泛的解压缩程序，它用于解开被gzip压缩过的文件，这些压缩文件预设最后的扩展名为".gz"。         事实上gzip就是gzip的硬连接，因此不论是压缩或解压缩，都可通过gzip指令单独完成。</code></pre><p>(3)选项参数:</p><pre><code>  1) -d --decompress --uncompress　　　　　　　　　　　　　　　　　 解开压缩文件；  2) -v --verbose　　　　　　　　　　　　　　　　　　　　　　　　　　  显示指令执行过程；  3) -l  --list 　　　　　　　　　　　　　　　　　　　　　　　　　　　　  列出压缩文件的相关信息；  4) -r --recursive　　　　　　　　　　　　　　　　　　　　　　　　　　递归处理，将指定目录下的所有文件及子目录一并处理；  5) -A --catenate：　　　　　　　　　　　　　　　　　　　　　　　　　新增文件到已存在的备份文件；   6) -B　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　    设置区块大小  7) -c 　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 把解压后的文件输出到标准输出设备</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost Dir]# gzip *　　　　　　压缩当前目录下的所有文件，文件后缀名加上.gz（gzip调用时自动执行压缩或解压缩命令）[root@localhost Dir]# gzip *[root@localhost Dir]# ll总用量 12-r-xr-xr-x. 1 sunjimeng root      411 5月   9 07:59 head_text.gz-r-xr-xr-x. 1 root      sunjimeng  67 5月   9 08:15 less1.gz-r-xr-xr-x. 1 root      sunjimeng  80 5月   9 08:16 less2.gz</code></pre><hr><pre><code>2)[root@localhost Dir]# gzip -d *    　　　 解压当前目录的所有文件复制代码[root@localhost Dir]# gzip *　　　　　　　　　　　　　　　　//解压并不能像压缩时那样什么参数都不带，需要带解压命令-dgzip: head_text.gz already has .gz suffix -- unchangedgzip: less1.gz already has .gz suffix -- unchangedgzip: less2.gz already has .gz suffix -- unchanged[root@localhost Dir]# gzip -d *[root@localhost Dir]# ll总用量 12-r-xr-xr-x. 1 sunjimeng root      664 5月   9 07:59 head_text-r-xr-xr-x. 1 root      sunjimeng  45 5月   9 08:15 less1-r-xr-xr-x. 1 root      sunjimeng  57 5月   9 08:16 less2</code></pre><hr><pre><code>3)[root@localhost Dir]# gzip -v *　　　　　　显示命令执行时的具体的步骤复制代码[root@localhost Dir]# gzip -v *head_text:     42.3% -- replaced with head_text.gzless1:      4.4% -- replaced with less1.gzless2:      1.8% -- replaced with less2.gz[root@localhost Dir]# gzip -dv *head_text.gz:     42.3% -- replaced with head_textless1.gz:      4.4% -- replaced with less1less2.gz:      1.8% -- replaced with less2</code></pre><hr><pre><code>4)[root@localhost Dir]# gzip -l *复制代码[root@localhost Dir]# gzip -l *         compressed        uncompressed  ratio uncompressed_name                411                 664  42.3% head_text                 67                  45   4.4% less1                 80                  57   1.8% less2                558                 766  30.3% (totals)[root@localhost Dir]# ll总用量 12-r-xr-xr-x. 1 sunjimeng root      411 5月   9 07:59 head_text.gz-r-xr-xr-x. 1 root      sunjimeng  67 5月   9 08:15 less1.gz-r-xr-xr-x. 1 root      sunjimeng  80 5月   9 08:16 less2.gz</code></pre><hr><pre><code>5)[root@localhost findDir]# tar -cvf Dir.tar Dir　　　　　　　　先用tar命令打包复制代码[root@localhost findDir]# tar -cvf Dir.tar DirDir/Dir/head_text.gzDir/less1.gzDir/less2.gz[root@localhost findDir]# ll总用量 12dr-xr-xr-x. 2 root sunjimeng    55 5月  24 07:28 Dir-rw-r--r--. 1 root root      10240 5月  24 07:34 Dir.tar[root@localhost findDir]# gzip -v Dir.tarDir.tar:     92.1% -- replaced with Dir.tar.gz[root@localhost findDir]# gzip -l Dir.tar.gz         compressed        uncompressed  ratio uncompressed_name                833               10240  92.1% Dir.tar</code></pre><hr><pre><code>5)[root@localhost findDir]# tar cvf Dir1.tar -R Dir　　　　　　打包的几种方法复制代码[root@localhost findDir]# tar cvf Dir1.tar -R Dir块 0：Dir/块 1：Dir/head_text.gz块 3：Dir/less1.gz块 5：Dir/less2.gz[root@localhost findDir]# tar -cvf Dir2.tar DirDir/Dir/head_text.gzDir/less1.gzDir/less2.gz[root@localhost findDir]# tar -cvf Dir3.tar -R Dir块 0：Dir/块 1：Dir/head_text.gz块 3：Dir/less1.gz块 5：Dir/less2.gz</code></pre><hr><pre><code>6)[root@localhost Documents]# gzip -vr findDir　　　　　　递归的压缩子文件夹下的文件复制代码[root@localhost Documents]# gzip -vr findDirgzip: findDir/Dir/head_text.gz already has .gz suffix -- unchangedgzip: findDir/Dir/less1.gz already has .gz suffix -- unchangedgzip: findDir/Dir/less2.gz already has .gz suffix -- unchangedgzip: findDir/Dir.tar.gz already has .gz suffix -- unchangedfindDir/Dir1.tar:     92.1% -- replaced with findDir/Dir1.tar.gzfindDir/Dir2.tar:     92.1% -- replaced with findDir/Dir2.tar.gzfindDir/Dir3.tar:     92.1% -- replaced with findDir/Dir3.tar.gz[root@localhost Documents]# ls -l findDir总用量 16-rw-r--r--. 1 root root      833 5月  24 07:34 Dir.tar.gz-rw-r--r--. 1 root root      834 5月  24 07:43 Dir3.tar.gz-rw-r--r--. 1 root root      834 5月  24 07:39 Dir2.tar.gz-rw-r--r--. 1 root root      834 5月  24 07:39 Dir1.tar.gzdr-xr-xr-x. 2 root sunjimeng  55 5月  24 07:28 Dir[root@localhost Documents]# ls -l findDir/Dir总用量 12-r-xr-xr-x. 1 root      sunjimeng  80 5月   9 08:16 less2.gz-r-xr-xr-x. 1 root      sunjimeng  67 5月   9 08:15 less1.gz-r-xr-xr-x. 1 sunjimeng root      411 5月   9 07:59 head_text.gz</code></pre><hr><pre><code>7)[root@localhost findDir]# gzip -rdv Dir　　　　　　　　递归的解压目录下的所有.gz的文件复制代码[root@localhost findDir]# ls -l Dir总用量 12-r-xr-xr-x. 1 sunjimeng root      411 5月   9 07:59 head_text.gz-r-xr-xr-x. 1 root      sunjimeng  67 5月   9 08:15 less1.gz-r-xr-xr-x. 1 root      sunjimeng  80 5月   9 08:16 less2.gz[root@localhost findDir]# gzip -rdv DirDir/head_text.gz:     42.3% -- replaced with Dir/head_textDir/less1.gz:      4.4% -- replaced with Dir/less1Dir/less2.gz:      1.8% -- replaced with Dir/less2[root@localhost findDir]# ls -l Dir总用量 12-r-xr-xr-x. 1 sunjimeng root      664 5月   9 07:59 head_text-r-xr-xr-x. 1 root      sunjimeng  45 5月   9 08:15 less1-r-xr-xr-x. 1 root      sunjimeng  57 5月   9 08:16 less2[root@localhost findDir]# gzip -r Dir[root@localhost findDir]# ls -l Dir总用量 12-r-xr-xr-x. 1 sunjimeng root      411 5月   9 07:59 head_text.gz-r-xr-xr-x. 1 root      sunjimeng  67 5月   9 08:15 less1.gz-r-xr-xr-x. 1 root      sunjimeng  80 5月   9 08:16 less2.gz[root@localhost findDir]# gzip -dv Dirgzip: Dir is a directory -- ignored</code></pre><hr><pre><code>8)[root@localhost Dir]# gzip --help　　　　　　　　　　　复制代码[root@localhost Dir]# gzip --helpUsage: gzip [OPTION]... [FILE]...Compress or uncompress FILEs (by default, compress FILES in-place).Mandatory arguments to long options are mandatory for short options too.  -c, --stdout      write on standard output, keep original files unchanged  -d, --decompress  decompress  -f, --force       force overwrite of output file and compress links  -h, --help        give this help  -l, --list        list compressed file contents  -L, --license     display software license  -n, --no-name     do not save or restore the original name and time stamp  -N, --name        save or restore the original name and time stamp  -q, --quiet       suppress all warnings  -r, --recursive   operate recursively on directories  -S, --suffix=SUF  use suffix SUF on compressed files  -t, --test        test compressed file integrity  -v, --verbose     verbose mode  -V, --version     display version number  -1, --fast        compress faster  -9, --best        compress better    --rsyncable   Make rsync-friendly archiveWith no FILE, or when FILE is -, read standard input.Report bugs to &lt;bug-gzip@gnu.org&gt;.</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 tar chgrp</title>
      <link href="/2017/07/26/mei-tian-2-ge-linux-ming-ling-tar-chgrp/"/>
      <url>/2017/07/26/mei-tian-2-ge-linux-ming-ling-tar-chgrp/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-25-linux每天2个命令-tar命令"><a href="#2017-07-25-linux每天2个命令-tar命令" class="headerlink" title=" 2017-07-25 linux每天2个命令 tar命令"></a><center> 2017-07-25 linux每天2个命令 tar命令</center></h2><p>tar命令可以为linux的文件和目录创建档案。</p><p>(1)用法:</p><pre><code>用法:  tar  [选项]   [文件参数]</code></pre><p>(2)功能:</p><pre><code>功能:  用来压缩和解压文件。tar本身不具有压缩功能。它是调用压缩功能实现的。利用tar命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。</code></pre><p>(3)选项参数:</p><pre><code>  1) -c   --create　　　　　　　　　　　　 建立新的备份文件  2) -z 　　　　　　　　　　　　　　  　　 支持gzip解压文件  3) -j 　　　　　　　　　　　　　　  　　 支持bzip2解压文件  4) -v  --verbose　　　　　　　　　 　　 显示指令执行过程  5) -f&lt;备份文件&gt; --file=&lt;备份文件&gt; 　　 指定备份文件  6) -t或--list　　　　　　　　　　　  　　 列出备份文件的内容  7) -N&lt;日期格式&gt;--newer=&lt;日期时间&gt;   只将较指定日期更新的文件保存到备份文件里  8) -x或--extract或--get　　　　　　      从备份文件中还原文件  9) -C &lt;目录&gt;　　　　　　　　　　　　   这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项  10) -P  --absolute-names   　　　　　    文件名使用绝对名称，不移除文件名称前的“/”号</code></pre><p> (4)实例:</p><pre><code>  1)[root@localhost Documents]# tar -cvf Dir.tar Dir　　　　　　　　　　　f选项参数是必不可少的，这里以普通压缩格式压缩文件夹　　　复制代码[root@localhost Documents]# tar -cvf Dir.tar DirDir/Dir/head_textDir/less1Dir/less2[root@localhost Documents]# ll总用量 28-rwx--xrwx. 1 root root    27 5月  19 04:21 core.logdr-xr-xr-x. 2 root root    46 5月  19 23:29 Dir-rw-r--r--. 1 root root 10240 5月  21 06:22 Dir.tar-r--r--r--. 1 root root     0 5月  19 04:16 finddr--r--r--. 2 root root    84 5月  19 04:57 findDir-r--r--r--. 1 root root     0 5月  15 18:21 newlocate-rw-r--r--. 1 root root    85 5月  19 04:25 t3.txt--w-------. 1 root root   259 5月  12 21:53 tail_text--w-------. 1 root root   216 5月  12 22:24 tempory--w-------. 1 root root     0 5月  15 18:34 uText</code></pre><hr><pre><code>2)[root@localhost Documents]# tar -czvf Dir.tar.gz Dir　　　</code></pre><p>　　以其他格式压缩有Gzip和bzip2两种格式</p><pre><code>复制代码[root@localhost Documents]# tar -czvf Dir.tar.gz DirDir/Dir/head_textDir/less1Dir/less2[root@localhost Documents]# tar -cjvf Dir.tar.bz2 DirDir/Dir/head_textDir/less1Dir/less2[root@localhost Documents]# ll总用量 40-rwx--xrwx. 1 root root    27 5月  19 04:21 core.logdr-xr-xr-x. 2 root root    46 5月  19 23:29 Dir-rw-r--r--. 1 root root 10240 5月  21 06:22 Dir.tar-rw-r--r--. 1 root root   646 5月  21 06:35 Dir.tar.bz2                 //公认的后缀名，以bzip2压缩-rw-r--r--. 1 root root   656 5月  21 06:30 Dir.tar.gz                  //公认的后缀名，以Gzip压缩-r--r--r--. 1 root root     0 5月  19 04:16 finddr--r--r--. 2 root root    84 5月  19 04:57 findDir-r--r--r--. 1 root root     0 5月  15 18:21 newlocate-rw-r--r--. 1 root root    85 5月  19 04:25 t3.txt--w-------. 1 root root   259 5月  12 21:53 tail_text--w-------. 1 root root   216 5月  12 22:24 tempory--w-------. 1 root root     0 5月  15 18:34 uText-rw-r--r--. 1 root root   105 5月  21 06:35 vf</code></pre><hr><pre><code>3)[root@localhost Documents]# tar -ztvf Dir.tar.gz　　　　　　　　　　查阅上述tar包内有哪些文件，按什么格式压缩就要按照什么格式解压    复制代码[root@localhost Documents]# tar -ztvf Dir.tar.gzdr-xr-xr-x root/root         0 2016-05-19 23:29 Dir/-r-xr-xr-x root/root       664 2016-05-09 07:59 Dir/head_text-r-xr-xr-x root/root        45 2016-05-09 08:15 Dir/less1-r-xr-xr-x root/root        57 2016-05-09 08:16 Dir/less2[root@localhost Documents]# tar -jtvf Dir.tar.bz2dr-xr-xr-x root/root         0 2016-05-19 23:29 Dir/-r-xr-xr-x root/root       664 2016-05-09 07:59 Dir/head_text-r-xr-xr-x root/root        45 2016-05-09 08:15 Dir/less1-r-xr-xr-x root/root        57 2016-05-09 08:16 Dir/less2</code></pre><hr><pre><code>4)[root@localhost findDir]# tar -zxvf Dir.tar.gz Dir　　　　　　　　　　解压tar.gz压缩包，到指定名的文件夹，必须是Dir，不能变复制代码[root@localhost findDir]# tar -zxvf Dir.tar.gz DirDir/Dir/head_textDir/less1Dir/less2[root@localhost findDir]# ll总用量 20dr-xr-xr-x. 2 root root    46 5月  19 23:29 Dir-rw-r--r--. 1 root root 10240 5月  21 06:22 Dir.tar-rw-r--r--. 1 root root   646 5月  21 06:35 Dir.tar.bz2-rw-r--r--. 1 root root   656 5月  21 06:30 Dir.tar.gz-r--r--r--. 1 root root     0 5月  17 04:18 p1.pdf-r--r--r--. 1 root root     0 5月  17 04:18 p2.pdf-r--r--r--. 1 root root     0 5月  17 03:50 t1.txt-r--r--r--. 1 root root     0 5月  17 04:02 T1.txt-r--r--r--. 1 root root     0 5月  19 04:58 t2.txt-r--r--r--. 1 root root     0 5月  17 04:02 T2.txt</code></pre><hr><pre><code>5)[root@localhost findDir]# tar -jxvf Dir.tar.bz2 Dir/less1　　　　只将tar内的部分文件解压出来，要进行匹配，如果不匹配会报错“归档找不到”　　　[root@localhost findDir]# tar -jxvf Dir.tar.bz2 Dir/less1Dir/less1</code></pre><hr><pre><code>6)[root@localhost Documents]# tar -pzcvf P.tar.gz find t3.txt vf uText　　　　　文件备份下来，并且保存其权限[root@localhost Documents]# tar -pzcvf P.tar.gz find t3.txt vf uTextfindt3.txtvfuText</code></pre><hr><pre><code>7)[root@localhost Documents]# tar -pzxvf P.tar.gz -C Pdir　　　　　　　　　指定解压的目录复制代码[root@localhost Documents]# tar -zcvf P1.tar.gz find t3.txt vf uText               //没有p参数的打包并压缩findt3.txtvfuText[root@localhost Documents]# ll总用量 32-rwx--xrwx. 1 root root   27 5月  19 04:21 core.logdr-xr-xr-x. 2 root root   46 5月  19 23:29 Dir-r--r--r--. 1 root root    0 5月  19 04:16 finddr--r--r--. 3 root root 4096 5月  21 06:52 findDir-r--r--r--. 1 root root    0 5月  15 18:21 newlocate-rw-r--r--. 1 root root  317 5月  21 07:06 P1.tar.gz                    //没有p参数-rw-r--r--. 1 root root  317 5月  21 07:05 P.tar.gz                     //有p参数-rw-r--r--. 1 root root   85 5月  19 04:25 t3.txt--w-------. 1 root root  259 5月  12 21:53 tail_text--w-------. 1 root root  216 5月  12 22:24 tempory--w-------. 1 root root    0 5月  15 18:34 uText-rw-r--r--. 1 root root  105 5月  21 06:35 vf[root@localhost Documents]# mkdir Pdir[root@localhost Documents]# tar -zxvf P.tar.gz -C Pdir                  //指定解压缩的路径findt3.txtvfuText[root@localhost Documents]# mkdir NoPdir[root@localhost Documents]# tar -zxvf P1.tar.gz -C NoPdirfindt3.txtvfuText[root@localhost Documents]# ls -l Pdir                         //查看有p无p的区别总用量 8-r--r--r--. 1 root root   0 5月  19 04:16 find-rw-r--r--. 1 root root  85 5月  19 04:25 t3.txt--w-------. 1 root root   0 5月  15 18:34 uText-rw-r--r--. 1 root root 105 5月  21 06:35 vf[root@localhost Documents]# ls -l NoPdir总用量 8-r--r--r--. 1 root root   0 5月  19 04:16 find-rw-r--r--. 1 root root  85 5月  19 04:25 t3.txt--w-------. 1 root root   0 5月  15 18:34 uText-rw-r--r--. 1 root root 105 5月  21 06:35 vf　　　　　　　　　　//并没有发现有什么区别</code></pre><hr><pre><code>8)[root@localhost Documents]# tar -N "2016/05/20" -zcvf 520.tar.gz ./*　　　　　　在文件夹当中，比某个日期新的文件才备份复制代码[root@localhost Documents]# tar -N "2016/05/20" -zcvf 520.tar.gz ./*tar: 选项 --after-date: 将日期 ‘2016/05/20’ 当作 2016-05-20 00:00:00./520.tar.gztar: ./520.tar.gz：文件缩小 45 字节；用零填充./core.log./Dir/./Dir/head_text./Dir/less1./Dir/less2./find./findDir/./findDir/t1.txt./findDir/T1.txt./findDir/T2.txt./findDir/p1.pdf./findDir/p2.pdf./findDir/t2.txt./findDir/Dir.tar./findDir/Dir.tar.gz./findDir/Dir.tar.bz2./findDir/Dir/./findDir/Dir/head_text./findDir/Dir/less2./findDir/Dir/less1./log17.tar.gz./newlocate./NoPdir/./NoPdir/find./NoPdir/t3.txt./NoPdir/vf./NoPdir/uText./P1.tar.gz./Pdir/./Pdir/find./Pdir/t3.txt./Pdir/vf./Pdir/uText./P.tar.gztar: ./t3.txt: 文件未改变；未输出tar: ./tail_text: 文件未改变；未输出tar: ./tempory: 文件未改变；未输出tar: ./uText: 文件未改变；未输出./vf</code></pre><hr><pre><code>9)[root@localhost Documents]# tar --exclude Dir/less1 -zcvf Dir.test2.tar.gz Dir　　　　　　打包时不包括特定目录下的文件复制代码[root@localhost Documents]# tar --exclude ./Dir/less1 -zcvf Dir.test.tar.gz Dir       //这里目录加个./，经后续验证，没有达到不包括的效果Dir/Dir/head_textDir/less1Dir/less2[root@localhost Documents]# tar -ztvf Dir.test.tar.gzdr-xr-xr-x root/root         0 2016-05-19 23:29 Dir/-r-xr-xr-x root/root       664 2016-05-09 07:59 Dir/head_text-r-xr-xr-x root/root        45 2016-05-09 08:15 Dir/less1-r-xr-xr-x root/root        57 2016-05-09 08:16 Dir/less2[root@localhost Documents]# tar --exclude Dir/less1 -zcvf Dir.test2.tar.gz DirDir/Dir/head_textDir/less2[root@localhost Documents]# tar -ztvf Dir.test2.tar.gzdr-xr-xr-x root/root         0 2016-05-19 23:29 Dir/-r-xr-xr-x root/root       664 2016-05-09 07:59 Dir/head_text-r-xr-xr-x root/root        57 2016-05-09 08:16 Dir/less2复制代码</code></pre><hr><pre><code>(5)其他:  利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。 </code></pre><h2 id="2017-07-25-linux每天2个命令-chgrp命令"><a href="#2017-07-25-linux每天2个命令-chgrp命令" class="headerlink" title=" 2017-07-25 linux每天2个命令 chgrp命令"></a><center> 2017-07-25 linux每天2个命令 chgrp命令</center></h2><p>chgrp命令用来改变文件或目录所属的用户组。</p><p>(1)用法:</p><pre><code>用法:  chgrp  [选项参数] [组] [文件]     或 chgrp  [选项]   组文件...   POSIX 选项: [-R] [--]</code></pre><p>(2)功能:</p><pre><code>功能:  改变文件的组所有权</code></pre><p>(3)选项参数:</p><pre><code>1) -c  --changes　　　　　　　　　　 　　效果类似“-v”参数，但仅回报更改的部分2) -f  --quiet  --silent　　　　　　　 　　 不显示错误信息3) -h  --no-dereference　　　　　　　　  只对符号连接的文件作修改，而不是该其他任何相关文件4) -R  --recursive　　　　　　　　　　　  递归处理，将指令目录下的所有文件及子目录一并处理5) -v  --verbose　　　　　　　　　　　　 显示指令执行过程6) --reference=&lt;参考文件或目录&gt;           把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# chgrp -v root Document　　　　　　　　　　将Document所在组改为root复制代码[root@localhost sunjimeng]# ll总用量 0drwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Desktopdrwxrwxr-x. 3 sunjimeng sunjimeng 100 5月  19 22:28 Documentdrwxr-xr-x. 5 root      root       44 5月  21 21:52 Documentsdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Downloadsdrwxrwxr-x. 2 sunjimeng sunjimeng   6 5月  17 04:55 findTextDirdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Musicdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Picturesdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Publicdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Templatesdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Videos[root@localhost sunjimeng]# chgrp -v root Documentchanged group of "Document" from sunjimeng to root[root@localhost sunjimeng]# ll总用量 0drwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Desktopdrwxrwxr-x. 3 sunjimeng root      100 5月  19 22:28 Documentdrwxr-xr-x. 5 root      root       44 5月  21 21:52 Documentsdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Downloadsdrwxrwxr-x. 2 sunjimeng sunjimeng   6 5月  17 04:55 findTextDirdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Musicdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Picturesdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Publicdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Templatesdrwxr-xr-x. 2 sunjimeng sunjimeng   6 5月   1 01:23 Videos</code></pre><hr><pre><code>2)[root@localhost Document]# chgrp -v --reference=newDir all.txt　　　　　　　</code></pre><p>　　　　　将文件所属组设置为同某一个文件或文件夹一样</p><pre><code>复制代码[root@localhost Document]# ll总用量 12-rw-r--r--. 1 root      root      85 5月  18 02:58 all.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 B.text3-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 C.text6-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:28 D.textdrwxr-xr-x. 2 root      root      51 5月  18 02:47 newDir-rw-r--r--. 1 root      root      42 5月  18 02:53 t1.txt-rw-r--r--. 1 root      root      43 5月  18 02:54 t2.txt[root@localhost Document]# chgrp -v  --reference=newDir all.txt"all.txt" 的所属组已保留为root[root@localhost Document]# ll总用量 12-rw-r--r--. 1 root      root      85 5月  18 02:58 all.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 B.text3-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 C.text6-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:28 D.textdrwxr-xr-x. 2 root      root      51 5月  18 02:47 newDir-rw-r--r--. 1 root      root      42 5月  18 02:53 t1.txt-rw-r--r--. 1 root      root      43 5月  18 02:54 t2.txt</code></pre><hr><pre><code>3)[root@localhost sunjimeng]# chgrp -vR sunjimeng Document                　　　　　　改变指定目录以及其子目录下的所有文件的群组属性       复制代码[root@localhost sunjimeng]# chgrp -vR sunjimeng Documentchanged group of "Document/newDir/mvt1.txt" from root to sunjimengchanged group of "Document/newDir/mvt2.txt" from root to sunjimengchanged group of "Document/newDir/mvt3.txt" from root to sunjimengchanged group of "Document/newDir" from root to sunjimengchanged group of "Document/t1.txt" from root to sunjimengchanged group of "Document/t2.txt" from root to sunjimengchanged group of "Document/all.txt" from root to sunjimeng"Document/B.text3" 的所属组已保留为sunjimeng"Document/C.text6" 的所属组已保留为sunjimeng"Document/D.text" 的所属组已保留为sunjimengchanged group of "Document" from root to sunjimeng[root@localhost sunjimeng]# ls -l Document总用量 12-rw-r--r--. 1 root      sunjimeng 85 5月  18 02:58 all.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 B.text3-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 C.text6-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:28 D.textdrwxr-xr-x. 2 root      sunjimeng 51 5月  18 02:47 newDir-rw-r--r--. 1 root      sunjimeng 42 5月  18 02:53 t1.txt-rw-r--r--. 1 root      sunjimeng 43 5月  18 02:54 t2.txt</code></pre><hr><pre><code>4)[root@localhost sunjimeng]# chgrp -vR 100 Document　　　　　　　　　　　通过群组识别码改变文件群组属性，100为users群组的识别码，具体群组和群组识别码可以去/etc/group文件中查看复制代码[root@localhost sunjimeng]# chgrp -vR 100 Documentchanged group of "Document/newDir/mvt1.txt" from sunjimeng to 100changed group of "Document/newDir/mvt2.txt" from sunjimeng to 100changed group of "Document/newDir/mvt3.txt" from sunjimeng to 100changed group of "Document/newDir" from sunjimeng to 100changed group of "Document/t1.txt" from sunjimeng to 100changed group of "Document/t2.txt" from sunjimeng to 100changed group of "Document/all.txt" from sunjimeng to 100changed group of "Document/B.text3" from sunjimeng to 100changed group of "Document/C.text6" from sunjimeng to 100changed group of "Document/D.text" from sunjimeng to 100changed group of "Document" from sunjimeng to 100[root@localhost sunjimeng]# ls -l Document总用量 12-rw-r--r--. 1 root      users 85 5月  18 02:58 all.txt-rw-rw-r--. 1 sunjimeng users  0 5月  19 22:27 B.text3-rw-rw-r--. 1 sunjimeng users  0 5月  19 22:27 C.text6-rw-rw-r--. 1 sunjimeng users  0 5月  19 22:28 D.textdrwxr-xr-x. 2 root      users 51 5月  18 02:47 newDir-rw-r--r--. 1 root      users 42 5月  18 02:53 t1.txt-rw-r--r--. 1 root      users 43 5月  18 02:54 t2.txt复制代码</code></pre><hr><pre><code>群组识别码:复制代码[root@localhost sunjimeng]# cat /etc/grouproot:x:0:bin:x:1:daemon:x:2:sys:x:3:adm:x:4:tty:x:5:disk:x:6:lp:x:7:mem:x:8:kmem:x:9:wheel:x:10:cdrom:x:11:mail:x:12:postfixman:x:15:dialout:x:18:floppy:x:19:games:x:20:tape:x:30:video:x:39:ftp:x:50:lock:x:54:audio:x:63:nobody:x:99:users:x:100:utmp:x:22:utempter:x:35:systemd-journal:x:190:dbus:x:81:polkitd:x:999:cgred:x:998:tss:x:59:colord:x:997:usbmuxd:x:113:dip:x:40:ntp:x:38:ssh_keys:x:996:libstoragemgmt:x:995:saslauth:x:76:rpc:x:32:rtkit:x:172:chrony:x:994:radvd:x:75:rpcuser:x:29:nfsnobody:x:65534:kvm:x:36:qemuqemu:x:107:abrt:x:173:sssd:x:993:avahi-autoipd:x:170:unbound:x:992:pulse-access:x:991:pulse:x:171:gdm:x:42:gnome-initial-setup:x:990:postdrop:x:90:postfix:x:89:sshd:x:74:slocate:x:21:avahi:x:70:stapusr:x:156:stapsys:x:157:stapdev:x:158:tcpdump:x:72:sunjimeng:x:1000:</code></pre><hr><pre><code>5)[sunjimeng@localhost Document]$ chgrp -vf sunjimeng findDir　　　　　　-v是不显示错误信息，v命令显示执行的步骤　　　　复制代码[root@localhost Documents]# ll总用量 0dr--r--r--. 3 root root 16 5月  21 21:52 findDirdrwxr-xr-x. 2 root root 51 5月  21 07:10 NoPdirdrwxr-xr-x. 2 root root 51 5月  21 07:09 Pdir[root@localhost Documents]# exitexit[sunjimeng@localhost ~]$ cd Document[sunjimeng@localhost Document]$ chgrp -v sunjimeng findDirchgrp: 无法访问"findDir": 没有那个文件或目录无法更改"findDir" 的所属组为sunjimeng[sunjimeng@localhost Document]$ chgrp -vf sunjimeng findDir无法更改"findDir" 的所属组为sunjimeng</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lucene学习</title>
      <link href="/2017/07/25/lucene-xue-xi/"/>
      <url>/2017/07/25/lucene-xue-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-21-Lucene"><a href="#2017-07-21-Lucene" class="headerlink" title=" 2017-07-21 Lucene"></a><center> 2017-07-21 Lucene</center></h2><p>1    课程计划</p><pre><code>1、    Lucene介绍    a)    什么是lucene    b)    全文检索的应用场景    c)    全文检索定义2、    Luence实现全文检索的流程（重点）3、    入门程序4、    Field域（重点）5、    索引维护    a)    添加索引    b)    删除索引    c)    修改索引6、    搜索（重点）    a)    通过Query子类创建查询对象    b)    通过QueryParser创建查询对象7、    相关度排序8、    中文分词器（重点）</code></pre><hr><p>2    Lucene介绍</p><pre><code>2.1    什么是luceneLucene是Apache的一个全文检索引擎工具包，通过lucene可以让程序员快速开发一个全文检索功能。引擎：核心组件工具包：jar包、类库2.2    全文检索的应用场景    2.2.1    搜索引擎</code></pre><p><img src="/images/20170721/1.png"></p><pre><code>    2.2.2    站内搜索（关注）</code></pre><p><img src="/images/20170721/2.png"></p><pre><code>    2.2.3    文件系统的搜索</code></pre><p><img src="/images/20170721/3.png"></p><pre><code>    2.2.4    总结        Lucene和搜索引擎不是一回事        Lucene是一个工具包，它不能独立运行，不能单独对外提供服务。        搜索引擎可以独立运行对外提供搜索服务。2.3    全文检索的定义全文检索首先对要搜索的文档进行分词，然后形成索引，通过查询索引来查询文档。全文检索就是先创建索引，然后根据索引来进行搜索的过程，就叫全文检索。比如：字典，字典的偏旁部首页，就类似于luence的索引        字典的具体内容，就类似于luence的文档内容</code></pre><hr><p>3    Lucene实现全文检索的流程</p><p><img src="/images/20170721/4.png"></p><pre><code>全文检索的流程：索引流程、搜索流程索引流程：采集数据—》文档处理存储到索引库中搜索流程：输入查询条件—》通过lucene的查询器查询索引—》从索引库中取出结—》视图渲染Lucene本身不能进行视图渲染。</code></pre><hr><p>4    入门程序</p><pre><code>4.1    需求    使用lucene完成对数据库中图书信息的索引和搜索功能4.2    环境准备        Jdk：1.7及以上        Lucene：4.10（从4.8版本以后，必须使用jdk1.7及以上）        Ide：indigo        数据库：mysql 5    4.2.1    数据库脚本初始化</code></pre><p><img src="/images/20170721/5.png"></p><pre><code>    4.2.2    Lucene下载        Lucene是开发全文检索功能的工具包，使用时从官方网站下载，并解压。        官方网站：http://lucene.apache.org/         目前最新版本：5.4.0        下载地址：http://archive.apache.org/dist/lucene/java/        下载版本：4.10.3        JDK要求：1.7以上（从版本4.8开始，不支持1.7以下）</code></pre><p><img src="/images/20170721/6.png"></p><p><img src="/images/20170721/7.png"></p><p><img src="/images/20170721/8.png"></p><p><img src="/images/20170721/9.png"></p><pre><code>4.3    工程搭建        Mysql驱动包        Analysis的包        Core包        QueryParser包        Junit包（非必须）</code></pre><p><img src="/images/20170721/10.png"></p><pre><code>4.4    索引流程    4.4.1    为什么采集数据            全文检索搜索的内容的格式是多种多样的，比如：视频、mp3、图片、文档等等。            对于这种格式不同的数据，需要先将他们采集到本地，然后统一封装到lucene的文档对象中，            也就是说需要将存储的内容进行统一才能对它进行查询。    4.4.2    采集数据的方式            对于互联网中的数据，使用爬虫工具（http工具）将网页爬取到本地            对于数据库中的数据，使用jdbc程序进行数据采集            对于文件系统的数据，使用io流采集        因为目前搜索引擎主要搜索数据的来源是互联网，搜索引擎使用一种爬虫程序抓取网页（ 通过http抓取html网页信息），以下是一些爬虫项目：        Solr（http://lucene.apache.org/solr） ，solr是apache的一个子项目，支持从关系数据库、xml文档中提取原始数据。        Nutch（http://lucene.apache.org/nutch）, Nutch是apache的一个子项目，包括大规模爬虫工具，能够抓取和分辨web网站数据。        jsoup（http://jsoup.org/ ），jsoup 是一款Java 的HTML解析器，        可直接解析某个URL地址、HTML文本内容。它提供了一套非常省力的API，        可通过DOM，CSS以及类似于jQuery的操作方法来取出和操作数据。        heritrix（http://sourceforge.net/projects/archive-crawler/files/），        Heritrix 是一个由 java 开发的、开源的网络爬虫，用户可以使用它来从网上抓取想要的资源。        其最出色之处在于它良好的可扩展性，方便用户实现自己的抓取逻辑。    4.4.3    索引文件的逻辑结构</code></pre><p><img src="/images/20170721/11.png"></p><pre><code>        文档域    文档域存储的信息就是采集到的信息，通过Document对象来存储，具体说是通过Document对象中field域来存储数据。    比如：数据库中一条记录会存储一个一个Document对象，数据库中一列会存储成Document中一个field域。    文档域中，Document对象之间是没有关系的。而且每个Document中的field域也不一定一样。        索引域    索引域主要是为了搜索使用的。索引域内容是经过lucene分词之后存储的。        倒排索引表    传统方法是先找到文件，如何在文件中找内容，在文件内容中匹配搜索关键字，这种方法是顺序扫描方法，数据量大就搜索慢。        倒排索引结构是根据内容（词语）找文档，倒排索引结构也叫反向索引结构，包括索引和文档两部分，索引即词汇表，    它是在索引中匹配搜索关键字，由于索引内容量有限并且采用固定优化算法搜索速度很快，找到了索引中的词汇，    词汇与文档关联，从而最终找到了文档。</code></pre><p><img src="/images/20170721/12.png"></p><pre><code>    4.4.4    索引        4.4.4.1    采集数据</code></pre><p><img src="/images/20170721/13.png"></p><pre><code>        public class BookDaoImpl implements BookDao {                @Override                public List&lt;Book&gt; queryBooks() {                    // 数据库链接                    Connection connection = null;                    // 预编译statement                    PreparedStatement preparedStatement = null;                    // 结果集                    ResultSet resultSet = null;                    // 图书列表                    List&lt;Book&gt; list = new ArrayList&lt;Book&gt;();                    try {                        // 加载数据库驱动                        Class.forName("com.mysql.jdbc.Driver");                        // 连接数据库                        connection = DriverManager.getConnection(                                "jdbc:mysql://localhost:3306/solr", "root", "root");                        // SQL语句                        String sql = "SELECT * FROM book";                        // 创建preparedStatement                        preparedStatement = connection.prepareStatement(sql);                        // 获取结果集                        resultSet = preparedStatement.executeQuery();                        // 结果集解析                        while (resultSet.next()) {                            Book book = new Book();                            book.setId(resultSet.getInt("id"));                            book.setName(resultSet.getString("name"));                            book.setPrice(resultSet.getFloat("price"));                            book.setPic(resultSet.getString("pic"));                            book.setDescription(resultSet.getString("description"));                            list.add(book);                        }                    } catch (Exception e) {                        e.printStackTrace();                    }                    return list;                }            }    4.4.4.2    创建索引            创建索引流程：</code></pre><p><img src="/images/20170721/14.png"></p><pre><code>            IndexWriter是索引过程的核心组件，通过IndexWriter可以创建新索引、更新索引、删除索引操作。IndexWriter需要通过Directory对索引进行存储操作。            Directory描述了索引的存储位置，底层封装了I/O操作，负责对索引进行存储。            它是一个抽象类，它的子类常用的包括FSDirectory（在文件系统存储索引）、RAMDirectory（在内存存储索引）。            @Test            public void createIndex() throws Exception {                // 采集数据                BookDao dao = new BookDaoImpl();                List&lt;Book&gt; list = dao.queryBooks();                // 将采集到的数据封装到Document对象中                List&lt;Document&gt; docList = new ArrayList&lt;&gt;();                Document document;                for (Book book : list) {                    document = new Document();                    // store:如果是yes，则说明存储到文档域中                    // 图书ID                    Field id = new TextField("id", book.getId().toString(), Store.YES);                    // 图书名称                    Field name = new TextField("name", book.getName(), Store.YES);                    // 图书价格                    Field price = new TextField("price", book.getPrice().toString(),                            Store.YES);                    // 图书图片地址                    Field pic = new TextField("pic", book.getPic(), Store.YES);                    // 图书描述                    Field description = new TextField("description",                            book.getDescription(), Store.YES);                    // 将field域设置到Document对象中                    document.add(id);                    document.add(name);                    document.add(price);                    document.add(pic);                    document.add(description);                    docList.add(document);                }                // 创建分词器，标准分词器                Analyzer analyzer = new StandardAnalyzer();                // 创建IndexWriter                IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_4_10_3,                        analyzer);                // 指定索引库的地址                File indexFile = new File("E:\\11-index\\hm19\\");                Directory directory = FSDirectory.open(indexFile);                IndexWriter writer = new IndexWriter(directory, cfg);                // 通过IndexWriter对象将Document写入到索引库中                for (Document doc : docList) {                    writer.addDocument(doc);                }                // 关闭writer                writer.close();            }    4.4.4.3    分词            Lucene中分词主要分为两个步骤：分词、过滤            分词：将field域中的内容一个个的分词。            过滤：将分好的词进行过滤，比如去掉标点符号、大写转小写、词的型还原（复数转单数、过去式转成现在式）、停用词过滤            停用词：单独应用没有特殊意义的词。比如的、啊、等，英文中的this is a the等等。                要分词的内容            Lucene is a Java full-text search engine.             分词            Lucene             is             a             Java             Full            -            text             search             engine            .            过滤            去掉标点符号            Lucene             is             a             Java             Full            text             search             engine            去掉停用词            Lucene             Java             Full            text             search             engine            大写转小写            lucene             java             full            text             search             engine            如下是org.apache.lucene.analysis.standard.standardAnalyzer的部分源码：            @Override              protected TokenStreamComponents createComponents(final String fieldName, final Reader reader) {                final StandardTokenizer src = new StandardTokenizer(getVersion(), reader);                src.setMaxTokenLength(maxTokenLength);                TokenStream tok = new StandardFilter(getVersion(), src);                tok = new LowerCaseFilter(getVersion(), tok);                tok = new StopFilter(getVersion(), tok, stopwords);                return new TokenStreamComponents(src, tok) {                  @Override                  protected void setReader(final Reader reader) throws IOException {                    src.setMaxTokenLength(StandardAnalyzer.this.maxTokenLength);                    super.setReader(reader);                  }                };              }            如下图是语汇单元的生成过程：</code></pre><p><img src="/images/20170721/15.png"></p><pre><code>            从一个Reader字符流开始，创建一个基于Reader的Tokenizer分词器，经过三个TokenFilter生成语汇单元Token。            同一个域中相同的语汇单元（Token）对应同一个Term（词），它记录了语汇单元的内容及所在域的域名等，            还包括来该token出现的频率及位置。                不同的域中拆分出来的相同的单词对应不同的term。                相同的域中拆分出来的相同的单词对应相同的term。            例如：图书信息里面，图书名称中的java和图书描述中的java对应不同的term    4.4.4.4    使用luke工具查看索引</code></pre><p><img src="/images/20170721/16.png"></p><p><img src="/images/20170721/17.png"></p><p><img src="/images/20170721/18.png"></p><pre><code>4.5    搜索流程        4.5.1    输入查询语句            同数据库的sql一样，lucene全文检索也有固定的语法：            最基本的有比如：AND, OR, NOT 等            举个例子，用户想找一个description中包括java关键字和lucene关键字的文档。            它对应的查询语句：description:java AND lucene            如下是使用luke搜索的例子</code></pre><p><img src="/images/20170721/19.png"></p><pre><code>        4.5.2    代码</code></pre><p><img src="/images/20170721/20.png"></p><pre><code>            @Test            public void indexSearch() throws Exception {                // 创建query对象                // 使用QueryParser搜索时，需要指定分词器，搜索时的分词器要和索引时的分词器一致                // 第一个参数：默认搜索的域的名称                QueryParser parser = new QueryParser("description",                        new StandardAnalyzer());                // 通过queryparser来创建query对象                // 参数：输入的lucene的查询语句(关键字一定要大写)                Query query = parser.parse("description:java AND lucene");                // 创建IndexSearcher                // 指定索引库的地址                File indexFile = new File("E:\\11-index\\hm19\\");                Directory directory = FSDirectory.open(indexFile);                IndexReader reader = DirectoryReader.open(directory);                IndexSearcher searcher = new IndexSearcher(reader);                // 通过searcher来搜索索引库                // 第二个参数：指定需要显示的顶部记录的N条                TopDocs topDocs = searcher.search(query, 10);                // 根据查询条件匹配出的记录总数                int count = topDocs.totalHits;                System.out.println("匹配出的记录总数:" + count);                // 根据查询条件匹配出的记录                ScoreDoc[] scoreDocs = topDocs.scoreDocs;                for (ScoreDoc scoreDoc : scoreDocs) {                    // 获取文档的ID                    int docId = scoreDoc.doc;                    // 通过ID获取文档                    Document doc = searcher.doc(docId);                    System.out.println("商品ID：" + doc.get("id"));                    System.out.println("商品名称：" + doc.get("name"));                    System.out.println("商品价格：" + doc.get("price"));                    System.out.println("商品图片地址：" + doc.get("pic"));                    System.out.println("==========================");                    // System.out.println("商品描述：" + doc.get("description"));                }                // 关闭资源                reader.close();            }</code></pre><hr><p>5.1    Field的属性</p><pre><code>    是否分词（Tokenized）是：对该field存储的内容进行分词，分词的目的，就是为了索引。比如：商品名称、商品描述、商品价格否：不需要对field存储的内容进行分词，不分词，不代表不索引，而是将整个内容进行索引。比如：商品id    是否索引（Indexed）是：将分好的词进行索引，索引的目的，就是为了搜索。比如：商品名称、商品描述、商品价格、商品id否：不索引，也就是不对该field域进行搜索。    是否存储（Stored）是：将field域中的内容存储到文档域中。存储的目的，就是为了搜索页面显示取值用的。比如：商品名称、商品价格、商品id、商品图片地址否：不将field域中的内容存储到文档域中。不存储，则搜索页面中没法获取该field域的值。比如：商品描述，由于商品描述在搜索页面中不需要显示，再加上商品描述的内容比较多，所以就不需要进行存储。如果需要商品描述，则根据搜索出的商品ID去数据库中查询，然后显示出商品描述信息即可。</code></pre><hr><pre><code>5.2    Field的常用类型    下边列出了开发中常用 的Filed类型，注意Field的属性，根据需求选择：</code></pre><p><img src="/images/20170721/21.png"></p><pre><code>5.3    修改入门程序的代码</code></pre><p><img src="/images/20170721/22.png"></p><hr><p>6    索引维护</p><pre><code>6.1    需求    图书信息在数据库 发生变化，所以索引库相对应的也要发生增删改变化。6.2    添加索引    参考入门程序的索引流程    IndexWriter.addDocument(document);6.3    删除索引    增删改操作，都是需要通过IndexWriter对象来操作    6.3.1    根据条件删除        Term是索引域中最小的单位。根据条件删除时，建议根据唯一键来进行删除。在solr中就是根据ID来进行删除和修改操作的。</code></pre><p><img src="/images/20170721/23.png"></p><pre><code>    6.3.2    删除全部</code></pre><p><img src="/images/20170721/24.png"></p><pre><code>6.4    修改索引</code></pre><p><img src="/images/20170721/25.png"></p><hr><p>7    搜索</p><pre><code>7.1    创建查询对象的方式        通过Query子类来创建查询对象    Query子类常用的有：TermQuery、NumericRangeQuery、BooleanQuery    不能输入lucene的查询语法，不需要指定分词器        通过QueryParser来创建查询对象（常用）    QueryParser、MultiFieldQueryParser    可以输入lucene的查询语法、可以指定分词器7.2    通过Query子类来创建查询对象    7.2.1    TermQuery            精确的词项查询</code></pre><p><img src="/images/20170721/26.png"></p><pre><code>    7.2.2    NumericRangeQuery 数字范围查询</code></pre><p><img src="/images/20170721/27.png"></p><pre><code>    7.2.3    BooleanQuery  组合查询</code></pre><p><img src="/images/20170721/28.png"></p><pre><code>        组合关系代表的意思如下:      1、MUST和MUST表示“与”的关系，即“并集”。      2、MUST和MUST_NOT前者包含后者不包含。      3、MUST_NOT和MUST_NOT没意义      4、SHOULD与MUST表示MUST，SHOULD失去意义；      5、SHOUlD与MUST_NOT相当于MUST与MUST_NOT。      6、SHOULD与SHOULD表示“或”的概念。7.3    通过QueryParser创建查询对象    7.3.1    QueryParser        通过QueryParser来创建query对象，可以指定分词器，搜索时的分词器和创建该索引的分词器一定要一致。还可以输入查询语句。        参考入门程序之搜索流程。    7.3.2    MultiFieldQueryParser  多域查询</code></pre><p><img src="/images/20170721/29.png"></p><pre><code>    7.3.3    查询语法    1、基础的查询语法，关键词查询：    域名+“：”+搜索的关键字    例如：content:java    2、范围查询    域名+“:”+[最小值 TO 最大值]    例如：size:[1 TO 1000]    注意：QueryParser不支持对数字范围的搜索，它支持字符串范围。数字范围搜索建议使用NumericRangeQuery。    3、组合条件查询    Occur.MUST 查询条件必须满足，相当于and    +（加号）    Occur.SHOULD 查询条件可选，相当于or        空（不用符号）    Occur.MUST_NOT 查询条件不能满足，相当于not非    -（减号）    1）+条件1 +条件2：两个条件之间是并且的关系and    例如：+filename:apache +content:apache    2）+条件1 条件2：必须满足第一个条件，忽略第二个条件    例如：+filename:apache content:apache    3）条件1 条件2：两个条件满足其一即可。    例如：filename:apache content:apache    4）-条件1 条件2：必须不满足条件1，要满足条件2    例如：-filename:apache content:apache    第二种写法：    条件1 AND 条件2    条件1 OR 条件2    条件1 NOT 条件27.4    TopDocs    Lucene搜索结果可通过TopDocs遍历，TopDocs类提供了少量的属性，如下：    方法或属性    说明    totalHits    匹配搜索条件的总记录数    scoreDocs    顶部匹配记录    注意：    Search方法需要指定匹配记录数量n：indexSearcher.search(query, n)    TopDocs.totalHits：是匹配索引库中所有记录的数量    TopDocs.scoreDocs：匹配相关度高的前边记录数组，scoreDocs的长度小于等于search方法指定的参数n</code></pre><hr><p>8    相关度排序</p><pre><code>8.1    什么是相关度排序相关度排序就是查询关键字与查询结果的匹配相关度。匹配越高的越靠前。Lucene是通过打分来进行相关度排序的。打分分两步：1、    根据词计算词的权重2、    根据词的权重进行打分词的权重：词指的就是term。也就是说一个term对一个文档的重要性，就叫词的权重。影响词的权重的方式有两种：    Tf词在同一个文档中出现的频率    Tf越高，说明词的权重越高    Df词在多个文档中出现的频率Df越高，说明词的权重越低以上是自然打分的规则。</code></pre><hr><pre><code>8.2    设置boost值影响打分    Boost：加权值，默认是1.0f。    设置加权值可以在创建索引时设置，也可以在查询时设置。    Boost值是设置到Field域上的。    8.2.1    创建索引时设置boost值</code></pre><p><img src="/images/20170721/30.png"></p><pre><code>    8.2.2    搜索时设置boost值  在MultiFieldQueryParser创建时设置boost值。</code></pre><p><img src="/images/20170721/31.png">            </p><hr><p>9    中文分词器</p><pre><code>9.1    什么是中文分词器对于英文，是安装空格、标点符号进行分词对于中文，应该安装具体的词来分，中文分词就是将词，切分成一个个有意义的词。比如：“我的中国人”，分词：我、的、中国、中国人、国人。</code></pre><hr><pre><code>9.2    Lucene自带的中文分词器    StandardAnalyzer：单字分词：就是按照中文一个字一个字地进行分词。如：“我爱中国”，效果：“我”、“爱”、“中”、“国”。    CJKAnalyzer二分法分词：按两个字进行切分。如：“我是中国人”，效果：“我是”、“是中”、“中国”“国人”。上边两个分词器无法满足需求。</code></pre><hr><pre><code>9.3    第三方中文分词器    paoding： 庖丁解牛最新版在 https://code.google.com/p/paoding/ 中最多支持Lucene 3.0，且最新提交的代码在 2008-06-03，在svn中最新也是2010年提交，已经过时，不予考虑。    mmseg4j：最新版已从 https://code.google.com/p/mmseg4j/ 移至 https://github.com/chenlb/mmseg4j-solr，支持Lucene 4.10，且在github中最新提交代码是2014年6月，从09年～14年一共有：18个版本，也就是一年几乎有3个大小版本，有较大的活跃度，用了mmseg算法。    IK-analyzer： 最新版在https://code.google.com/p/ik-analyzer/上，支持Lucene 4.10从2006年12月推出1.0版开始， IKAnalyzer已经推出了4个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。从3.0版本开 始，IK发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。在2012版本中，IK实现了简单的分词 歧义排除算法，标志着IK分词器从单纯的词典分词向模拟语义分词衍化。 但是也就是2012年12月后没有在更新。    ansj_seg：最新版本在 https://github.com/NLPchina/ansj_seg tags仅有1.1版本，从2012年到2014年更新了大小6次，但是作者本人在2014年10月10日说明：“可能我以后没有精力来维护ansj_seg了”，现在由”nlp_china”管理。2014年11月有更新。并未说明是否支持Lucene，是一个由CRF（条件随机场）算法所做的分词算法。    imdict-chinese-analyzer：最新版在 https://code.google.com/p/imdict-chinese-analyzer/ ， 最新更新也在2009年5月，下载源码，不支持Lucene 4.10 。是利用HMM（隐马尔科夫链）算法。    Jcseg：最新版本在git.oschina.net/lionsoul/jcseg，支持Lucene 4.10，作者有较高的活跃度。利用mmseg算法。</code></pre><hr><pre><code>9.4    Ikanalyzer</code></pre><p><img src="/images/20170721/32.png"></p><pre><code>    9.4.1    添加ikanalyzer的jar包</code></pre><p><img src="/images/20170721/33.png"></p><pre><code>    9.4.2    代码</code></pre><p><img src="/images/20170721/34.png"></p><pre><code>    9.4.3    扩展中文词库 将以下文件拷贝到config目录下</code></pre><p><img src="/images/20170721/35.png"></p><pre><code>        从ikanalyzer包中拷贝配置文件到classpath下。        &lt;?xml version="1.0" encoding="UTF-8"?&gt;        &lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;          &lt;properties&gt;              &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;            &lt;!-- 用户可以在这里配置自己的扩展字典 --&gt;             &lt;entry key="ext_dict"&gt;dicdata/mydict.dic&lt;/entry&gt;              &lt;!-- 用户可以在这里配置自己的扩展停用词字典    --&gt;            &lt;entry key="ext_stopwords"&gt;dicdata/ext_stopword.dic&lt;/entry&gt;         &lt;/properties&gt;        如果想配置扩展词和停用词，就创建扩展词的文件和停用词的文件，文件的编码要是utf-8。        注意：不要用记事本保存扩展词文件和停用词文件，那样的话，格式中是含有bom的。    9.4.4    使用luke来查询中文分词效果            第一步：将ikanalyzer的jar包，拷贝到luke工具的目录</code></pre><p><img src="/images/20170721/36.png"></p><pre><code>            第二步：使用命令打开luke工具            java -Djava.ext.dirs=. -jar lukeall-4.10.3.jar</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> lucene </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
            <tag> lucene </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 find chmod</title>
      <link href="/2017/07/25/mei-tian-2-ge-linux-ming-ling-find-chmod/"/>
      <url>/2017/07/25/mei-tian-2-ge-linux-ming-ling-find-chmod/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-24-每天2个Linux-find命令-命令详解"><a href="#2017-07-24-每天2个Linux-find命令-命令详解" class="headerlink" title=" 2017-07-24 每天2个Linux find命令_命令详解"></a><center> 2017-07-24 每天2个Linux find命令_命令详解</center></h2><p>find命令的一些常用参数的常用实例和用时的注意事项。</p><p>实例:</p><pre><code>(1)-name参数:  1)[sunjimeng@localhost home]$ find ~ -name "less*" -print     　在指定目录和指定目录的子目录中查找与文件名匹配的文件[sunjimeng@localhost home]$ find ~ -name "less*" -print/home/sunjimeng/Documents/less1/home/sunjimeng/Documents/less2  ~是一个代位符，表明的是个人目录的地址，因为每个用户都有自己的个人目录地址，所以用 ~ 作为统一替代这个根据用户不同而不同但有规可循的地址，来保证某些情况下的兼容性问题。  如果以root登录，则~代表/home/root，若以username登录，则~代表/home/username，例如：我的目录就是/home/sunjimeng。  linux 中的$PATH $HOME 是什么意思？  在linux及unix的sh中，以$开头的字符串表示的是sh中定义的变量，这些变量可以是系统自动增加的，也可以是用户自己定义的。 $PATH表示的是系统的命令搜索路径，和windows的%path%是一样的；$HOME则表示是用户的主目录，也就是用户登录后工作目录。  波浪号~代表了你的$HOME目录。</code></pre><hr><pre><code>2)[sunjimeng@localhost Document]$ find . -name "[A-Z]*[1-9]"　　　　　　　　查找当前目录下以大写字母开头，数字结尾的文件。(注意[]符号的用法)复制代码[sunjimeng@localhost Document]$ ll总用量 12-rw-r--r--. 1 root      root      85 5月  18 02:58 all.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 B.text3-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 C.text6-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:28 D.textdrwxr-xr-x. 2 root      root      51 5月  18 02:47 newDir-rw-r--r--. 1 root      root      42 5月  18 02:53 t1.txt-rw-r--r--. 1 root      root      43 5月  18 02:54 t2.txt[sunjimeng@localhost Document]$ find . -name "[A-Z]*[1-9]"./B.text3./C.text6[sunjimeng@localhost Document]$ find . -name "[A-Z]*"./B.text3./C.text6./D.text</code></pre><hr><pre><code>3)[sunjimeng@localhost Document]$ find / -name "*"    　　　　查找Linux文件系统中的所有文件，让系统高负荷运行[sunjimeng@localhost Document]$ find / -name "*"  由于Linux的find命令是通过后台执行操作，遍历整个磁盘文件进行文件的查找，不仅包括名称的查找，还包括其他的例如权限，文件的内容的字符串匹配的查找，因此十分耗费资源，因此这里会让系统高负荷运行。而前几个命令，都是高效查询命令，例如which，whereis等，因为他们不是直接深入磁盘中查找，而是通过数据库的键值对应进行快速查找。</code></pre><hr><pre><code>(2)-perm参数按照文件权限模式用-perm选项,按文件权限模式来查找文件的话。最好使用八进制的权限表示法。  1)[root@localhost home]# find . -perm 755 |more -5　　　　　　　　按权限在目录中查找文件，并执行分页显示复制代码[root@localhost home]# find . -perm 755 |more -5../sunjimeng/.mozilla./sunjimeng/.mozilla/extensions./sunjimeng/.mozilla/plugins./sunjimeng/.config--more--                         //按q键退出more命令 回车下一行，空格下一页</code></pre><hr><pre><code>2)[root@localhost home]# find / -perm -mode |more -5　　　　　　 根据权限查看文件，当权限值前有-号时复制代码[root@localhost home]# find / -perm 555 |more -5//boot/proc/proc/asound/proc/asound/card0--more--[root@localhost home]# find / -perm -555 |more -5//boot/boot/grub/boot/grub2/boot/grub2/themes--more--[root@localhost home]# find / -perm -005 |more -5//boot/boot/grub/boot/grub2/boot/grub2/themes--more--复制代码  find -perm，根据文件的权限来查找文件，有三种形式：  1.find -perm mode　  表示严格匹配，也就是你的文件权限位转换成对应的十进制数字与mode一模一样，那么匹配成功，需要注意的是如果mode给的数字不足3位，那么前面自动添0(严格的说是不足4位)  2.find -perm -mode      表示mode中转换成二进制的1在文件权限位里面必须匹配，比如mode=644那么转换成二进制为110 100 100，而被查找的文件的权限位也可以被转换成一个二进制数，两者在位上为1的部分必须完全匹配，而0则不管。例如被查找的文件的权限为转换成二进制数是111 111 111那么这个比如被匹配，而假如是100 100 100那么则不会匹配。所以这个'-'的作用归结起来就是匹配比mode权限更充足的文件  3.find -perm +mode  与 -mode的区别是+mode只需其中的任意一个1的部分被匹配，-mode是所有1的部分都必须被匹配，同样+mode也不管0位。  在linux中文件或目录有三者权限r,w,x，代表的含义分别是读、写、可执行。而一个文件或目录的属性中又包括所属用户u、所属组g、其他o三个部分的属性，分别表示所属用户、所属组、其他用户对这个文件所拥有的权限。看起来大概是这个样子：所属用户   所属组    其他rwx       rwx      rwx用户在其拥有权限的位上设置1，没有权限的位设置0。如果将每个部分的这些权限位看成二进制数，每个部分可以用3位二进制数表示，最大值为7(2^3-1)，表示可读、可写、可执行。</code></pre><hr><pre><code>(3) -prune参数:如果在查找文件时希望忽略某个目录，因为你知道那个目录中没有你所要查找的文件，那么可以使用-prune选项来指出需要忽略的目录。在使用-prune选项时要当心，因为如果你同时使用了-depth选项，那么-prune选项就会被find命令忽略。1)[root@localhost sunjimeng]# find Document -path "Document/newDir" -prune -o -print     　　　　查询文件时忽略特定目录复制代码[root@localhost sunjimeng]# find DocumentDocumentDocument/newDirDocument/newDir/mvt1.txtDocument/newDir/mvt2.txtDocument/newDir/mvt3.txtDocument/t1.txtDocument/t2.txtDocument/all.txtDocument/B.text3Document/C.text6Document/D.text[root@localhost sunjimeng]# find Document -path "Document/newDir" -prune -o -printDocumentDocument/t1.txtDocument/t2.txtDocument/all.txtDocument/B.text3Document/C.text6Document/D.text</code></pre><hr><pre><code>2)[root@localhost sunjimeng]# find Document -path "Document/newDir" -prune　　　find命令后默认只能跟一个参数命令，如果还需要执行其他的命令，需要-o命令连接符复制代码[root@localhost sunjimeng]# find Document -path "Document/newDir" -prune        //-prune不加-print命令的话，输出的是要忽略的文件夹及其路径Document/newDir[root@localhost sunjimeng]# find Document -path "Document/newDir" -prune -o  -exec ls -l {} \; -o用于设置执行的两个连续的命令，这里执行-exec命令，上一个命令执行的是-print命令，也可以换成其他的总用量 12-rw-r--r--. 1 root      root      85 5月  18 02:58 all.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 B.text3-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 C.text6-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:28 D.textdrwxr-xr-x. 2 root      root      51 5月  18 02:47 newDir-rw-r--r--. 1 root      root      42 5月  18 02:53 t1.txt-rw-r--r--. 1 root      root      43 5月  18 02:54 t2.txt-rw-r--r--. 1 root root 42 5月  18 02:53 Document/t1.txt-rw-r--r--. 1 root root 43 5月  18 02:54 Document/t2.txt-rw-r--r--. 1 root root 85 5月  18 02:58 Document/all.txt-rw-rw-r--. 1 sunjimeng sunjimeng 0 5月  19 22:27 Document/B.text3-rw-rw-r--. 1 sunjimeng sunjimeng 0 5月  19 22:27 Document/C.text6-rw-rw-r--. 1 sunjimeng sunjimeng 0 5月  19 22:28 Document/D.text复制代码</code></pre><hr><pre><code>3)[root@localhost Documents]# find . \( -path "./Dir" -o -path "./findDir" \) -prune -o -exec ls -l {} \;　忽略多个文件夹复制代码[root@localhost Documents]# ll总用量 28-rw-r--r--. 1 root root  27 5月  19 04:21 core.log-rw-r--r--. 1 root root   0 5月  19 04:16 finddrwxr-xr-x. 2 root root  84 5月  19 04:57 findDir    //是文件夹--w-------. 1 root root 664 5月   9 07:59 head_text--w-------. 1 root root  45 5月   9 08:15 less1--w-------. 1 root root  57 5月   9 08:16 less2--w-------. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root  85 5月  19 04:25 t3.txt--w-------. 1 root root 259 5月  12 21:53 tail_text--w-------. 1 root root 216 5月  12 22:24 tempory--w-------. 1 root root   0 5月  15 18:34 uText[root@localhost Documents]# mkdir Dir              //新建一个文件夹[root@localhost Documents]# mv {head_text,less1,less2} Dir      //将几个文件移到里面[root@localhost Documents]# ll总用量 16-rw-r--r--. 1 root root  27 5月  19 04:21 core.logdrwxr-xr-x. 2 root root  46 5月  19 23:29 Dir-rw-r--r--. 1 root root   0 5月  19 04:16 finddrwxr-xr-x. 2 root root  84 5月  19 04:57 findDir--w-------. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root  85 5月  19 04:25 t3.txt--w-------. 1 root root 259 5月  12 21:53 tail_text--w-------. 1 root root 216 5月  12 22:24 tempory--w-------. 1 root root   0 5月  15 18:34 uText[root@localhost Documents]# find .  -exec ls -l {} \;    //执行一次查询当前Documents文件夹下的所有目录及文件操作总用量 16-rw-r--r--. 1 root root  27 5月  19 04:21 core.logdrwxr-xr-x. 2 root root  46 5月  19 23:29 Dir-rw-r--r--. 1 root root   0 5月  19 04:16 finddrwxr-xr-x. 2 root root  84 5月  19 04:57 findDir--w-------. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root  85 5月  19 04:25 t3.txt--w-------. 1 root root 259 5月  12 21:53 tail_text--w-------. 1 root root 216 5月  12 22:24 tempory--w-------. 1 root root   0 5月  15 18:34 uText--w-------. 1 root root 259 5月  12 21:53 ./tail_text--w-------. 1 root root 216 5月  12 22:24 ./tempory--w-------. 1 root root 0 5月  15 18:21 ./newlocate--w-------. 1 root root 0 5月  15 18:34 ./uText总用量 0--w-------. 1 root root 0 5月  17 04:18 p1.pdf--w-------. 1 root root 0 5月  17 04:18 p2.pdf--w-------. 1 root root 0 5月  17 03:50 t1.txt--w-------. 1 root root 0 5月  17 04:02 T1.txt-rw-r--r--. 1 root root 0 5月  19 04:58 t2.txt--w-------. 1 root root 0 5月  17 04:02 T2.txt--w-------. 1 root root 0 5月  17 03:50 ./findDir/t1.txt--w-------. 1 root root 0 5月  17 04:02 ./findDir/T1.txt--w-------. 1 root root 0 5月  17 04:02 ./findDir/T2.txt--w-------. 1 root root 0 5月  17 04:18 ./findDir/p1.pdf--w-------. 1 root root 0 5月  17 04:18 ./findDir/p2.pdf-rw-r--r--. 1 root root 0 5月  19 04:58 ./findDir/t2.txt-rw-r--r--. 1 root root 0 5月  19 04:16 ./find-rw-r--r--. 1 root root 27 5月  19 04:21 ./core.log-rw-r--r--. 1 root root 85 5月  19 04:25 ./t3.txt总用量 12--w-------. 1 root root 664 5月   9 07:59 head_text--w-------. 1 root root  45 5月   9 08:15 less1--w-------. 1 root root  57 5月   9 08:16 less2--w-------. 1 root root 664 5月   9 07:59 ./Dir/head_text--w-------. 1 root root 45 5月   9 08:15 ./Dir/less1--w-------. 1 root root 57 5月   9 08:16 ./Dir/less2[root@localhost Documents]# find . \( -path "./Dir" -o -path "./findDir" \) -prune -o -exec ls -l {} \;    //忽略两个文件夹，执行操作总用量 16-rw-r--r--. 1 root root  27 5月  19 04:21 core.logdrwxr-xr-x. 2 root root  46 5月  19 23:29 Dir-rw-r--r--. 1 root root   0 5月  19 04:16 finddrwxr-xr-x. 2 root root  84 5月  19 04:57 findDir--w-------. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root  85 5月  19 04:25 t3.txt--w-------. 1 root root 259 5月  12 21:53 tail_text--w-------. 1 root root 216 5月  12 22:24 tempory--w-------. 1 root root   0 5月  15 18:34 uText--w-------. 1 root root 259 5月  12 21:53 ./tail_text--w-------. 1 root root 216 5月  12 22:24 ./tempory--w-------. 1 root root 0 5月  15 18:21 ./newlocate--w-------. 1 root root 0 5月  15 18:34 ./uText-rw-r--r--. 1 root root 0 5月  19 04:16 ./find-rw-r--r--. 1 root root 27 5月  19 04:21 ./core.log-rw-r--r--. 1 root root 85 5月  19 04:25 ./t3.txt[root@localhost Documents]# find . \( -path "./Dir" -o -path "findDir" \) -prune -o -exec ls -l {} \;不加./是无法进行匹配的，-path “findDir”无意义(根据结果可知)总用量 16-rw-r--r--. 1 root root  27 5月  19 04:21 core.logdrwxr-xr-x. 2 root root  46 5月  19 23:29 Dir-rw-r--r--. 1 root root   0 5月  19 04:16 finddrwxr-xr-x. 2 root root  84 5月  19 04:57 findDir--w-------. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root  85 5月  19 04:25 t3.txt--w-------. 1 root root 259 5月  12 21:53 tail_text--w-------. 1 root root 216 5月  12 22:24 tempory--w-------. 1 root root   0 5月  15 18:34 uText--w-------. 1 root root 259 5月  12 21:53 ./tail_text--w-------. 1 root root 216 5月  12 22:24 ./tempory--w-------. 1 root root 0 5月  15 18:21 ./newlocate--w-------. 1 root root 0 5月  15 18:34 ./uText总用量 0--w-------. 1 root root 0 5月  17 04:18 p1.pdf--w-------. 1 root root 0 5月  17 04:18 p2.pdf--w-------. 1 root root 0 5月  17 03:50 t1.txt--w-------. 1 root root 0 5月  17 04:02 T1.txt-rw-r--r--. 1 root root 0 5月  19 04:58 t2.txt--w-------. 1 root root 0 5月  17 04:02 T2.txt--w-------. 1 root root 0 5月  17 03:50 ./findDir/t1.txt--w-------. 1 root root 0 5月  17 04:02 ./findDir/T1.txt--w-------. 1 root root 0 5月  17 04:02 ./findDir/T2.txt--w-------. 1 root root 0 5月  17 04:18 ./findDir/p1.pdf--w-------. 1 root root 0 5月  17 04:18 ./findDir/p2.pdf-rw-r--r--. 1 root root 0 5月  19 04:58 ./findDir/t2.txt-rw-r--r--. 1 root root 0 5月  19 04:16 ./find-rw-r--r--. 1 root root 27 5月  19 04:21 ./core.log-rw-r--r--. 1 root root 85 5月  19 04:25 ./t3.txt</code></pre><hr><pre><code>(4)-user参数  1)[root@localhost Document]# find . -user sunjimeng -exec ls -l {} \;　　　　　</code></pre><p>　　　查找属于特定用户的文件及文件夹</p><pre><code>复制代码[root@localhost Document]# find . -user sunjimeng -exec ls -l {} \;总用量 12-rw-r--r--. 1 root      root      85 5月  18 02:58 all.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 B.text3-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:27 C.text6-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  19 22:28 D.textdrwxr-xr-x. 2 root      root      51 5月  18 02:47 newDir-rw-r--r--. 1 root      root      42 5月  18 02:53 t1.txt-rw-r--r--. 1 root      root      43 5月  18 02:54 t2.txt-rw-rw-r--. 1 sunjimeng sunjimeng 0 5月  19 22:27 ./B.text3-rw-rw-r--. 1 sunjimeng sunjimeng 0 5月  19 22:27 ./C.text6-rw-rw-r--. 1 sunjimeng sunjimeng 0 5月  19 22:28 ./D.text[root@localhost Document]# find . -user root -exec ls -l {} \;总用量 0-rw-r--r--. 1 root root 0 5月  18 02:46 mvt1.txt-rw-r--r--. 1 root root 0 5月  18 02:46 mvt2.txt-rw-r--r--. 1 root root 0 5月  18 02:46 mvt3.txt-rw-r--r--. 1 root root 0 5月  18 02:46 ./newDir/mvt1.txt-rw-r--r--. 1 root root 0 5月  18 02:46 ./newDir/mvt2.txt-rw-r--r--. 1 root root 0 5月  18 02:46 ./newDir/mvt3.txt-rw-r--r--. 1 root root 42 5月  18 02:53 ./t1.txt-rw-r--r--. 1 root root 43 5月  18 02:54 ./t2.txt-rw-r--r--. 1 root root 85 5月  18 02:58 ./all.txt</code></pre><hr><pre><code>2)[root@localhost /]# find . -nouser -exec ls -l {} \;　　　　　　查找不属于任何用户的文件[root@localhost /]# find . -nouser -exec ls -l {} \;　　　　　　　　　　　　　　　　　　//这里没找着find: ‘./proc/37913/task/37913/fd/6’: 没有那个文件或目录find: ‘./proc/37913/task/37913/fdinfo/6’: 没有那个文件或目录find: ‘./proc/37913/fd/6’: 没有那个文件或目录find: ‘./proc/37913/fdinfo/6’: 没有那个文件或目录find: ‘./run/user/1000/gvfs’: 权限不够  另外，还有其他的参数，例如按文件的大小-size,按查询路径的深度-depth,按文件的新旧程度-newer,按更改时间或访问时间-mtime,按类型-type等等。  在此并不一一举例。况且前两篇也有一些示例。</code></pre><h2 id="2017-07-24-每天2个Linux-chmod命令"><a href="#2017-07-24-每天2个Linux-chmod命令" class="headerlink" title=" 2017-07-24 每天2个Linux chmod命令"></a><center> 2017-07-24 每天2个Linux chmod命令</center></h2><p>chmod命令用来变更文件或目录的权限。<br><br>在UNIX系统家族里，文件或目录权限的控制分别以读取、写入、执行3种一般权限来区分，<br><br>另有3种特殊权限可供运用。用户可以使用chmod指令去变更文件与目录的权限，<br><br>设置方式采用文字或数字代号皆可。符号连接的权限无法变更，如果用户对符号连接修改权限，<br><br>其改变会作用在被连接的原始文件。<br></p><p>(1)用法:</p><pre><code>用法:  chmod  [选项]     [mode] 模式  文件     或 chmod  [-cfvR] [--help] [--version] mode file命令有两种用法:一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。</code></pre><p>(2)功能:</p><pre><code>功能:用于改变文件或目录的访问权限，用它控制文件或目录的访问权限。</code></pre><p>(3)参数详解:</p><pre><code>  1) -R    ——recursive:　　　　　　　　　　　　　　递归处理，将指令目录下的所有文件及子目录一并处理  2) -v    ——verbose :　　　　　　　　　　　　　　 显示指令执行过程  3) --reference=&lt;参考文件或目录&gt;: 　　　　　　　  把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同  4) &lt;权限范围&gt;+&lt;权限设置&gt;:　　　　　　　　　　　开启权限范围的文件或目录的该选项权限设置      &lt;权限范围&gt; -&lt;权限设置&gt;:                               关闭权限范围的文件或目录的该选项权限设置      &lt;权限范围&gt;=&lt;权限设置&gt;:                               指定权限范围的文件或目录的该选项权限设置</code></pre><p>(4)权限范围的表示法:<br>      1) u         User　　　　即文件或目录的拥有者</p><pre><code>  2) g         Group　　   即文件或目录的所属群组  3) o         Other         除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围  4) a         All 　　　　 即全部的用户，包含拥有者，所属群组以及其他用户  5) r                          读取权限，数字代号为“4”  6) w 　　　　　　　　  写入权限，数字代号为“2”  7) x                          执行或切换权限，数字代号为“1”  8) -                          不具任何权限，数字代号为“0”  9) s                          特殊功能说明：变更文件或目录的权限</code></pre><hr><pre><code>(5)实例:  1)[root@localhost Documents]# chmod a+x core.log　　　　　　　　　　为所有用户组添加可执行权限复制代码[root@localhost Documents]# ll -al core.log         //ll -al 文件名与 ls -l 文件名貌似没啥区别-rw-r--r--. 1 root root 27 5月  19 04:21 core.log[root@localhost Documents]# ls -l core.log-rw-r--r--. 1 root root 27 5月  19 04:21 core.log[root@localhost Documents]# chmod a+x core.log     [root@localhost Documents]# ll -al core.log-rwxr-xr-x. 1 root root 27 5月  19 04:21 core.log</code></pre><hr><pre><code>2)[root@localhost Documents]# chmod ug+w,o-x core.log　　　　　　　同时为不同用户添加或删除权限[root@localhost Documents]# ll -al core.log-rwxr-xr-x. 1 root root 27 5月  19 04:21 core.log[root@localhost Documents]# chmod ug+w,o-x core.log[root@localhost Documents]# ll -l core.log-rwxrwxr--. 1 root root 27 5月  19 04:21 core.log</code></pre><hr><pre><code>3)[root@localhost Documents]# chmod g=x,o=rwx core.log　　　　　设置文件的u,g,o的三个权限。这里是设置文件所有者权限为可执行，其他用户可以读写执行，组用户权限不变[root@localhost Documents]# ll -l core.log-rwxrwxr--. 1 root root 27 5月  19 04:21 core.log[root@localhost Documents]# chmod g=x,o=rwx core.log[root@localhost Documents]# ls -l core.log-rwx--xrwx. 1 root root 27 5月  19 04:21 core.log</code></pre><hr><pre><code>4)[root@localhost Documents]# chmod -R o=--- findDir　　　　　　递归的设置findDir文件夹下的文件及文件夹的其他用户权限为不具备任何权限复制代码[root@localhost Documents]# chmod -R o=--- findDir[root@localhost Documents]# find . -name "Dir" -print./Dir[root@localhost Documents]# find . -name "Dir" -exec ls -l {} \;总用量 12--w-------. 1 root root 664 5月   9 07:59 head_text--w-------. 1 root root  45 5月   9 08:15 less1--w-------. 1 root root  57 5月   9 08:16 less2[root@localhost Documents]# ls -l Dir总用量 12--w-------. 1 root root 664 5月   9 07:59 head_text--w-------. 1 root root  45 5月   9 08:15 less1--w-------. 1 root root  57 5月   9 08:16 less2</code></pre><hr><pre><code>5)[root@localhost Documents]# chmod -R u=r,g=r,o=r findDir 与  [root@localhost Documents]# chmod -R =rx Dir　　　　等价地给ugo的用户设置权限复制代码[root@localhost Documents]# chmod -R u=r,g=r,o=r findDir[root@localhost Documents]# ls -l findDir总用量 0-r--r--r--. 1 root root 0 5月  17 04:18 p1.pdf-r--r--r--. 1 root root 0 5月  17 04:18 p2.pdf-r--r--r--. 1 root root 0 5月  17 03:50 t1.txt-r--r--r--. 1 root root 0 5月  17 04:02 T1.txt-r--r--r--. 1 root root 0 5月  19 04:58 t2.txt-r--r--r--. 1 root root 0 5月  17 04:02 T2.txt[root@localhost Documents]# ls -l Dir总用量 12--w-------. 1 root root 664 5月   9 07:59 head_text--w-------. 1 root root  45 5月   9 08:15 less1--w-------. 1 root root  57 5月   9 08:16 less2[root@localhost Documents]# chmod -R =rx Dir           //设置所有组用户权限为rw之后，以前的所有者的w权限就没了[root@localhost Documents]# ls -l Dir总用量 12-r-xr-xr-x. 1 root root 664 5月   9 07:59 head_text-r-xr-xr-x. 1 root root  45 5月   9 08:15 less1-r-xr-xr-x. 1 root root  57 5月   9 08:16 less2</code></pre><hr><pre><code>6)[root@localhost Documents]# chmod 444 find　　　　　　　　用数字给文件设置权限[root@localhost Documents]# chmod 444 find[root@localhost Documents]# ls -l find-r--r--r--. 1 root root 0 5月  19 04:16 find[root@localhost Documents]# chmod =r newlocate                //两种方法等价，但同时都会将原有的权限清除[root@localhost Documents]# ls -l newlocate-r--r--r--. 1 root root 0 5月  15 18:21 newlocate</code></pre><hr><pre><code>(6)其他:  Linux用户分为：拥有者、组群(Group)、其他（other）。  Linux系统中，预设的情況下，系统中所有的帐号与一般身份使用者，以及root的相关信息， 都是记录在/etc/passwd文件中。每个人的密码则是记录在/etc/shadow文件下。 此外，所有的组群名称记录在/etc/group內！分类: CentOS服务器管理</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 find</title>
      <link href="/2017/07/25/mei-tian-2-ge-linux-ming-ling-find/"/>
      <url>/2017/07/25/mei-tian-2-ge-linux-ming-ling-find/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-23-每天2个Linux-find命令-exec参数"><a href="#2017-07-23-每天2个Linux-find命令-exec参数" class="headerlink" title=" 2017-07-23 每天2个Linux find命令_exec参数"></a><center> 2017-07-23 每天2个Linux find命令_exec参数</center></h2><p>find命令的exec参数，用于find查找命令完成以后的后续操作。</p><p>(1)用法:</p><pre><code>用法:  [find命令]  [-exec  其他命令 {} \;] </code></pre><p>(2)功能:</p><pre><code>功能:-exec find命令对匹配的文件执行该参数所给出的其他linux命令。</code></pre><p>(3)-exec的解释:</p><pre><code>-exec参数后面跟的是command命令，它的终止是以;为结束标志的，所以这句命令后面的分号是不可缺少的 考虑到各个系统中分号会有不同的意义，所以前面加反斜杠。{}   花括号代表前面find查找出来的文件名。</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost Documents]# find -type f -exec ls -l {} \;　将查找出来的结果用ls -l命令列出复制代码[root@localhost sunjimeng]# cd Documents[root@localhost Documents]# ll　　　　　　　　　　　　　　　　　　　　//ll命令等价于 ls -l总用量 20drwxr-xr-x. 2 root root  71 5月  17 04:18 findDir-rw-r--r--. 1 root root 664 5月   9 07:59 head_text-rw-r--r--. 1 root root  45 5月   9 08:15 less1-rw-r--r--. 1 root root  57 5月   9 08:16 less2-rw-r--r--. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root 259 5月  12 21:53 tail_text-rw-r--r--. 1 root root 216 5月  12 22:24 tempory-rw-r--r--. 1 root root   0 5月  15 18:34 uText[root@localhost Documents]# find -type f -exec ls -l {} \;　　　//这里与直接执行ls -l命令不同的是，find命令会递归地将所有当前要查询的文件的子目录进行遍历，将每个后代文件均输出。-rw-r--r--. 1 root root 45 5月   9 08:15 ./less1-rw-r--r--. 1 root root 57 5月   9 08:16 ./less2-rw-r--r--. 1 root root 664 5月   9 07:59 ./head_text-rw-r--r--. 1 root root 259 5月  12 21:53 ./tail_text-rw-r--r--. 1 root root 216 5月  12 22:24 ./tempory-rw-r--r--. 1 root root 0 5月  15 18:21 ./newlocate-rw-r--r--. 1 root root 0 5月  15 18:34 ./uText　　             //只输出文件，却没有输出文件夹-rw-r--r--. 1 root root 0 5月  17 03:50 ./findDir/t1.txt-rw-r--r--. 1 root root 0 5月  17 04:02 ./findDir/T1.txt-rw-r--r--. 1 root root 0 5月  17 04:02 ./findDir/T2.txt-rw-r--r--. 1 root root 0 5月  17 04:18 ./findDir/p1.pdf-rw-r--r--. 1 root root 0 5月  17 04:18 ./findDir/p2.pdf[root@localhost Documents]# 复制代码     -type d与-type f的区别:复制代码[root@localhost Documents]# find -type d -exec ls -l {} \;     //这里没有显示相对的路径总用量 20drwxr-xr-x. 2 root root  71 5月  17 04:18 findDir-rw-r--r--. 1 root root 664 5月   9 07:59 head_text-rw-r--r--. 1 root root  45 5月   9 08:15 less1-rw-r--r--. 1 root root  57 5月   9 08:16 less2-rw-r--r--. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root 259 5月  12 21:53 tail_text-rw-r--r--. 1 root root 216 5月  12 22:24 tempory-rw-r--r--. 1 root root   0 5月  15 18:34 uText总用量 0-rw-r--r--. 1 root root 0 5月  17 04:18 p1.pdf-rw-r--r--. 1 root root 0 5月  17 04:18 p2.pdf-rw-r--r--. 1 root root 0 5月  17 03:50 t1.txt-rw-r--r--. 1 root root 0 5月  17 04:02 T1.txt-rw-r--r--. 1 root root 0 5月  17 04:02 T2.txt</code></pre><hr><pre><code>2)[root@localhost Document]# find . -type f -mtime +10 -exec rm -i {} \;删除10天以外修改过的文件，删除时给出提醒复制代码[root@localhost Document]# find . -type f -mtime +14 -exec rm -i {} \;　　　由+14给出后没有反应，而给参数+10之后有反应，可知这些文件是10到14天以前建立或修改过的[root@localhost Document]# find . -type f -mtime +10 -exec rm -i {} \;rm：是否删除普通空文件 "./newDir/text1"？nrm：是否删除普通空文件 "./newDir/text2"？nrm：是否删除普通空文件 "./text1/newDir/text1"？nrm：是否删除普通空文件 "./text1/newDir/text2"？nrm：是否删除普通空文件 "./text2/newDir/text1"？nrm：是否删除普通空文件 "./text2/newDir/text2"？nrm：是否删除普通空文件 "./text3/text1"？nrm：是否删除普通空文件 "./text3/text2"？nrm：是否删除普通空文件 "./text4/text1"？nrm：是否删除普通空文件 "./text4/text2"？nrm：是否删除普通空文件 "./mytext"？nrm：是否删除普通空文件 "./mytext.txt"？n</code></pre><hr><pre><code>3)[root@localhost Document]# find . -type f -mtime +10 -ok rm {} \;　　　　　　　　　　  另一种方法实现删除时的交互复制代码[root@localhost Document]# find . -type f -mtime +10 -ok rm {} \;&lt; rm ... ./newDir/text1 &gt; ? n&lt; rm ... ./newDir/text2 &gt; ? n&lt; rm ... ./text1/newDir/text1 &gt; ? n&lt; rm ... ./text1/newDir/text2 &gt; ? n&lt; rm ... ./text2/newDir/text1 &gt; ? n&lt; rm ... ./text2/newDir/text2 &gt; ? n&lt; rm ... ./text3/text1 &gt; ? n&lt; rm ... ./text3/text2 &gt; ? n&lt; rm ... ./text4/text1 &gt; ? n&lt; rm ... ./text4/text2 &gt; ? n&lt; rm ... ./mytext &gt; ? n&lt; rm ... ./mytext.txt &gt; ? n</code></pre><hr><pre><code>4)[root@localhost Document]# find /etc -name "passwd*" -exec grep "root" {} \;　　　　　　查看查询出来的文件中有没有root用户复制代码[root@localhost Document]# ll                          //此目录下有用户文件，也有root文件总用量 0-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  18 02:24 grepTest-rw-r--r--. 1 root      root       0 5月   6 22:15 mytext-rw-r--r--. 1 root      root       0 5月   6 22:15 mytext.txtdrwxr-xr-x. 2 root      root      30 5月   6 22:02 newDir-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月  18 02:34 userfile[root@localhost Document]# find /etc -name "passwd*" -exec grep "root" {} \;         //用grep命令查看在这些文件中是否存在一个root用户。（不太清楚什么意思）root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinroot:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin[root@localhost Document]# find . -type f -exec grep "root" {} \;　　　　　　　　　　　　//然而用这个命令，一点反应没有！</code></pre><hr><pre><code>5)[root@localhost Document]# find . -name "mv*" -exec mv {} newDir \;　　将查询到的内容移动到newDir目录下复制代码[root@localhost Document]# lsnewDir[root@localhost Document]# touch {mvt1.txt,mvt2.txt,mvt3.txt}[root@localhost Document]# find . -name "mv*" -exec ls -l {} \;-rw-r--r--. 1 root root 0 5月  18 02:46 ./mvt1.txt-rw-r--r--. 1 root root 0 5月  18 02:46 ./mvt2.txt-rw-r--r--. 1 root root 0 5月  18 02:46 ./mvt3.txt[root@localhost Document]# find . -name "mv*" -exec mv newDir {} \;　　//注意顺序不要弄错mv: 无法以目录"newDir" 来覆盖非目录"./mvt1.txt"mv: 无法以目录"newDir" 来覆盖非目录"./mvt2.txt"mv: 无法以目录"newDir" 来覆盖非目录"./mvt3.txt"[root@localhost Document]# find . -name "mv*" -exec mv {} newDir \;    //mv命令将前面的文件集移动到后面的文件夹中[root@localhost Document]# ll总用量 0drwxr-xr-x. 2 root root 51 5月  18 02:47 newDir[root@localhost Document]# ls -l ./newDir总用量 0-rw-r--r--. 1 root root 0 5月  18 02:46 mvt1.txt-rw-r--r--. 1 root root 0 5月  18 02:46 mvt2.txt-rw-r--r--. 1 root root 0 5月  18 02:46 mvt3.txt</code></pre><hr><pre><code>6)[root@localhost sunjimeng]# find . -name "t*.txt" -mtime -1 -exec cat {} \; &gt; ./Document/all.txt　　　合并查询到的多个文件的文本内容到一个新的文件复制代码[root@localhost Document]# ll　　　　　　　　　　　　//查看当前目录总用量 0drwxr-xr-x. 2 root root 51 5月  18 02:47 newDir[root@localhost Document]# cat &gt;t1.txt &lt;&lt;EOF     //新建t1.txt&gt; this is t1.txt!&gt; I'm testing -exec option!&gt; EOF[root@localhost Document]# cat &gt;t2.txt &lt;&lt;EOF     //新建t2.txt&gt; this is t2.txt!&gt; I'm testing -exec optioin!&gt; EOF[root@localhost Document]# cd ../[root@localhost sunjimeng]# find -name "t*.txt" -exec ls -l {} \;             //查出了很多，前几项红的不是我们要的-rw-rw-r--. 1 sunjimeng sunjimeng 58 5月   4 21:45 ./.local/share/Trash/files/test1.txt-rw-rw-r--. 1 sunjimeng sunjimeng 61 5月   4 21:46 ./.local/share/Trash/files/test2.txt-rw-rw-r--. 1 sunjimeng sunjimeng 61 5月   4 21:47 ./.local/share/Trash/files/test3.txt-rw-r--r--. 1 root root 42 5月  18 02:53 ./Document/t1.txt-rw-r--r--. 1 root root 43 5月  18 02:54 ./Document/t2.txt[root@localhost sunjimeng]# find -name "t*.txt" -mtime -1 -exec ls -l {} \;   //加上日期限制为一天以内修改过的之后，显示正确的文件-rw-r--r--. 1 root root 42 5月  18 02:53 ./Document/t1.txt-rw-r--r--. 1 root root 43 5月  18 02:54 ./Document/t2.txt[root@localhost sunjimeng]# find . -name "t*.txt" -mtime -1 -exec cat {} \; &gt; ./Document/all.txt   //将文件输出到当前子目录Document下的all.txt文件中，如果不存在则创建[root@localhost sunjimeng]# cat ./Document/all.txtthis is t1.txt!I'm testing -exec option!this is t2.txt!I'm testing -exec optioin!</code></pre><hr><pre><code>7)[root@localhost sunjimeng]# find ./Documents -type f -name "*.txt" -exec printf "File: %s\n" {} \;　　　　将查询到的文件当作字符数组，用类似c语言的printf的形式控制格式输出复制代码[root@localhost sunjimeng]# find ./Documents -type f -name "*.txt" -exec printf "File: %s\n" {} \; File: ./Documents/findDir/t1.txtFile: ./Documents/findDir/T1.txtFile: ./Documents/findDir/T2.txt[root@localhost sunjimeng]# find ./Documents -type f -name "*.txt" -exec printf "File: %s\n\n" {} \;  //也可以多加一个\nFile: ./Documents/findDir/t1.txtFile: ./Documents/findDir/T1.txtFile: ./Documents/findDir/T2.txt[root@localhost sunjimeng]# 复制代码</code></pre><hr><pre><code>(4)其他:Linux中exec命令相关:bash shell的命令分为两类：外部命令和内部命令。外部命令是通过系统调用或独立的程序实现的，如sed、awk等等。内部命令是由特殊的文件格式(.def)所实现，如cd、history、exec等等。1. 系统调用exec是以新的进程去代替原来的进程，但进程的PID保持不变。因此，可以这样认为，exec系统调用并没有创建新的进程，只是替换了原来进程上下文的内容。原进程的代码段，数据段，堆栈段被新的进程所代替。fork的概念 fork是linux的系统调用，用来创建子进程(child process)。子进程是父进程(parent process)的一个副本，从父进程那里获得一定的资源分配以及继承父进程的环境。子进程与父进程唯一不同的地方在于pid(process id)。 一个进程主要包括以下几个方面的内容:  (1)一个可以执行的程序  (2) 与进程相关联的全部数据(包括变量，内存，缓冲区)  (3)程序上下文(程序计数器PC,保存程序执行的位置)2. exec是一个函数簇，由6个函数组成，分别是以excl和execv打头的。 3. 执行exec系统调用，一般都是这样，用fork()函数新建立一个进程，然后让进程去执行exec调用。4. 我们知道，在fork()建立 新进程之后，父进各与子进程共享代码段，但数据空间是分开的，5. 但父进程会把自己数据空间的内容copy到子进程中去，还有上 下文也会copy到子进程中去。6. 而为了提高效率，采用一种写时copy的策略，即创建子进程的时候，并不copy父进程的地址空间， 7. 父子进程拥有共同的地址空间，只有当子进程需要写入数据时(如向缓冲区写入数据),这时候会复制地址空间，8. 复制缓冲区到子 进程中去。从而父子进程拥有独立的地址空间。而对于fork()之后执行exec后，9. 这种策略能够很好的提高效率，如果一开始就 copy,那么exec之后，子进程的数据会被放弃，被新的进程所代替。</code></pre><h2 id="2017-07-23-每天2个Linux-find命令-xargs参数"><a href="#2017-07-23-每天2个Linux-find命令-xargs参数" class="headerlink" title=" 2017-07-23 每天2个Linux find命令_xargs参数"></a><center> 2017-07-23 每天2个Linux find命令_xargs参数</center></h2><p>xargs 与 exec 的作用类似，但是xargs与find 一起使用时，一般配合管道一起使用。</p><p>前面的输出转换为后方指令的参数输入，使用exec和xargs可以使用户对所匹配到的文件执行几乎所有的命令。</p><p>(1)用法:</p><pre><code>用法:  [find命令] | [xargs] [其他命令]</code></pre><p>(2)功能:</p><pre><code> 功能: 该命令的主要功能是从输入中构建和执行shell命令。与-exec类似，将find找到的文件当作参数执行接下来的命令。</code></pre><p>(3)xargs参数的解释</p><pre><code>在使用find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高；  而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。</code></pre><p>(4)实例:</p><pre><code>  1)[root@localhost Documents]# find . -type f -print     　　　　find的输出到标准输出的参数-print复制代码[root@localhost Documents]# find . -type f  -print    //等价于find . -type f 因为默认是输出到标准输出的，所以加不加标准输出-print一样./less1./less2./head_text./tail_text./tempory./newlocate./uText./findDir/t1.txt./findDir/T1.txt./findDir/T2.txt./findDir/p1.pdf./findDir/p2.pdf</code></pre><hr><pre><code>2)[root@localhost Documents]# find . -type f -print | xargs file　　　　　　　 查找当前目录下的每一个普通文件，然后使用xargs命令来测试它们分别属于哪类文件复制代码[root@localhost Documents]# find . -type f -print | xargs file./less1:          ASCII text./less2:          ASCII text./head_text:      ASCII text./tail_text:      ASCII text./tempory:        ASCII text./newlocate:      empty./uText:          empty./findDir/t1.txt: empty./findDir/T1.txt: empty./findDir/T2.txt: empty./findDir/p1.pdf: empty./findDir/p2.pdf: empty</code></pre><hr><pre><code>3)[root@localhost Documents]# find . -type f | xargs ls -l　　列出每个查找到的文件的详细信息，包括相对路径复制代码[root@localhost Documents]# find . -type f | xargs ll           //为每一个找到的文件执行ll命令显然是不行的(虽然ll是“ls -l”的缩写)xargs: ll: 没有那个文件或目录[root@localhost Documents]# find . -type f | xargs ls -l-rw-r--r--. 1 root root   0 5月  17 04:18 ./findDir/p1.pdf-rw-r--r--. 1 root root   0 5月  17 04:18 ./findDir/p2.pdf-rw-r--r--. 1 root root   0 5月  17 03:50 ./findDir/t1.txt-rw-r--r--. 1 root root   0 5月  17 04:02 ./findDir/T1.txt-rw-r--r--. 1 root root   0 5月  17 04:02 ./findDir/T2.txt-rw-r--r--. 1 root root 664 5月   9 07:59 ./head_text-rw-r--r--. 1 root root  45 5月   9 08:15 ./less1-rw-r--r--. 1 root root  57 5月   9 08:16 ./less2-rw-r--r--. 1 root root   0 5月  15 18:21 ./newlocate-rw-r--r--. 1 root root 259 5月  12 21:53 ./tail_text-rw-r--r--. 1 root root 216 5月  12 22:24 ./tempory-rw-r--r--. 1 root root   0 5月  15 18:34 ./uText[root@localhost Documents]# ls -l总用量 20drwxr-xr-x. 2 root root  71 5月  17 04:18 findDir-rw-r--r--. 1 root root 664 5月   9 07:59 head_text-rw-r--r--. 1 root root  45 5月   9 08:15 less1-rw-r--r--. 1 root root  57 5月   9 08:16 less2-rw-r--r--. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root 259 5月  12 21:53 tail_text-rw-r--r--. 1 root root 216 5月  12 22:24 tempory-rw-r--r--. 1 root root   0 5月  15 18:34 uText</code></pre><hr><pre><code>4)[root@localhost Documents]# find . -type f -print | xargs chmod a-r　　　　　　　　　回收文件的权限(r代表读，w代表写，r代表可执行)复制代码[root@localhost Documents]# find . -type f -print | xargs chmod a-x    //回收x权限[root@localhost Documents]# ll总用量 20drwxr-xr-x. 2 root root  71 5月  17 04:18 findDir-rw-r--r--. 1 root root 664 5月   9 07:59 head_text-rw-r--r--. 1 root root  45 5月   9 08:15 less1-rw-r--r--. 1 root root  57 5月   9 08:16 less2-rw-r--r--. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root 259 5月  12 21:53 tail_text-rw-r--r--. 1 root root 216 5月  12 22:24 tempory-rw-r--r--. 1 root root   0 5月  15 18:34 uText[root@localhost Documents]# find . -type f -print | xargs chmod a-r  //回收r权限[root@localhost Documents]# ll总用量 20drwxr-xr-x. 2 root root  71 5月  17 04:18 findDir--w-------. 1 root root 664 5月   9 07:59 head_text--w-------. 1 root root  45 5月   9 08:15 less1--w-------. 1 root root  57 5月   9 08:16 less2--w-------. 1 root root   0 5月  15 18:21 newlocate--w-------. 1 root root 259 5月  12 21:53 tail_text--w-------. 1 root root 216 5月  12 22:24 tempory--w-------. 1 root root   0 5月  15 18:34 uText</code></pre><hr><pre><code>5)[root@localhost sunjimeng]# find ./Document -name "all.txt" -print | xargs echo "Success" &gt;/home/sunjimeng/Documents/core.log      将找到的文件加上相对路径和自定义字符串输出到另一个文件中复制代码[root@localhost Document]# cat all.txtthis is t1.txt!I'm testing -exec option!this is t2.txt!I'm testing -exec optioin![root@localhost Document]# cd ./[root@localhost Document]# cd ../[root@localhost sunjimeng]# find ./Document -name "all.txt" -print | xargs echo "Success" &gt;/home/sunjimeng/Documents/core.log[root@localhost sunjimeng]# cat /home/sunjimeng/Documents/core.log   //可以看出上个命令将什么拷进了自定义文件中Success ./Document/all.txt[root@localhost sunjimeng]# find ./Document -name "all.txt"./Document/all.txt</code></pre><hr><pre><code>6)[root@localhost sunjimeng]# find ./Document -name "all.txt" | xargs cat &gt;/home/sunjimeng/Documents/t3.txt          将找到的文件内容拷贝到另一个文件中复制代码[root@localhost Document]# cat all.txtthis is t1.txt!I'm testing -exec option!this is t2.txt!I'm testing -exec optioin![root@localhost sunjimeng]# find ./Document -name "all.txt" | xargs cat &gt;/home/sunjimeng/Documents/t3.txt  //（5）输出的是自定义内容，而这个命令是把找到的文件内容拷贝一份到自定义文件中[root@localhost sunjimeng]# cat /home/sunjimeng/Documents/t3.txtthis is t1.txt!I'm testing -exec option!this is t2.txt!I'm testing -exec optioin!复制代码</code></pre><hr><pre><code>7)[root@localhost sunjimeng]# find ./ -type f | xargs ls -l | awk 'BEGIN{size=0}{size+=$5};END{print size}'          统计当前目录下所有文件的大小,含子目录,精确到字节[root@localhost sunjimeng]# find ./ -type f | xargs ls -l | awk 'BEGIN{size=0}{size+=$5};END{print size}'5173736</code></pre><hr><pre><code>8)[root@localhost Documents]# find . -type f -print | xargs grep "Lost"　　　　　　　　查找find找到的文件中有没有包含"Lost"字符串的复制代码[root@localhost Documents]# find . -type f -print | xargs grep "t3.txt" //虽然当前目录下有t3.txt，但查询的结果却为空[root@localhost Documents]# find . -type f -print./less1./less2./head_text./tail_text./tempory./newlocate./uText./findDir/t1.txt./findDir/T1.txt./findDir/T2.txt./findDir/p1.pdf./findDir/p2.pdf./find./core.log./t3.txt复制代码复制代码[root@localhost Documents]# cat less1Lost means Get!No losing No getting!End![root@localhost Documents]# find . -type f -print | xargs grep "Lost"       //表明它是根据文件内容进行匹配的，而不是根据查找到的文件的名字。./less1:Lost means Get!</code></pre><hr><pre><code>9)[root@localhost findDir]# find -type f -name "t1.txt" -print |xargs -p mv t2.txt　　　</code></pre><p>　　　提醒是否执行find后面的其他命令</p><pre><code>[root@localhost findDir]# find -type f -name "t1.txt" -print |xargs -p mv t2.txt         这里用mv命令出了错误，后面解决！mv t2.txt ./t1.txt ?...n[root@localhost findDir]# find -type f -name "t1.txt" -print |xargs -p mv t2.txtmv t2.txt ./t1.txt ?...ymv: 无法获取"t2.txt" 的文件状态(stat): 没有那个文件或目录</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>springMVC学习-02</title>
      <link href="/2017/07/24/springmvc-xue-xi-02/"/>
      <url>/2017/07/24/springmvc-xue-xi-02/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-20-springMVC-02"><a href="#2017-07-20-springMVC-02" class="headerlink" title=" 2017-07-20 springMVC-02"></a><center> 2017-07-20 springMVC-02</center></h2><p>Springmvc第二天</p><pre><code>@responseBody和@RequestBody@responseBody把后台pojo转换json对象，返回到页面。@RequestBody接受前台json数据，把json数据自动封装javaBean</code></pre><p>导入json的jar</p><p><img src="/images/20170720/63.png"></p><p>修改springmvc</p><p><img src="/images/20170720/64.png"></p><pre><code>页面传递json格式Ajax传递 json格式数据</code></pre><p><img src="/images/20170720/65.png"></p><p>后台代码</p><p><img src="/images/20170720/66.png"></p><hr><p>需求：pojo，后台返回json<br>前台请求数据构造：key=value&amp;key=value.</p><p>页面</p><p><img src="/images/20170720/67.png"></p><p>代码</p><p><img src="/images/20170720/68.png"></p><hr><p>Springmvc多视图</p><pre><code>导入xml格式支持jar</code></pre><p><img src="/images/20170720/69.png"></p><pre><code>配置springmvc支持多视图&lt;bean class="org.springframework.web.servlet.view.ContentNegotiatingViewResolver"&gt;    &lt;!-- 配置支持媒体类型 --&gt;    &lt;property name="contentNegotiationManager"&gt;    &lt;bean class="org.springframework.web.accept.ContentNegotiationManagerFactoryBean"&gt;    &lt;property name="mediaTypes"&gt;    &lt;map&gt;    &lt;entry key="json" value="application/json"&gt;&lt;/entry&gt;    &lt;entry key="xml" value="application/xml"&gt;&lt;/entry&gt;            &lt;/map&gt;            &lt;/property&gt;    &lt;/bean&gt;    &lt;/property&gt;    &lt;!-- 指定默认视图 --&gt;    &lt;property name="defaultViews"&gt;    &lt;!-- 支持多个视图 --&gt;    &lt;list&gt;    &lt;!-- 对josn格式视图支持 --&gt;    &lt;bean class="org.springframework.web.servlet.view.json.MappingJacksonJsonView"&gt;&lt;/bean&gt;    &lt;!-- xml格式视图支持 --&gt;    &lt;bean class="org.springframework.web.servlet.view.xml.MarshallingView"&gt;    &lt;constructor-arg&gt;    &lt;bean class="org.springframework.oxm.jaxb.Jaxb2Marshaller"&gt;    &lt;property name="classesToBeBound"&gt;    &lt;list&gt;    &lt;value&gt;cn.itcast.domain.User&lt;/value&gt;    &lt;/list&gt;    &lt;/property&gt;    &lt;/bean&gt;    &lt;/constructor-arg&gt;    &lt;/bean&gt;    &lt;/list&gt;    &lt;/property&gt;    &lt;/bean&gt;</code></pre><p>代码</p><p><img src="/images/20170720/70.png"></p><p>访问</p><pre><code>约定rest目录下所有以json和xml扩展名都支持相应的视图</code></pre><p><img src="/images/20170720/71.png"></p><p><img src="/images/20170720/72.png"></p><hr><p>Ssm</p><pre><code>导入jar导入spring(包含springmvc)，mybatis，mybatis-spring整合。数据库驱动，jstl，c3p0管理数据源，log4j.</code></pre><p>创建一个web工程并导入jar</p><p><img src="/images/20170720/73.png"></p><p>配置web.xml入门文件<br>加载springmvc配置文件</p><p><img src="/images/20170720/74.png"></p><p>加载spring配置文件</p><pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans"xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc"xmlns:context="http://www.springframework.org/schema/context"xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx"xsi:schemaLocation="http://www.springframework.org/schema/beans     http://www.springframework.org/schema/beans/spring-beans-3.2.xsd     http://www.springframework.org/schema/mvc     http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd     http://www.springframework.org/schema/context     http://www.springframework.org/schema/context/spring-context-3.2.xsd     http://www.springframework.org/schema/aop     http://www.springframework.org/schema/aop/spring-aop-3.2.xsd     http://www.springframework.org/schema/tx     http://www.springframework.org/schema/tx/spring-tx-3.2.xsd"&gt;    &lt;context:component-scan base-package="cn.itcast"&gt;&lt;/context:component-scan&gt;&lt;!-- 第一步：配置数据源 --&gt;&lt;context:property-placeholder location="classpath:jdbc.properties" /&gt;&lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt;    &lt;property name="jdbcUrl" value="${jdbc.url}"&gt;&lt;/property&gt;    &lt;property name="driverClass" value="${jdbc.driver}"&gt;&lt;/property&gt;    &lt;property name="user" value="${jdbc.username}"&gt;&lt;/property&gt;    &lt;property name="password" value="${jdbc.password}"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 第二步：创建sqlSessionFactory。生产sqlSession --&gt;&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt;&lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;property name="configLocation" value="classpath:sqlMapConfig.xml"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置mybatis接口代理开发    * 接口类名和映射文件必须同名    *　接口类和映射文件必须在同一个目录　下    * 映射文件namespace名字必须是接口的全类路径名    *　接口的方法名必须和映射Statement的ｉｄ一致 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="cn.itcast.dao"&gt;&lt;/property&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;!-- 第三步：事务 --&gt;&lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;&lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置通知 --&gt;&lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt;&lt;tx:attributes&gt;&lt;tx:method name="save*" propagation="REQUIRED" /&gt;&lt;tx:method name="update*" propagation="REQUIRED" /&gt;&lt;tx:method name="delete*" propagation="REQUIRED" /&gt;&lt;tx:method name="insert*" propagation="REQUIRED" /&gt;&lt;tx:method name="*" propagation="REQUIRED" /&gt;    &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 配置拦截service --&gt;&lt;aop:config&gt;&lt;aop:advisor advice-ref="txAdvice" pointcut="execution(* cn.itcast.service.*.*(..))"/&gt;&lt;/aop:config&gt;&lt;/beans&gt;</code></pre><p>使用sqlGenarator自动生产。    </p><pre><code>Service层：@Resourceprivate ItemsMapper itemsMapper;public List&lt;Items&gt; findAll() {    List&lt;Items&gt; list =     itemsMapper.findAll();    return list;}public Items findByID(Integer id) {    Items items = itemsMapper.selectByPrimaryKey(id);    return items;}public void saveOrUpdate(Items items) {    itemsMapper.updateByPrimaryKey(items);}public void deleteByID(Integer id) {    itemsMapper.deleteByPrimaryKey(id);}Controllerpackage cn.itcast.controller;import java.util.List;import javax.annotation.Resource;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import cn.itcast.domain.Items;import cn.itcast.service.ItemsService;@Controller@RequestMapping("/items")public class ItemsController {@Resourceprivate ItemsService itemsService;//查询所有商品@RequestMapping("list")public String list(Model model){    List&lt;Items&gt; list = itemsService.findAll();    model.addAttribute("itemsList", list);    return "itemsList";}//跳转到修改页面@RequestMapping("edit")public String edit(Integer id , Model model){    //根据Id查询商品    Items items = itemsService.findByID(id);    //页面回显    model.addAttribute("item", items);    return "editItem";}@RequestMapping("saveOrUpdate")public String saveOrUpdate(Items items){    itemsService.saveOrUpdate(items);    return "redirect:list.do";}//根据Id进行删除@RequestMapping("deleteByID")public String deleteByID(Integer id){    itemsService.deleteByID(id);    return "redirect: list.do";}//批量删除@RequestMapping("deleteByIds")public String deleteByIds(Integer[] id){    for(Integer ids : id){        itemsService.deleteByID(ids);    }    return "redirect: list.do";}}</code></pre><hr><p>Springmvc文件上传</p><pre><code>导入jar跨服务器上传文件jar。Io，fileupload</code></pre><p><img src="/images/20170720/75.png"></p><pre><code>上传图片，图片里面回显。Ajax。页面不刷新图片回显。Ajax能不能提交表单？&lt;img src=”图片路径”/&gt;//把文件关联表单//触发ajax事件&lt;input type=file onchange=“ajax事件”/&gt;&lt;input type=”hidden” value=”图片相对路径”/&gt;</code></pre><p><img src="/images/20170720/76.png"></p><pre><code>模拟2台服务器：创建一个项目，图片服务器项目，图片服务器和上传图片的项目端口不一致。</code></pre><p><img src="/images/20170720/77.png"></p><pre><code>开启文件上传Springmvc配置文件配置支持文件上传类:</code></pre><p><img src="/images/20170720/78.png"></p><pre><code>页面ajax发送请求，上传图片：图片被关联表单。提交表单：jquery.form.js</code></pre><p><img src="/images/20170720/79.png"></p><pre><code>uploadController使用jersy服务器进行跨服务器上传：@Controller@RequestMapping("/upload")public class UploadController {@RequestMapping("uploadPic")public void uploadPic(HttpServletRequest request,String fileName,PrintWriter out){    //把Request强转成多部件请求对象    MultipartHttpServletRequest mh = (MultipartHttpServletRequest) request;    //根据文件名称获取文件对象    CommonsMultipartFile cm = (CommonsMultipartFile) mh.getFile(fileName);    //获取文件上传流    byte[] fbytes = cm.getBytes();    //文件名称在服务器有可能重复？    String newFileName="";    SimpleDateFormat sdf = new SimpleDateFormat("yyyyMMddHHmmssSSS");    newFileName = sdf.format(new Date());    Random r = new Random();    for(int i =0 ;i&lt;3;i++){        newFileName=newFileName+r.nextInt(10);    }    //获取文件扩展名    String originalFilename = cm.getOriginalFilename();    String suffix = originalFilename.substring(originalFilename.lastIndexOf("."));    //创建jesy服务器，进行跨服务器上传    Client client = Client.create();    //把文件关联到远程服务器    WebResource resource = client.resource(Commons.PIC_HOST+"/upload/"+newFileName+suffix);    //上传    resource.put(String.class, fbytes);    //ajax回调函数需要会写写什么东西？    //图片需要回显：需要图片完整路径    //数据库保存图片的相对路径.    String fullPath = Commons.PIC_HOST+"/upload/"+newFileName+suffix;    String relativePath="/upload/"+newFileName+suffix;    //{"":"","":""}    String result="{\"fullPath\":\""+fullPath+"\",\"relativePath\":\""+relativePath+"\"}";    out.print(result);}修改图片服务器文件上传权限</code></pre><p><img src="/images/20170720/80.png"></p><pre><code>图片上传位置</code></pre><p><img src="/images/20170720/81.png"></p><hr><p>页面缓存</p><pre><code>简单理解缓存原理</code></pre><p><img src="/images/20170720/82.png"></p><pre><code>互联网架构</code></pre><p><img src="/images/20170720/83.png"></p><pre><code>页面缓存使用Oscache实现页面缓存。测试页面缓存创建web工程，导入jar</code></pre><p><img src="/images/20170720/84.png"></p><pre><code>测试创建一个index.jsp页面，使用时间来测试：</code></pre><p><img src="/images/20170720/85.png"></p><pre><code>访问地址http://localhost:8080/Oscache19/index.jsphttp://localhost:8080/Oscache19/分析：上面2个地址都访问同一个页面，为什么缓存会变化？缓存原理：缓存数据结构：map，key存储浏览器访问url，上面2个url不一致，缓存肯定变化。Value：缓存页面数据存储范围缓存默认存储在application域当中。改变缓存Session</code></pre><p><img src="/images/20170720/86.png"></p><pre><code>固定缓存key</code></pre><p><img src="/images/20170720/87.png"></p><pre><code>每隔4秒同步一次</code></pre><p><img src="/images/20170720/88.png"></p><pre><code>缓存持久化创建oscache.properties这个配置文件必须在classpath下面：</code></pre><p><img src="/images/20170720/89.png"></p><pre><code>cache.memory=falsecache.persistence.class=com.opensymphony.oscache.plugins.diskpersistence.DiskPersistenceListenercache.path=F:\\cache持久化文件</code></pre><p><img src="/images/20170720/90.png"></p><hr><p>Oscache整合ssm项目</p><pre><code>约定：商品页面访问量特别大，给商品页面缓存。  Items路径下所有请求都缓存。</code></pre><p><img src="/images/20170720/91.png"></p><pre><code>测试缓存：打一个断点(给商品查询列表)，第一次断点必须走，第二次断点不走，走缓存页面。Springmvc的freemarker支持分析：需要jarFreemarker的jar，context-support.jar配置freemarker视图支持</code></pre><p><img src="/images/20170720/92.png"></p><pre><code>编写freemarker页面</code></pre><p><img src="/images/20170720/93.png"></p><pre><code>代码</code></pre><p><img src="/images/20170720/94.png">    </p><pre><code>修改itemsList页面</code></pre><p><img src="/images/20170720/95.png"></p><p><img src="/images/20170720/96.png"></p><hr><p>拦截器</p><pre><code>局部拦截器针对单个处理器映射器，就叫局部拦截器。全局拦截器</code></pre><p><img src="/images/20170720/97.png"></p><pre><code>测试第一个拦截器放行，第二个拦截器也放行：这是第一个拦截器Interceptor1。。。preHandle这是第二个拦截器Interceptor2。。。preHandle这是第二个拦截器Interceptor2。。。postHandle这是第一个拦截器Interceptor1。。。postHandle这是第二个拦截器Interceptor2。。。afterCompletion这是第一个拦截器Interceptor1。。。afterCompletion第一个拦截器放行，第二个不放行：Springmvc规定：凡是preHandle返回true，afterCompletion必须执行。这是第一个拦截器Interceptor1。。。preHandle这是第二个拦截器Interceptor2。。。preHandle这是第一个拦截器Interceptor1。。。afterCompletion</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> springMVC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>springMVC学习-01</title>
      <link href="/2017/07/24/springmvc-xue-xi-01/"/>
      <url>/2017/07/24/springmvc-xue-xi-01/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-20-springMVC-01"><a href="#2017-07-20-springMVC-01" class="headerlink" title=" 2017-07-20 springMVC-01"></a><center> 2017-07-20 springMVC-01</center></h2><p>Springmvc</p><p>JAVAEE体系结构</p><p><img src="/images/20170720/1.png"></p><p>什么是mvc？</p><p><img src="/images/20170720/2.png"></p><p>Model2：</p><p><img src="/images/20170720/3.png"></p><p>Springmvc是什么?</p><p>Springmvc是一个web层mvc框架，类似struts2.</p><p>Springmvc和spring？</p><p><img src="/images/20170720/4.png"></p><p>Springmvc是spring的部分</p><p>Springmvc执行流程</p><p>Struts2执行流程：</p><pre><code>    strutsPrepareAndExcuteFilter拦截请求（控制层），拦截请求，转发请求    寻找Action执行    ActionProxy：strutsActionProxy extends defaultActionProxy    ActionMapping去寻找执行类Action根据mvc设计模式：自己来设计springmvc？</code></pre><p><img src="/images/20170720/5.png"></p><p>Springmvc入门程序</p><pre><code>创建一个web工程</code></pre><p><img src="/images/20170720/6.png"></p><pre><code>导入jar</code></pre><p><img src="/images/20170720/7.png"></p><pre><code>配置web.xml在web.xml配置前端控制器：DispatcherServlet</code></pre><p><img src="/images/20170720/8.png"></p><pre><code>配置springmvc.xml</code></pre><p><img src="/images/20170720/9.png"></p><pre><code>自定义Controller</code></pre><p><img src="/images/20170720/10.png"></p><pre><code>定义视图页面根据视图解析路径：WEB-INF/jsps/index.jsp</code></pre><p><img src="/images/20170720/11.png"></p><pre><code>根据代码分析springmvc执行流程</code></pre><p><img src="/images/20170720/12.png"></p><pre><code>适配器源码</code></pre><p><img src="/images/20170720/13.png"></p><hr><p>处理器映射器  </p><pre><code>BeanNameUrlHandlerMapping功能：寻找Controller  根据url请求去匹配bean的name属性url，从而获取Controller</code></pre><p><img src="/images/20170720/14.png"></p><pre><code>SimpleUrlHandlerMaping功能：寻找Controller  根据浏览器url匹配简单url的key，key又Controller的id找到Controller</code></pre><p><img src="/images/20170720/15.png"></p><pre><code>ControllerClassNameHandlerMapping功能：寻找Controller   根据类名（MyController）类名.do来访问,类名首字母小写</code></pre><p><img src="/images/20170720/16.png"></p><p>映射器之间能不能共存？   3个处理器映射器可以共存。</p><hr><p>处理器适配器</p><pre><code>SimpleControllerHandlerAdapter功能：执行controller  调用controller里面方法，返回modelAndView。</code></pre><p><img src="/images/20170720/17.png"></p><pre><code>HttpRequestHandlerAdapter功能：执行controller</code></pre><p><img src="/images/20170720/18.png"></p><p>2个处理器适配器能共存？<br>可以共存</p><hr><p>命令控制器</p><pre><code>Springmvc通过命令设计模式接受页面参数。</code></pre><p>自定义命令控制器</p><p><img src="/images/20170720/19.png"></p><p>定义javaBean</p><p><img src="/images/20170720/20.png"></p><p>封装参数页面</p><p><img src="/images/20170720/21.png"></p><p>跳转到add页面</p><pre><code>由于add页面在WEB-INF下面不能直接访问，需要通过Controller来访问。</code></pre><p><img src="/images/20170720/22.png"></p><p>在springmvc配置bean</p><p><img src="/images/20170720/23.png"></p><hr><p>中文乱码解决</p><pre><code>Get请求乱码</code></pre><p><img src="/images/20170720/24.png"></p><pre><code>Post乱码Spring编码过滤器：在web.xml配置</code></pre><p><img src="/images/20170720/25.png"></p><hr><p>时间类型转换</p><p><img src="/images/20170720/26.png"></p><hr><p>注解开发</p><pre><code>创建一个web工程，并导入jar</code></pre><p><img src="/images/20170720/27.png"></p><pre><code>配置web.xml</code></pre><p><img src="/images/20170720/28.png"></p><pre><code>    &lt;filter&gt;  &lt;filter-name&gt;characterEncoding&lt;/filter-name&gt;  &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;  &lt;init-param&gt;  &lt;param-name&gt;encoding&lt;/param-name&gt;  &lt;param-value&gt;UTF-8&lt;/param-value&gt;  &lt;/init-param&gt;  &lt;/filter&gt;  &lt;filter-mapping&gt;  &lt;filter-name&gt;characterEncoding&lt;/filter-name&gt;  &lt;url-pattern&gt;/*&lt;/url-pattern&gt;  &lt;/filter-mapping&gt;  &lt;servlet&gt;  &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;  &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;  &lt;!-- 默认加载方式         默认加载必须规范：         * 文件命名：servlet-name-servlet.xml====springmvc-servlet.xml         * 路径规范：必须在WEB-INF目录下面   --&gt;   &lt;init-param&gt;   &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;   &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;      &lt;/init-param&gt;  &lt;/servlet&gt;  &lt;servlet-mapping&gt;  &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;  &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;  &lt;/servlet-mapping&gt;配置springmvc配置文件&lt;context:component-scan base-package="cn.itcast"&gt;&lt;/context:component-scan&gt;        &lt;!-- 配置注解处理器映射器             功能：寻找执行类Controller        --&gt;        &lt;bean class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping"&gt;&lt;/bean&gt;        &lt;!-- 配置注解处理器适配器             功能：调用controller方法，执行controller        --&gt;        &lt;bean class="org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter"&gt;&lt;/bean&gt;        &lt;!-- 配置sprigmvc视图解析器：解析逻辑试图              后台返回逻辑试图：index            视图解析器解析出真正物理视图：前缀+逻辑试图+后缀====/WEB-INF/jsps/index.jsp        --&gt;        &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt;        &lt;property name="prefix" value="/WEB-INF/jsps/"&gt;&lt;/property&gt;        &lt;property name="suffix" value=".jsp"&gt;&lt;/property&gt;                &lt;/bean&gt;</code></pre><p>自定义Controller类</p><p><img src="/images/20170720/29.png"></p><p>注解开发流程</p><p><img src="/images/20170720/30.png"></p><p>RequestMapping</p><pre><code>requestMapping(“hello”)requestMapping(“/hello.do”)requestMapping(value=”/hello.do”)</code></pre><p><img src="/images/20170720/31.png"></p><pre><code>requestMapping(value=”/hello.do”,method=RequestMethod.POST)浏览器直接访问,a标签都是get请求表单提交(指定post)，ajax指定post提交，post提交。</code></pre><p><img src="/images/20170720/32.png"></p><p>RequestMaping根路径</p><pre><code>@RequestMapping（”/user”）UserController｛requestMapping(“save”)Save()requestMapping(“update”)Update{}requestMapping(“find”)Fiind()｝项目名/user/save.do@RequestMapping（”/items”）ItemsController｛requestMapping(“save”)Save()requestMapping(“update”)Update{}requestMapping(“find”)Fiind()｝项目名/items/save.do</code></pre><p>自定义根路径</p><p><img src="/images/20170720/33.png"></p><hr><p>封装参数</p><pre><code>分析接受参数类型：基本类型，int，String等等基本类型。Pojo类型包装类型Springmvc默认支持类型：HttpSession，HttpRequstServlet，Model等等。Struts2参数：基于属性封装。Springmvc参数封装：基于方法进行封装。</code></pre><p>基本类型</p><pre><code>需求封装int类型参数页面页面传递参数都是字符串。</code></pre><p><img src="/images/20170720/34.png"></p><pre><code>接受参数方法</code></pre><p><img src="/images/20170720/35.png"></p><pre><code>接受字符串类型页面</code></pre><p><img src="/images/20170720/36.png"></p><pre><code>代码</code></pre><p><img src="/images/20170720/37.png"></p><hr><pre><code>接受数组分析：批量删除：checkbox复选框。Value必须有值。</code></pre><p>页面</p><p><img src="/images/20170720/38.png"></p><p>代码</p><p><img src="/images/20170720/39.png"></p><hr><p>接受Pojo</p><p>页面</p><p><img src="/images/20170720/40.png"></p><p>代码</p><p><img src="/images/20170720/41.png"></p><p>接受包装类型参数</p><pre><code>userCustom｛private user user；private List&lt;User&gt; userList;private Map&lt;K,V&gt; maps;private items items;｝</code></pre><p>定义UserCustom</p><p><img src="/images/20170720/42.png"></p><p>页面</p><p><img src="/images/20170720/43.png"></p><p>代码</p><p><img src="/images/20170720/44.png"></p><p>接受集合类型参数</p><pre><code>接受list集合</code></pre><p><img src="/images/20170720/45.png"></p><p>接受map</p><pre><code>页面</code></pre><p><img src="/images/20170720/46.png"></p><p>代码</p><p><img src="/images/20170720/47.png"></p><pre><code>有了struts2，为什么还需要sprigmvc？实现机制：Struts2是基于过滤器实现的。Springmvc基于servlet实现。Servlet比过滤器快。运行速度：Struts2是多列请求来了以后，struts2创建多少个对象：ActionContext，valuestack，UserAction，ActionSuport，ModelDrivenuserAction里面属性：User对象，userlist集合等Springmvc是单列。参数封装来分析：Struts基于属性进行封装。Springmvc基于方法封装。</code></pre><hr><p>页面回显</p><pre><code>查询所有@RequestMapping("list")public String list(Model model){    //model    相当于application域对象    List&lt;User&gt; userList = new ArrayList&lt;User&gt;();    User user1 = new User();    user1.setId(1);    user1.setSex("男");    user1.setUsername("张山峰");    user1.setAddress("武当山");    user1.setBirthday(new Date());    User user2 = new User();    user2.setId(2);    user2.setSex("男2");    user2.setUsername("张山峰222");    user2.setAddress("武当山222");    user2.setBirthday(new Date());    User user3 = new User();    user3.setId(3);    user3.setSex("男3");    user3.setUsername("张山峰333");    user3.setAddress("武当山333");    user3.setBirthday(new Date());    userList.add(user1);    userList.add(user2);    userList.add(user3);    model.addAttribute("userList", userList);    return "list";}</code></pre><p>页面获取</p><p><img src="/images/20170720/48.png"></p><p>修改</p><p><img src="/images/20170720/49.png"></p><p>修改代码</p><p><img src="/images/20170720/50.png"></p><p>回显</p><p><img src="/images/20170720/51.png"></p><hr><p>URL模版映射</p><pre><code>url模版映射可以restfull软件架构。url模版映射过程</code></pre><p><img src="/images/20170720/52.png"></p><p>Restfull风格设计</p><p><img src="/images/20170720/53.png"></p><p>Web.xml拦截方式：在rest目录下所有请求都被拦截，servlet可以拦截目录</p><p><img src="/images/20170720/54.png"></p><p>{}:匹配接受页面Url路径参数<br>@Pathariable：{}里面参数注入后面参数里面</p><p><img src="/images/20170720/55.png"></p><hr><p>转发和重定向</p><pre><code>关键字：forward本类进行转发：本类方法与方法之间进行forward转发方式：方式一：return ”forward：list.do“；代码：</code></pre><p><img src="/images/20170720/56.png"></p><p>测试方式：在list方法打断点，如果断点能成功，证明转发成功。</p><p><img src="/images/20170720/57.png"></p><p>方式二：return ”forward：/user/list.do“；</p><p><img src="/images/20170720/58.png"></p><pre><code>注意：user根路径前面必须有/.跨类进行转发：转发方式：return ”forward：/items/list.do“；</code></pre><p><img src="/images/20170720/59.png"></p><pre><code>重定向关键字：redirect本类进行重定向：本类方法与方法之间进行redirect重定向方式：方式一：return ”redirect：list.do“；</code></pre><p><img src="/images/20170720/60.png"></p><p>方式二：return ”redirect：/user/list.do“；</p><p><img src="/images/20170720/61.png"></p><p>跨类进行重定向：<br>转发方式：return ”redirect：/items/list.do“；</p><p><img src="/images/20170720/62.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> springMVC </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 loacte find</title>
      <link href="/2017/07/24/mei-tian-2-ge-linux-ming-ling-loacte-find/"/>
      <url>/2017/07/24/mei-tian-2-ge-linux-ming-ling-loacte-find/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-22-每天2个Linux-loacte命令"><a href="#2017-07-22-每天2个Linux-loacte命令" class="headerlink" title=" 2017-07-22 每天2个Linux loacte命令"></a><center> 2017-07-22 每天2个Linux loacte命令</center></h2><p>locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。</p><p>(1)用法:</p><pre><code>用法:  Locate  [选项] [参数]</code></pre><p>(2)功能:</p><pre><code>功能:  在mlocate数据库中搜索条目,用来快速查找文件或目录</code></pre><p>(3)选项参数:</p><pre><code>1) -d&lt;目录&gt;或--database=&lt;目录&gt;:　　　　　　　　　　　　指定数据库所在的目录2) -i, --ignore-case　　　　　　　　　　　　　　　　　　　　匹配模式时忽略大小写区别3) --help:　　　　　　　　　　　　　　　　　　　　　　　　  显示帮助4) --version:　　　　　　　　　　　　　　　　　　　　　　　 显示版本信息5) -d, --database DBPATH 　　用 DBPATH 替代默认的数据库(/var/lib/mlocate/mlocate.db)</code></pre><p>(4)实例:</p><pre><code>1)[root@localhost Documents]# loacte less1      　　　　　　在各个目录下查找名为less1的这个文件或者文件夹复制代码[root@localhost Documents]# ll总用量 20-rw-r--r--. 1 root root 664 5月   9 07:59 head_text-rw-r--r--. 1 root root  45 5月   9 08:15 less1-rw-r--r--. 1 root root  57 5月   9 08:16 less2-rw-r--r--. 1 root root 259 5月  12 21:53 tail_text-rw-r--r--. 1 root root 216 5月  12 22:24 tempory[root@localhost Documents]# slocate less1   //经验证，已经没有slocate这个命令bash: slocate: 未找到命令...相似命令是： 'locate'[root@localhost Documents]# loacte less1bash: loacte: 未找到命令...相似命令是： 'locate'</code></pre><hr><pre><code>2)[root@localhost Documents]# locate Documents 　如果是搜索的是文件夹的名称，则默认会先显示该文件夹及以下的各个文件及文件夹复制代码[root@localhost Documents]# locate Documents/home/sunjimeng/Documents/home/sunjimeng/Documents/head_text/home/sunjimeng/Documents/less1/home/sunjimeng/Documents/less2/home/sunjimeng/Documents/tail_text/home/sunjimeng/Documents/tempory/usr/share/dbus-1/services/org.gnome.Documents.GDataMiner.service/usr/share/dbus-1/services/org.gnome.Documents.SearchProvider.service/usr/share/dbus-1/services/org.gnome.Documents.ZpjMiner.service/usr/share/glib-2.0/schemas/org.gnome.Documents.enums.xml</code></pre><hr><pre><code>3)[root@localhost Documents]# locate newlocate　和updatedb 为了避免新建的文件夹找不到，可以立即更新数据库(updatedb命令)            　　　　　　　  复制代码[root@localhost Documents]# touch newlocate                          //新建文件[root@localhost Documents]# ll  　　　　　　　　　　　　　　　　　　　　　 //已经存在总用量 20-rw-r--r--. 1 root root 664 5月   9 07:59 head_text-rw-r--r--. 1 root root  45 5月   9 08:15 less1-rw-r--r--. 1 root root  57 5月   9 08:16 less2-rw-r--r--. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root 259 5月  12 21:53 tail_text-rw-r--r--. 1 root root 216 5月  12 22:24 tempory[root@localhost Documents]# locate newlocate                         //但并找不到[root@localhost Documents]# updatedb　　　　　　　　　　　　　　　　　　  //更新数据库[root@localhost Documents]# locate newlocate　//待计算机反应2秒后，再执行locate命令，就能找到了/home/sunjimeng/Documents/newlocate</code></pre><hr><pre><code>4)查找指定目录下的某个文件，也可以用通配符[root@localhost /]# locate /home/sunjimeng/Documents/*e/home/sunjimeng/Documents/newlocate</code></pre><hr><pre><code>5)[root@localhost /]# locate -i /home/sunjimeng/Documents/*Cate                 在使用通配符时忽略大小写[root@localhost /]# locate -i /home/sunjimeng/Documents/*Cate/home/sunjimeng/Documents/newlocate[root@localhost /]# locate  /home/sunjimeng/Documents/*Cate[root@localhost /]# </code></pre><hr><pre><code>6)[root@localhost /]# locate /home/sunjimeng/Documents/le                         寻找以特定字符串开头的文件或文件夹复制代码[root@localhost /]# locate /home/sunjimeng/Documents/le                                    //不加通配符也可以/home/sunjimeng/Documents/less1/home/sunjimeng/Documents/less2[root@localhost /]# locate /home/sunjimeng/Documents/le*                     /home/sunjimeng/Documents/less1/home/sunjimeng/Documents/less2[root@localhost /]# </code></pre><hr><pre><code>7)[root@localhost Documents]# locate --help复制代码[root@localhost Documents]# locate --helpUsage: locate [OPTION]... [PATTERN]...Search for entries in a mlocate database.  -A, --all              only print entries that match all patterns  -b, --basename         match only the base name of path names  -c, --count            only print number of found entries  -d, --database DBPATH  use DBPATH instead of default database (which is                         /var/lib/mlocate/mlocate.db)  -e, --existing         only print entries for currently existing files  -L, --follow           follow trailing symbolic links when checking file                         existence (default)  -h, --help             print this help  -i, --ignore-case      ignore case distinctions when matching patterns  -l, --limit, -n LIMIT  limit output (or counting) to LIMIT entries  -m, --mmap             ignored, for backward compatibility  -P, --nofollow, -H     don't follow trailing symbolic links when checking file                         existence  -0, --null             separate entries with NUL on output  -S, --statistics       don't search for entries, print statistics about each                         used database  -q, --quiet            report no error messages about reading databases  -r, --regexp REGEXP    search for basic regexp REGEXP instead of patterns      --regex            patterns are extended regexps  -s, --stdio            ignored, for backward compatibility  -V, --version          print version information  -w, --wholename        match whole path name (default)将 bug 报告给 mitr@redhat.com.</code></pre><hr><pre><code>(5)其他:说明:  locate命令其实是find -name的另一种写法，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库/var/lib/locatedb，这个数据库中含有本地所有文件信息。Linux系统自动创建这个数据库，并且每天自动更新一次，所以使用locate命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库。  locate命令可以在搜寻数据库时快速找到档案，数据库由updatedb程序来更新，updatedb是由cron daemon周期性建立的，locate命令在搜寻数据库时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是locate所找到的档案若是最近才建立或 刚更名的，可能会找不到，在内定值中，updatedb每天会跑一次，可以由修改crontab来更新设定值。(etc/crontab)  locate指定用在搜寻符合条件的档案，它会去储存档案与目录名称的数据库内，寻找合乎范本样式条件的档案或目录录，可以使用特殊字元（如”*” 或”?”等）来指定范本样式，如指定范本为kcpa*ner, locate会找出所有起始字串为kcpa且结尾为ner的档案或目录，如名称为kcpartner若目录录名称为kcpa_ner则会列出该目录下包括 子目录在内的所有档案。</code></pre><h2 id="2017-07-22-每天2个Linux-find命令-初识"><a href="#2017-07-22-每天2个Linux-find命令-初识" class="headerlink" title=" 2017-07-22 每天2个Linux find命令_初识"></a><center> 2017-07-22 每天2个Linux find命令_初识</center></h2><p>Linux下find命令在目录结构中搜索文件，并执行指定的操作。</p><p>(1)用法:</p><pre><code>用法: find pathname    -option      [-print | -exec | -ok]find 路径名           选项参数    [-print | -exec | -ok]</code></pre><p>(2)功能:</p><pre><code> 功能：用于在文件树种查找文件，并作出相应的处理。</code></pre><p>(3)命令参数:</p><pre><code>1) pathname: 　　　　find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。  2) -print:　　　　　　 find命令将匹配的文件输出到标准输出。3) -exec:　　　　　　 find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为'command' { } \;注意{ }和\；之间的空格。4) -ok:　　　和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。</code></pre><p>(4)选项参数：</p><pre><code>  1) -name    　　　　      按照文件名查找文件。  2) -perm     　　　　     按照文件权限来查找文件。  3) -prune   　　　　      使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth    选项，那么-prune将被find命令忽略。 4) -user   　　 　　　　  按照文件属主来查找文件。5) -group   　　　　　　 按照文件所属的组来查找文件。6) -mtime  -n +n  　　  按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。find命令还有-atime和-ctime 选项，但它们都和-m time选项。  7) -nogroup  　　　　　 查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。  8) -nouser                   查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。  9) -newer file1 ! file2    查找更改时间比文件file1新但比文件file2旧的文件。10) -empty　　　　　　   查找长度为0的文件或文件夹11) -type  　　　　　　　 查找某一类型的文件，诸如：b                              -块设备文件。    d 　　　　　　　　　   - 目录。    c 　　　　　　　　      - 字符设备文件。    p 　　　　　　　　　   - 管道文件。    l 　　　　　　　　　　 - 符号链接文件。    f 　　　　　　　　　　 - 普通文件。12) -size n:　　　　　　　    [c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。13) -depth:　　　　　　　    在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 14) -fstype:　查找位于某一类型文件系统中的文件，这些文件系统类型通常可以在配置文件/etc/fstab中找到，该配置文件中包含了本系统中有关文件系统的信息。15) -mount:　　　　　　　   在查找文件时不跨越文件系统mount点。16) -follow:　　　　　　　   如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。17) -cpio:　　　　　　　　   对匹配的文件使用cpio命令，将这些文件备份到磁带设备中。18) -regex&lt;范本样式&gt;:      指定字符串作为寻找文件或目录的范本样式另外,下面三个的区别:-amin n   查找系统中最后N分钟访问的文件-atime n  查找系统中最后n*24小时访问的文件-cmin n   查找系统中最后N分钟被改变文件状态的文件-ctime n  查找系统中最后n*24小时被改变文件状态的文件-mmin n   查找系统中最后N分钟被改变文件数据的文件-mtime n  查找系统中最后n*24小时被改变文件数据的文件 </code></pre><hr><pre><code>(5)实例:  1)[root@localhost findDir]# find .　列出当前目录及子目录下所有文件和文件夹复制代码[root@localhost Documents]# touch ./findDir/t1.txt //在当前目录的子目录findDir目录下创建t1.txt文本文件[root@localhost Documents]# cd findDir[root@localhost findDir]# ll总用量 0-rw-r--r--. 1 root root 0 5月  17 03:50 t1.txt[root@localhost findDir]# find .../t1.txt[root@localhost findDir]# cd ../[root@localhost Documents]# find .../less1./less2./head_text./tail_text./tempory./newlocate./uText./findDir./findDir/t1.txt[root@localhost Documents]# 复制代码      用ls命令列出当前目录及子目录下所有文件和文件夹：复制代码[root@localhost Documents]# ls -Rl.:总用量 20drwxr-xr-x. 2 root root  19 5月  17 03:50 findDir-rw-r--r--. 1 root root 664 5月   9 07:59 head_text-rw-r--r--. 1 root root  45 5月   9 08:15 less1-rw-r--r--. 1 root root  57 5月   9 08:16 less2-rw-r--r--. 1 root root   0 5月  15 18:21 newlocate-rw-r--r--. 1 root root 259 5月  12 21:53 tail_text-rw-r--r--. 1 root root 216 5月  12 22:24 tempory-rw-r--r--. 1 root root   0 5月  15 18:34 uText./findDir:总用量 0-rw-r--r--. 1 root root 0 5月  17 03:50 t1.txt</code></pre><hr><pre><code> 2)[root@localhost /]# find /home/sunjimeng/Documents -name "*.txt"    　　   在特定目录下找到以.txt结尾的文件[root@localhost /]# find /home/sunjimeng/Documents -name "*.txt"/home/sunjimeng/Documents/findDir/t1.txt</code></pre><hr><pre><code>3)[root@localhost /]# find /home/sunjimeng/Documents -iname "T*"　　　　　在特定目录下找到以T开头的文件或文件夹，但忽略大小写(-i操作)复制代码[root@localhost /]# find /home/sunjimeng/Documents -name "T*"                                       //不忽略/home/sunjimeng/Documents/findDir/T1.txt/home/sunjimeng/Documents/findDir/T2.txt[root@localhost /]# find /home/sunjimeng/Documents -iname "T*"　　　　　　　　　　　　　　　　　　　　　　//忽略大小写/home/sunjimeng/Documents/tail_text/home/sunjimeng/Documents/tempory/home/sunjimeng/Documents/findDir/t1.txt/home/sunjimeng/Documents/findDir/T1.txt/home/sunjimeng/Documents/findDir/T2.txt</code></pre><hr><pre><code>4)[root@localhost /]# find /home/sunjimeng/Documents \( -name "*.txt" -o -name "*.pdf" \)　　用两个条件来查询文件复制代码[root@localhost /]# touch /home/sunjimeng/Documents/findDir/{p1.pdf,p2.pdf}[root@localhost /]# find /home/sunjimeng/Documents  \( -name "*.txt" -o -name "*.pdf" \)/home/sunjimeng/Documents/findDir/t1.txt/home/sunjimeng/Documents/findDir/T1.txt/home/sunjimeng/Documents/findDir/T2.txt/home/sunjimeng/Documents/findDir/p1.pdf/home/sunjimeng/Documents/findDir/p2.pdf[root@localhost /]# cd /home/sunjimeng/Documents/findDir[root@localhost findDir]# find . -name "*.txt" -o -name "*.pdf"./t1.txt./T1.txt./T2.txt./p1.pdf./p2.pdf</code></pre><hr><pre><code>5)[root@localhost /]# find /home/sunjimeng/Documents ! -name "*.txt" 　　　　找寻目录下不是以.txt结尾的文件或目录复制代码[root@localhost /]# find /home/sunjimeng/Documents ! -name  "*.txt"/home/sunjimeng/Documents/home/sunjimeng/Documents/less1/home/sunjimeng/Documents/less2/home/sunjimeng/Documents/head_text/home/sunjimeng/Documents/tail_text/home/sunjimeng/Documents/tempory/home/sunjimeng/Documents/newlocate/home/sunjimeng/Documents/uText/home/sunjimeng/Documents/findDir/home/sunjimeng/Documents/findDir/p1.pdf/home/sunjimeng/Documents/findDir/p2.pdf</code></pre><hr><pre><code>6)[root@localhost sunjimeng]# find /home/ -path "*cume*"　　在指定目录下的后代目录中进行路径匹配，匹配完成后列出匹配目录下的所有文件及文件夹及其子目录及文件。复制代码[root@localhost sunjimeng]# find /home/ -path "*cume*"           //等价于find /home -path "*cume*"/home/sunjimeng/Documents/home/sunjimeng/Documents/less1/home/sunjimeng/Documents/less2/home/sunjimeng/Documents/head_text/home/sunjimeng/Documents/tail_text/home/sunjimeng/Documents/tempory/home/sunjimeng/Documents/newlocate/home/sunjimeng/Documents/uText/home/sunjimeng/Documents/findDir/home/sunjimeng/Documents/findDir/t1.txt/home/sunjimeng/Documents/findDir/T1.txt/home/sunjimeng/Documents/findDir/T2.txt/home/sunjimeng/Documents/findDir/p1.pdf/home/sunjimeng/Documents/findDir/p2.pdf/home/sunjimeng/Document/home/sunjimeng/Document/newDir/home/sunjimeng/Document/newDir/text1/home/sunjimeng/Document/newDir/text2/home/sunjimeng/Document/text1/home/sunjimeng/Document/text1/newDir/home/sunjimeng/Document/text1/newDir/text1/home/sunjimeng/Document/text1/newDir/text2/home/sunjimeng/Document/text2/home/sunjimeng/Document/text2/newDir/home/sunjimeng/Document/text2/newDir/text1/home/sunjimeng/Document/text2/newDir/text2/home/sunjimeng/Document/text3/home/sunjimeng/Document/text3/text1/home/sunjimeng/Document/text3/text2/home/sunjimeng/Document/text4/home/sunjimeng/Document/text4/text1/home/sunjimeng/Document/text4/text2/home/sunjimeng/Document/mytext/home/sunjimeng/Document/mytext.txt</code></pre><hr><pre><code> 7)[root@localhost /]# find /home/sunjimeng -regex ".*\(txt\|pdf\)$"      　　　　  进行字符串匹配复制代码[root@localhost /]# find /home/sunjimeng -regex ".*\(\.txt\|\.pdf\)$"               //原始[root@localhost /]# find /home/sunjimeng -regex ".*\(.txt\|.pdf\)$"                 //去掉两个斜杠[root@localhost /]# find /home/sunjimeng -regex ".*\(txt\|pdf\)$"　　　　　　　　　　  //把点去了/home/sunjimeng/.cache/tracker/db-version.txt/home/sunjimeng/.cache/tracker/db-locale.txt/home/sunjimeng/.cache/tracker/miner-applications-locale.txt/home/sunjimeng/.cache/tracker/last-crawl.txt/home/sunjimeng/.cache/tracker/first-index.txt/home/sunjimeng/.local/share/Trash/files/test1.txt/home/sunjimeng/.local/share/Trash/files/test2.txt/home/sunjimeng/.local/share/Trash/files/test3.txt/home/sunjimeng/Documents/findDir/t1.txt/home/sunjimeng/Documents/findDir/T1.txt/home/sunjimeng/Documents/findDir/T2.txt/home/sunjimeng/Documents/findDir/p1.pdf/home/sunjimeng/Documents/findDir/p2.pdf/home/sunjimeng/Document/mytext.txt</code></pre><hr><pre><code>8)[root@localhost /]# find /home/sunjimeng/Documents -type d | p | f | c | l | b　查找特定类型的文件复制代码[root@localhost /]# find /home/sunjimeng/Documents -type d/home/sunjimeng/Documents/home/sunjimeng/Documents/findDir[root@localhost /]# find /home/sunjimeng/Documents -type p[root@localhost /]# find /home/sunjimeng/Documents -type f/home/sunjimeng/Documents/less1/home/sunjimeng/Documents/less2/home/sunjimeng/Documents/head_text/home/sunjimeng/Documents/tail_text/home/sunjimeng/Documents/tempory/home/sunjimeng/Documents/newlocate/home/sunjimeng/Documents/uText/home/sunjimeng/Documents/findDir/t1.txt/home/sunjimeng/Documents/findDir/T1.txt/home/sunjimeng/Documents/findDir/T2.txt/home/sunjimeng/Documents/findDir/p1.pdf/home/sunjimeng/Documents/findDir/p2.pdf</code></pre><hr><pre><code>9)[root@localhost /]# find /home -maxdepth 3 -type f　　　　　　　　　　　　　　找指定目录下的普通文件，文件目录深度不超过3复制代码[root@localhost /]# find /home -maxdepth 3 -type f/home/sunjimeng/.bash_logout/home/sunjimeng/.bash_profile/home/sunjimeng/.bashrc/home/sunjimeng/.config/user-dirs.dirs/home/sunjimeng/.config/user-dirs.locale/home/sunjimeng/.config/gnome-initial-setup-done/home/sunjimeng/.cache/event-sound-cache.tdb.localhost.localdomain.x86_64-redhat-linux-gnu/home/sunjimeng/.ICEauthority/home/sunjimeng/.esd_auth/home/sunjimeng/.bash_history/home/sunjimeng/Documents/less1/home/sunjimeng/Documents/less2/home/sunjimeng/Documents/head_text/home/sunjimeng/Documents/tail_text/home/sunjimeng/Documents/tempory/home/sunjimeng/Documents/newlocate/home/sunjimeng/Documents/uText/home/sunjimeng/Document/mytext/home/sunjimeng/Document/mytext.txt</code></pre><hr><pre><code>10)[root@localhost /]# find /home/sunjimeng -mindepth 5 -type d   找指定目录下的普通文件，文件目录深度不低于5复制代码[root@localhost /]# find /home/sunjimeng -mindepth 5 -type d/home/sunjimeng/.local/share/evolution/addressbook/trash/home/sunjimeng/.local/share/evolution/addressbook/system/home/sunjimeng/.local/share/evolution/addressbook/system/photos/home/sunjimeng/.local/share/evolution/calendar/trash/home/sunjimeng/.local/share/evolution/calendar/system/home/sunjimeng/.local/share/evolution/mail/trash/home/sunjimeng/.local/share/evolution/memos/trash/home/sunjimeng/.local/share/evolution/tasks/trash/home/sunjimeng/.local/share/Trash/files/未命名文件夹</code></pre><hr><pre><code>11)[root@localhost /]# find /home/sunjimeng/Documents -atime -2　　　　　　　　查找指定时间内修改过的文件复制代码[root@localhost /]# find /home/sunjimeng/Documents -atime -2　　　　　　　　　　//两个以内/home/sunjimeng/Documents/home/sunjimeng/Documents/newlocate/home/sunjimeng/Documents/uText/home/sunjimeng/Documents/findDir/home/sunjimeng/Documents/findDir/t1.txt/home/sunjimeng/Documents/findDir/T1.txt/home/sunjimeng/Documents/findDir/T2.txt/home/sunjimeng/Documents/findDir/p1.pdf/home/sunjimeng/Documents/findDir/p2.pdf[root@localhost /]# find /home/sunjimeng/Documents -atime -1　　　　　　　　   //一天以内/home/sunjimeng/Documents/home/sunjimeng/Documents/findDir/home/sunjimeng/Documents/findDir/t1.txt/home/sunjimeng/Documents/findDir/T1.txt/home/sunjimeng/Documents/findDir/T2.txt/home/sunjimeng/Documents/findDir/p1.pdf/home/sunjimeng/Documents/findDir/p2.pdf</code></pre><hr><pre><code>12)[root@localhost /]# find . -perm 777　　　　　　　　　　　　　　　　　　　　　　查找权限为777的文件及文件夹[root@localhost /]# find . -perm 777[root@localhost /]# find /usr/libexec/gcc -perm 777/usr/libexec/gcc/x86_64-redhat-linux/4.8.2/liblto_plugin.so/usr/libexec/gcc/x86_64-redhat-linux/4.8.2/liblto_plugin.so.0/usr/libexec/gcc/x86_64-redhat-linux/4.8.3</code></pre><hr><pre><code>(6)其他:  权限：  读取权限 r = 4  写入权限 w = 2  执行权限 x = 1  775这三个数字代表拥有者，组用户，其他用户的权限。  例如： 7 拥有者有 读取，写入，执行权限 7 组用户有 读取，写入，执行权限           5 其他用户有 读取，执行权限(4+1 = 5)  777 与 775的区别是：其他用户有写入权限，而775的没有。linux下设置777权限和用户权限 设置www目录的所有文件可写777sudo chmod 777 -R www  (这里－R是继承)  设置www目录下的所有文件权限为user所有  sudo chown -hR user www  exit    linux下账户的权限是:drwx------ 表示是那些权限?  首先d是代表这个是一个目录文件，rwx是属主权限rw代表可读写x代表可执行，后面三个---是属主同组的权限，如果是---代表没有权限，最后三个是除文件属主组以外所有人的权限，---也是没有权限，所以这个目录只有属主有权限进入，其他人连读的权限也没有，更不用说写入和执行。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 which whereis</title>
      <link href="/2017/07/24/mei-tian-2-ge-linux-ming-ling-which-whereis/"/>
      <url>/2017/07/24/mei-tian-2-ge-linux-ming-ling-which-whereis/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-21-每天2个Linux-which命令"><a href="#2017-07-21-每天2个Linux-which命令" class="headerlink" title=" 2017-07-21 每天2个Linux which命令"></a><center> 2017-07-21 每天2个Linux which命令</center></h2><p>which命令用于查找并显示给定命令的绝对路径。</p><p>环境变量PATH中保存了查找命令时需要遍历的目录。<br><br>which指令会在环境变量$PATH设置的目录里查找符合条件的文件。<br><br>也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。</p><hr><p>(1)用法:</p><pre><code>用法:  which  [选项参数] [命令名]</code></pre><p>(2)功能:</p><pre><code>功能:查找环境变量中的文件</code></pre><p>(3)选项参数:</p><pre><code>  1) -n 　　　　　　　　　　　　指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。    2) -p                                   与-n参数相同，但此处的包括了文件的路径。    3) -w                                   指定输出时栏位的宽度。    4) -V                                   显示版本信息**</code></pre><hr><p>(4)实例:</p><pre><code>  1)[root@localhost sunjimeng]# which pwd    查看命令所在目录[root@localhost sunjimeng]# which pwd/usr/bin/pwd[root@localhost sunjimeng]# which head/usr/bin/head[root@localhost sunjimeng]# which cat/usr/bin/cat[root@localhost sunjimeng]# which adduser/usr/sbin/adduser</code></pre><p>2)[root@localhost sunjimeng]# which which      用which命令找which命令</p><pre><code>[root@localhost sunjimeng]# which whichalias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'    /usr/bin/alias    /usr/bin/which</code></pre><p>3)[root@localhost sunjimeng]# which –help</p><pre><code>复制代码[root@localhost sunjimeng]# which --helpUsage: /usr/bin/which [options] [--] COMMAND [...]Write the full path of COMMAND(s) to standard output.  --version, -[vV] Print version and exit successfully.  --help,          Print this help and exit successfully.  --skip-dot       Skip directories in PATH that start with a dot.  --skip-tilde     Skip directories in PATH that start with a tilde.  --show-dot       Don't expand a dot to current directory in output.  --show-tilde     Output a tilde for HOME directory for non-root.  --tty-only       Stop processing options on the right if not on tty.  --all, -a        Print all matches in PATH, not just the first  --read-alias, -i Read list of aliases from stdin.  --skip-alias     Ignore option --read-alias; don't read stdin.  --read-functions Read shell functions from stdin.  --skip-functions Ignore option --read-functions; don't read stdin.Recommended use is to write the output of (alias; declare -f) to standardinput, so that which can show aliases and shell functions. See which(1) forexamples.If the options --read-alias and/or --read-functions are specified then theoutput can be a full alias or function definition, optionally followed bythe full path of each command used inside of those.Report bugs to &lt;which-bugs@gnu.org&gt;.</code></pre><p>4)[root@localhost sunjimeng]# which –version</p><pre><code>[root@localhost sunjimeng]# which --versionGNU which v2.20, Copyright (C) 1999 - 2008 Carlo Wood.GNU which comes with ABSOLUTELY NO WARRANTY;This program is free software; your freedom to use, changeand distribute this program is protected by the GPL.[root@localhost sunjimeng]# which -VGNU which v2.20, Copyright (C) 1999 - 2008 Carlo Wood.GNU which comes with ABSOLUTELY NO WARRANTY;This program is free software; your freedom to use, changeand distribute this program is protected by the GPL.</code></pre><hr><p>5)其他:</p><pre><code>说明:1.which 是根据使用者所配置的 PATH 变量内的目录去搜寻可运行档的！所以，不同的 PATH 配置内容所找到的命令当然不一样的！2.竟然会有两个 which ，其中一个是 alias 这就是所谓的『命令别名』，意思是输入 which 会等於后面接的那串命令！3.bash内建命令:  1).什么是build in命令：shell内建命令是指bash（或其它版本）工具集中的命令。一般都会有一个与之同名的系统命令，比如bash中的echo命令与/bin/echo是两个不同的命令，尽管他们行为大体相仿。当在bash中键入一个命令时系统会先看他是否是一个内建命令，如果不是才会查看是否是系统命令或第三方工具。所以在bash中键入echo命令实际上执行bash工具集中的bash命令也就是内建命令，而不是/bin/echo这个系统命令。  2).内建命令与系统命令 内建命令要比系统论命令有比较高的执行效率。外部命令执行时往往需要fork出（产生出）一个子进程，而内建命令一般不用。  3).查看一个命令是系统命令还是内建命令：type复制代码[root@localhost sunjimeng]# type -a pwdpwd 是 shell 内嵌pwd 是 /usr/bin/pwdpwd 是 /bin/pwd[root@localhost sunjimeng]# type -a echoecho 是 shell 内嵌echo 是 /usr/bin/echoecho 是 /bin/echo复制代码　　可以看出，有些命令，echo和pwd同时是内建命令和系统命令。    4.补充: 我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索：    which  查看可执行文件的位置。   whereis 查看文件的位置。    locate   配合数据库查看文件位置。   find   实际搜寻硬盘查询文件名称。</code></pre><h2 id="2017-07-21-每天2个Linux-whereis命令"><a href="#2017-07-21-每天2个Linux-whereis命令" class="headerlink" title=" 2017-07-21 每天2个Linux whereis命令"></a><center> 2017-07-21 每天2个Linux whereis命令</center></h2><p>whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）<br><br>和源代码文件（参数-s）。如果省略参数，则返回所有信息。 </p><hr><p>(1)用法:</p><pre><code>用法:    whereis  [-bmsu]   [BMS 目录名 -f ]    文件名</code></pre><p> (2)功能:</p><pre><code>功能:    用来定位指令的二进制程序、源代码文件和man手册页等相关文件的路径。</code></pre><p>(3)选项参数:</p><pre><code>  1) -b:                        　　　　只查找二进制文件  2) -B&lt;目录&gt;:             　　　　只在设置的目录下查找二进制文件  3) -f:                        　　　　不显示文件名前的路径名称  4) -m:                      　　　　只查找说明文件  5) -M&lt;目录&gt;:            　　　　只在设置的目录下查找说明文件  6) -s:　　　　　　　　　　　　只查找原始代码文件    7) -S&lt;目录&gt;:　　　　　　　　 只在设置的目录下查找原始代码文件    8) -u: 　　　　　　　　　　　  查找不包含指定类型的文件</code></pre><p>(4)实例:</p><pre><code>  1)[sunjimeng@localhost ~]$ whereis cd    查找与cd命令有关的所有文件，包括二进制，man说明文件，源代码文件。[sunjimeng@localhost ~]$ whereis cdcd: /usr/bin/cd /usr/share/man/man1/cd.1.gz /usr/share/man/man1p/cd.1p.gz[sunjimeng@localhost ~]$ whereis pwdpwd: /usr/bin/pwd /usr/include/pwd.h /usr/share/man/man1/pwd.1.gz /usr/share/man/man1p/pwd.1p.gz</code></pre><hr><pre><code>2)[sunjimeng@localhost ~]$ whereis -b|-s|-m cd[sunjimeng@localhost ~]$ whereis -b cdcd: /usr/bin/cd[sunjimeng@localhost ~]$ whereis -s cdcd:[sunjimeng@localhost ~]$ whereis -m cdcd: /usr/share/man/man1/cd.1.gz /usr/share/man/man1p/cd.1p.gz</code></pre><hr><p>3)[sunjimeng@localhost ~]$ whereis -f cd</p><pre><code>[sunjimeng@localhost ~]$ whereis -f cd                         //好像没什么区别啊cd: /usr/bin/cd /usr/share/man/man1/cd.1.gz /usr/share/man/man1p/cd.1p.gz[sunjimeng@localhost ~]$ whereis cdcd: /usr/bin/cd /usr/share/man/man1/cd.1.gz /usr/share/man/man1p/cd.1p.gz</code></pre><hr><p>4)[sunjimeng@localhost ~]$ whereis whereis</p><pre><code>复制代码[sunjimeng@localhost ~]$ whereis whereiswhereis: /usr/bin/whereis /usr/share/man/man1/whereis.1.gz[sunjimeng@localhost ~]$ whereis -b whereiswhereis: /usr/bin/whereis[sunjimeng@localhost ~]$ whereis -m whereiswhereis: /usr/share/man/man1/whereis.1.gz[sunjimeng@localhost ~]$ whereis -s whereis</code></pre><hr><p>(5)其他:</p><pre><code>说明:和find相比，whereis查找的速度非常快，这是因为linux系统会将 系统内的所有文件都记录在一个数据库文件中，当使用whereis和下面即将介绍的locate时，会从数据库中查找数据，而不是像find命令那样，通 过遍历硬盘来查找，效率自然会很高。 但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用whereis和locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mybatis学习-02</title>
      <link href="/2017/07/20/mybatis-xue-xi-02/"/>
      <url>/2017/07/20/mybatis-xue-xi-02/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-19-mybatis-02"><a href="#2017-07-19-mybatis-02" class="headerlink" title=" 2017-07-19 mybatis-02"></a><center> 2017-07-19 mybatis-02</center></h2><p>1    课程计划</p><pre><code>1、    高级结果映射（一对一、一对多、多对多）（重点）2、    延迟加载3、    查询缓存4、    Spring和mybatis的整合（重点）5、    逆向工程</code></pre><hr><p>2    高级结果映射</p><pre><code>2.1    数据模型分析    1、    明确每张表存储的信息    2、    明确每张表中关键字段（主键、外键、非空）    3、    明确数据库中表与表之间的外键关系    4、    明确业务中表与表的关系（建立在具体的业务）</code></pre><p><img src="/images/20170719/48.png"></p><hr><pre><code>2.2    一对一映射    2.2.1    需求        查询订单信息，关联查询用户信息    2.2.2    Sql        主信息：orders        从信息：user        SELECT           orders.`id`,          orders.`user_id`,          orders.`number`,          user.`username`,          user.`sex`         FROM          orders,          USER         WHERE orders.`user_id` = user.`id`    2.2.3    resultType        2.2.3.1    创建扩展类</code></pre><p><img src="/images/20170719/49.png"></p><pre><code>        2.2.3.2    映射文件</code></pre><p><img src="/images/20170719/50.png"></p><pre><code>        2.2.3.3    Mapper接口</code></pre><p><img src="/images/20170719/51.png"></p><pre><code>        2.2.3.4    测试代码</code></pre><p><img src="/images/20170719/52.png"></p><pre><code>        2.2.3.5    小结        使用resultType来进行一对一结果映射，查询出的列的个数和映射的属性的个数要一致。        而且映射的属性要存在与一个大的对象中，它是一种平铺式的映射，即数据库查询出多少条记录，则映射成多少个对象。</code></pre><hr><pre><code>    2.2.4    resultMap    使用resultMap来进行一对一结果映射，它是将关联对象添加到主信息的对象中，具体说是对象嵌套对象的一种映射方式。        2.2.4.1    修改扩展类</code></pre><p><img src="/images/20170719/53.png"></p><pre><code>        2.2.4.2    映射文件</code></pre><p><img src="/images/20170719/54.png"></p><pre><code>        2.2.4.3    Mapper接口</code></pre><p><img src="/images/20170719/55.png"></p><pre><code>        2.2.4.4    测试代码</code></pre><p><img src="/images/20170719/56.png"></p><pre><code>    2.2.5    小结    在一对一结果映射时，使用resultType更加简单方便，如果有特殊要求（对象嵌套对象）时，    需要使用resultMap进行映射，比如：查询订单列表，然后在点击列表中的查看订单明细按钮，    这个时候就需要使用resultMap进行结果映射。而resultType更适应于查询明细信息，比如，查询订单明细列表。</code></pre><hr><pre><code>2.3    一对多映射    2.3.1    需求        查询订单信息，关联查询订单明细信息及用户信息    2.3.2    Sql        主信息：orders        从信息：orderdetail、user        SELECT           orders.`id`,          orders.`user_id`,          orders.`number`,          user.`username`,          user.`sex`,          orderdetail.`id` detailId,          orderdetail.`items_id`,          orderdetail.`items_num`         FROM          orders,          USER,          orderdetail         WHERE orders.`user_id` = user.`id`           AND orders.`id` = orderdetail.`orders_id`    2.3.3    修改扩展类</code></pre><p><img src="/images/20170719/57.png"></p><pre><code>    2.3.4    映射文件</code></pre><p><img src="/images/20170719/58.png"></p><pre><code>    2.3.5    Mapper接口</code></pre><p><img src="/images/20170719/59.png"></p><pre><code>    2.3.6    测试代码</code></pre><p><img src="/images/20170719/60.png"></p><hr><pre><code>2.4    多对多映射    多对多映射是一对多映射的特例    2.4.1    需求        查询用户信息，关联查询该用户购买的商品信息    2.4.2    Sql        主信息：user        从信息：items、orders、orderdetail        SELECT           orders.`id`,          orders.`user_id`,          orders.`number`,          user.`username`,          user.`sex`,          orderdetail.`id` detailId,          orderdetail.`items_id`,          orderdetail.`items_num`,          items.`name`,          items.`price`         FROM          orders,          USER,          orderdetail,          items         WHERE orders.`user_id` = user.`id`           AND orders.`id` = orderdetail.`orders_id`           AND orderdetail.`items_id` = items.`id`    2.4.3    修改po类        在User类中添加List&lt;Orders&gt; orders;</code></pre><p><img src="/images/20170719/61.png"></p><pre><code>    在Orders类中添加List&lt;Orderdetail&gt; detailList;</code></pre><p><img src="/images/20170719/62.png"></p><pre><code>    在Orderdetail中添加Items items；</code></pre><p><img src="/images/20170719/63.png"></p><hr><pre><code>2.4.4    Mapper接口</code></pre><p><img src="/images/20170719/64.png"></p><pre><code>2.4.5    映射文件</code></pre><p><img src="/images/20170719/65.png"></p><p><img src="/images/20170719/66.png"></p><pre><code>2.4.6    测试代码</code></pre><p><img src="/images/20170719/67.png"></p><hr><p>3    延迟加载</p><pre><code>3.1    什么是延迟加载延迟加载又叫懒加载，也叫按需加载。也就是说先加载主信息，在需要的时候，再去加载从信息。在mybatis中，resultMap标签 的association标签和collection标签具有延迟加载的功能。3.2    需求    查询订单信息，关联查询用户信息    1、    创建一个statement来查询订单信息    2、    创建一个statement来查询用户信息3.3    映射文件    1、    创建查询订单信息的映射文件</code></pre><p><img src="/images/20170719/68.png"></p><p><img src="/images/20170719/69.png"></p><pre><code>    2、    创建查询用户信息的映射文件</code></pre><p><img src="/images/20170719/70.png"></p><pre><code>3.4    Mapper接口</code></pre><p><img src="/images/20170719/71.png">    </p><pre><code>3.5    测试代码</code></pre><p><img src="/images/20170719/72.png"></p><pre><code>3.6    设置延迟加载    在SqlMapConfig.xml中，配置settings标签</code></pre><p><img src="/images/20170719/73.png"></p><hr><p>4    查询缓存</p><pre><code>4.1    Mybatis的缓存理解</code></pre><p><img src="/images/20170719/74.png"></p><pre><code>Mybatis的缓存，包括一级缓存和二级缓存一级缓存指的就是sqlsession，在sqlsession中有一个数据区域，是map结构，这个区域就是一级缓存区域。一级缓存中的key是由sql语句、条件、statement等信息组成一个唯一值。一级缓存中的value，就是查询出的结果对象。二级缓存指的就是同一个namespace下的mapper，二级缓存中，也有一个map结构，这个区域就是一级缓存区域。一级缓存中的key是由sql语句、条件、statement等信息组成一个唯一值。一级缓存中的value，就是查询出的结果对象。一级缓存是默认使用的。二级缓存需要手动开启。</code></pre><hr><pre><code>4.2    一级缓存    4.2.1    原理</code></pre><p><img src="/images/20170719/75.png"></p><pre><code>    4.2.2    测试1</code></pre><p><img src="/images/20170719/76.png"></p><pre><code>    4.2.3    测试2</code></pre><p><img src="/images/20170719/77.png"></p><p><img src="/images/20170719/78.png"></p><hr><pre><code>4.3    二级缓存    4.3.1    原理</code></pre><p><img src="/images/20170719/79.png"></p><pre><code>    4.3.2    开启二级缓存        1、    开启二级缓存的总开关</code></pre><p><img src="/images/20170719/80.png"></p><pre><code>        2、    在mapper映射文件中开启二级缓存</code></pre><p><img src="/images/20170719/81.png"></p><pre><code>    4.3.3    序列化</code></pre><p><img src="/images/20170719/82.png"></p><pre><code>    4.3.4    测试1</code></pre><p><img src="/images/20170719/83.png"></p><p><img src="/images/20170719/84.png">    </p><pre><code>    4.3.5    测试2</code></pre><p><img src="/images/20170719/85.png"></p><p><img src="/images/20170719/86.png"></p><pre><code>    4.3.6    禁用缓存        默认值是true</code></pre><p><img src="/images/20170719/87.png">    </p><pre><code>    4.3.7    刷新缓存</code></pre><p><img src="/images/20170719/88.png">    </p><pre><code>    4.3.8    整合ehcache        Mybatis本身是一个持久层框架，它不是专门的缓存框架，所以它对缓存的实现不够好，不能支持分布式。        Ehcache是一个分布式的缓存框架。        4.3.8.1    什么是分布式            系统为了提高性能，通常会对系统采用分布式部署（集群部署方式）</code></pre><p><img src="/images/20170719/89.png"></p><pre><code>        4.3.8.2    整合思路        Cache是一个接口，它的默认实现是mybatis的PerpetualCache。如果想整合mybatis的二级缓存，那么实现Cache接口即可。</code></pre><p><img src="/images/20170719/90.png">    </p><pre><code>        4.3.8.3    添加jar包</code></pre><p><img src="/images/20170719/91.png">    </p><pre><code>        4.3.8.4    设置映射文件中cache标签的type值为ehcache的实现类</code></pre><p><img src="/images/20170719/92.png">    </p><pre><code>        4.3.8.5    添加ehcache的配置文件            在config下，创建ehcache.xml</code></pre><p><img src="/images/20170719/93.png"></p><pre><code>        4.3.8.6    测试ehcache的二级缓存</code></pre><p><img src="/images/20170719/94.png"></p><pre><code>    4.3.9    应用场景    使用场景：对于访问响应速度要求高，但是实时性不高的查询，可以采用二级缓存技术。    注意：在使用二级缓存的时候，要设置一下刷新间隔（cache标签中有一个flashInterval属性）来定时刷新二级缓存，    这个刷新间隔根据具体需求来设置，比如设置30分钟、60分钟等，单位为毫秒。    4.3.10    局限性    Mybatis二级缓存对细粒度的数据，缓存实现不好。    场景：对商品信息进行缓存，由于商品信息查询访问量大，但是要求用户每次查询都是最新的商品信息，    此时如果使用二级缓存，就无法实现当一个商品发生变化只刷新该商品的缓存信息而不刷新其他商品缓存信息，    因为二级缓存是mapper级别的，当一个商品的信息发送更新，所有的商品信息缓存数据都会清空。    解决此类问题，需要在业务层根据需要对数据有针对性的缓存。    比如可以对经常变化的 数据操作单独放到另一个namespace的mapper中。</code></pre><hr><p>5    Mybatis整合spring</p><pre><code>5.1    整合思路    1、    数据源信息交给spring管理    2、    SqlSessionFactory交给spring进行单例管理    3、    由spring来管理原始dao的实现类或者mapper代理的代理类。</code></pre><hr><pre><code>5.2    需求使用原始dao方式和mapper代理方式实现以下功能：根据用户ID查询商品信息</code></pre><hr><pre><code>5.3    工程搭建    Mysql的驱动包    Mybatis的核心包和依赖包    Mybatis和spring的整合包    Spring的包    dbcp数据库连接池包</code></pre><p><img src="/images/20170719/95.png"></p><hr><pre><code>5.4    具体整合    5.4.1    整合配置文件        5.4.1.1    Mybatis        在config下，创建mybatis目录，然后创建SqlMapConfig.xml</code></pre><p><img src="/images/20170719/96.png">    </p><pre><code>        将db.properties和log4j.properties拷贝到config目录下。            5.4.1.2    Spring        在config下，创建spring目录，然后创建applicationContext.xml</code></pre><p><img src="/images/20170719/97.png"></p><pre><code>    5.4.2    整合代码        5.4.2.1    原始dao开发方式                5.4.2.1.1    映射文件                在config/mybatis下创建sqlmap，然后创建User.xml</code></pre><p><img src="/images/20170719/98.png">    </p><pre><code>                5.4.2.1.2    Dao代码</code></pre><p><img src="/images/20170719/99.png">    </p><pre><code>                5.4.2.1.3    配置UserDao实现类                在applicationContext.xml中配置UserDao实现类</code></pre><p><img src="/images/20170719/100.png"></p><pre><code>                5.4.2.1.4    测试代码</code></pre><p><img src="/images/20170719/101.png"></p><pre><code>        5.4.2.2    Mapper代理            5.4.2.2.1    映射文件            将映射文件放到UserMapper接口的同包下</code></pre><p><img src="/images/20170719/102.png">        </p><pre><code>            5.4.2.2.2    Mapper接口</code></pre><p><img src="/images/20170719/103.png">    </p><pre><code>            5.4.2.2.3    配置mapper代理类</code></pre><p><img src="/images/20170719/104.png">        </p><pre><code>            5.4.2.2.4    测试代码</code></pre><p><img src="/images/20170719/105.png"></p><hr><p>6    逆向工程（会用）</p><pre><code>6.1    什么是逆向工程mybatis提供来一个逆向工程工具，通过逆向工程，可以帮助程序员根据单表来生成po类、mapper映射文件、mapper接口。</code></pre><hr><pre><code>6.2    下载逆向工程https://github.com/mybatis/generator/releases/tag/mybatis-generator-1.3.2</code></pre><p><img src="/images/20170719/106.png"></p><pre><code>6.3    创建逆向工程</code></pre><p><img src="/images/20170719/107.png"></p><pre><code>6.4    创建Generator.java</code></pre><p><img src="/images/20170719/108.png"></p><pre><code>6.5    添加generatorConfig.xml        &lt;?xml version="1.0" encoding="UTF-8"?&gt;    &lt;!DOCTYPE generatorConfiguration      PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN"      "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;    &lt;generatorConfiguration&gt;        &lt;context id="testTables" targetRuntime="MyBatis3"&gt;            &lt;commentGenerator&gt;                &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt;                &lt;property name="suppressAllComments" value="true" /&gt;            &lt;/commentGenerator&gt;            &lt;!--数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt;            &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver"                connectionURL="jdbc:mysql://localhost:3306/mybatis" userId="root"                password="root"&gt;            &lt;/jdbcConnection&gt;            &lt;!-- &lt;jdbcConnection driverClass="oracle.jdbc.OracleDriver" connectionURL="jdbc:oracle:thin:@127.0.0.1:1521:yycg"                 userId="yycg" password="yycg"&gt; &lt;/jdbcConnection&gt; --&gt;            &lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL                 和 NUMERIC 类型解析为java.math.BigDecimal --&gt;            &lt;javaTypeResolver&gt;                &lt;property name="forceBigDecimals" value="false" /&gt;            &lt;/javaTypeResolver&gt;            &lt;!-- targetProject:生成PO类的位置 --&gt;            &lt;javaModelGenerator targetPackage="com.itheima.ms.po"                targetProject=".\src"&gt;                &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt;                &lt;property name="enableSubPackages" value="false" /&gt;                &lt;!-- 从数据库返回的值被清理前后的空格 --&gt;                &lt;property name="trimStrings" value="true" /&gt;            &lt;/javaModelGenerator&gt;            &lt;!-- targetProject:mapper映射文件生成的位置 --&gt;            &lt;sqlMapGenerator targetPackage="com.itheima.ms.mapper"                targetProject=".\src"&gt;                &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt;                &lt;property name="enableSubPackages" value="false" /&gt;            &lt;/sqlMapGenerator&gt;            &lt;!-- targetPackage：mapper接口生成的位置 --&gt;            &lt;javaClientGenerator type="XMLMAPPER"                targetPackage="com.itheima.ms.mapper" targetProject=".\src"&gt;                &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt;                &lt;property name="enableSubPackages" value="false" /&gt;            &lt;/javaClientGenerator&gt;            &lt;!-- 指定数据库表 --&gt;            &lt;table tableName="items"&gt;&lt;/table&gt;            &lt;table tableName="orders"&gt;&lt;/table&gt;            &lt;table tableName="orderdetail"&gt;&lt;/table&gt;            &lt;table tableName="user"&gt;&lt;/table&gt;        &lt;/context&gt;    &lt;/generatorConfiguration&gt;6.6    将逆向工程生成的代码拷贝到指定项目中6.7    使用逆向工程生成的代码</code></pre><p><img src="/images/20170719/109.png"></p><p>6.8    注意事项</p><pre><code>Mapper.xml文件已经存在时，如果进行重新生成则mapper.xml文件时，内容不被覆盖而是进行内容追加，结果导致mybatis解析失败。解决方法：删除原来已经生成的mapper xml文件再进行生成。Mybatis自动生成的po及mapper.java文件不是内容而是直接覆盖没有此问题。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> mybatis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
            <tag> mybatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mybatis学习-01</title>
      <link href="/2017/07/20/mybatis-xue-xi-01/"/>
      <url>/2017/07/20/mybatis-xue-xi-01/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-19-mybatis-01"><a href="#2017-07-19-mybatis-01" class="headerlink" title=" 2017-07-19 mybatis-01"></a><center> 2017-07-19 mybatis-01</center></h2><p>Mybatis<br>框架课程</p><p>1    课程计划<br><br>1、    mybatis的介绍<br><br>2、    mybatis的框架原理（重点）<br><br>3、    入门程序<br><br>订单商品案例（用户表）<br><br>4、    Mybatis开发dao的方式（重点）<br><br>a)    原始dao开发方式（开发dao接口和dao实现类，由ibatis遗留下来的风格）<br><br>b)    Mapper代理的开发方式（推荐，开发mapper接口（相当于dao接口））<br><br>5、    全局配置文件<br><br>6、    映射文件（重点）<br><br>a)    输入映射<br><br>b)    输出映射<br><br>c)    动态sql<br><br>7、    mybatis和hibernate的区别及应用场景<br></p><hr><p>2    mybatis的介绍</p><p>mybatis就是一个封装来jdbc的持久层框架，它和hibernate都属于ORM框架，但是具体的说，hibernate是一个完全的orm框架，而mybatis是一个不完全的orm框架。</p><p>Mybatis让程序员只关注sql本身，而不需要去关注如连接的创建、statement的创建等操作。</p><p>Mybatis会将输入参数、输出结果进行映射。</p><hr><p>3    分析jdbc的问题</p><pre><code>3.1    原生态的jdbc代码public static void main(String[] args) {        Connection connection = null;        PreparedStatement preparedStatement = null;        ResultSet resultSet = null;        try {            //1、加载数据库驱动            Class.forName("com.mysql.jdbc.Driver");            //2、通过驱动管理类获取数据库链接            connection =  DriverManager.getConnection("jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf-8", "root", "root");            //3、定义sql语句 ?表示占位符        String sql = "select * from user where username = ?";            //4、获取预处理statement            preparedStatement = connection.prepareStatement(sql);            //5、设置参数，第一个参数为sql语句中参数的序号（从1开始），第二个参数为设置的参数值            preparedStatement.setString(1, "王五");            //6、向数据库发出sql执行查询，查询出结果集            resultSet =  preparedStatement.executeQuery();            //7、遍历查询结果集            while(resultSet.next()){                User user                 System.out.println(resultSet.getString("id")+"  "+resultSet.getString("username"));            }        } catch (Exception e) {            e.printStackTrace();        }finally{            //8、释放资源            if(resultSet!=null){                try {                    resultSet.close();                } catch (SQLException e) {                    // TODO Auto-generated catch block                    e.printStackTrace();                }            }            if(preparedStatement!=null){                try {                    preparedStatement.close();                } catch (SQLException e) {                    // TODO Auto-generated catch block                    e.printStackTrace();                }            }            if(connection!=null){                try {                    connection.close();                } catch (SQLException e) {                    // TODO Auto-generated catch block                    e.printStackTrace();                }            }        }    }</code></pre><hr><pre><code>3.2    问题总结1、    在创建连接时，存在硬编码配置文件（全局配置文件）2、    在执行statement时存在硬编码配置文件（映射文件）3、    频繁的开启和关闭数据库连接，会造成数据库性能下降。数据库连接池（全局配置文件）</code></pre><hr><p>4    Mybatis的框架原理</p><p><img src="/images/20170719/1.png"></p><hr><p>5    入门程序</p><pre><code>5.1    需求对订单商品案例中的用户表进行增删改查操作1、    根据用户ID查询用户信息2、    根据用户名称模糊查询用户列表3、    添加用户4、    删除用户（练习）5、    修改用户（练习）</code></pre><hr><pre><code>5.2    环境准备    Jdk：1.7    Ide：eclipse indigo    Mybatis：3.2.7    数据库：MySQL 5X</code></pre><hr><pre><code>5.2.1    下载mybatismybaits的代码由github.com管理，下载地址：https://github.com/mybatis/mybatis-3/releases</code></pre><p><img src="/images/20170719/2.png"></p><hr><pre><code>5.2.2    数据库脚本初始化    5.2.2.1    数据库脚本</code></pre><p><img src="/images/20170719/3.png"></p><pre><code>1、    执行sql_table.sql脚本，创建数据库表；2、    执行sql_data.sql初始化测试数据。</code></pre><p><img src="/images/20170719/4.png"></p><hr><pre><code>5.3    工程搭建    Mybatis的核心包和依赖包    MySQl的驱动包    Junit（非必须）</code></pre><p><img src="/images/20170719/5.png"></p><hr><pre><code>5.4    代码实现    5.4.1    创建po类</code></pre><p><img src="/images/20170719/6.png"></p><pre><code>    5.4.2    创建全局配置文件    在config目录下，创建SqlMapConfig.xml文件，该名称不是固定不变的。</code></pre><p><img src="/images/20170719/7.png"></p><hr><pre><code>5.4.3    需求开发    5.4.3.1    根据用户ID查询用户信息        5.4.3.1.1    映射文件            在config目录下，创建User.xml（这种命名规范是由ibatis遗留下来）</code></pre><p><img src="/images/20170719/8.png"></p><pre><code>        5.4.3.1.2    在全局配置文件中加载映射文件</code></pre><p><img src="/images/20170719/9.png"></p><pre><code>        5.4.3.1.3    测试代码</code></pre><p><img src="/images/20170719/10.png"></p><hr><pre><code>    5.4.3.2    根据用户名称模糊查询用户列表        5.4.3.2.1    映射文件</code></pre><p><img src="/images/20170719/11.png"></p><pre><code>        5.4.3.2.2    测试代码</code></pre><p><img src="/images/20170719/12.png"></p><hr><pre><code>    5.4.3.3    添加用户        5.4.3.3.1    映射文件</code></pre><p><img src="/images/20170719/12.png"></p><pre><code>        5.4.3.3.2    测试代码</code></pre><p><img src="/images/20170719/13.png"></p><hr><pre><code>    5.4.3.3.3    主键返回之自增主键</code></pre><p><img src="/images/20170719/14.png"></p><pre><code>    5.4.3.3.4    主键返回值UUID    UUID函数是mysql的函数</code></pre><p><img src="/images/20170719/15.png"></p><pre><code>    5.4.3.3.5    主键返回值序列    序列也就是sequence，它是Oracle的主键生成策略</code></pre><p><img src="/images/20170719/16.png"></p><hr><pre><code>5.4.4    小结    #{}和${}#{}表示占位符?，#{}接收简单类型的参数时，里面的名称可以任意${}表示拼接符，${}接收简单类型的参数时，里面的名称必须是value${}里面的值会原样输出，不加解析（如果该参数值是字符串，有不会添加引号）${}存在sql注入的风险，但是有些场景下必须使用，比如排序后面会动态传入排序的列名    parameterType和resultTypeparameterType指定输入参数的java类型，parameterType只有一个，也就是说入参只有一个。resultType指定输出结果的java类型（是单条记录的java类型）    selectOne和selectListselectOne查询单个对象selectList查询集合对象</code></pre><p><img src="/images/20170719/17.png"></p><hr><p>6    mybatis开发dao的方式</p><pre><code>6.1    需求1、    根据用户ID查询用户信息2、    根据用户名称模糊查询用户列表3、    添加用户</code></pre><hr><pre><code>6.2    原始dao的开发方式    即开发dao接口和dao实现类    6.2.1    Dao接口</code></pre><p><img src="/images/20170719/18.png"></p><pre><code>    6.2.2    Dao实现类    SqlSessionFactory，它的生命周期，应该是应用范围，全局范围只有一个工厂，    使用单例模式来实现这个功能。与spring集成之后，由spring来对其进行单例管理。    SqlSession，它内部含有一块数据区域，存在线程不安全的问题，所以应该将sqlsession声明到方法内部。    public class UserDaoImpl implements UserDao {        // 依赖注入        private SqlSessionFactory sqlSessionFactory;        public UserDaoImpl(SqlSessionFactory sqlSessionFactory) {            this.sqlSessionFactory = sqlSessionFactory;        }        @Override        public User findUserById(int id) throws Exception {            // 创建SqlSession            SqlSession sqlSession = sqlSessionFactory.openSession();            // 调用SqlSession的增删改查方法            // 第一个参数：表示statement的唯一标示            User user = sqlSession.selectOne("test.findUserById", id);            System.out.println(user);            // 关闭资源            sqlSession.close();            return sqlSession.selectOne("test.findUserById", 1);        }        @Override        public List&lt;User&gt; findUsersByName(String name) {            // 创建SqlSession            SqlSession sqlSession = sqlSessionFactory.openSession();            // 调用SqlSession的增删改查方法            // 第一个参数：表示statement的唯一标示            List&lt;User&gt; list = sqlSession.selectOne("test.findUsersByName", name);            System.out.println(list);            // 关闭资源            sqlSession.close();            return list;        }        @Override        public void insertUser(User user) {            // 创建SqlSession            SqlSession sqlSession = sqlSessionFactory.openSession();            // 调用SqlSession的增删改查方法            // 第一个参数：表示statement的唯一标示            sqlSession.insert("test.insertUser", user);            System.out.println(user.getId());            // 提交事务            sqlSession.commit();            // 关闭资源            sqlSession.close();        }    }    6.2.3    测试代码</code></pre><p><img src="/images/20170719/19.png"></p><hr><pre><code>6.2.4    问题思考1、    有大量的重复的模板代码2、    存在硬编码</code></pre><hr><pre><code>6.3    Mapper代理的开发方式    即开发mapper接口（相当于dao接口）    Mapper代理使用的是jdk的代理策略。</code></pre><hr><pre><code>6.3.1    Mapper代理的开发规范    1、    mapper接口的全限定名要和mapper映射文件的namespace值一致。    2、    mapper接口的方法名称要和mapper映射文件的statement的id一致。    3、    mapper接口的方法参数类型要和mapper映射文件的statement的parameterType的值一致，而且它的参数是一个。    4、    mapper接口的方法返回值类型要和mapper映射文件的statement的resultType的值一致。</code></pre><hr><pre><code>6.3.2    mapper接口</code></pre><p><img src="/images/20170719/20.png"></p><hr><pre><code>6.3.3    mapper映射文件    在config下创建mapper目录然后创建UserMapper.xml（这是mybatis的命名规范，当然，也不是必须是这个名称）    sqlSession内部的数据区域本身就是一级缓存，是通过map来存储的。</code></pre><p><img src="/images/20170719/21.png"></p><hr><pre><code>6.3.4    加载映射文件</code></pre><p><img src="/images/20170719/22.png"></p><hr><pre><code>6.3.5    测试代码</code></pre><p><img src="/images/20170719/23.png"></p><hr><p>7    全局配置文件</p><pre><code>7.1    概览    SqlMapConfig.xml的配置内容和顺序如下（顺序不能乱）：    Properties（属性）    Settings（全局参数设置）    typeAliases（类型别名）    typeHandlers（类型处理器）    objectFactory（对象工厂）    plugins（插件）    environments（环境信息集合）        environment（单个环境信息）            transactionManager（事物）            dataSource（数据源）    mappers（映射器）</code></pre><hr><pre><code>7.2    常用配置    7.2.1    Properties        Db.properties</code></pre><p><img src="/images/20170719/24.png"></p><pre><code>        SqlMapConfig.xml</code></pre><p><img src="/images/20170719/25.png"></p><pre><code>        加载的顺序        1、    先加载properties中property标签声明的属性        2、    再加载properties标签引入的java配置文件中的属性        3、    parameterType的值会和properties的属性值发生冲突</code></pre><hr><pre><code>    7.2.2    settings    mybatis全局配置参数，全局参数将会影响mybatis的运行行为。    详细参见“mybatis学习资料/mybatis-settings.xlsx”文件</code></pre><p><img src="/images/20170719/26.png"></p><p><img src="/images/20170719/27.png"></p><p><img src="/images/20170719/28.png"></p><hr><pre><code>    7.2.3    typeAliases        对po类进行别名的定义        7.2.3.1    mybatis支持的别名            别名    映射的类型            _byte     byte             _long     long             _short     short             _int     int             _integer     int             _double     double             _float     float             _boolean     boolean             string     String             byte     Byte             long     Long             short     Short             int     Integer             integer     Integer             double     Double             float     Float             boolean     Boolean             date     Date             decimal     BigDecimal             bigdecimal     BigDecimal         7.2.3.2    自定义别名</code></pre><p><img src="/images/20170719/29.png">        </p><hr><pre><code>    7.2.4    Mappers        7.2.4.1    &lt;mapper resource=’’/&gt;            使用相对于类路径的资源            如：&lt;mapper resource="sqlmap/User.xml" /&gt;        7.2.4.2    &lt;mapper url=’’/&gt;            使用完全限定路径            如：&lt;mapper url="file:///D:\workspace_spingmvc\mybatis_01\config\sqlmap\User.xml" /&gt;        7.2.4.3    &lt;mapper class=’’/&gt;            使用mapper接口的全限定名            如：&lt;mapper class="cn.itcast.mybatis.mapper.UserMapper"/&gt;            注意：此种方法要求mapper接口和mapper映射文件要名称相同，且放到同一个目录下；        7.2.4.4    &lt;package name=’’/&gt;（推荐）            注册指定包下的所有映射文件            如：&lt;package name="cn.itcast.mybatis.mapper"/&gt;            注意：此种方法要求mapper接口和mapper映射文件要名称相同，且放到同一个目录下；</code></pre><hr><p>8    映射文件</p><pre><code>8.1    输入映射    8.1.1    简单类型    参考入门程序之根据用户ID查询用户信息的映射文件</code></pre><hr><pre><code>    8.1.2    Pojo类型    参考入门程序之添加用户的映射文件</code></pre><hr><pre><code>    8.1.3    包装pojo类型        8.1.3.1    需求        综合查询时，可能会根据用户信息、商品信息、订单信息等作为条件进行查询，用户信息中的查询条件由：用户的名称和性别进行查询        8.1.3.2    创建包装pojo</code></pre><p><img src="/images/20170719/30.png"></p><pre><code>        8.1.3.3    映射文件</code></pre><p><img src="/images/20170719/31.png"></p><pre><code>        8.1.3.4    Mapper接口</code></pre><p><img src="/images/20170719/32.png"></p><pre><code>        8.1.3.5    测试代码</code></pre><p><img src="/images/20170719/33.png"></p><hr><pre><code>8.1.4    Map        同传递POJO对象一样，map的key相当于pojo的属性8.1.4.1    映射文件    &lt;!-- 传递hashmap综合查询用户信息 --&gt;        &lt;select id="findUserByHashmap" parameterType="hashmap" resultType="user"&gt;           select * from user where id=#{id} and username like '%${username}%'        &lt;/select&gt;    上边红色标注的是hashmap的key。8.1.4.2    测试代码    Public void testFindUserByHashmap()throws Exception{            //获取session            SqlSession session = sqlSessionFactory.openSession();            //获限mapper接口实例            UserMapper userMapper = session.getMapper(UserMapper.class);            //构造查询条件Hashmap对象            HashMap&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();            map.put("id", 1);            map.put("username", "管理员");            //传递Hashmap对象查询用户列表            List&lt;User&gt;list = userMapper.findUserByHashmap(map);            //关闭session            session.close();        }    异常测试：    传递的map中的key和sql中解析的key不一致。    测试结果没有报错，只是通过key获取值为空。</code></pre><hr><pre><code>8.2    输出映射    8.2.1    resultType        8.2.1.1    使用要求        使用resultType进行结果映射时，需要查询出的列名和映射的对象的属性名一致，才能映射成功。        如果查询的列名和对象的属性名全部不一致，那么映射的对象为空。        如果查询的列名和对象的属性名有一个一致，那么映射的对象不为空，但是只有映射正确那一个属性才有值。        如果查询的sql的列名有别名，那么这个别名就是和属性映射的列名。        8.2.1.2    简单类型        注意，对简单类型的结果映射也是有要求的，查询的列必须是一列，才能映射为简单类型。            8.2.1.2.1    需求                综合查询时，需要根据综合查询的添加查询用户的总数            8.2.1.2.2    映射文件</code></pre><p><img src="/images/20170719/34.png"></p><pre><code>            8.2.1.2.3    Mapper接口</code></pre><p><img src="/images/20170719/35.png"></p><pre><code>            8.2.1.2.4    测试代码</code></pre><p><img src="/images/20170719/36.png"></p><hr><pre><code>8.2.1.3    Pojo对象和pojo列表    参考入门程序之根据用户ID查询用户信息和根据用户名称模糊查询用户列表</code></pre><hr><pre><code>8.2.2.2    需求    对以下sql查询的结果集进行对象映射    Select id id_,username username_,sex sex_ from user where id = 1;</code></pre><hr><pre><code>8.2.2.3    映射文件</code></pre><p><img src="/images/20170719/37.png"></p><hr><pre><code>8.2.2.4    Mapper接口</code></pre><p><img src="/images/20170719/38.png"></p><hr><pre><code>8.2.2.5    测试代码</code></pre><p><img src="/images/20170719/39.png"></p><hr><pre><code>8.2.3    动态sql在mybatis中，它提供了一些动态sql标签，可以让程序员更快的进行mybatis的开发，这些动态sql可以通过sql的可重用性。。常用的动态sql标签：if标签、where标签、sql片段、foreach标签</code></pre><hr><pre><code>    8.2.3.1    If标签/where标签        8.2.3.1.1    需求            综合查询时，查询条件由用户来输入，用户名称可以为空，需要满足这种情况下的sql编写。        8.2.3.1.2    映射文件</code></pre><p><img src="/images/20170719/40.png"></p><pre><code>        8.2.3.1.3    测试代码</code></pre><p><img src="/images/20170719/41.png"></p><p><img src="/images/20170719/42.png"></p><hr><pre><code>8.2.3.2    Sql片段    Sql片段可以让代码有更高的可重用性    Sql片段需要先定义后使用</code></pre><p><img src="/images/20170719/43.png"></p><hr><pre><code>8.2.3.3    Foreach标签    可以循环传入参数值    8.2.3.3.1    需求        综合查询时，会根据用户ID集合进行查询        SELECT * FROM USER WHERE id IN (1,2,10)        8.2.3.3.2    修改包装pojo</code></pre><p><img src="/images/20170719/44.png"></p><pre><code>        8.2.3.3.3    映射文件</code></pre><p><img src="/images/20170719/45.png"></p><pre><code>        8.2.3.3.4    测试代码</code></pre><p><img src="/images/20170719/46.png"></p><p><img src="/images/20170719/47.png"></p><hr><p>9    mybatis与hibernate的区别及各自应用场景</p><pre><code>Mybatis技术特点：1、    通过直接编写SQL语句，可以直接对SQL进行性能的优化；2、    学习门槛低，学习成本低。只要有SQL基础，就可以学习mybatis，而且很容易上手；3、    由于直接编写SQL语句，所以灵活多变，代码维护性更好。4、    不能支持数据库无关性，即数据库发生变更，要写多套代码进行支持，移植性不好。Hibernate技术特点：1、    标准的orm框架，程序员不需要编写SQL语句。2、    具有良好的数据库无关性，即数据库发生变化的话，代码无需再次编写。3、    学习门槛高，需要对数据关系模型有良好的基础，而且在设置OR映射的时候，需要考虑好性能和对象模型的权衡。4、    程序员不能自主的去进行SQL性能优化。Mybatis应用场景：    需求多变的互联网项目，例如电商项目。Hibernate应用场景：        需求明确、业务固定的项目，例如OA项目、ERP项目等。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> mybatis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
            <tag> mybatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 tail head</title>
      <link href="/2017/07/20/mei-tian-2-ge-linux-ming-ling-tail-head/"/>
      <url>/2017/07/20/mei-tian-2-ge-linux-ming-ling-tail-head/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-19-每天2个Linux命令-tail命令"><a href="#2017-07-19-每天2个Linux命令-tail命令" class="headerlink" title=" 2017-07-19 每天2个Linux命令 tail命令"></a><center> 2017-07-19 每天2个Linux命令 tail命令</center></h2><p>tail命令用于输入文件中的尾部内容。tail命令默认在屏幕上显示指定文件的末尾10行。</p><p>如果给定的文件不止一个，则在显示的每个文件前面加一个文件名标题。 </p><hr><p>(1)用法:</p><pre><code>用法:   tail [必要参数] [选择参数]   [文件]             如果没有指定文件或者文件名为“-”，则读取标准输入。</code></pre><hr><p>(2)功能:</p><pre><code>功能:  输出文件的末尾部分</code></pre><hr><p>(3)选项参数:</p><pre><code>1) -n &lt;k行数&gt;                                     显示文件末尾k行内容2) -c &lt;k字节数&gt;                                  显示文件末尾k个字节数3) -f 　　　　　　　　　　　　　　　　　 循环读取 　　　　　　　　　　　　　　 4) -q 　　　　　　　　　　　　　　　　　不显示处理信息5) -v 　　　　　　　　　　　　　　　　　显示详细的处理信息</code></pre><hr><p>(4)实例:</p><pre><code>  1)[root@localhost Documents]# tail -n 5 ./tail_text 查看文件后5行的内容          复制代码        [root@localhost Documents]# cat tail_text        &gt; 01 the first line!        &gt; 02 the second line!        &gt; 03 the third line!        &gt; 04 the forth line!        &gt; 05 the fifth line!        &gt; 06 the sixth line!        &gt; o7 the seventh line!        &gt; 08 the eighth line!        &gt; 09 the nineth line!        &gt; 10 the tenth line!        &gt; 11 the eleven line!        &gt; 12 the twelve line!        [root@localhost Documents]# tail -n 5 ./tail_text        &gt; 08 the eighth line!        &gt; 09 the nineth line!        &gt; 10 the tenth line!        &gt; 11 the eleven line!        &gt; 12 the twelve line!        复制代码</code></pre><p>　　              等价于tail -5  text_tail  查看后5行的内容</p><pre><code>        [root@localhost Documents]# tail -5 tail_text        &gt; 08 the eighth line!        &gt; 09 the nineth line!        &gt; 10 the tenth line!        &gt; 11 the eleven line!        &gt; 12 the twelve line!</code></pre><hr><pre><code>    2)[root@localhost Documents]# tail -n +5 tail_text             从第5行开始显示    复制代码    [root@localhost Documents]# tail -n +5 tail_text    &gt; 05 the fifth line!    &gt; 06 the sixth line!    &gt; o7 the seventh line!    &gt; 08 the eighth line!    &gt; 09 the nineth line!     10 the tenth line!    &gt; 11 the eleven line!    &gt; 12 the twelve line!</code></pre><hr><pre><code>3)[root@localhost Documents]# head -n -5 tail_text与[root@localhost Documents]# tail -n -5 tail_text复制代码[root@localhost Documents]# head -n 5 tail_text　　　　　　　　　　//显示文件前5行的内容01 the first line!02 the second line!03 the third line!04 the forth line!05 the fifth line![root@localhost Documents]# head -n -5 tail_text　　　　　　　　　　//除了文件后五行全部显示&gt; 01 the first line!&gt; 02 the second line!&gt; 03 the third line!&gt; 04 the forth line!&gt; 05 the fifth line!&gt; 06 the sixth line!&gt; o7 the seventh line!                                          //head命令的-n参数，当后面的整数为正为负是有区别的[root@localhost Documents]# tail -n 5 tail_text                 //tail命令的-n参数，当后面的整数为正为负是一样的&gt; 08 the eighth line!&gt; 09 the nineth line!&gt; 10 the tenth line!&gt; 11 the eleven line!&gt; 12 the twelve line![root@localhost Documents]# tail -n -5 tail_text               //都是显示末尾的整数的绝对值行&gt; 08 the eighth line!&gt; 09 the nineth line!&gt; 10 the tenth line!&gt; 11 the eleven line!&gt; 12 the twelve line!复制代码</code></pre><hr><pre><code>4)[root@localhost Documents]# tail -c 30 tail_text                     显示末尾的字节数复制代码[root@localhost Documents]# tail -c 30 tail_textn line! 12 the twelve line![root@localhost Documents]# tail -c -30 tail_textn line!&gt; 12 the twelve line![root@localhost Documents]# head -c 30 tail_text&gt; 01 the first line!&gt; 02 the [root@localhost Documents]# head -c -30 tail_text&gt; 01 the first line!&gt; 02 the second line!&gt; 03 the third line!&gt; 04 the forth line!&gt; 05 the fifth line! 06 the sixth line!&gt; o7 the seventh line!&gt; 08 the eighth line!&gt; 09 the nineth line!&gt; 10 the tenth line!&gt; 11 the eleve[root@localhost Documents]# </code></pre><hr><pre><code>5)[root@localhost Documents]# tail -f tail_text               循环读取内容输出到标准输出复制代码[root@localhost Documents]# tail -f tail_text                             //默认是后10行&gt; 03 the third line!&gt; 04 the forth line!&gt; 05 the fifth line!&gt; 06 the sixth line!&gt; o7 the seventh line!&gt; 08 the eighth line!&gt; 09 the nineth line!&gt; 10 the tenth line!&gt; 11 the eleven line!&gt; 12 the twelve line!^C[root@localhost Documents]# tail -f -n 12 tail_text   //也可以自己指定&gt; 01 the first line!&gt; 02 the second line!    &gt; 03 the third line!&gt; 04 the forth line!&gt; 05 the fifth line!&gt; 06 the sixth line!&gt; o7 the seventh line!&gt; 08 the eighth line!&gt; 09 the nineth line!&gt; 10 the tenth line!&gt; 11 the eleven line!&gt; 12 the twelve line!^Z[6]+  已停止               tail -f -n 12 tail_text[root@localhost Documents]# tail -f -n 7 tail_text&gt; 06 the sixth line!&gt; o7 the seventh line!&gt; 08 the eighth line!&gt; 09 the nineth line!&gt; 10 the tenth line!&gt; 11 the eleven line!&gt; 12 the twelve line!复制代码  当然，也可以把信息输入到文件中:复制代码[root@localhost Documents]# tail -f tail_text&gt;tempory    ^Z[9]+  已停止               tail -f tail_text &gt; tempory[root@localhost Documents]# cat tempory&gt; 03 the third line!&gt; 04 the forth line!&gt; 05 the fifth line!&gt; 06 the sixth line!&gt; o7 the seventh line!&gt; 08 the eighth line!&gt; 09 the nineth line!&gt; 10 the tenth line!&gt; 11 the eleven line!&gt; 12 the twelve line!</code></pre><hr><pre><code>6)[root@localhost Documents]# tail -n +5 tail_text与[root@localhost Documents]# tail -n 5 tail_text复制代码[root@localhost Documents]# tail -n +5 tail_text&gt; 05 the fifth line!&gt; 06 the sixth line!&gt; o7 the seventh line!&gt; 08 the eighth line!&gt;&gt; 09 the nineth line!&gt; 10 the tenth line!&gt; 11 the eleven line!&gt;&gt; 12 the twelve line![root@localhost Documents]# tail -n 5 tail_text&gt; 08 the eighth line!&gt; 09 the nineth line!&gt; 10 the tenth line!&gt; 11 the eleven line! 12 the twelve line![root@localhost Documents]# head -n +5 tail_text 01 the first line!&gt; 02 the second line!&gt; 03 the third line!&gt; 04 the forth line!&gt; 05 the fifth line![root@localhost Documents]# head -n 5 tail_text&gt; 01 the first line!&gt; 02 the second line!&gt; 03 the third line!&gt; 04 the forth line!&gt; 05 the fifth line!</code></pre><hr><pre><code>7)[root@localhost Documents]# tail -n +10 tail_text |head -n -2复制代码[root@localhost Documents]# tail -n +10 tail_text       //从第10行显示到尾部&gt; 10 the tenth line!&gt; 11 the eleven line!&gt; 12 the twelve line![root@localhost Documents]# head -n -2 tail_text       //除了末尾两行之外前面的都显示 01 the first line!&gt; 02 the second line!&gt; 03 the third line!&gt; 04 the forth line!&gt; 05 the fifth line!&gt; 06 the sixth line!&gt; o7 the seventh line!&gt; 08 the eighth line!&gt; 09 the nineth line!&gt; 10 the tenth line![root@localhost Documents]# tail -n +10 tail_text |head -n -2   //综合起来，用管道命令就是后一个命令处理前面的结果，因此达到只显示第10行的效果&gt; 10 the tenth line![root@localhost Documents]# </code></pre><hr><h2 id="2017-07-19-每天2个Linux命令-head命令"><a href="#2017-07-19-每天2个Linux命令-head命令" class="headerlink" title=" 2017-07-19 每天2个Linux命令 head命令"></a><center> 2017-07-19 每天2个Linux命令 head命令</center></h2><p>head命令用于显示文件的开头的内容。在默认情况下，head命令显示文件的头10行内容。<br><br>如果指定了多于一个文件，在每一段输出前会给出文件名作为文件头。</p><p>如果不指定文件，或者文件为”-“，则从标准输入读取数据。</p><hr><p>(1)用法:</p><pre><code>用法: head [选项]... [文件]...</code></pre><hr><p>(2)功能:</p><pre><code>将每个指定文件的头10 行显示到标准输出。</code></pre><hr><p>(3)选项参数:</p><pre><code>1)-q 　　　　　　　　　　　　隐藏文件名2)-v 　　　　　　　　　　　　显示文件名3)-c&lt;字节&gt; 　　　　　　　　 显示字节数4)-n&lt;行数&gt; 　　　　　　　　 显示的行数</code></pre><hr><p>(4)实例:</p><pre><code>  1)[root@localhost Documents]# head head_text      　　　　　　默认显示文件的前10行    复制代码    [root@localhost Documents]# ll    总用量 12    -rw-r--r--. 1 root root 664 5月   9 07:59 head_text    -rw-r--r--. 1 root root  45 5月   9 08:15 less1    -rw-r--r--. 1 root root  57 5月   9 08:16 less2    [root@localhost Documents]# head head_text    I am studing orders of Linux!    I am trying to write as many as lines of text!    No matter how low you consider yourself,    there is always someone looking behind you,    hoping that they were that high!    Something you want keep all the time,always you will lose!</code></pre><hr><pre><code>2)[root@localhost Documents]# head -5 head_text  与    [root@localhost Documents]# head -n 5 head_text         　　  相同的功能：自定义显示文件前5行复制代码[root@localhost Documents]# head -5 head_textI am studing orders of Linux!I am trying to write as many as lines of text!No matter how low you consider yourself,[root@localhost Documents]# head -n 5 head_textI am studing orders of Linux!I am trying to write as many as lines of text!No matter how low you consider yourself,</code></pre><hr><pre><code>3)[root@localhost Documents]# head -c 20 head_text    指定自定义显示前20个字节的内容[root@localhost Documents]# head -c 20 head_textI am studing orders [root@localhost Documents]# [root@localhost Documents]# head -c 60 head_textI am studing orders of Linux!I am trying to write as many a</code></pre><hr><pre><code>4)[root@localhost Documents]# head -c -50 head_text     　　　　　 指定除末尾的50个字节外全部显示复制代码[root@localhost Documents]# head -c -50 head_textI am studing orders of Linux!I am trying to write as many as lines of text!No matter how low you consider yourself,there is always someone looking behind you,hoping that they were that high!Something you want keep all the time,always you will lose!Never forget to say "thanks"!Hppay today,also,prepared for happiness in the future!Don't aim your success if you want it,just do what you love and believe and finally you will success!Maybe you can be laze man like a pig,but you can't feel free as it!I am a college school student!I am planning to live and work in hangzhou or guangzhou!I am from[root@localhost Documents]# </code></pre><hr><pre><code>5)I am from[root@localhost Documents]# head -n -10 head_text    除最后10行外全部显示复制代码I am from[root@localhost Documents]# head -n -10 head_textI am studing orders of Linux!I am trying to write as many as lines of text!No matter how low you consider yourself,there is always someone looking behind you,hoping that they were that high!Something you want keep all the time,always you will lose!Never forget to say "thanks"![root@localhost Documents]# </code></pre><hr><pre><code>6)[root@localhost Documents]# head -v less1 less2  显示多个文件，并且在显示前打印出每个文件的文件名复制代码[root@localhost Documents]# head -v  less1 less2==&gt; less1 &lt;==Lost means Get!No losing No getting!End!==&gt; less2 &lt;==If you want keep,you always lose!Certainly It is!End!-v参数是默认的，即是不加也会如此:复制代码[root@localhost Documents]# head less1 less2==&gt; less1 &lt;==Lost means Get!No losing No getting!End!==&gt; less2 &lt;==If you want keep,you always lose!Certainly It is!End!</code></pre><hr><pre><code>7)[root@localhost Documents]# head -q -n 3 less1 less2 head_text              -q参数用来指定显示多个文件，不加文件名。同时也可以用-n 10指定只显示前3行复制代码[root@localhost Documents]# head -q -n 3 less1 less2 head_textLost means Get!No losing No getting!If you want keep,you always lose!Certainly It is!I am studing orders of Linux!I am trying to write as many as lines of text![root@localhost Documents]# </code></pre><hr><pre><code>8)[root@localhost Documents]# head --help复制代码[root@localhost Documents]# head --help用法：head [选项]... [文件]...Print the first 10 lines of each FILE to standard output.With more than one FILE, precede each with a header giving the file name.With no FILE, or when FILE is -, read standard input.Mandatory arguments to long options are mandatory for short options too.  -c, --bytes=[-]K         print the first K bytes of each file;                             with the leading '-', print all but the last                             K bytes of each file  -n, --lines=[-]K         print the first K lines instead of the first 10;                             with the leading '-', print all but the last                             K lines of each file  -q, --quiet, --silent    不显示包含给定文件名的文件头  -v, --verbose        总是显示包含给定文件名的文件头      --help        显示此帮助信息并退出      --version        显示版本信息并退出K 后面可以跟乘号:b 512, kB 1000, K 1024, MB 1000*1000, M 1024*1024,GB 1000*1000*1000, G 1024*1024*1024, 对于T, P, E, Z, Y 同样适用。GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告head 的翻译错误要获取完整文档，请运行：info coreutils 'head invocation'</code></pre><hr><pre><code>9)[root@localhost Documents]# head --version复制代码[root@localhost Documents]# head --versionhead (GNU coreutils) 8.22Copyright (C) 2013 Free Software Foundation, Inc.许可证：GPLv3+：GNU 通用公共许可证第3 版或更新版本&lt;http://gnu.org/licenses/gpl.html&gt;。本软件是自由软件：您可以自由修改和重新发布它。在法律范围内没有其他保证。由David MacKenzie 和Jim Meyering 编写。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>webService和SOAP的区别</title>
      <link href="/2017/07/19/webservice-he-soap-de-qu-bie/"/>
      <url>/2017/07/19/webservice-he-soap-de-qu-bie/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-18-WebService和SOAP的区别"><a href="#2017-07-18-WebService和SOAP的区别" class="headerlink" title="2017-07-18 WebService和SOAP的区别"></a><center>2017-07-18 WebService和SOAP的区别</center></h2><pre><code>在SOA的基础技术实现方式中WebService占据了很重要的地位，通常我们提到WebService第一想法就是SOAP消息在各种传输协议上交互。近几年REST的思想伴随着SOA逐渐被大家接受，同时各大网站不断开放API提供给开发者，也激起了REST风格WebService的热潮。  SOAP</code></pre><hr><pre><code>什么是SOAP，我想不用多说，google一把满眼都是。其实SOAP最早是针对RPC的一种解决方案，简单对象访问协议，很轻量，同时作为应用协议可以基于多种传输协议来传递消息（Http,SMTP等）。但是随着SOAP作为WebService的广泛应用，不断地增加附加的内容，使得现在开发人员觉得SOAP很重，使用门槛很高。在SOAP后续的发展过程中，WS-*一系列协议的制定，增加了SOAP的成熟度，也给SOAP增加了负担。</code></pre><hr><pre><code>REST   REST其实并不是什么协议也不是什么标准，而是将Http协议的设计初衷作了诠释，在Http协议被广泛利用的今天，   越来越多的是将其作为传输协议，而非原先设计者所考虑的应用协议。SOAP类型的WebService就是最好的例子，   SOAP消息完全就是将Http协议作为消息承载，以至于对于Http协议中的各种参数（例如编码，错误码等）都置之不顾。   其实，最轻量级的应用协议就是Http协议。Http协议所抽象的get,post,put,delete就好比数据库中最基本的增删改查，   而互联网上的各种资源就好比数据库中的记录（可能这么比喻不是很好），对于各种资源的操作最后总是能抽象成为这四种基本操作，   在定义了定位资源的规则以后，对于资源的操作通过标准的Http协议就可以实现，开发者也会受益于这种轻量级的协议。REST的思想归结以下有如下几个关键点：</code></pre><hr><p>1．面向资源的接口设计</p><pre><code>所有的接口设计都是针对资源来设计的，也就很类似于我们的面向对象和面向过程的设计区别，只不过现在将网络上的操作实体都作为资源来看待，同时URI的设计也是体现了对于资源的定位设计。后面会提到有一些网站的API设计说是REST设计，其实是RPC-REST的混合体，并非是REST的思想。</code></pre><hr><p>2．抽象操作为基础的CRUD</p><pre><code>这点很简单，Http中的get,put,post,delete分别对应了read,update,create,delete四种操作，如果仅仅是作为对于资源的操作，抽象成为这四种已经足够了，但是对于现在的一些复杂的业务服务接口设计，可能这样的抽象未必能够满足。其实这也在后面的几个网站的API设计中暴露了这样的问题，如果要完全按照REST的思想来设计，那么适用的环境将会有限制，而非放之四海皆准的。     </code></pre><hr><p>3．Http是应用协议而非传输协议</p><pre><code>这点在后面各大网站的API分析中有很明显的体现，其实有些网站已经走到了SOAP的老路上，说是REST的理念设计，其实是作了一套私有的SOAP协议，因此称之为REST风格的自定义SOAP协议。</code></pre><hr><p>4．无状态，自包含</p><pre><code>这点其实不仅仅是对于REST来说的，作为接口设计都需要能够做到这点，也是作为可扩展和高效性的最基本的保证，就算是使用SOAP的WebService也是一样。</code></pre><hr><p>REST vs SOAP</p><p>成熟度：</p><pre><code>    SOAP虽然发展到现在已经脱离了初衷，但是对于异构环境服务发布和调用，以及厂商的支持都已经达到了较为成熟的情况。    不同平台，开发语言之间通过SOAP来交互的web service都能够较好的互通（在部分复杂和特殊的参数和返回对象解析上，    协议没有作很细致的规定，导致还是需要作部分修正）    REST国外很多大网站都发布了自己的开发API，很多都提供了SOAP和REST两种Web Service，    根据调查部分网站的REST风格的使用情况要高于SOAP。但是由于REST只是一种基于Http协议实现资源操作的思想，    因此各个网站的REST实现都自有一套，在后面会讲诉各个大网站的REST API的风格。也正是因为这种各自实现的情况，    在性能和可用性上会大大高于SOAP发布的web service，但统一通用方面远远不及SOAP。    由于这些大网站的SP往往专注于此网站的API开发，因此通用性要求不高。    由于没有类似于SOAP的权威性协议作为规范，REST实现的各种协议仅仅只能算是私有协议，    当然需要遵循REST的思想，但是这样细节方面有太多没有约束的地方。    REST日后的发展所走向规范也会直接影响到这部分的设计是否能够有很好的生命力。    总的来说SOAP在成熟度上优于REST。</code></pre><hr><p>效率和易用性：</p><pre><code>   SOAP协议对于消息体和消息头都有定义，同时消息头的可扩展性为各种互联网的标准提供了扩展的基础，   WS-*系列就是较为成功的规范。但是也由于SOAP由于各种需求不断扩充其本身协议的内容，   导致在SOAP处理方面的性能有所下降。同时在易用性方面以及学习成本上也有所增加。   REST被人们的重视，其实很大一方面也是因为其高效以及简洁易用的特性。   这种高效一方面源于其面向资源接口设计以及操作抽象简化了开发者的不良设计，   同时也最大限度的利用了Http最初的应用协议设计理念。   同时，在我看来REST还有一个很吸引开发者的就是能够很好的融合当前Web2.0的很多前端技术来提高开发效率。   例如很多大型网站开放的REST风格的API都会有多种返回形式，除了传统的xml作为数据承载，   还有（JSON,RSS,ATOM）等形式，这对很多网站前端开发人员来说就能够很好的mashup各种资源信息。   因此在效率和易用性上来说，REST更胜一筹。</code></pre><hr><p>安全性：</p><pre><code>   这点其实可以放入到成熟度中，不过在当前的互联网应用和平台开发设计过程中，   安全已经被提到了很高的高度，特别是作为外部接口给第三方调用，安全性可能会高过业务逻辑本身。   SOAP在安全方面是通过使用XML-Security和XML-Signature两个规范组成了WS-Security来实现安全控制的，   当前已经得到了各个厂商的支持，.net ，php ，java 都已经对其有了很好的支持  （虽然在一些细节上还是有不兼容的问题，但是互通基本上是可以的）。   REST没有任何规范对于安全方面作说明，同时现在开放REST风格API的网站主要分成两种，   一种是自定义了安全信息封装在消息中（其实这和SOAP没有什么区别），  另外一种就是靠硬件SSL来保障,但是这只能够保证点到点的安全，如果是需要多点传输的话SSL就无能为力了。  安全这块其实也是一个很大的问题，今年在BEA峰会上看到有演示采用SAML2实现的网站间SSO，  其实是直接采用了XML-Security和XML-Signature，效率看起来也不是很高。  未来REST规范化和通用化过程中的安全是否也会采用这两种规范，是未知的，但是加入的越多，REST失去它高效性的优势越多。</code></pre><hr><p>应用设计与改造：</p><pre><code>   我们的系统要么就是已经有了那些需要被发布出去的服务，要么就是刚刚设计好的服务，   但是开发人员的传统设计思想让REST的形式被接受还需要一点时间。   同时在资源型数据服务接口设计上来说按照REST的思想来设计相对来说要容易一些，而对于一些复杂的服务接口来说，   可能强要去按照REST的风格来设计会有些牵强。这一点其实可以看看各大网站的接口就可以知道，   很多网站还要传入function的名称作为参数，这就明显已经违背了REST本身的设计思路。   而SOAP本身就是面向RPC来设计的，开发人员十分容易接受，所以不存在什么适应的过程。   总的来说，其实还是一个老观念，适合的才是最好的</code></pre><hr><pre><code>技术没有好坏，只有是不是合适，一种好的技术和思想被误用了，那么就会得到反效果。REST和SOAP各自都有自己的优点，同时如果在一些场景下如果去改造REST，其实就会走向SOAP（例如安全）。   REST对于资源型服务接口来说很合适，同时特别适合对于效率要求很高，但是对于安全要求不高的场景。   而SOAP的成熟性可以给需要提供给多开发语言的，对于安全性要求较高的接口设计带来便利。   所以我觉得纯粹说什么设计模式将会占据主导地位没有什么意义，关键还是看应用场景。   同时很重要一点就是不要扭曲了REST现在很多网站都跟风去开发REST风格的接口，其实都是在学其形，   不知其心，最后弄得不伦不类，性能上不去，安全又保证不了，徒有一个看似象摸象样的皮囊。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> webservice </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
            <tag> webservice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>理解restful架构</title>
      <link href="/2017/07/19/li-jie-restful-jia-gou/"/>
      <url>/2017/07/19/li-jie-restful-jia-gou/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-18-理解RESTful架构"><a href="#2017-07-18-理解RESTful架构" class="headerlink" title="2017-07-18 理解RESTful架构"></a><center>2017-07-18 理解RESTful架构</center></h2><pre><code>越来越多的人开始意识到，网站即软件，而且是一种新型的软件。这种"互联网软件"采用客户端/服务器模式，建立在分布式体系上，通过互联网通信，具有高延时（high latency）、高并发等特点。网站开发，完全可以采用软件开发的模式。但是传统上，软件和网络是两个不同的领域，很少有交集；软件开发主要针对单机环境，网络则主要研究系统之间的通信。互联网的兴起，使得这两个领域开始融合，现在我们必须考虑，如何开发在互联网环境中使用的软件。</code></pre><p><img src="/images/20170718/27.png"></p><pre><code>RESTful架构，就是目前最流行的一种互联网软件架构。它结构清晰、符合标准、易于理解、扩展方便，所以正得到越来越多网站的采用。但是，到底什么是RESTful架构，并不是一个容易说清楚的问题。下面，我就谈谈我理解的RESTful架构。</code></pre><hr><p>一、起源</p><pre><code>REST这个词，是Roy Thomas Fielding在他2000年的博士论文中提出的。</code></pre><p><img src="/images/20170718/28.png"></p><pre><code>Fielding是一个非常重要的人，他是HTTP协议（1.0版和1.1版）的主要设计者、Apache服务器软件的作者之一、Apache基金会的第一任主席。所以，他的这篇论文一经发表，就引起了关注，并且立即对互联网开发产生了深远的影响。他这样介绍论文的写作目的："本文研究计算机科学两大前沿----软件和网络----的交叉点。长期以来，软件研究主要关注软件设计的分类、设计方法的演化，很少客观地评估不同的设计选择对系统行为的影响。而相反地，网络研究主要关注系统之间通信行为的细节、如何改进特定通信机制的表现，常常忽视了一个事实，那就是改变应用程序的互动风格比改变互动协议，对整体表现有更大的影响。我这篇文章的写作目的，就是想在符合架构原理的前提下，理解和评估以网络为基础的应用软件的架构设计，得到一个功能强、性能好、适宜通信的架构。"(This dissertation explores a junction on the frontiers of two research disciplines in computer science: &lt;br/&gt; software and networking. Software research has long been concerned with the categorization of software &lt;br/&gt;designs and the development of design methodologies, but has rarely been able to objectively evaluate &lt;br/&gt;the impact of various design choices on system behavior. Networking research, &lt;br/&gt;in contrast, &lt;br/&gt;is focused on the details of generic communication behavior between systems and improving the performance of &lt;br/&gt;particular communication techniques, often ignoring the fact that changing the interaction style of an application&lt;br/&gt; can have more impact on performance than the communication protocols used for that interaction.&lt;br/&gt; My work is&lt;br/&gt; motivated by the desire to understand and evaluate the architectural design of network-based application software &lt;br/&gt;through principled use of architectural constraints, thereby obtaining the functional, performance, &lt;br/&gt;and social properties desired of an architecture. )</code></pre><hr><p>二、名称</p><pre><code>Fielding将他对互联网软件的架构原则，定名为REST，即Representational State Transfer的缩写。我对这个词组的翻译是"表现层状态转化"。如果一个架构符合REST原则，就称它为RESTful架构。要理解RESTful架构，最好的方法就是去理解Representational State Transfer这个词组到底是什么意思，它的每一个词代表了什么涵义。如果你把这个名称搞懂了，也就不难体会REST是一种什么样的设计</code></pre><hr><p>三、资源（Resources）</p><pre><code>REST的名称"表现层状态转化"中，省略了主语。"表现层"其实指的是"资源"（Resources）的"表现层"。所谓"资源"，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。你可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的URI。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或独一无二的识别符。所谓"上网"，就是与互联网上一系列的"资源"互动，调用它的URI。</code></pre><hr><p>四、表现层（Representation）</p><pre><code>"资源"是一种信息实体，它可以有多种外在表现形式。我们把"资源"具体呈现出来的形式，叫做它的"表现层"（Representation）。比如，文本可以用txt格式表现，也可以用HTML格式、XML格式、JSON格式表现，甚至可以采用二进制格式；图片可以用JPG格式表现，也可以用PNG格式表现。URI只代表资源的实体，不代表它的形式。严格地说，有些网址最后的".html"后缀名是不必要的，因为这个后缀名表示格式，属于"表现层"范畴，而URI应该只代表"资源"的位置。它的具体表现形式，应该在HTTP请求的头信息中用Accept和Content-Type字段指定，这两个字段才是对"表现层"的描述。</code></pre><hr><p>五、状态转化（State Transfer）</p><pre><code>访问一个网站，就代表了客户端和服务器的一个互动过程。在这个过程中，势必涉及到数据和状态的变化。互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生"状态转化"（State Transfer）。而这种转化是建立在表现层之上的，所以就是"表现层状态转化"。客户端用到的手段，只能是HTTP协议。具体来说，就是HTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。</code></pre><hr><p>六、综述</p><pre><code>综合上面的解释，我们总结一下什么是RESTful架构：　　（1）每一个URI代表一种资源；　　（2）客户端和服务器之间，传递这种资源的某种表现层；　　（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现"表现层状态转化"。</code></pre><hr><p>七、误区</p><pre><code>RESTful架构有一些典型的设计误区。最常见的一种设计错误，就是URI包含动词。因为"资源"表示一种实体，所以应该是名词，URI不应该有动词，动词应该放在HTTP协议中。举例来说，某个URI是/posts/show/1，其中show是动词，这个URI就设计错了，正确的写法应该是/posts/1，然后用GET方法表示show。如果某些动作是HTTP动词表示不了的，你就应该把动作做成一种资源。比如网上汇款，从账户1向账户2汇款500元，错误的URI是：　　POST /accounts/1/transfer/500/to/2正确的写法是把动词transfer改成名词transaction，资源不能是动词，但是可以是一种服务：　　POST /transaction HTTP/1.1　　Host: 127.0.0.1　　　　from=1&amp;to=2&amp;amount=500.00另一个设计误区，就是在URI中加入版本号：　　http://www.example.com/app/1.0/foo　　http://www.example.com/app/1.1/foo　　http://www.example.com/app/2.0/foo因为不同的版本，可以理解成同一种资源的不同表现形式，所以应该采用同一个URI。版本号可以在HTTP请求头信息的Accept字段中进行区分（参见Versioning REST Services）：　　Accept: vnd.example-com.foo+json; version=1.0　　Accept: vnd.example-com.foo+json; version=1.1　　Accept: vnd.example-com.foo+json; version=2.0</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> restful </category>
          
      </categories>
      
      
        <tags>
            
            <tag> restful </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>webservice学习-02</title>
      <link href="/2017/07/19/webservice-xue-xi-02/"/>
      <url>/2017/07/19/webservice-xue-xi-02/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-18-Webservice-02"><a href="#2017-07-18-Webservice-02" class="headerlink" title=" 2017-07-18 Webservice-02"></a><center> 2017-07-18 Webservice-02</center></h2><p>1    课程回顾</p><hr><p>2    课程安排：</p><pre><code>*    CXF的介绍、安装和配置*    CXF发布SOAP协议的服务*    CXF+Spring整合发布SOAP的服务*    CXF发布REST服务*    什么是REST*    CXF+Spring整合发布REST服务*    综合案例</code></pre><hr><p>3    CXF介绍、安装和配置</p><pre><code>3.1    CXF介绍*    CXF是一个开源的webservice框架，提供很多完善功能，可以实现快速开发*    CXF支持的协议：SOAP1.1/1.2，REST*    CXF支持数据格式：XML，JSON（仅在REST方式下支持）</code></pre><hr><pre><code>3.2    CXF的安装和配置    下载地址http://cxf.apache.org/download.html*    包结构介绍</code></pre><p><img src="/images/20170718/17.png"></p><pre><code>*    安装和配置*    第一步：安装JDK，建议1.7</code></pre><p><img src="/images/20170718/18.png"></p><pre><code>*    第二步：解压apache-cxf-2.7.11.zip到指定目录，创建CXF_HOME</code></pre><p><img src="/images/20170718/19.png"></p><pre><code>*    第三步：把CXF_HOME加入到Path路径下</code></pre><p><img src="/images/20170718/20.png"></p><pre><code>*    第四步：测试，在cmd下加入wsdl2java –h</code></pre><p><img src="/images/20170718/21.png"></p><pre><code>*    如果不想使用IDE（比如Eclipse），需要在环境变量下配置如下信息</code></pre><p><img src="/images/20170718/22.png"></p><hr><p>4    CXF发布SOAP协议的服务</p><pre><code>4.1    需求服务端：发布服务，接收客户端的城市名，返回天气数据给客户端客户端：发送城市名给服务端，接收服务端的响应信息，打印</code></pre><hr><pre><code>4.2    实现    4.2.1    服务端    开发步骤：    第一步：导入Jar包    第二步：创建SEI接口，要加入@WebService    package cn.itcast.ws.cxf.server;    import javax.jws.WebService;    /**     *      * &lt;p&gt;Title: WeatherInterface.java&lt;/p&gt;     * &lt;p&gt;Description:SEI接口&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月27日上午9:47:43     * @version 1.0     */    @WebService    public interface WeatherInterface {        public String queryWeather(String cityName);    }    第三步：创建SEI实现类    package cn.itcast.ws.cxf.server;    /**     *      * &lt;p&gt;Title: WeatherInterfaceImpl.java&lt;/p&gt;     * &lt;p&gt;Description:SEI实现类&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月27日上午9:50:59     * @version 1.0     */    public class WeatherInterfaceImpl implements WeatherInterface {        @Override        public String queryWeather(String cityName) {            System.out.println("from client..."+cityName);            if("北京".equals(cityName)){                return "冷且霾";            } else {                return "暖且晴";            }        }    }    第四步：发布服务, JaxWsServerFactoryBean发布，设置3个参数，1.服务接口；2.服务实现类；3.服务地址；    endpoint仅支持发布实现类，JaxWsServerFactoryBean支持发布接口。    package cn.itcast.ws.cxf.server;    import org.apache.cxf.jaxws.JaxWsServerFactoryBean;    import org.apache.cxf.tools.java2wsdl.processor.internal.jaxws.generator.JaxwsServerGenerator;    /**     *      * &lt;p&gt;Title: WeatherServer.java&lt;/p&gt;     * &lt;p&gt;Description:服务端&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月27日上午9:51:36     * @version 1.0     */    public class WeatherServer {        public static void main(String[] args) {            //JaxWsServerFactoryBean发布服务            JaxWsServerFactoryBean jaxWsServerFactoryBean = new JaxWsServerFactoryBean();            //设置服务接口            jaxWsServerFactoryBean.setServiceClass(WeatherInterface.class);            //设置服务实现类            jaxWsServerFactoryBean.setServiceBean(new WeatherInterfaceImpl());            //设置服务地址            jaxWsServerFactoryBean.setAddress("http://127.0.0.1:12345/weather");            //发布            jaxWsServerFactoryBean.create();        }    }    第五步：测试服务是否发布成功，阅读使用说明书，确定关键点    如果在CXF发布的服务下，直接访问服务地址，会如下异常</code></pre><p><img src="/images/20170718/23.png"></p><pre><code>    此时直接访问使用说明书地址即可</code></pre><hr><pre><code>4.2.1.1    发布SOAP1.2的服务端*    在接口上加入如下注解：@BindingType(SOAPBinding.SOAP12HTTP_BINDING)4.2.1.2    拦截器*    原理：*    拦截器可以拦截请求和响应*    拦截器可以有多个*    拦截器可以根据需要自定义*    使用*    拦截器必须加到服务端，在服务端发布之前*    获取拦截器列表，将自己的拦截器加入列表中    重新发布服务端</code></pre><hr><pre><code>4.2.2    客户端第一步：生成客户端代码*    Wsdl2java命令是CXF提供的生成客户端的工具，他和wsimport类似，可以根据WSDL生成客户端代码*    Wsdl2java常用参数：    -d，指定输出目录    -p，指定包名，如果不指定该参数，默认包名是WSDL的命名空间的倒序*    Wsdl2java支持SOAP1.1和SOAP1.2第二步：使用说明书，使用生成代码调用服务端JaxWsProxyFactoryBean调用服务端，设置2个参数，1.设置服务接口；2.设置服务地址package cn.itcast.cxf.client;import org.apache.cxf.jaxws.JaxWsProxyFactoryBean;import cn.itcast.cxf.weather.WeatherInterface;/** *  * &lt;p&gt;Title: WeatherClient.java&lt;/p&gt; * &lt;p&gt;Description:客户端&lt;/p&gt; * &lt;p&gt;Company: www.itcast.com&lt;/p&gt; * @author  传智.at * @date    2015年11月27日上午10:12:24 * @version 1.0 */public class WeatherClient {    public static void main(String[] args) {        //JaxWsProxyFactoryBean调用服务端        JaxWsProxyFactoryBean jaxWsProxyFactoryBean = new JaxWsProxyFactoryBean();        //设置服务接口        jaxWsProxyFactoryBean.setServiceClass(WeatherInterface.class);        //设置服务地址        jaxWsProxyFactoryBean.setAddress("http://127.0.0.1:12345/weather");        //获取服务接口实例        WeatherInterface weatherInterface = jaxWsProxyFactoryBean.create(WeatherInterface.class);        //调用查询方法        String weather = weatherInterface.queryWeather("保定");        System.out.println(weather);    }}</code></pre><hr><p>5    CXF+Spring整合发布SOAP协议的服务</p><p>5.1    服务端</p><hr><pre><code>开发步骤：第一步：创建web项目（引入jar包）第二步：创建SEI接口第三步：创建SEI实现类第四步：配置spring配置文件，applicationContext.xml，用&lt;jaxws:server标签发布服务，设置1.服务地址；2.设置服务接口；3设置服务实现类&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans"    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jaxws="http://cxf.apache.org/jaxws"    xmlns:jaxrs="http://cxf.apache.org/jaxrs" xmlns:cxf="http://cxf.apache.org/core"    xsi:schemaLocation="http://www.springframework.org/schema/beans                             http://www.springframework.org/schema/beans/spring-beans.xsd                            http://cxf.apache.org/jaxrs http://cxf.apache.org/schemas/jaxrs.xsd                            http://cxf.apache.org/jaxws http://cxf.apache.org/schemas/jaxws.xsd                            http://cxf.apache.org/core http://cxf.apache.org/schemas/core.xsd"&gt;    &lt;!-- &lt;jaxws:server发布SOAP协议的服务 ，对JaxWsServerFactoryBean类封装--&gt;    &lt;jaxws:server address="/weather" serviceClass="cn.itcast.ws.cxf.server.WeatherInterface"&gt;        &lt;jaxws:serviceBean&gt;            &lt;ref bean="weatherInterface"/&gt;        &lt;/jaxws:serviceBean&gt;    &lt;/jaxws:server&gt;    &lt;!-- 配置服务实现类 --&gt;    &lt;bean name="weatherInterface" class="cn.itcast.ws.cxf.server.WeatherInterfaceImpl"/&gt;&lt;/beans&gt;第五步：配置web.xml，配置spring配置文件地址和加载的listener，配置CXF的servlet&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd" id="WebApp_ID" version="3.0"&gt;  &lt;display-name&gt;ws_2_cxf_spring_server&lt;/display-name&gt;  &lt;!-- 设置spring的环境 --&gt;  &lt;context-param&gt;      &lt;!--contextConfigLocation是不能修改的  --&gt;      &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;      &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;  &lt;/context-param&gt;  &lt;listener&gt;      &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;  &lt;/listener&gt;  &lt;!-- 配置CXF的Servlet --&gt;  &lt;servlet&gt;      &lt;servlet-name&gt;CXF&lt;/servlet-name&gt;      &lt;servlet-class&gt;org.apache.cxf.transport.servlet.CXFServlet&lt;/servlet-class&gt;  &lt;/servlet&gt;  &lt;servlet-mapping&gt;      &lt;servlet-name&gt;CXF&lt;/servlet-name&gt;      &lt;url-pattern&gt;/ws/*&lt;/url-pattern&gt;  &lt;/servlet-mapping&gt;  &lt;welcome-file-list&gt;    &lt;welcome-file&gt;index.html&lt;/welcome-file&gt;    &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt;    &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt;    &lt;welcome-file&gt;default.html&lt;/welcome-file&gt;    &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt;    &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt;  &lt;/welcome-file-list&gt;&lt;/web-app&gt;第六步：部署到tomcat下，启动tomcat第七步：测试服务，阅读使用说明书WSDL地址规则：http://ip:端口号/项目名称/servlet拦截路径/服务名称?wsdl</code></pre><hr><pre><code>5.1.1    拦截器配置配置applicationContext.xml中。</code></pre><p><img src="/images/20170718/24.png"></p><hr><p>5.1.2    Endpoint标签发布服务</p><pre><code>&lt;jaxws:endpoint&gt;标签package cn.itcast.ws.cxf.server;import javax.jws.WebService;/** *  * &lt;p&gt;Title: HelloWorld.java&lt;/p&gt; * &lt;p&gt;Description:简单类&lt;/p&gt; * &lt;p&gt;Company: www.itcast.com&lt;/p&gt; * @author  传智.at * @date    2015年11月27日上午11:11:10 * @version 1.0 */@WebServicepublic class HelloWorld {    public String sayHello(String name){        return "hello,"+name;    }}</code></pre><hr><pre><code>5.2    客户端    开发步骤：    第一步：引入jar包    第二步：生成客户端代码    第三步：配置spring配置文件，applicationContent.xml    &lt;?xml version="1.0" encoding="UTF-8"?&gt;    &lt;beans xmlns="http://www.springframework.org/schema/beans"        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jaxws="http://cxf.apache.org/jaxws"        xmlns:jaxrs="http://cxf.apache.org/jaxrs" xmlns:cxf="http://cxf.apache.org/core"        xsi:schemaLocation="http://www.springframework.org/schema/beans                                 http://www.springframework.org/schema/beans/spring-beans.xsd                                http://cxf.apache.org/jaxrs http://cxf.apache.org/schemas/jaxrs.xsd                                http://cxf.apache.org/jaxws http://cxf.apache.org/schemas/jaxws.xsd                                http://cxf.apache.org/core http://cxf.apache.org/schemas/core.xsd"&gt;        &lt;!-- &lt;jaxws:client实现客户端 ，对JaxWsProxyFactoryBean类封装--&gt;            &lt;jaxws:client id="weatherClient"         address="http://127.0.0.1:8080/ws_2_cxf_spring_server/ws/weather" serviceClass="cn.itcast.cxf.weather.WeatherInterface"/&gt;    &lt;/beans&gt;    第四步：从spring上下文件获取服务实现类    第五步：调用查询方法，打印    package cn.itcast.cxf.client;    import org.springframework.context.ApplicationContext;    import org.springframework.context.support.ClassPathXmlApplicationContext;    import cn.itcast.cxf.weather.WeatherInterface;    public class WeatherClient {        public static void main(String[] args) {            //初始化spring的上下文            ApplicationContext context = new ClassPathXmlApplicationContext("classpath:applicationContext.xml");            WeatherInterface  weatherInterface = (WeatherInterface) context.getBean("weatherClient");            String weather = weatherInterface.queryWeather("保定");            System.out.println(weather);        }    }</code></pre><hr><p>6    上午课程回顾</p><hr><p>7    CXF发布REST的服务</p><pre><code>7.1    什么是REST*    定义：REST就是一种编程风格，它可以精确定位网上资源（服务接口、方法、参数）*    REST支持数据格式：XML、JSON*    REST支持发送方式：GET，POST</code></pre><hr><pre><code>7.2    需求*    第一个：查询单个学生*    第二个：查询多个学生</code></pre><hr><pre><code>7.3    实现    7.3.1    服务端    开发步骤：    第一步：导入jar包    第二步：创建学生pojo类，要加入@ XmlRootElement    package cn.itcast.ws.rest.pojo;    import java.util.Date;    import javax.xml.bind.annotation.XmlRootElement;    /**     *      * &lt;p&gt;Title: Student.java&lt;/p&gt;     * &lt;p&gt;Description:学生实体类&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月27日下午3:00:17     * @version 1.0     */    @XmlRootElement(name="student")//@XmlRootElement可以实现对象和XML数据之间的转换    public class Student {        private long id;        private String name;        private Date birthday;        public long getId() {            return id;        }        public void setId(long id) {            this.id = id;        }        public String getName() {            return name;        }        public void setName(String name) {            this.name = name;        }        public Date getBirthday() {            return birthday;        }        public void setBirthday(Date birthday) {            this.birthday = birthday;        }    }    第三步：创建SEI接口    package cn.itcast.ws.rest.server;    import java.util.List;    import javax.jws.WebService;    import javax.ws.rs.GET;    import javax.ws.rs.Path;    import javax.ws.rs.PathParam;    import javax.ws.rs.Produces;    import javax.ws.rs.core.MediaType;    import cn.itcast.ws.rest.pojo.Student;    /**     *      * &lt;p&gt;Title: StudentInterface.java&lt;/p&gt;     * &lt;p&gt;Description:学生接口&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月27日下午3:03:08     * @version 1.0     */    @WebService    @Path("/student")//@Path("/student")就是将请求路径中的“/student”映射到接口上    public interface StudentInterface {        //查询单个学生        @GET//指定请求方式，如果服务端发布的时候指定的是GET（POST），那么客户端访问时必须使用GET（POST）        @Produces(MediaType.APPLICATION_XML)//指定服务数据类型        @Path("/query/{id}")//@Path("/query/{id}")就是将“/query”映射到方法上，“{id}”映射到参数上，多个参数，以“/”隔开，放到“{}”中        public Student query(@PathParam("id")long id);        //查询多个学生        @GET//指定请求方式，如果服务端发布的时候指定的是GET（POST），那么客户端访问时必须使用GET（POST）        @Produces(MediaType.APPLICATION_XML)//指定服务数据类型        @Path("/queryList/{name}")//@Path("/queryList/{name}")就是将“/queryList”映射到方法上，“{name}”映射到参数上，多个参数，以“/”隔开，放到“{}”中        public List&lt;Student&gt; queryList(@PathParam("name")String name);    }    第四步：创建SEI实现类    package cn.itcast.ws.rest.server;    import java.util.ArrayList;    import java.util.Date;    import java.util.List;    import cn.itcast.ws.rest.pojo.Student;    /**     *      * &lt;p&gt;Title: StudentInterfaceImpl.java&lt;/p&gt;     * &lt;p&gt;Description:学生的实现类&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月27日下午3:12:54     * @version 1.0     */    public class StudentInterfaceImpl implements StudentInterface {        @Override        public Student query(long id) {            Student st = new Student();            st.setId(110);            st.setName("张三");            st.setBirthday(new Date());            return st;        }        @Override        public List&lt;Student&gt; queryList(String name) {            Student st = new Student();            st.setId(110);            st.setName("张三");            st.setBirthday(new Date());            Student st2 = new Student();            st2.setId(120);            st2.setName("李四");            st2.setBirthday(new Date());            List&lt;Student&gt; list = new ArrayList&lt;Student&gt;();            list.add(st);            list.add(st2);            return list;        }    }    第五步：发布服务, JAXRSServerFactoryBean发布服务，3个参数，1：服务实现类；2.设置资源类；3.设置服务地址    package cn.itcast.ws.rest.server;    import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;    import cn.itcast.ws.rest.pojo.Student;    /**     *      * &lt;p&gt;Title: StudentServer.java&lt;/p&gt;     * &lt;p&gt;Description:服务端&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月27日下午3:16:06     * @version 1.0     */    public class StudentServer {        public static void main(String[] args) {            //JAXRSServerFactoryBean发布REST的服务            JAXRSServerFactoryBean jaxRSServerFactoryBean = new JAXRSServerFactoryBean();            //设置服务实现类            jaxRSServerFactoryBean.setServiceBean(new StudentInterfaceImpl());            //设置资源类，如果有多个资源类，可以以“,”隔开。            jaxRSServerFactoryBean.setResourceClasses(StudentInterfaceImpl.class);            //设置服务地址            jaxRSServerFactoryBean.setAddress("http://127.0.0.1:12345/user");            //发布服务            jaxRSServerFactoryBean.create();        }    }    第六步：测试服务    http://127.0.0.1:12345/user/student/query/110 查询单个学生，返回XML数据    &lt;student&gt;    &lt;birthday&gt;2015-11-27T15:22:14.240+08:00&lt;/birthday&gt;    &lt;id&gt;110&lt;/id&gt;    &lt;name&gt;张三&lt;/name&gt;    &lt;/student&gt;    http://127.0.0.1:12345/user/student/queryList/110?_type=json     查询多个学生，返回JSON    {"student":[{"birthday":"2015-11-27T15:24:21.565+08:00","id":110,"name":"张三"},{"birthday":"2015-11-27T15:24:21.565+08:00","id":120,"name":"李四"}]}    http://127.0.0.1:12345/user/student/queryList/110?_type=xml     查询多个学生，返回XML    &lt;students&gt;    &lt;student&gt;    &lt;birthday&gt;2015-11-27T15:30:33.754+08:00&lt;/birthday&gt;    &lt;id&gt;110&lt;/id&gt;    &lt;name&gt;张三&lt;/name&gt;    &lt;/student&gt;    &lt;student&gt;    &lt;birthday&gt;2015-11-27T15:30:33.754+08:00&lt;/birthday&gt;    &lt;id&gt;120&lt;/id&gt;    &lt;name&gt;李四&lt;/name&gt;    &lt;/student&gt;    &lt;/students&gt;    如果服务端发布时指定请求方式是GET（POST），客户端必须使用GET（POST）访问服务端，否则会报如下异常</code></pre><p><img src="/images/20170718/25.png"></p><pre><code>    如果在同一方法上同时指定XML和JSON媒体类型，在GET请求下，默认返回XML，在POST请求下，默认返回JSON</code></pre><hr><pre><code>7.3.2    客户端可以自学一下httpclienthttp://hc.apache.org/httpclient-3.x/package cn.itcast.cxf.client;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import java.io.OutputStream;import java.net.HttpURLConnection;import java.net.MalformedURLException;import java.net.URL;/** *  * &lt;p&gt;Title: HttpClient.java&lt;/p&gt; * &lt;p&gt;Description:HttpURLConnection调用方式&lt;/p&gt; * &lt;p&gt;Company: www.itcast.com&lt;/p&gt; * @author  传智.at * @date    2015年11月26日下午3:58:57 * @version 1.0 */public class HttpClient {    public static void main(String[] args) throws IOException {        //第一步：创建服务地址，不是WSDL地址        URL url = new URL("http://127.0.0.1:12345/user/student/query/110");        //第二步：打开一个通向服务地址的连接        HttpURLConnection connection = (HttpURLConnection) url.openConnection();        //第三步：设置参数        //3.1发送方式设置：POST必须大写        connection.setRequestMethod("POST");        //3.2设置数据格式：content-type        //3.3设置输入输出，因为默认新创建的connection没有读写权限，        connection.setDoInput(true);        //第五步：接收服务端响应，打印        int responseCode = connection.getResponseCode();        if(200 == responseCode){//表示服务端响应成功            InputStream is = connection.getInputStream();            InputStreamReader isr = new InputStreamReader(is);            BufferedReader br = new BufferedReader(isr);            StringBuilder sb = new StringBuilder();            String temp = null;            while(null != (temp = br.readLine())){                sb.append(temp);            }            System.out.println(sb.toString());            //dom4j解析返回数据，课下作业            is.close();            isr.close();            br.close();        }    }}</code></pre><hr><p>8    CXF+Spring整合发布REST的服务</p><pre><code>8.1    服务端    开发步骤：    第一步：创建web项目（引入jar包）    第二步：创建POJO类    第三步：创建SEI接口    第四步：创建SEI实现类    第五步：配置Spring配置文件,applicationContext.xml，&lt;jaxrs:server，设置1.服务地址；2.服务实现类    &lt;?xml version="1.0" encoding="UTF-8"?&gt;    &lt;beans xmlns="http://www.springframework.org/schema/beans"        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jaxws="http://cxf.apache.org/jaxws"        xmlns:jaxrs="http://cxf.apache.org/jaxrs" xmlns:cxf="http://cxf.apache.org/core"        xsi:schemaLocation="http://www.springframework.org/schema/beans                                 http://www.springframework.org/schema/beans/spring-beans.xsd                                http://cxf.apache.org/jaxrs http://cxf.apache.org/schemas/jaxrs.xsd                                http://cxf.apache.org/jaxws http://cxf.apache.org/schemas/jaxws.xsd                                http://cxf.apache.org/core http://cxf.apache.org/schemas/core.xsd"&gt;        &lt;!-- &lt;jaxrs:server发布REST的服务 ，对JAXRSServerFactoryBean类封装--&gt;            &lt;jaxrs:server address="/user"&gt;            &lt;jaxrs:serviceBeans&gt;                &lt;ref bean="studentInterface"/&gt;            &lt;/jaxrs:serviceBeans&gt;        &lt;/jaxrs:server&gt;        &lt;!-- 配置服务实现类 --&gt;        &lt;bean name="studentInterface" class="cn.itcast.ws.rest.server.StudentInterfaceImpl"/&gt;    &lt;/beans&gt;    第六步：配置web.xml    &lt;?xml version="1.0" encoding="UTF-8"?&gt;    &lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd" id="WebApp_ID" version="3.0"&gt;      &lt;display-name&gt;ws_2_cxf_spring_server&lt;/display-name&gt;      &lt;!-- 设置spring的环境 --&gt;      &lt;context-param&gt;          &lt;!--contextConfigLocation是不能修改的  --&gt;          &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;          &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;      &lt;/context-param&gt;      &lt;listener&gt;          &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;      &lt;/listener&gt;      &lt;!-- 配置CXF的Servlet --&gt;      &lt;servlet&gt;          &lt;servlet-name&gt;CXF&lt;/servlet-name&gt;          &lt;servlet-class&gt;org.apache.cxf.transport.servlet.CXFServlet&lt;/servlet-class&gt;      &lt;/servlet&gt;      &lt;servlet-mapping&gt;          &lt;servlet-name&gt;CXF&lt;/servlet-name&gt;          &lt;url-pattern&gt;/ws/*&lt;/url-pattern&gt;      &lt;/servlet-mapping&gt;      &lt;welcome-file-list&gt;        &lt;welcome-file&gt;index.html&lt;/welcome-file&gt;        &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt;        &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt;        &lt;welcome-file&gt;default.html&lt;/welcome-file&gt;        &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt;        &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt;      &lt;/welcome-file-list&gt;    &lt;/web-app&gt;    第七步：部署到tomcat下，启动tomcat    第八步：测试服务        REST服务的使用说明书地址：    http://127.0.0.1:8080/ws_4_cxf_rest_spring_server/ws/user?_wadl</code></pre><hr><pre><code>    8.2    客户端    &lt;!doctype html&gt;    &lt;html lang="en"&gt;     &lt;head&gt;      &lt;meta charset="UTF-8"&gt;      &lt;title&gt;Document&lt;/title&gt;      &lt;script type="text/javascript"&gt;        function queryStudent(){            //创建XMLHttpRequest对象            var xhr = new XMLHttpRequest();            //打开连接            xhr.open("get","http://127.0.0.1:8080/ws_4_cxf_rest_spring_server/ws/user/student/queryList/110?_type=json",true);            //设置回调函数            xhr.onreadystatechange=function(){                //判断是否发送成功和判断服务端是否响应成功                if(4 == xhr.readyState &amp;&amp; 200 == xhr.status){                    alert(eval("("+xhr.responseText+")").student[0].name);                }            }            //发送数据            xhr.send(null);        }      &lt;/script&gt;     &lt;/head&gt;     &lt;body&gt;      &lt;input type="button" value="查询" onclick="javascript:queryStudent();"/&gt;     &lt;/body&gt;    &lt;/html&gt;</code></pre><hr><p>9    综合案例</p><p>9.1    需求：</p><pre><code>*    集成公网手机号归属地查询服务*    对外发布自己的手机号归属地查询服务*    提供查询界面</code></pre><hr><p>9.2    分析</p><p><img src="/images/20170718/26.png"></p><hr><p>9.3    实现</p><pre><code>开发步骤：第一步：创建web项目（引入jar包）第二步：生成公网客户端代码第三步：创建SEI接口package cn.itcast.mobile.server;import javax.jws.WebService;/** *  * &lt;p&gt;Title: MobileInterface.java&lt;/p&gt; * &lt;p&gt;Description:SEI接口&lt;/p&gt; * &lt;p&gt;Company: www.itcast.com&lt;/p&gt; * @author  传智.at * @date    2015年11月27日下午4:21:24 * @version 1.0 */@WebServicepublic interface MobileInterface {    public String queryMobile(String phoneNum);}第四步：创建SEI实现类package cn.itcast.mobile.server;import cn.itcast.mobile.MobileCodeWSSoap;public class MobileInterfaceImpl implements MobileInterface {    private MobileCodeWSSoap mobileClient;    @Override    public String queryMobile(String phoneNum) {        return mobileClient.getMobileCodeInfo(phoneNum, "");    }    public MobileCodeWSSoap getMobileClient() {        return mobileClient;    }    public void setMobileClient(MobileCodeWSSoap mobileClient) {        this.mobileClient = mobileClient;    }}第五步：创建queryMobile.jsp&lt;%@ page language="java" contentType="text/html; charset=utf-8"    pageEncoding="utf-8"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"&gt;&lt;title&gt;手机号归属查询网站&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;form action="queryMobile.action" method="post"&gt;        手机号归属地查询：&lt;input type="text" name="phoneNum"/&gt;&lt;input type="submit" value="查询"/&gt;&lt;br/&gt;        查询结果：${result}    &lt;/form&gt;&lt;/body&gt;&lt;/html&gt;第六步：创建MobileServlet.javapackage cn.itcast.mobile.server.servlet;import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.context.ApplicationContext;import org.springframework.web.context.support.WebApplicationContextUtils;import cn.itcast.mobile.server.MobileInterface;/** *  * &lt;p&gt; * Title: MobileServlet.java * &lt;/p&gt; * &lt;p&gt; * Description:MobileServlet * &lt;/p&gt; * &lt;p&gt; * Company: www.itcast.com * &lt;/p&gt; *  * @author 传智.at * @date 2015年11月27日下午4:42:23 * @version 1.0 */public class MobileServlet extends HttpServlet {    private MobileInterface mobileServer;    public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {        String phoneNum = request.getParameter("phoneNum");        if(null != phoneNum &amp;&amp; !"".equals(phoneNum)){            ApplicationContext context = WebApplicationContextUtils.getWebApplicationContext(this.getServletContext());            mobileServer = (MobileInterface) context.getBean("mobileServer");            String result = mobileServer.queryMobile(phoneNum);            request.setAttribute("result", result);        }        request.getRequestDispatcher("/WEB-INF/jsp/queryMobile.jsp").forward(request, response);    }    public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {        this.doGet(request, response);    }}第七步：配置spring配置文件，applicationContext.xml&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans"    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jaxws="http://cxf.apache.org/jaxws"    xmlns:jaxrs="http://cxf.apache.org/jaxrs" xmlns:cxf="http://cxf.apache.org/core"    xsi:schemaLocation="http://www.springframework.org/schema/beans                             http://www.springframework.org/schema/beans/spring-beans.xsd                            http://cxf.apache.org/jaxrs http://cxf.apache.org/schemas/jaxrs.xsd                            http://cxf.apache.org/jaxws http://cxf.apache.org/schemas/jaxws.xsd                            http://cxf.apache.org/core http://cxf.apache.org/schemas/core.xsd"&gt;    &lt;!-- &lt;jaxws:server发布服务--&gt;        &lt;jaxws:server address="/mobile" serviceClass="cn.itcast.mobile.server.MobileInterface"&gt;        &lt;jaxws:serviceBean&gt;            &lt;ref bean="mobileServer"/&gt;        &lt;/jaxws:serviceBean&gt;    &lt;/jaxws:server&gt;    &lt;!-- 配置服务实现类 --&gt;    &lt;bean name="mobileServer" class="cn.itcast.mobile.server.MobileInterfaceImpl"&gt;        &lt;property name="mobileClient" ref="mobileClient"/&gt;    &lt;/bean&gt;    &lt;!-- 配置公网客户端 --&gt;    &lt;jaxws:client id="mobileClient" address="http://webservice.webxml.com.cn/WebServices/MobileCodeWS.asmx"         serviceClass="cn.itcast.mobile.MobileCodeWSSoap"/&gt;&lt;/beans&gt;第八步：配置web.xml&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd" id="WebApp_ID" version="3.0"&gt;  &lt;display-name&gt;ws_2_cxf_spring_server&lt;/display-name&gt;  &lt;!-- 设置spring的环境 --&gt;  &lt;context-param&gt;      &lt;!--contextConfigLocation是不能修改的  --&gt;      &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;      &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;  &lt;/context-param&gt;  &lt;listener&gt;      &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;  &lt;/listener&gt;  &lt;!-- 配置CXF的Servlet --&gt;  &lt;servlet&gt;      &lt;servlet-name&gt;CXF&lt;/servlet-name&gt;      &lt;servlet-class&gt;org.apache.cxf.transport.servlet.CXFServlet&lt;/servlet-class&gt;  &lt;/servlet&gt;  &lt;servlet-mapping&gt;      &lt;servlet-name&gt;CXF&lt;/servlet-name&gt;      &lt;url-pattern&gt;/ws/*&lt;/url-pattern&gt;  &lt;/servlet-mapping&gt;  &lt;!-- 配置mobileServlet --&gt;  &lt;servlet&gt;      &lt;servlet-name&gt;mobileServlet&lt;/servlet-name&gt;      &lt;servlet-class&gt;cn.itcast.mobile.server.servlet.MobileServlet&lt;/servlet-class&gt;  &lt;/servlet&gt;  &lt;servlet-mapping&gt;      &lt;servlet-name&gt;mobileServlet&lt;/servlet-name&gt;      &lt;url-pattern&gt;*.action&lt;/url-pattern&gt;  &lt;/servlet-mapping&gt;  &lt;welcome-file-list&gt;    &lt;welcome-file&gt;index.html&lt;/welcome-file&gt;    &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt;    &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt;    &lt;welcome-file&gt;default.html&lt;/welcome-file&gt;    &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt;    &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt;  &lt;/welcome-file-list&gt;&lt;/web-app&gt;第九步：部署到tomcat下，启动tomcat第十步：测试    测试服务是否发布成功    测试查询界面</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> webservice </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
            <tag> webservice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>webservice学习-01</title>
      <link href="/2017/07/19/webservice-xue-xi-01/"/>
      <url>/2017/07/19/webservice-xue-xi-01/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-18-Webservice-01"><a href="#2017-07-18-Webservice-01" class="headerlink" title=" 2017-07-18 Webservice-01"></a><center> 2017-07-18 Webservice-01</center></h2><p><font color="red">Webservice就是一种远程调用技术，他的作用就是从远程系统中获取业务数据</font></p><hr><p>1    课程安排</p><pre><code>*    什么是webservice*    Webservice入门程序*    Webservice的应用场景*    Webservice的三要素*    WSDL：web服务描述语言*    SOAP：简单对象访问协议*    UDDI：目录服务*    Webservice的四种客户端调用方式*    生成客户端调用方式*    客户端编程调用方式*    HttpURLConnecton调用方式*    Ajax调用方式*    深入开发：用注解修改WSDL内容</code></pre><hr><p>2    什么是webservice</p><pre><code>2.1    什么是远程调用技术远程调用数据定义：是系统和系统之间的调用</code></pre><p><img src="/images/20170718/1.png"></p><hr><pre><code>2.2    Webservice的原理图*    Webservice是使用Http发送SOAP协议的数据的一种远程调用技术*    Webservice要开发服务端*    Webservice要开发客户端*    Webservice客户端开发需要阅读服务端的使用说明书（WSDL）</code></pre><p><img src="/images/20170718/2.png"></p><hr><p>3    Webservice的入门程序</p><pre><code>3.1    需求*    服务端：发布一个天气查询服务，接收客户端城市名，返回天气数据给客户端*    客户端：发送城市名称给服务端，接收服务端的返回天气数据，打印</code></pre><hr><pre><code>3.2    环境*    JDK：1.7*    Eclipse：mars</code></pre><hr><pre><code>3.3    实现</code></pre><hr><pre><code>    3.3.1    服务端：    开发步骤：    *    第一步：创建SEI（Service Endpoint Interface）接口，本质上就是Java接口    package cn.itcast.ws.jaxws.ws;    /**     *      * &lt;p&gt;Title: WeatherInterface.java&lt;/p&gt;     * &lt;p&gt;Description:SEI接口&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月26日上午9:28:00     * @version 1.0     */    public interface WeatherInterface {        public String queryWeather(String cityName);    }    *    第二步：创建SEI实现类，在实现类上加入@WebService    package cn.itcast.ws.jaxws.ws;    import javax.jws.WebService;    /**     *      * &lt;p&gt;Title: WeatherInterfaceImpl.java&lt;/p&gt;     * &lt;p&gt;Description:SEI实现类&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月26日上午9:29:27     * @version 1.0     */    @WebService//@WebService表示该类是一个服务类，需要发布其中的public的方法    public class WeatherInterfaceImpl implements WeatherInterface {        @Override        public String queryWeather(String cityName) {            System.out.println("from client..."+cityName);            String weather = "晴";            return weather;        }    }    *    第三步：发布服务，Endpoint发布服务，publish方法，两个参数：1.服务地址；2.服务实现类    package cn.itcast.ws.jaxws.ws;    import javax.xml.ws.Endpoint;    /**     *      * &lt;p&gt;Title: WeatherServer.java&lt;/p&gt;     * &lt;p&gt;Description:天气服务端&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月26日上午9:41:20     * @version 1.0     */    public class WeatherServer {        public static void main(String[] args) {            //Endpoint发布服务            //参数解释            //1.address - 服务地址            //2.implementor - 实现类            Endpoint.publish("http://127.0.0.1:12345/weather", new WeatherInterfaceImpl());        }    }    *    第四步：测试服务是否发布成功，通过阅读使用说明书，确定客户端调用的接口、方法、参数和返回值存在，证明服务发布成功。    *    WSDL地址：服务地址+”?wsdl”    *    WSDL阅读方式：从下往上</code></pre><p><img src="/images/20170718/3.png"></p><p><img src="/images/20170718/4.png"></p><p><img src="/images/20170718/5.png"></p><hr><pre><code>3.3.2    客户端：开发步骤*    第一步：wsimport命令生成客户端代码wsimport -s . http://127.0.0.1:12345/weather?wsdl*    第二步：根据使用说明书，使用客户端代码调用服务端*    第一步：创建服务视图，视图是从service标签的name属性获取*    第二步：获取服务实现类，实现类从portType的name属性获取*    第三步：获取查询方法，从portType的operation标签获取package cn.itcast.ws.jaxws.ws.client;import cn.itcast.ws.jaxws.ws.WeatherInterfaceImpl;import cn.itcast.ws.jaxws.ws.WeatherInterfaceImplService;/** *  * &lt;p&gt;Title: WeatherClient.java&lt;/p&gt; * &lt;p&gt;Description:天气查询客户端&lt;/p&gt; * &lt;p&gt;Company: www.itcast.com&lt;/p&gt; * @author  传智.at * @date    2015年11月26日上午9:57:40 * @version 1.0 */public class WeatherClient {    public static void main(String[] args) {        //创建服务视图        WeatherInterfaceImplService weatherInterfaceImplService = new WeatherInterfaceImplService();        //获取服务实现类        WeatherInterfaceImpl weatherInterfaceImpl = weatherInterfaceImplService.getPort(WeatherInterfaceImpl.class);        //调用查询方法，打印        String weather = weatherInterfaceImpl.queryWeather("北京");        System.out.println(weather);    }}</code></pre><hr><pre><code>3.4    Webservice的优缺点优点：*    发送方式采用http的post发送，http的默认端口是80，防火墙默认不拦截80，所以跨防火墙*    采用XML格式封装数据，XML是跨平台的，所以webservice也可以跨平台。*    Webservice支持面向对象缺点：*    采用XML格式封装数据，所以在传输过程中，要传输额外的标签，随着SOAP协议的不断完善，标签越来越大，导致webservice性能下降</code></pre><hr><p>4    Webservice应用场景</p><pre><code>4.1    软件集成和复用</code></pre><p><img src="/images/20170718/6.png"></p><hr><pre><code>4.2    适用场景*    发布一个服务（对内/对外），不考虑客户端类型，不考虑性能，建议使用webservice*    服务端已经确定使用webservice，客户端不能选择，必须使用webservice</code></pre><hr><pre><code>4.3    不适用场景*    考虑性能时不建议使用webservice*    同构程序下不建议使用webservice，比如java 用RMI，不需要翻译成XML的数据</code></pre><hr><p>5    WSDL</p><pre><code>5.1    定义WSDL及web服务描述语言，他是webservice服务端使用说明书，说明服务端接口、方法、参数和返回值，WSDL是随服务发布成功，自动生成，无需编写</code></pre><hr><pre><code>5.2    文档结构</code></pre><p><img src="/images/20170718/7.png"></p><pre><code>service&gt;    服务视图，webservice的服务结点，它包括了服务端点*    &lt;binding&gt;     为每个服务端点定义消息格式和协议细节*    &lt;portType&gt;   服务端点，描述 web service可被执行的操作方法，以及相关的消息，通过binding指向portType*    &lt;message&gt;   定义一个操作（方法）的数据参数(可有多个参数)*    &lt;types&gt;        定义 web service 使用的全部数据类型</code></pre><hr><pre><code>5.3    阅读方式：从下往上</code></pre><p><img src="/images/20170718/8.png"></p><hr><p>6    SOAP</p><pre><code>6.1    定义：*    SOAP即简单对象访问协议，他是使用http发送的XML格式的数据，它可以跨平台，跨防火墙，SOAP不是webservice的专有协议。*    SOAP=http+xm</code></pre><p><img src="/images/20170718/9.png"></p><hr><pre><code>6.2    协议格式*    必需有 Envelope 元素，此元素将整个 XML 文档标识为一条 SOAP 消息*    可选的 Header 元素，包含头部信息*    必需有Body 元素，包含所有的调用和响应信息 *    可选的 Fault 元素，提供有关在处理此消息所发生错误的信息</code></pre><hr><pre><code>6.3    TCP/IP Monitor    6.3.1    代理原理</code></pre><p><img src="/images/20170718/10.png"></p><pre><code>    6.3.2    配置</code></pre><p><img src="/images/20170718/11.png"></p><p><img src="/images/20170718/12.png"></p><pre><code>    6.3.3    测试    在浏览器中输入代理服务地址，能正常访问，代表代理服务器设置成功</code></pre><p><img src="/images/20170718/13.png"></p><hr><pre><code>6.4    SOAP1.1    请求    POST /weather HTTP/1.1    Accept: text/xml, multipart/related    Content-Type: text/xml; charset=utf-8    SOAPAction: "http://ws.jaxws.ws.itcast.cn/WeatherInterfaceImpl/queryWeatherRequest"    User-Agent: JAX-WS RI 2.2.4-b01    Host: 127.0.0.1:54321    Connection: keep-alive    Content-Length: 214    &lt;?xml version="1.0" ?&gt;    &lt;S:Envelope xmlns:S="http://schemas.xmlsoap.org/soap/envelope/"&gt;    &lt;S:Body&gt;&lt;ns2:queryWeather xmlns:ns2="http://ws.jaxws.ws.itcast.cn/"&gt;&lt;arg0&gt;北京&lt;/arg0&gt;&lt;/ns2:queryWeather&gt;    &lt;/S:Body&gt;    &lt;/S:Envelope&gt;    响应    HTTP/1.1 200 OK    Transfer-encoding: chunked    Content-type: text/xml; charset=utf-8    Date: Thu, 26 Nov 2015 03:14:29 GMT    &lt;?xml version="1.0" ?&gt;    &lt;S:Envelope xmlns:S="http://schemas.xmlsoap.org/soap/envelope/"&gt;    &lt;S:Body&gt;    &lt;ns2:queryWeatherResponse xmlns:ns2="http://ws.jaxws.ws.itcast.cn/"&gt;&lt;return&gt;晴&lt;/return&gt;&lt;/ns2:queryWeatherResponse&gt;    &lt;/S:Body&gt;    &lt;/S:Envelope&gt;</code></pre><hr><pre><code>6.5    SOAP1.2    *    如何发布SOAP1.2服务端    *    Jaxws不支持SOAP1.2服务端发布，直接发布会报如下异常</code></pre><p><img src="/images/20170718/14.png"></p><pre><code>    *    如果想发布SOAP1.2服务端，需要在服务端引入第三方JAR（jaxws-ri-2.2.8）    *    在实现类上加入如下注解    @BindingType(SOAPBinding.SOAP12HTTP_BINDING)    请求：    POST /weather HTTP/1.1    Accept: application/soap+xml, multipart/related    Content-Type: application/soap+xml; charset=utf-8;    action="http://ws.jaxws.ws.itcast.cn/WeatherInterfaceImpl/queryWeatherRequest"    User-Agent: JAX-WS RI 2.2.4-b01    Host: 127.0.0.1:54321    Connection: keep-alive    Content-Length: 212    &lt;?xml version="1.0" ?&gt;    &lt;S:Envelope xmlns:S="http://www.w3.org/2003/05/soap-envelope"&gt;    &lt;S:Body&gt;&lt;ns2:queryWeather xmlns:ns2="http://ws.jaxws.ws.itcast.cn/"&gt;&lt;arg0&gt;北京&lt;/arg0&gt;&lt;/ns2:queryWeather&gt;    &lt;/S:Body&gt;    &lt;/S:Envelope&gt;    响应    HTTP/1.1 200 OK    Transfer-encoding: chunked    Content-type: application/soap+xml; charset=utf-8    Date: Thu, 26 Nov 2015 03:25:24 GMT    &lt;?xml version='1.0' encoding='UTF-8'?&gt;    &lt;S:Envelope xmlns:S="http://www.w3.org/2003/05/soap-envelope"&gt;    &lt;S:Body&gt;    &lt;ns2:queryWeatherResponse xmlns:ns2="http://ws.jaxws.ws.itcast.cn/"&gt;&lt;return&gt;晴&lt;/return&gt;&lt;/ns2:queryWeatherResponse&gt;    &lt;/S:Body&gt;    &lt;/S:Envelope&gt;</code></pre><hr><pre><code>6.6    SOAP1.1和SOAP1.2区别    *    相同点：            请求发送方式相同：都是使用POST            协议内容相同：都有Envelope和Body标签    *    不同点：        数据格式不同：content-type不同        SOAP1.1：text/xml;charset=utf-8        SOAP1.2：application/soap+xml;charset=utf-8            命名空间不同：        SOAP1.1：http://schemas.xmlsoap.org/soap/envelope/        SOAP1.2：http://www.w3.org/2003/05/soap-envelope</code></pre><hr><p>7    UDDI</p><pre><code>UDDI 是一种目录服务，企业可以使用它对 Web services 进行注册和搜索。UDDI，英文为 "Universal Description, Discovery and Integration"，可译为“通用描述、发现与集成服务”。UDDI 并不像 WSDL 和 SOAP 一样深入人心，因为很多时候，使用者知道 Web 服务的位置（通常位于公司的企业内部网中）。</code></pre><hr><p>9    Webservice的四种客户端调用方式</p><pre><code>公网服务地址：http://www.webxml.com.cn/zh_cn/index.aspx</code></pre><hr><p>9.1    第一种生成客户端调用方式</p><pre><code>    9.1.1    Wsimport命令介绍    *    Wsimport就是jdk提供的的一个工具，他作用就是根据WSDL地址生成客户端代码    *    Wsimport位置JAVA_HOME/bin    *    Wsimport常用的参数：    *    -s，生成java文件的    *        -d，生成class文件的，默认的参数    *        -p，指定包名的，如果不加该参数，默认包名就是wsdl文档中的命名空间的倒序    *    Wsimport仅支持SOAP1.1客户端的生成    9.1.2    调用公网手机号归属地查询服务    *    第一步：wsimport生成客户端代码    wsimport -p cn.itcast.mobile -s . http://webservice.we    bxml.com.cn/WebServices/MobileCodeWS.asmx?wsdl    *    第二步：阅读使用说明书，使用生成客户端代码调用服务端    package cn.itcast.mobile.client;    import cn.itcast.mobile.MobileCodeWS;    import cn.itcast.mobile.MobileCodeWSSoap;    /**     *      * &lt;p&gt;Title: MobileClient.java&lt;/p&gt;     * &lt;p&gt;Description:公网手机号查询客户端&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月26日下午3:16:05     * @version 1.0     */    public class MobileClient {        public static void main(String[] args) {            //创建服务视图            MobileCodeWS mobileCodeWS = new MobileCodeWS();            //获取服务实现类            MobileCodeWSSoap mobileCodeWSSoap = mobileCodeWS.getPort(MobileCodeWSSoap.class);            //调用查询方法            String reuslt = mobileCodeWSSoap.getMobileCodeInfo("13888888", null);            System.out.println(reuslt);        }    }    9.1.3    公网天气服务端查询    package cn.itcast.mobile.client;    import java.util.List;    import cn.itcast.weather.ArrayOfString;    import cn.itcast.weather.WeatherWS;    import cn.itcast.weather.WeatherWSSoap;    /**     *      * &lt;p&gt;Title: WeatherClient.java&lt;/p&gt;     * &lt;p&gt;Description:公网天气查询客户端&lt;/p&gt;     * &lt;p&gt;Company: www.itcast.com&lt;/p&gt;     * @author  传智.at     * @date    2015年11月26日下午3:24:12     * @version 1.0     */    public class WeatherClient {        public static void main(String[] args) {            WeatherWS weatherWS = new WeatherWS();            WeatherWSSoap weatherWSSoap = weatherWS.getPort(WeatherWSSoap.class);            ArrayOfString  arrayOfString = weatherWSSoap.getWeather("北京", "");            List&lt;String&gt; list = arrayOfString.getString();            for(String str : list){                System.out.println(str);            }        }    }    9.1.4    特点    该种方式使用简单，但一些关键的元素在代码生成时写死到生成代码中，不方便维护，所以仅用于测试。</code></pre><hr><p>10    第二种：service编程调用方式</p><pre><code>package cn.itcast.mobile.client;import java.io.IOException;import java.net.MalformedURLException;import java.net.URL;import javax.xml.namespace.QName;import javax.xml.ws.Service;import cn.itcast.mobile.MobileCodeWSSoap;/** *  * &lt;p&gt;Title: ServiceClient.java&lt;/p&gt; * &lt;p&gt;Description:Service编程实现服务端调用&lt;/p&gt; * &lt;p&gt;Company: www.itcast.com&lt;/p&gt; * @author  传智.at * @date    2015年11月26日下午3:43:55 * @version 1.0 */public class ServiceClient {    public static void main(String[] args) throws IOException {        //创建WSDL的URL，注意不是服务地址        URL url = new URL("http://webservice.webxml.com.cn/WebServices/MobileCodeWS.asmx?wsdl");        //创建服务名称        //1.namespaceURI - 命名空间地址        //2.localPart - 服务视图名        QName qname = new QName("http://WebXml.com.cn/", "MobileCodeWS");        //创建服务视图        //参数解释：        //1.wsdlDocumentLocation - wsdl地址        //2.serviceName - 服务名称        Service service = Service.create(url, qname);        //获取服务实现类        MobileCodeWSSoap mobileCodeWSSoap = service.getPort(MobileCodeWSSoap.class);        //调用查询方法        String result = mobileCodeWSSoap.getMobileCodeInfo("1866666666", "");        System.out.println(result);    }}10.1    特点该种方式可以自定义关键元素，方便以后维护，是一种标准的开发方式</code></pre><hr><p>11    第三种：HttpURLConnection调用方式</p><pre><code>开发步骤：第一步：创建服务地址第二步：打开一个通向服务地址的连接第三步：设置参数设置POST，POST必须大写，如果不大写，报如下异常</code></pre><p><img src="/images/20170718/15.png"></p><pre><code>如果不设置输入输出，会报如下异常</code></pre><p><img src="/images/20170718/16.png"></p><pre><code>第四步：组织SOAP数据，发送请求第五步：接收服务端响应，打印package cn.itcast.mobile.client;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import java.io.OutputStream;import java.net.HttpURLConnection;import java.net.MalformedURLException;import java.net.URL;/** *  * &lt;p&gt;Title: HttpClient.java&lt;/p&gt; * &lt;p&gt;Description:HttpURLConnection调用方式&lt;/p&gt; * &lt;p&gt;Company: www.itcast.com&lt;/p&gt; * @author  传智.at * @date    2015年11月26日下午3:58:57 * @version 1.0 */public class HttpClient {    public static void main(String[] args) throws IOException {        //第一步：创建服务地址，不是WSDL地址        URL url = new URL("http://webservice.webxml.com.cn/WebServices/MobileCodeWS.asmx");        //第二步：打开一个通向服务地址的连接        HttpURLConnection connection = (HttpURLConnection) url.openConnection();        //第三步：设置参数        //3.1发送方式设置：POST必须大写        connection.setRequestMethod("POST");        //3.2设置数据格式：content-type        connection.setRequestProperty("content-type", "text/xml;charset=utf-8");        //3.3设置输入输出，因为默认新创建的connection没有读写权限，        connection.setDoInput(true);        connection.setDoOutput(true);        //第四步：组织SOAP数据，发送请求        String soapXML = getXML("15226466316");        OutputStream os = connection.getOutputStream();        os.write(soapXML.getBytes());        //第五步：接收服务端响应，打印        int responseCode = connection.getResponseCode();        if(200 == responseCode){//表示服务端响应成功            InputStream is = connection.getInputStream();            InputStreamReader isr = new InputStreamReader(is);            BufferedReader br = new BufferedReader(isr);            StringBuilder sb = new StringBuilder();            String temp = null;            while(null != (temp = br.readLine())){                sb.append(temp);            }            System.out.println(sb.toString());            is.close();            isr.close();            br.close();        }        os.close();    }    /**     * &lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;soap:Envelope xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"&gt;  &lt;soap:Body&gt;    &lt;getMobileCodeInfo xmlns="http://WebXml.com.cn/"&gt;      &lt;mobileCode&gt;string&lt;/mobileCode&gt;      &lt;userID&gt;string&lt;/userID&gt;    &lt;/getMobileCodeInfo&gt;  &lt;/soap:Body&gt;&lt;/soap:Envelope&gt;     * @param phoneNum     * @return     */    public static String getXML(String phoneNum){        String soapXML = "&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;"        +"&lt;soap:Envelope xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\"&gt;"            +"&lt;soap:Body&gt;"            +"&lt;getMobileCodeInfo xmlns=\"http://WebXml.com.cn/\"&gt;"                +"&lt;mobileCode&gt;"+phoneNum+"&lt;/mobileCode&gt;"              +"&lt;userID&gt;&lt;/userID&gt;"            +"&lt;/getMobileCodeInfo&gt;"          +"&lt;/soap:Body&gt;"        +"&lt;/soap:Envelope&gt;";        return soapXML;    }}</code></pre><hr><p>12    Ajax调用方式</p><pre><code>&lt;!doctype html&gt;&lt;html lang="en"&gt; &lt;head&gt;  &lt;meta charset="UTF-8"&gt;  &lt;title&gt;Document&lt;/title&gt;  &lt;script type="text/javascript"&gt;    function queryMobile(){        //创建XMLHttpRequest对象        var xhr = new XMLHttpRequest();        //打开连接        xhr.open("post","http://webservice.webxml.com.cn/WebServices/MobileCodeWS.asmx",true);        //设置数据类型        xhr.setRequestHeader("content-type","text/xml;charset=utf-8");        //设置回调函数        xhr.onreadystatechange=function(){            //判断是否发送成功和判断服务端是否响应成功            if(4 == xhr.readyState &amp;&amp; 200 == xhr.status){                alert(xhr.responseText);            }        }        //组织SOAP协议数据        var soapXML = "&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;"        +"&lt;soap:Envelope xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\"&gt;"            +"&lt;soap:Body&gt;"            +"&lt;getMobileCodeInfo xmlns=\"http://WebXml.com.cn/\"&gt;"                +"&lt;mobileCode&gt;"+document.getElementById("phoneNum").value+"&lt;/mobileCode&gt;"              +"&lt;userID&gt;&lt;/userID&gt;"            +"&lt;/getMobileCodeInfo&gt;"          +"&lt;/soap:Body&gt;"        +"&lt;/soap:Envelope&gt;";        alert(soapXML);        //发送数据        xhr.send(soapXML);    }  &lt;/script&gt; &lt;/head&gt; &lt;body&gt;  手机号查询：&lt;input type="text" id="phoneNum"/&gt; &lt;input type="button" value="查询" onclick="javascript:queryMobile();"/&gt; &lt;/body&gt;&lt;/html&gt;</code></pre><hr><p>13    深入开发：用注解修改WSDL内容</p><pre><code>WebService的注解都位于javax.jws包下:@WebService-定义服务，在public class上边targetNamespace：指定命名空间name：portType的名称portName：port的名称serviceName：服务名称endpointInterface：SEI接口地址，如果一个服务类实现了多个接口，只需要发布一个接口的方法，可通过此注解指定要发布服务的接口。@WebMethod-定义方法，在公开方法上边    operationName：方法名    exclude：设置为true表示此方法不是webservice方法，反之则表示webservice方法，默认是false@WebResult-定义返回值，在方法返回值前边    name：返回结果值的名称@WebParam-定义参数，在方法参数前边    name：指定参数的名称作用：通过注解，可以更加形像的描述Web服务。对自动生成的wsdl文档进行修改，为使用者提供一个更加清晰的wsdl文档。当修改了WebService注解之后，会影响客户端生成的代码。调用的方法名和参数名也发生了变化</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> webservice </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
            <tag> webservice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 more less</title>
      <link href="/2017/07/19/mei-tian-2-ge-linux-ming-ling-more-less/"/>
      <url>/2017/07/19/mei-tian-2-ge-linux-ming-ling-more-less/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-19-每天2个Linux命令-more命令-less命令"><a href="#2017-07-19-每天2个Linux命令-more命令-less命令" class="headerlink" title=" 2017-07-19 每天2个Linux命令 more命令 less命令"></a><center> 2017-07-19 每天2个Linux命令 more命令 less命令</center></h2><pre><code>more命令是一个基于vi编辑器文本过滤器，它以全屏幕的方式按页显示文本文件的内容，支持vi中的关键字定位操作。   该命令一次显示一屏文本，满屏后停下来，并且在屏幕的底部出现一个提示信息，给出至今己显示的该文件的百分比：   --More--（XX%）可以用下列不同的方法对提示做出回答：  按Space键:     显示文本的下一屏内容。  按Enier键:      只显示文本的下一行内容。 按斜线符|：接着输入一个模式，可以在文本中寻找下一个相匹配的模式。  按H键:           显示帮助屏，该屏上有相关的帮助信息。  按B键:           显示上一屏内容。  按Q键:           退出more命令。  Ctrl+Z:          退出命令</code></pre><hr><p>(1)用法:</p><pre><code>用法:  more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ]          more [选项]  [文件]</code></pre><hr><p>(2)功能:</p><pre><code>功能:查看文件文档中的内容(支持按页查看和直接跳转行)</code></pre><hr><p>(3)选项参数:</p><pre><code>  1) -&lt;数字&gt;:   指定每屏显示的行数[-num]  2) -d:        显示“[press space to continue,'q' to quit.]”和“[Press 'h' for instructions]”  3) -c:        不进行滚屏操作。每次刷新这个屏幕  4) -s:       将多个空行压缩成一行显示  5) -u:         禁止下划线  6) +&lt;数字&gt;:        从指定数字的行开始显示[+linenum]  7) +/pattern:    在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 </code></pre><hr><p>(4)实例:</p><pre><code>  1)[sunjimeng@localhost Documents]$ more -dc more_text1     显示文件more_text1的内容，但在显示之前先清屏，并且在屏幕的最下方显示完核的百分比。     [sunjimeng@localhost ~]$ cd Documents    [sunjimeng@localhost Documents]$ ll    总用量 4    -rw-r--r--. 1 root root 664 5月   8 19:36 more_text1    [sunjimeng@localhost Documents]$ more -dc more_text1    执行过以后，屏幕只剩下:    复制代码    I am studing orders of Linux!    I am trying to write as many as lines of text!    No matter how low you consider yourself,    there is always someone looking behind you,    hoping that they were that high!    Something you want keep all the time,always you will lose!    Never forget to say "thanks"!    Hppay today,also,prepared for happiness in the future!    Don't aim your success if you want it,just do what you love and believe and fina    lly you will success!    Maybe you can be laze man like a pig,but you can't feel free as it!    I am a college school student!    I am planning to live and work in hangzhou or guangzhou!    I am from hefei anhui!    Enough,I have write too many words!    [sunjimeng@localhost Documents]$     上面的是终端窗口比较大的情况，所有内容能完全显示，下面是显示不完全的情况:    复制代码    I am studing orders of Linux!    I am trying to write as many as lines of text!    No matter how low you consider yourself,    there is always someone looking behind you,    hoping that they were that high!    Something you want keep all the time,always you will lose!    Never forget to say "thanks"!    Hppay today,also,prepared for happiness in the future!    --More--(51%)[Press space to continue, 'q' to quit.]                  //在这里显示百分比    复制代码</code></pre><hr><pre><code>2)[sunjimeng@localhost Documents]$ more -10 more_text1                       显示文件more_text1的内容，每10行显示一次，而且在显示之前先清屏。复制代码[sunjimeng@localhost Documents]$ more -10 more_text1I am studing orders of Linux!I am trying to write as many as lines of text!No matter how low you consider yourself,there is always someone looking behind you,hoping that they were that high!Something you want keep all the time,always you will lose!</code></pre><hr><pre><code>3)[sunjimeng@localhost Documents]$ more +4 -10 more_text1                 从第4行开始显示，每页显示10行                  复制代码    [sunjimeng@localhost Documents]$ more -d -10 more_text1    I am studing orders of Linux!    I am trying to write as many as lines of text!    No matter how low you consider yourself,    there is always someone looking behind you,    hoping that they were that high!    Something you want keep all the time,always you will lose!    --More--(38%)[Press space to continue, 'q' to quit.]   //在这里我按了h键，弹出命令的参考。    Most commands optionally preceded by integer argument k.  Defaults in brackets.    Star (*) indicates argument becomes new default.    -------------------------------------------------------------------------------    &lt;space&gt;                 Display next k lines of text [current screen size]    z                       Display next k lines of text [current screen size]*    &lt;return&gt;                Display next k lines of text [1]*    d or ctrl-D             Scroll k lines [current scroll size, initially 11]*    q or Q or &lt;interrupt&gt;   Exit from more    s                       Skip forward k lines of text [1]    f                       Skip forward k screenfuls of text [1]    b or ctrl-B             Skip backwards k screenfuls of text [1]    '                       Go to place where previous search started    =                       Display current line number    /&lt;regular expression&gt;   Search for kth occurrence of regular expression [1]    n                       Search for kth occurrence of last r.e [1]    !&lt;cmd&gt; or :!&lt;cmd&gt;       Execute &lt;cmd&gt; in a subshell    v                       Start up /usr/bin/vi at current line    ctrl-L                  Redraw screen    :n                      Go to kth next file [1]    :p                      Go to kth previous file [1]    :f                      Display current file name and line number    .                       Repeat previous command    -------------------------------------------------------------------------------    复制代码          和上面的对比可知，此时显示的也是10行，但第一行的内容和上面第一行的不一样    复制代码    [sunjimeng@localhost Documents]$ more +4 -10 more_text1    No matter how low you consider yourself,    there is always someone looking behind you,    hoping that they were that high!    Something you want keep all the time,always you will lose!    Never forget to say "thanks"!    Hppay today,also,prepared for happiness in the future!    --More--(51%)        //上面的百分比是38%</code></pre><hr><pre><code>4)[sunjimeng@localhost Documents]$ more +/Never more_text1                  找到Never字符串所在的行，然后从此行显示，之前的跳过    复制代码    [sunjimeng@localhost Documents]$ more more_text1                          //先查看文档中的所有文本数据    I am studing orders of Linux!    I am trying to write as many as lines of text!    No matter how low you consider yourself,    there is always someone looking behind you,    hoping that they were that high!    Something you want keep all the time,always you will lose!    Never forget to say "thanks"!    Hppay today,also,prepared for happiness in the future!    Don't aim your success if you want it,just do what you love and believe and finally you will success!    Maybe you can be laze man like a pig,but you can't feel free as it!    I am a college school student!    I am planning to live and work in hangzhou or guangzhou!    I am from hefei anhui!    Enough,I have write too many words!                                       //命令详解从这里开始    [sunjimeng@localhost Documents]$ more +/Never more_text1    ...跳过    Something you want keep all the time,always you will lose!    Never forget to say "thanks"!    Hppay today,also,prepared for happiness in the future!    Don't aim your success if you want it,just do what you love and believe and finally you will success!    Maybe you can be laze man like a pig,but you can't feel free as it!    I am a college school student!    I am planning to live and work in hangzhou or guangzhou!    I am from hefei anhui!    Enough,I have write too many words!</code></pre><hr><pre><code>5)[sunjimeng@localhost Documents]$ cat -n more_text1 |more -10  more命令通常和管道|结合起来使用，配合cat命令带有特定格式输出复制代码[sunjimeng@localhost Documents]$ cat -n more_text1 |more -10     1    I am studing orders of Linux!     2    I am trying to write as many as lines of text!     3         4         5    No matter how low you consider yourself,     6    there is always someone looking behind you,     7    hoping that they were that high!     8         9    Something you want keep all the time,always you will lose!    10    --More--</code></pre><hr><pre><code>6)[sunjimeng@localhost Documents]$ ls -l / | more -5   列一个目录下的文件，由于内容太多，我们应该学会用more来分页显示。这得和管道 | 结合起来。复制代码[sunjimeng@localhost Documents]$ ls -l / | more -5总用量 32lrwxrwxrwx.   1 root root    7 5月   1 08:38 bin -&gt; usr/bindr-xr-xr-x.   4 root root 4096 5月   1 18:22 bootdrwxr-xr-x.  19 root root 3180 5月   4 07:17 devdrwxr-xr-x. 137 root root 8192 5月   4 15:16 etc--more-- 复制代码      说明： 每页显示5个文件信息，按 Ctrl+F 或者 空格键 将会显示下5条文件信息。</code></pre><hr><p>(5)其他:  </p><p>　　常用操作命令</p><p>　　  　 Enter    　　  向下n行，需要定义。默认为1行</p><p>　　　　Ctrl+F   　　 向下滚动一屏</p><p>　　　　空格键  　　   向下滚动一屏</p><p>　　　　Ctrl+B  　　 返回上一屏</p><p>　　　　=       　　   输出当前行的行号</p><p>　　　　f     　　　 输出文件名和当前行的行号</p><p>　　　　V      　　    调用vi编辑器</p><p>　　　　!命令   　　  调用Shell，并执行命令 </p><p>　　　　q       　　　退出more****</p><hr><h2 id="每天2个Linux命令-less命令"><a href="#每天2个Linux命令-less命令" class="headerlink" title=" 每天2个Linux命令 less命令"></a><center> 每天2个Linux命令 less命令</center></h2><p>less命令的作用与more十分相似，都可以用来浏览文字档案的内容，不同的是less命令允许用户向前或向后浏览文件<br><br>，而more命令只能向前浏览。</p><p>用less命令显示文件时，用PageUp键向上翻页，用PageDown键向下翻页。要退出less程序，应按Q键。</p><hr><p>(1)用法:</p><pre><code>用法: less  [选项参数] [文件参数]</code></pre><hr><p>(2)功能:</p><pre><code>功能: less 与more命令类似，但可以通过翻页键查看上下页的内容</code></pre><hr><p>(3)选项参数:</p><pre><code>1) -e:    文件内容显示完毕后，自动退出2) -f:       强制显示文件3) -g:      不加亮显示搜索到的所有关键词，仅显示当前显示的关键字，以提高显示速度4) -l:       搜索时忽略大小写的差异5) -N:       每一行行首显示行号6) -s:      将连续多个空行压缩成一行显示7) -S:        在单行显示较长的内容，而不换行显示8) -x&lt;数字&gt;:        将TAB字符显示为指定个数的空格字符。</code></pre><hr><p>(4)实例:</p><pre><code>  1)[root@localhost Documents]# less  less_text                  在另一个进程页面中显示文本内容，按q键退出                        [root@localhost Documents]# mv more_text1 less_text    //将more_text1改名为less_text    [root@localhost Documents]# ll    总用量 4    -rw-r--r--. 1 root root 664 5月   9 07:59 less_text    [root@localhost Documents]# cat less_text    //在当前终端中显示(和less命令显示的效果还是有差别的)    复制代码    [root@localhost Documents]# less less_text   //在另一个页面中显示文本    I am studing orders of Linux!    I am trying to write as many as lines of text!    No matter how low you consider yourself,    there is always someone looking behind you,    hoping that they were that high!    Something you want keep all the time,always you will lose!    Never forget to say "thanks"!    Hppay today,also,prepared for happiness in the future!    Don't aim your success if you want it,just do what you love and believe and finally you will success!    Maybe you can be laze man like a pig,but you can't feel free as it!    I am a college school student!    I am planning to live and work in hangzhou or guangzhou!    I am from hefei anhui!    Enough,I have write too many words!    (END)</code></pre><hr><pre><code>2)[root@localhost Documents]# ps -ef |less      显示已有进程信息    复制代码    ID         PID   PPID  C STIME TTY          TIME CMD    root          1      0  0 00:16 ?     00:00:10 /usr/lib/systemd/systemd --switched-root --system --deserialize 24    root          2      0  0 00:16 ?        00:00:00 [kthreadd]    root          3      2  0 00:16 ?        00:00:03 [ksoftirqd/0]    root          5      2  0 00:16 ?        00:00:00 [kworker/0:0H]    root          7      2  0 00:16 ?        00:00:00 [migration/0]    root          8      2  0 00:16 ?        00:00:00 [rcu_bh]    root          9      2  0 00:16 ?        00:00:00 [rcuob/0]    root         10      2  0 00:16 ?        00:00:00 [rcuob/1]    root         11      2  0 00:16 ?        00:00:00 [rcuob/2]    root         12      2  0 00:16 ?        00:00:00 [rcuob/3]    root         13      2  0 00:16 ?        00:00:00 [rcuob/4]    root         14      2  0 00:16 ?        00:00:00 [rcuob/5]    root         15      2  0 00:16 ?        00:00:00 [rcuob/6]    root         16      2  0 00:16 ?        00:00:00 [rcuob/7]    root         17      2  0 00:16 ?        00:00:00 [rcuob/8]    root         18      2  0 00:16 ?        00:00:00 [rcuob/9]    root         19      2  0 00:16 ?        00:00:00 [rcuob/10]    root         20      2  0 00:16 ?        00:00:00 [rcuob/11]    root         21      2  0 00:16 ?        00:00:00 [rcuob/12]    root         22      2  0 00:16 ?        00:00:00 [rcuob/13]    root         23      2  0 00:16 ?        00:00:00 [rcuob/14]    root         24      2  0 00:16 ?        00:00:00 [rcuob/15]    root         25      2  0 00:16 ?        00:00:00 [rcuob/16]    root         26      2  0 00:16 ?        00:00:00 [rcuob/17]    root         27      2  0 00:16 ?        00:00:00 [rcuob/18]    root         28      2  0 00:16 ?        00:00:00 [rcuob/19]    root         29      2  0 00:16 ?        00:00:00 [rcuob/20]    root         30      2  0 00:16 ?        00:00:00 [rcuob/21]    root         31      2  0 00:16 ?        00:00:00 [rcuob/22]    root         32      2  0 00:16 ?        00:00:00 [rcuob/23]    root         33      2  0 00:16 ?        00:00:00 [rcuob/24]    root         34      2  0 00:16 ?        00:00:00 [rcuob/25]    root         35      2  0 00:16 ?        00:00:00 [rcuob/26]    :    .......//还有很多没有显示</code></pre><hr><pre><code>3)[root@localhost Documents]# history | less               显示历史输入的进程信息复制代码    1  touch touch_test /home/sunjimeng/Document    2  cd /home/sunjimeng/Document    3  ll    4  cd /    5  touch touch_text /home/sunjimeng/Document/touch_test    6  cd /home/sunjimeng/Document    7  ll    8  rm touch_test    9  cd /   10  ls -l /home/sunjimeng/Document   11  touch /home/sunjimeng/Document/touch_test_file   12  cd home/sunjimeng/Document   13  ll   14  touch touch_test_file   15  ll   16  touch -t 06061806 touch_test_file   17  ll   18  touch touch_test_file   19  ll   20  touch -t 06061806 touch_test_file   21  ll   22  touch touch_test_file2   23  ll   24  touch -r touch_testfile touch_test_tile2   25  touch -r touch_test_file touch_test_file2   26  ll   27  touch -d "10 day ago" touch_test_file2   28  ll   29  touch -r touch_test_file touch_test_file2   30  ll   31  touch -d "10 days ago" touch_test_file2   32  ll   33  touch "10 days ago" touch_test_file   34  ll:</code></pre><hr><pre><code>4)[root@localhost Documents]# less less1 less2 查看多个文件（怎么切换下一个还不清楚）复制代码root@localhost Documents]# cat &gt;less1 &lt;&lt;EOF&gt; Lost means Get!&gt; &gt; No losing No getting!&gt; &gt; End!&gt; EOF[root@localhost Documents]# cat &gt;less2 &lt;&lt;EOF&gt; If you want keep,you always lose!&gt; &gt; Certainly It is!&gt; End!&gt; EOF[root@localhost Documents]# ll总用量 12-rw-r--r--. 1 root root  45 5月   9 08:15 less1-rw-r--r--. 1 root root  57 5月   9 08:16 less2-rw-r--r--. 1 root root 664 5月   9 07:59 less_text[root@localhost Documents]# less less1 less2复制代码复制代码Lost means Get!No losing No getting!End!less1 (file 1 of 2) (END) - Next: less2</code></pre><hr><pre><code>5)[sunjimeng@localhost ~]$ netstat -tpnl |less      在另一个进程页面中分页显示信息，这里显示的是网络信息复制代码[sunjimeng@localhost ~]$ netstat -tpnl |less(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      -                   tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN      -                   tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      -                   tcp6       0      0 :::22                   :::*                    LISTEN      -                   tcp6       0      0 ::1:631                 :::*                    LISTEN      -                   tcp6       0      0 ::1:25                  :::*                    LISTEN      -     </code></pre><hr><p>(5)其他:</p><p>　　1.全屏导航</p><p>　　ctrl + F - 向前移动一屏</p><p>  　 ctrl + B - 向后移动一屏</p><p>　　ctrl + D - 向前移动半屏</p><p>　　ctrl + U - 向后移动半屏</p><p>　　2.单行导航</p><p>　　j - 向前移动一行</p><p>　　k - 向后移动一行</p><p>　　3.其它导航</p><p>　　G - 移动到最后一行</p><p>　　g - 移动到第一行 </p><p>　　q / ZZ - 退出 less 命令</p><p>　　4.其它有用的命令</p><p>　　v - 使用配置的编辑器编辑当前文件</p><p>　　h - 显示 less 的帮助文档</p><p>　　&amp;pattern - 仅显示匹配模式的行，而不是整个文件</p><p>　　5.标记导航</p><p>　　当使用 less 查看大文件时，可以在任何一个位置作标记，可以通过命令导航到标有特定标记的文本位置：</p><p>　　ma - 使用 a 标记文本的当前位置</p><p>　　‘a - 导航到标记 a 处             </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 cp nl</title>
      <link href="/2017/07/18/mei-tian-2-ge-linux-ming-ling-cp-nl/"/>
      <url>/2017/07/18/mei-tian-2-ge-linux-ming-ling-cp-nl/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-18-每天2个Linux命令-cp命令"><a href="#2017-07-18-每天2个Linux命令-cp命令" class="headerlink" title="2017-07-18 每天2个Linux命令 cp命令"></a><center>2017-07-18 每天2个Linux命令 cp命令</center></h2><p>cp命令用来将一个或多个源文件或者目录复制到指定的目的文件或目录。<br><br>它可以将单个源文件复制成一个指定文件名的具体的文件或一个已经存在的目录下。<br><br>cp命令还支持同时复制多个文件，当一次复制多个文件时，目标文件参数必须是一个已经存在的目录，否则将出现错误。</p><hr><p>(1)用法:</p><pre><code>用法： cp [选项]... [-T]   源文件    目标文件  或： cp  [选项]...         源文件...  目录  或： cp  [选项]... -t      目录         源文件...</code></pre><hr><p>(2)功能:</p><pre><code>将源文件复制至目标文件，或将多个源文件复制至目标目录。</code></pre><hr><p>(3)选项参数:</p><pre><code>1) -f：                   　　　　　　强行复制文件或目录，不论目标文件或目录是否已存在2) -i：                   　　　　　　覆盖既有文件之前先询问用户3) -s：                  　　　　　　对源文件建立符号连接，而非复制文件4) -b：                  　　　　　　覆盖已存在的文件目标前将目标文件备份5) -v：                  　　　　　　详细显示命令执行的操作。6) -f：                   　　　　　　强行复制文件或目录，不论目标文件或目录是否已存在7) -i：                   　　　　　　覆盖既有文件之前先询问用户；8) -a：                  　　　　　　等于-dR --preserve=all9) -R, -r, --recursive               递归复制目录及其子目录内的所有内容  10) -d                                     等于--no-dereference --preserve=links   </code></pre><hr><p>(4)实例:</p><pre><code>1)[root@localhost Document]# cp mytext cpDir                  将文档拷贝到另一个文件夹下，该文件夹下没有同名文档复制代码[root@localhost Document]# mkdir cpDir[root@localhost Document]# ll总用量 0drwxr-xr-x. 2 root root 6 5月   6 21:20 cpDir[root@localhost Document]# cat &gt;mytext &lt;&lt;EOF&gt; this is mytext!&gt; EOF[root@localhost Document]# ll总用量 4drwxr-xr-x. 2 root root  6 5月   6 21:20 cpDir-rw-r--r--. 1 root root 16 5月   6 21:21 mytext[root@localhost Document]# cp mytext cpDir[root@localhost Document]# ls -l ./cpDir总用量 4-rw-r--r--. 1 root root 16 5月   6 21:22 mytext[root@localhost Document]# cat mytextthis is mytext![root@localhost Document]# ll总用量 4drwxr-xr-x. 2 root root 19 5月   6 21:22 cpDir-rw-r--r--. 1 root root 16 5月   6 21:21 mytext</code></pre><hr><pre><code>2)[root@localhost Document]# cp mytext cpDir  将文档拷贝到另一个文件夹下，该文件夹下有同名文档，因此会提醒是否覆盖。复制代码[root@localhost Document]# ll总用量 4drwxr-xr-x. 2 root root 19 5月   6 21:22 cpDir-rw-r--r--. 1 root root 16 5月   6 21:21 mytext[root@localhost Document]# cat &gt;mytext &lt;&lt;EOF&gt; Modify the text !&gt; EOF[root@localhost Document]# cp mytext cpDircp：是否覆盖"cpDir/mytext"？ y[root@localhost Document]# cat ./cpDir/mytextModify the text !</code></pre><hr><pre><code>3)[root@localhost Document]# cp newDir Dir1  将newDir拷贝一份到Dir1目录下(当Dir1文件夹存在时);将newDir下的所有东西拷贝一份到新建的Dir2目录(Dir2不存在)复制代码[root@localhost Document]# ll总用量 0[root@localhost Document]# mkdir newDir[root@localhost Document]# touch ./newDir/{text1.txt,text2.txt}[root@localhost Document]# ll总用量 0drwxr-xr-x. 2 root root 38 5月   6 21:36 newDir[root@localhost Document]# mkdir Dir1[root@localhost Document]# cp newDir Dir1     //没加-a参数会报错cp: 略过目录"newDir"[root@localhost Document]# cp -a newDir Dir1  //Dir1存在 [root@localhost Document]# cp -a newDir Dir2  //Dir2不存在[root@localhost Document]# ll总用量 0drwxr-xr-x. 3 root root 19 5月   6 21:37 Dir1drwxr-xr-x. 2 root root 38 5月   6 21:36 Dir2drwxr-xr-x. 2 root root 38 5月   6 21:36 newDir[root@localhost Document]# ls ./Dir1        //存在的效果newDir[root@localhost Document]# ls ./Dir2        //不存在的效果text1.txt  text2.txt</code></pre><hr><pre><code>4)[root@localhost newDir]# cp -s text1.txt t1_link       建立一个指向text1.txt的快捷方式 ：t1_link复制代码[root@localhost Document]# cp -s newDir newDir_link                //貌似文件夹的快捷方式只用-s参数不能创建cp: 略过目录"newDir"[root@localhost Document]# ll总用量 0drwxr-xr-x. 3 root root 19 5月   6 21:37 Dir1drwxr-xr-x. 2 root root 38 5月   6 21:36 Dir2drwxr-xr-x. 2 root root 38 5月   6 21:36 newDir[root@localhost Document]# cd newDir[root@localhost newDir]# ll总用量 0-rw-r--r--. 1 root root 0 5月   6 21:36 text1.txt-rw-r--r--. 1 root root 0 5月   6 21:36 text2.txt[root@localhost newDir]# cp -s text1.txt t1_link[root@localhost newDir]# ll总用量 0lrwxrwxrwx. 1 root root 9 5月   6 21:43 t1_link -&gt; text1.txt-rw-r--r--. 1 root root 0 5月   6 21:36 text1.txt-rw-r--r--. 1 root root 0 5月   6 21:36 text2.txt</code></pre><hr><pre><code>5)[root@localhost Document]# cp -as newDir newDir_link        创建文件夹的快捷方式复制代码[root@localhost Document]# cp -as  newDir newDir_link     //a参数指定所有的newDir包括其内的内容创建快捷方式，但这里貌似有点限制cp: "newDir_link/text1.txt"：只能于当前目录中创建相对的符号链接cp: "newDir_link/text2.txt"：只能于当前目录中创建相对的符号链接cp: "newDir_link/t1_link"：只能于当前目录中创建相对的符号链接[root@localhost Document]# ll总用量 0drwxr-xr-x. 3 root root 19 5月   6 21:37 Dir1drwxr-xr-x. 2 root root 38 5月   6 21:36 Dir2drwxr-xr-x. 2 root root 52 5月   6 21:43 newDirdrwxr-xr-x. 2 root root  6 5月   6 21:43 newDir_link     //文件夹快捷方式创建成功</code></pre><hr><pre><code>6)[root@localhost Document]# cp -a newDir text1与[root@localhost Document]# cp -r newDir text2复制代码[root@localhost Document]# ll总用量 0[root@localhost Document]# mkdir newDir[root@localhost Document]# touch ./newDir/{t1,t2}[root@localhost Document]# mkdir text1 text2[root@localhost Document]# cp -a newDir text1   //text1用-a参数[root@localhost Document]# cp -r newDir text2   //text2用-r参数[root@localhost Document]# ls -l text1/*总用量 0-rw-r--r--. 1 root root 0 5月   6 22:02 t1-rw-r--r--. 1 root root 0 5月   6 22:02 t2[root@localhost Document]# ls -l text2/*总用量 0-rw-r--r--. 1 root root 0 5月   6 22:03 t1-rw-r--r--. 1 root root 0 5月   6 22:03 t2[root@localhost Document]# cp -a newDir text3[root@localhost Document]# cp -r newDir text4[root@localhost Document]# ls -l text3/*-rw-r--r--. 1 root root 0 5月   6 22:02 text3/t1-rw-r--r--. 1 root root 0 5月   6 22:02 text3/t2[root@localhost Document]# ls -l text4/*-rw-r--r--. 1 root root 0 5月   6 22:04 text4/t1-rw-r--r--. 1 root root 0 5月   6 22:04 text4/t2[root@localhost Document]# ll总用量 0drwxr-xr-x. 2 root root 30 5月   6 22:02 newDirdrwxr-xr-x. 3 root root 19 5月   6 22:03 text1drwxr-xr-x. 3 root root 19 5月   6 22:03 text2drwxr-xr-x. 2 root root 30 5月   6 22:02 text3drwxr-xr-x. 2 root root 30 5月   6 22:04 text4[root@localhost Document]# cd text1[root@localhost text1]# ll总用量 0drwxr-xr-x. 2 root root 30 5月   6 22:02 newDir[root@localhost text1]# cd ../text2[root@localhost text2]# ll总用量 0drwxr-xr-x. 2 root root 30 5月   6 22:03 newDir[root@localhost text2]# cd ../text3[root@localhost text3]# ll总用量 0-rw-r--r--. 1 root root 0 5月   6 22:02 t1-rw-r--r--. 1 root root 0 5月   6 22:02 t2[root@localhost text3]# cd ../text4[root@localhost text4]# ll总用量 0-rw-r--r--. 1 root root 0 5月   6 22:04 t1-rw-r--r--. 1 root root 0 5月   6 22:04 t2  //-a和-r没有差别，cp命令的差别主要集中在第二个参数是否存在上，与此同时，ls -l命令的效果也有所差别</code></pre><hr><pre><code>7)[root@localhost Document]# cp mytext{,.txt}   复制一份加上后缀存起来复制代码[root@localhost Document]# touch mytext[root@localhost Document]# cp mytext{,.txt}[root@localhost Document]# ll总用量 0-rw-r--r--. 1 root root  0 5月   6 22:15 mytext-rw-r--r--. 1 root root  0 5月   6 22:15 mytext.txtdrwxr-xr-x. 2 root root 30 5月   6 22:02 newDirdrwxr-xr-x. 3 root root 19 5月   6 22:03 text1drwxr-xr-x. 3 root root 19 5月   6 22:03 text2drwxr-xr-x. 2 root root 30 5月   6 22:02 text3drwxr-xr-x. 2 root root 30 5月   6 22:04 text4</code></pre><hr><pre><code>8)[root@localhost Document]# cp --help复制代码[root@localhost Document]# cp --help用法：cp [选项]... [-T] 源文件 目标文件　或：cp [选项]... 源文件... 目录　或：cp [选项]... -t 目录 源文件...Copy SOURCE to DEST, or multiple SOURCE(s) to DIRECTORY.Mandatory arguments to long options are mandatory for short options too.  -a, --archive            等于-dR --preserve=all      --attributes-only    仅复制属性而不复制数据      --backup[=CONTROL        为每个已存在的目标文件创建备份  -b                类似--backup 但不接受参数      --copy-contents        在递归处理是复制特殊文件内容  -d                等于--no-dereference --preserve=links  -f, --force                  if an existing destination file cannot be                                 opened, remove it and try again (this option                                 is ignored when the -n option is also used)  -i, --interactive            prompt before overwrite (overrides a previous -n                                  option)  -H                           follow command-line symbolic links in SOURCE  -l, --link                   hard link files instead of copying  -L, --dereference            always follow symbolic links in SOURCE  -n, --no-clobber        不要覆盖已存在的文件(使前面的 -i 选项失效)  -P, --no-dereference        不跟随源文件中的符号链接  -p                等于--preserve=模式,所有权,时间戳      --preserve[=属性列表    保持指定的属性(默认：模式,所有权,时间戳)，如果                    可能保持附加属性：环境、链接、xattr 等  -c                           deprecated, same as --preserve=context      --sno-preserve=属性列表    不保留指定的文件属性      --parents            复制前在目标目录创建来源文件路径中的所有目录  -R, -r, --recursive        递归复制目录及其子目录内的所有内容      --reflink[=WHEN]        控制克隆/CoW 副本。请查看下面的内如。      --remove-destination    尝试打开目标文件前先删除已存在的目的地                    文件 (相对于 --force 选项)      --sparse=WHEN        控制创建稀疏文件的方式      --strip-trailing-slashes    删除参数中所有源文件/目录末端的斜杠  -s, --symbolic-link        只创建符号链接而不复制文件  -S, --suffix=后缀        自行指定备份文件的后缀  -t,  --target-directory=目录    将所有参数指定的源文件/目录                                           复制至目标目录  -T, --no-target-directory    将目标目录视作普通文件  -u, --update            只在源文件比目标文件新，或目标文件                    不存在时才进行复制  -v, --verbose        显示详细的进行步骤  -x, --one-file-system    不跨越文件系统进行操作  -Z, --context[=CTX]          set SELinux security context of destination                                 file to default type, or to CTX if specified      --help        显示此帮助信息并退出      --version        显示版本信息并退出默认情况下，源文件的稀疏性仅仅通过简单的方法判断，对应的目标文件目标文件也被为稀疏。这是因为默认情况下使用了--sparse=auto 参数。如果明确使用--sparse=always 参数则不论源文件是否包含足够长的0 序列也将目标文件创文建为稀疏件。使用--sparse=never 参数禁止创建稀疏文件。当指定了--reflink[=always] 参数时执行轻量化的复制，即只在数据块被修改的情况下才复制。如果复制失败或者同时指定了--reflink=auto，则返回标准复制模式。The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX.The version control method may be selected via the --backup option or throughthe VERSION_CONTROL environment variable.  Here are the values:  none, off       不进行备份(即使使用了--backup 选项)  numbered, t     备份文件加上数字进行排序  existing, nil   若有数字的备份文件已经存在则使用数字，否则使用普通方式备份  simple, never   永远使用普通方式备份有一个特别情况：如果同时指定--force 和--backup 选项，而源文件和目标文件是同一个已存在的一般文件的话，cp 会将源文件备份。GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告cp 的翻译错误要获取完整文档，请运行：info coreutils 'cp invocation'    </code></pre><hr><pre><code>9)[root@localhost Document]# cp --version复制代码[root@localhost Document]# cp --versioncp (GNU coreutils) 8.22Copyright (C) 2013 Free Software Foundation, Inc.许可证：GPLv3+：GNU 通用公共许可证第3 版或更新版本&lt;http://gnu.org/licenses/gpl.html&gt;。本软件是自由软件：您可以自由修改和重新发布它。在法律范围内没有其他保证。由Torbjörn Granlund、David MacKenzie 和Jim Meyering 编写。</code></pre><hr><p>(5)其他；</p><pre><code>注意:   一般情况下，shell会设置一个别名，在命令行下复制文件时，如果目标文件已经存在，&lt;br/&gt;就会询问是否覆盖，不管你是否使用-i参数。但是如果是在shell脚本中执行cp时，没有-i参数时不会询问是否覆盖。&lt;br/&gt;这说明命令行和shell脚本的执行方式有些不同。&lt;br/&gt;命令行与shell脚本:&lt;br/&gt;shell命令就是你说的终端的命令，shell翻译成壳的意思，它是包裹在linux内核外层的，&lt;br/&gt;一个可通过一系列的linux命令对操作系统发出相关指令的人机界面。shell可以通过其条件语句和循环语句等，&lt;br/&gt;把一系列linux命令结合在一起，形成一个相当于面向过程的程序，shell script，来实现一些较为复杂的功能。 &lt;br/&gt;总括，shell是linux命令集的概称，是属于命令行的人机界面。linux的shell script 是由命令加一些条件组合起来的。&lt;br/&gt;shell命令就是终端命令，shell编程其实和windows的批处理差不多，区别的是，shell的语言功能比批处理强大&lt;br/&gt;</code></pre><hr><h2 id="2017-07-18-每天2个Linux命令-nl命令"><a href="#2017-07-18-每天2个Linux命令-nl命令" class="headerlink" title="2017-07-18 每天2个Linux命令 nl命令"></a><center>2017-07-18 每天2个Linux命令 nl命令</center></h2><p>nl命令读取 file 参数（缺省情况下标准输入），计算输入中的行号，将计算过的行号写入标准输出。</p><p>其默认的结果与cat -n有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐0等等的功能。</p><hr><p>(1)用法:</p><pre><code>用法:    nl  [选项]...  [文件]...</code></pre><p> (2)功能:</p><pre><code>功能:   nl命令在linux系统中用来计算文件中行号。nl 可以将输出的文件内容自动的加上行号！</code></pre><p>(3)选项参数:</p><pre><code>  1) -b:                                            指定行号指定的方式，主要有两种：           -b a:                                     表示不论是否为空行，也同样列出行号(类似 cat -n)           -b t:                                     如果有空行，空的那一行不要列出行号(默认值)   2) -n:                                           列出行号表示的方法，主要有三种：          -n ln:                                    行号在萤幕的最左方显示          -n rn:                                    行号在自己栏位的最右方显示，且不加 0          -n rz:                                    行号在自己栏位的最右方显示，且加 0  3) -w:                                           行号栏位的占用的位数  4) -p:                                           在逻辑定界符处不重新开始计算</code></pre><p>(4)实例:</p><pre><code> 1)[root@localhost Documents]# nl nl_text1                     用nl列出文档中的内容，文件中的空白行不会加上行号复制代码[root@localhost Documents]# ll 总用量 0[root@localhost Documents]# cat &gt;nl_text1 &lt;&lt;EOF&gt; I am studing orders of Linux!&gt; I am MenAngel!&gt; &gt; I am 19 years old!&gt; &gt; &gt; I am from AnHui HeFei!&gt; EOF[root@localhost Documents]# nl nl_text1     1    I am studing orders of Linux!     2    I am MenAngel!     3    I am 19 years old!     4    I am from AnHui HeFei!复制代码复制代码[root@localhost Documents]# cat -b nl_text1          //效果等于cat -b     1    I am studing orders of Linux!     2    I am MenAngel!     3    I am 19 years old!     4    I am from AnHui HeFei!复制代码</code></pre><hr><pre><code>2)[root@localhost Documents]# nl -b a nl_text1                                     用nl命令打开输出文档内容，空行也输出行号！复制代码[root@localhost Documents]# nl -b a nl_text1     1    I am studing orders of Linux!     2    I am MenAngel!     3         4    I am 19 years old!     5         6         7    I am from AnHui HeFei![root@localhost Documents]# cat -n nl_text1                               //与cat -n具有相同的效果     1    I am studing orders of Linux!     2    I am MenAngel!     3         4    I am 19 years old!     5         6         7    I am from AnHui HeFei!</code></pre><hr><pre><code>3)[root@localhost Documents]# nl -b a -n rz nl_text1                            让行号前面自动补上0，统一输出格式复制代码[root@localhost Documents]# nl -b a -n rz nl_text1000001    I am studing orders of Linux!000002    I am MenAngel!000003    000004    I am 19 years old!000005    000006    000007    I am from AnHui HeFei!</code></pre><hr><pre><code>4)[root@localhost Documents]# nl -b a -n rz -w 3 nl_text1  nl -b a -n rz命令行号默认为六位，要调整位数可以加上参数-w 3调整为3位。复制代码[root@localhost Documents]# nl -b a -n rz -w 3 nl_text1001    I am studing orders of Linux!002    I am MenAngel!003    004    I am 19 years old!005    006    007    I am from AnHui HeFei!复制代码</code></pre><hr><pre><code>5)[root@localhost Documents]# nl --help复制代码[root@localhost Documents]# nl --help用法：nl [选项]... [文件]...Write each FILE to standard output, with line numbers added.With no FILE, or when FILE is -, read standard input.Mandatory arguments to long options are mandatory for short options too.  -b, --body-numbering=样式    使用指定样式编号文件的正文行目  -d, --section-delimiter=CC    使用指定的CC 分割逻辑页数  -f, --footer-numbering=样式    使用指定样式编号文件的页脚行目  -h, --header-numbering=样式    使用指定样式编号文件的页眉行目  -i, --page-increment=数值    设置每一行遍历后的自动递增值  -l, --join-blank-lines=数值    设置数值为多少的若干空行被视作一行  -n, --number-format=格式    根据指定格式插入行号  -p, --no-renumber        在逻辑页数切换时不将行号值复位  -s, --number-separator=字符串    可能的话在行号后添加字符串  -v, --starting-line-number=数字    每个逻辑页上的第一行的行号  -w, --number-width=数字    为行号使用指定的栏数      --help        显示此帮助信息并退出      --version        显示版本信息并退出默认的选项设置是-v1 -i1 -l1 -sTAB -w6 -nrn -hn -bt -fn。CC 是用于分隔逻辑页数的两个分界符，其中缺失的第二个字符暗含了":"，如果您要指定"\"，请输入"\\"。可用的样式如下：  a    对所有行编号  t    对非空行编号  n    不编行号  pBRE    只对符合正则表达式BRE 的行编号FORMAT 是下列之一:  ln    左对齐，空格不用0 填充  rn     右对齐，空格不用0 填充  rz     右对齐，空格用0 填充GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告nl 的翻译错误要获取完整文档，请运行：info coreutils 'nl invocation'复制代码</code></pre><hr><pre><code>6)[root@localhost Documents]# nl --version复制代码[root@localhost Documents]# nl --versionnl (GNU coreutils) 8.22Copyright (C) 2013 Free Software Foundation, Inc.许可证：GPLv3+：GNU 通用公共许可证第3 版或更新版本&lt;http://gnu.org/licenses/gpl.html&gt;。本软件是自由软件：您可以自由修改和重新发布它。在法律范围内没有其他保证。由Scott Bartram 和David MacKenzie 编写。</code></pre><hr><p>(5)其他:</p><pre><code>功能的详细介绍:在输出中，nl 命令根据您在命令行中指定的标志来计算左边的行。 输入文本必须写在逻辑页中。每个逻辑页有头、主体和页脚节（可以有空节）。 除非使用 -p 标志，nl 命令在每个逻辑页开始的地方重新设置行号。可以单独为头、主体和页脚节设置行计算标志（例如，头和页脚行可以被计算然而文本行不能）。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring事物管理、整合SSH、整合Junit</title>
      <link href="/2017/07/17/spring-shi-wu-guan-li-zheng-he-ssh-zheng-he-junit/"/>
      <url>/2017/07/17/spring-shi-wu-guan-li-zheng-he-ssh-zheng-he-junit/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-17-spring事物管理、整合SSH、整合Junit"><a href="#2017-07-17-spring事物管理、整合SSH、整合Junit" class="headerlink" title="2017-07-17 spring事物管理、整合SSH、整合Junit"></a><center>2017-07-17 spring事物管理、整合SSH、整合Junit</center></h2><p>1 spring day02回顾</p><pre><code>*    AOP ：切面编程&lt;br/&gt;    切面：切入点 和 通知 结合&lt;br/&gt;*    spring aop 编程&lt;br/&gt;    &lt;aop:config&gt;&lt;br/&gt;    方法1：&lt;br/&gt;      &lt;aop:pointcut expression="切入点表达式" id=""&gt;&lt;br/&gt;      &lt;aop:advisor  advice-ref="通知引用" pointcut-ref="切入点的引用"&gt;&lt;br/&gt;    方法2：&lt;br/&gt;       &lt;aop:advisor  advice-ref="通知引用" pointcut="切入点表达式"&gt;&lt;br/&gt;*    AspectJ xml&lt;br/&gt;    &lt;aop:config&gt;&lt;br/&gt;      &lt;aop:aspect ref="切面类"&gt;&lt;br/&gt;         &lt;aop:pointcut&gt;&lt;br/&gt;         &lt;aop:before&gt;  前置&lt;br/&gt;         &lt;aop:afterReturning  returning="第二个参数名称"&gt; 后置&lt;br/&gt;         &lt;aop:around&gt; 环绕&lt;br/&gt;         &lt;aop:afterThrowing throwing="第二。。。"&gt; 抛出异常&lt;br/&gt;         &lt;aop:after&gt; 最终&lt;br/&gt;*    AspectJ annotation &lt;br/&gt;    @Aspect&lt;br/&gt;    @Pointcut("表达式")  private void xxx(){}&lt;br/&gt;    @Before @...&lt;br/&gt;*    切入点表达式&lt;br/&gt;    &lt;aop:pointcut expression="execution(* com.itheima.crm.*.service..*.*(..))" id=""&gt;</code></pre><hr><p>2 事务管理</p><p>2.1    回顾事务</p><pre><code>*    事务：一组业务操作ABCD，要么全部成功，要么全部不成功。*    特性：ACID        原子性：整体        一致性：完成        隔离性：并发        持久性：结果*    隔离问题：        脏读：一个事务读到另一个事务没有提交的数据        不可重复读：一个事务读到另一个事务已提交的数据（update）        虚读(幻读)：一个事务读到另一个事务已提交的数据（insert）*    隔离级别：        read uncommitted：读未提交。存在3个问题        read committed：读已提交。解决脏读，存在2个问题        repeatable read：可重复读。解决：脏读、不可重复读，存在1个问题。        serializable ：串行化。都解决，单事务。</code></pre><p><img src="/images/20170717/1.png"></p><pre><code>*    mysql 事务操作--简单        ABCD 一个事务        Connection conn = null;        try{          //1 获得连接          conn = ...;          //2 开启事务          conn.setAutoCommit(false);          A          B          C          D          //3 提交事务          conn.commit();        } catche(){          //4 回滚事务          conn.rollback();        }*    mysql 事务操作--Savepoint    需求：AB（必须），CD（可选）     Connection conn = null;    Savepoint savepoint = null;  //保存点，记录操作的当前位置，之后可以回滚到指定的位置。（可以回滚一部分）    try{      //1 获得连接      conn = ...;      //2 开启事务      conn.setAutoCommit(false);      A      B      savepoint = conn.setSavepoint();      C      D      //3 提交事务      conn.commit();    } catche(){      if(savepoint != null){   //CD异常         // 回滚到CD之前         conn.rollback(savepoint);         // 提交AB         conn.commit();      } else{   //AB异常         // 回滚AB         conn.rollback();      }    }</code></pre><hr><p>2.2    事务管理介绍</p><p>2.2.1    导入jar包<br><br>    transaction  –&gt;  tx</p><p><img src="/images/20170717/2.png"></p><hr><p>2.2.2    三个顶级接口</p><p><img src="/images/20170717/3.png"></p><pre><code>1.PlatformTransactionManager  平台事务管理器，spring要管理事务，必须使用事务管理器进行事务配置时，必须配置事务管理器。2.TransactionDefinition：事务详情（事务定义、事务属性），spring用于确定事务具体详情，例如：隔离级别、是否只读、超时时间 等3.进行事务配置时，必须配置详情。spring将配置项封装到该对象实例。TransactionStatus：事务状态，spring用于记录当前事务运行状态。例如：是否有保存点，事务是否完成。spring底层根据状态进行相应操作。</code></pre><hr><p>2.2.3    PlatformTransactionManager  事务管理器</p><pre><code>*    导入jar包：需要时平台事务管理器的实现类</code></pre><p><img src="/images/20170717/4.png"></p><pre><code>常见的事务管理器DataSourceTransactionManager  ，jdbc开发时事务管理器，采用JdbcTemplateHibernateTransactionManager，hibernate开发时事务管理器，整合hibernate</code></pre><p><img src="/images/20170717/5.png"></p><pre><code>api详解TransactionStatus getTransaction(TransactionDefinition definition) ，事务管理器 通过“事务详情”，获得“事务状态”，从而管理事务。void commit(TransactionStatus status)  根据状态提交void rollback(TransactionStatus status) 根据状态回滚</code></pre><hr><p>2.2.4    TransactionStatus</p><p><img src="/images/20170717/6.png"></p><hr><p>2.2.5    TransactionDefinition</p><p><img src="/images/20170717/7.png"></p><hr><pre><code>传播行为：在两个业务之间如何共享事务。PROPAGATION_REQUIRED , required , 必须  【默认值】    支持当前事务，A如果有事务，B将使用该事务。    如果A没有事务，B将创建一个新的事务。PROPAGATION_SUPPORTS ，supports ，支持    支持当前事务，A如果有事务，B将使用该事务。    如果A没有事务，B将以非事务执行。PROPAGATION_MANDATORY，mandatory ，强制    支持当前事务，A如果有事务，B将使用该事务。    如果A没有事务，B将抛异常。PROPAGATION_REQUIRES_NEW ， requires_new ，必须新的    如果A有事务，将A的事务挂起，B创建一个新的事务    如果A没有事务，B创建一个新的事务PROPAGATION_NOT_SUPPORTED ，not_supported ,不支持    如果A有事务，将A的事务挂起，B将以非事务执行    如果A没有事务，B将以非事务执行PROPAGATION_NEVER ，never，从不    如果A有事务，B将抛异常    如果A没有事务，B将以非事务执行PROPAGATION_NESTED ，nested ，嵌套    A和B底层采用保存点机制，形成嵌套事务。掌握：PROPAGATION_REQUIRED、PROPAGATION_REQUIRES_NEW、PROPAGATION_NESTED </code></pre><hr><p>2.3    案例：转账</p><p>2.3.1    搭建环境</p><pre><code>2.3.1.1    创建表create database ee19_spring_day03;use ee19_spring_day03;create table account(  id int primary key auto_increment,  username varchar(50),  money int);insert into account(username,money) values('jack','10000');insert into account(username,money) values('rose','10000');</code></pre><hr><pre><code>2.3.1.2    导入jar包*    核心：4+1*    aop ： 4 (aop联盟、spring aop、aspectj规范、spring aspect)*    数据库：2  （jdbc/tx）*    驱动：mysql*    连接池：c3p0</code></pre><p><img src="/images/20170717/8.png"></p><hr><pre><code>2.3.1.3    dao层public class AccountDaoImpl extends JdbcDaoSupport implements AccountDao {    @Override    public void out(String outer, Integer money) {        this.getJdbcTemplate().update("update account set money = money - ? where username = ?", money,outer);    }    @Override    public void in(String inner, Integer money) {        this.getJdbcTemplate().update("update account set money = money + ? where username = ?", money,inner);    }}</code></pre><hr><pre><code>2.3.1.4    service层public class AccountServiceImpl implements AccountService {    private AccountDao accountDao;    public void setAccountDao(AccountDao accountDao) {        this.accountDao = accountDao;    }    @Override    public void transfer(String outer, String inner, Integer money) {        accountDao.out(outer, money);        //断电//        int i = 1/0;        accountDao.in(inner, money);    }}</code></pre><hr><pre><code>2.3.1.5    spring配置&lt;!-- 1 datasource --&gt;&lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt;    &lt;property name="driverClass" value="com.mysql.jdbc.Driver"&gt;&lt;/property&gt;    &lt;property name="jdbcUrl" value="jdbc:mysql://localhost:3306/ee19_spring_day03"&gt;&lt;/property&gt;    &lt;property name="user" value="root"&gt;&lt;/property&gt;    &lt;property name="password" value="1234"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 2 dao  --&gt;&lt;bean id="accountDao" class="com.itheima.dao.impl.AccountDaoImpl"&gt;    &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 3 service --&gt;&lt;bean id="accountService" class="com.itheima.service.impl.AccountServiceImpl"&gt;    &lt;property name="accountDao" ref="accountDao"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><pre><code>2.3.1.6    测试@Testpublic void demo01(){    String xmlPath = "applicationContext.xml";    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(xmlPath);    AccountService accountService =  (AccountService) applicationContext.getBean("accountService");    accountService.transfer("jack", "rose", 1000);}</code></pre><hr><p>2.3.2    手动管理事务（了解）</p><pre><code>*    spring底层使用 TransactionTemplate 事务模板进行操作。*    操作1.service 需要获得 TransactionTemplate 2.spring 配置模板，并注入给service3.模板需要注入事务管理器4.配置事务管理器：DataSourceTransactionManager ，需要注入DataSource</code></pre><hr><pre><code>2.3.2.1    修改service//需要spring注入模板private TransactionTemplate transactionTemplate;public void setTransactionTemplate(TransactionTemplate transactionTemplate) {    this.transactionTemplate = transactionTemplate;}@Overridepublic void transfer(final String outer,final String inner,final Integer money) {    transactionTemplate.execute(new TransactionCallbackWithoutResult() {        @Override        protected void doInTransactionWithoutResult(TransactionStatus arg0) {            accountDao.out(outer, money);            //断电//                int i = 1/0;            accountDao.in(inner, money);        }    });}</code></pre><hr><pre><code>2.3.2.2    修改spring配置&lt;!-- 3 service --&gt;&lt;bean id="accountService" class="com.itheima.service.impl.AccountServiceImpl"&gt;    &lt;property name="accountDao" ref="accountDao"&gt;&lt;/property&gt;    &lt;property name="transactionTemplate" ref="transactionTemplate"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 4 创建模板 --&gt;&lt;bean id="transactionTemplate" class="org.springframework.transaction.support.TransactionTemplate"&gt;    &lt;property name="transactionManager" ref="txManager"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 5 配置事务管理器 ,管理器需要事务，事务从Connection获得，连接从连接池DataSource获得 --&gt;&lt;bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;    &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><p>2.3.3    工厂bean 生成代理：半自动</p><pre><code>*    spring提供 管理事务的代理工厂bean TransactionProxyFactoryBean1.getBean() 获得代理对象2.spring 配置一个代理</code></pre><hr><pre><code>2.3.3.1    spring配置&lt;!-- 4 service 代理对象     4.1 proxyInterfaces 接口     4.2 target 目标类    4.3 transactionManager 事务管理器    4.4 transactionAttributes 事务属性（事务详情）        prop.key ：确定哪些方法使用当前事务配置        prop.text:用于配置事务详情            格式：PROPAGATION,ISOLATION,readOnly,-Exception,+Exception                传播行为        隔离级别    是否只读        异常回滚        异常提交            例如：                &lt;prop key="transfer"&gt;PROPAGATION_REQUIRED,ISOLATION_DEFAULT&lt;/prop&gt; 默认传播行为，和隔离级别                &lt;prop key="transfer"&gt;PROPAGATION_REQUIRED,ISOLATION_DEFAULT,readOnly&lt;/prop&gt; 只读                &lt;prop key="transfer"&gt;PROPAGATION_REQUIRED,ISOLATION_DEFAULT,+java.lang.ArithmeticException&lt;/prop&gt;  有异常扔提交--&gt;&lt;bean id="proxyAccountService" class="org.springframework.transaction.interceptor.TransactionProxyFactoryBean"&gt;    &lt;property name="proxyInterfaces" value="com.itheima.service.AccountService"&gt;&lt;/property&gt;    &lt;property name="target" ref="accountService"&gt;&lt;/property&gt;    &lt;property name="transactionManager" ref="txManager"&gt;&lt;/property&gt;    &lt;property name="transactionAttributes"&gt;        &lt;props&gt;            &lt;prop key="transfer"&gt;PROPAGATION_REQUIRED,ISOLATION_DEFAULT&lt;/prop&gt;        &lt;/props&gt;    &lt;/property&gt;&lt;/bean&gt;&lt;!-- 5 事务管理器 --&gt;&lt;bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;    &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><pre><code>2.3.3.2    测试</code></pre><p><img src="/images/20170717/9.png">    </p><hr><p>2.3.4    AOP 配置基于xml【掌握】</p><pre><code>*    在spring xml 配置aop 自动生成代理，进行事务的管理1.配置管理器2.配置事务详情3.配置aop&lt;!-- 4 事务管理 --&gt;    &lt;!-- 4.1 事务管理器 --&gt;    &lt;bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;        &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 4.2 事务详情（事务通知）  ， 在aop筛选基础上，对ABC三个确定使用什么样的事务。例如：AC读写、B只读 等        &lt;tx:attributes&gt; 用于配置事务详情（属性属性）            &lt;tx:method name=""/&gt; 详情具体配置                propagation 传播行为 ， REQUIRED：必须；REQUIRES_NEW:必须是新的                isolation 隔离级别    --&gt;    &lt;tx:advice id="txAdvice" transaction-manager="txManager"&gt;        &lt;tx:attributes&gt;            &lt;tx:method name="transfer" propagation="REQUIRED" isolation="DEFAULT"/&gt;        &lt;/tx:attributes&gt;    &lt;/tx:advice&gt;    &lt;!-- 4.3 AOP编程，目标类有ABCD（4个连接点），切入点表达式 确定增强的连接器，从而获得切入点：ABC --&gt;    &lt;aop:config&gt;        &lt;aop:advisor advice-ref="txAdvice" pointcut="execution(* com.itheima.service..*.*(..))"/&gt;    &lt;/aop:config&gt;</code></pre><hr><p>2.3.5    AOP配置基于注解【掌握】</p><pre><code>*    1.配置事务管理器，将并事务管理器交予spring*    2.在目标类或目标方法添加注解即可 @Transactional</code></pre><hr><pre><code>2.3.5.1    spring配置&lt;!-- 4 事务管理 --&gt;&lt;!-- 4.1 事务管理器 --&gt;&lt;bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;    &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 4.2 将管理器交予spring     * transaction-manager 配置事务管理器    * proxy-target-class        true ： 底层强制使用cglib 代理--&gt;&lt;tx:annotation-driven transaction-manager="txManager"/&gt;</code></pre><hr><pre><code>2.3.5.2    service 层@Transactionalpublic class AccountServiceImpl implements AccountService {</code></pre><hr><pre><code>2.3.5.3    事务详情配置</code></pre><p><img src="/images/20170717/10.png"></p><pre><code>@Transactional(propagation=Propagation.REQUIRED , isolation = Isolation.DEFAULT)public class AccountServiceImpl implements AccountService {</code></pre><hr><p>3    整合Junit<br>    *    导入jar包<br>        基本 ：4+1<br>        测试：spring-test…jar</p><pre><code>1.让Junit通知spring加载配置文件2.让spring容器自动进行注入*    修改测试类@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext.xml")public class TestApp {    @Autowired  //与junit整合，不需要在spring xml配置扫描    private AccountService accountService;    @Test    public void demo01(){//        String xmlPath = "applicationContext.xml";//        ApplicationContext applicationContext = new ClassPathXmlApplicationContext(xmlPath);//        AccountService accountService =  (AccountService) applicationContext.getBean("accountService");        accountService.transfer("jack", "rose", 1000);    }}</code></pre><hr><p>4    整合web</p><pre><code>0.导入jar包    spring-web.xml1.tomcat启动加载配置文件    servlet --&gt; init(ServletConfig) --&gt; &lt;load-on-startup&gt;2    filter --&gt; init(FilterConfig)  --&gt; web.xml注册过滤器自动调用初始化    listener --&gt; ServletContextListener --&gt; servletContext对象监听【】    spring提供监听器 ContextLoaderListener  --&gt; web.xml  &lt;listener&gt;&lt;listener-class&gt;....        如果只配置监听器，默认加载xml位置：/WEB-INF/applicationContext.xml</code></pre><p><img src="/images/20170717/11.png"></p><pre><code>2.确定配置文件位置，通过系统初始化参数ServletContext 初始化参数 web.xml      &lt;context-param&gt;        &lt;param-name&gt;contextConfigLocation        &lt;param-value&gt;classpath:applicationContext.xml  &lt;!-- 确定配置文件位置 --&gt;  &lt;context-param&gt;      &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;      &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;  &lt;/context-param&gt;  &lt;!-- 配置spring 监听器，加载xml配置文件 --&gt;  &lt;listener&gt;      &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;  &lt;/listener&gt;3.从servletContext作用域 获得spring容器 （了解）// 从application作用域（ServletContext）获得spring容器    //方式1： 手动从作用域获取    ApplicationContext applicationContext =             (ApplicationContext) this.getServletContext().getAttrib            (WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE);    //方式2：通过工具获取    ApplicationContext apppApplicationContext2 =             WebApplicationContextUtils.getWebApplicationContext(this.getServletContext());</code></pre><hr><p>5    SSH整合</p><pre><code>5.1    jar整合struts：2.3.15.3hibernate : 3.6.10spring: 3.2.0</code></pre><hr><pre><code>5.1.1    strutsstruts-2.3.15.3\apps\struts2-blank\WEB-INF\lib</code></pre><p><img src="/images/20170717/12.png"></p><pre><code>模板技术  ，一般用于页面静态化freemarker：扩展名：*.ftlvelocity ：扩展名  *.vm</code></pre><hr><pre><code>5.1.2    spring*    基础：4+1 ， beans、core、context、expression ， commons-logging (struts已经导入)*    AOP：aop联盟、spring aop 、aspect规范、spring aspect*    db：jdbc、tx*    测试：test*    web开发：spring web*    驱动：mysql*    连接池：c3p0*    整合hibernate：spring orm </code></pre><p><img src="/images/20170717/13.png"></p><p><img src="/images/20170717/14.png"></p><hr><pre><code>5.1.3    hibernate%h%\hibernate3.jar            核心%h%\lib\required            必须</code></pre><p><img src="/images/20170717/15.png"></p><pre><code>%h%\lib\jpa                jpa规范 （java persistent api 持久api），hibernate注解开发 @Entity @Id 等*    整合log4j导入 log4j...jar (struts已经导入)整合（过渡）：slf4j-log4j12-1.7.5.jar</code></pre><p><img src="/images/20170717/16.png"></p><pre><code>*    二级缓存核心：ehcache-1.5.0.jar依赖：    backport-util-concurrent-2.1.jar    commons-logging  (存在)</code></pre><hr><pre><code>5.1.4    整合包*    spring整合hibernate： spring orm*    struts 整合spring：struts2-spring-plugin-2.3.15.3.jar删除重复jar包</code></pre><p><img src="/images/20170717/17.png"></p><hr><p>5.2    spring整合hibernate：有hibernate.cfg.xml</p><pre><code>5.2.1    创建表create table t_user(  id int primary key auto_increment,  username varchar(50),  password varchar(32),  age int );</code></pre><hr><pre><code>5.2.2    PO 类</code></pre><p><img src="/images/20170717/18.png"></p><pre><code>*    javabeanpublic class User {    private Integer id;    private String username;    private String password;    private Integer age;*    映射文件&lt;!DOCTYPE hibernate-mapping PUBLIC     "-//Hibernate/Hibernate Mapping DTD 3.0//EN"    "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping&gt;    &lt;class name="com.itheima.domain.User" table="t_user"&gt;        &lt;id name="id"&gt;            &lt;generator class="native"&gt;&lt;/generator&gt;        &lt;/id&gt;        &lt;property name="username"&gt;&lt;/property&gt;        &lt;property name="password"&gt;&lt;/property&gt;        &lt;property name="age"&gt;&lt;/property&gt;    &lt;/class&gt;&lt;/hibernate-mapping&gt;</code></pre><hr><pre><code>5.2.3    dao层*    spring提供 HibernateTemplate 用于操作PO对象，类似Hibernate Session对象。public class UserDaoImpl implements UserDao {    //需要spring注入模板    private HibernateTemplate hibernateTemplate;    public void setHibernateTemplate(HibernateTemplate hibernateTemplate) {        this.hibernateTemplate = hibernateTemplate;    }    @Override    public void save(User user) {        this.hibernateTemplate.save(user);    }}</code></pre><hr><pre><code>5.2.4    service层public class UserServiceImpl implements UserService {    private UserDao userDao;    public void setUserDao(UserDao userDao) {        this.userDao = userDao;    }    @Override    public void register(User user) {        userDao.save(user);    }}</code></pre><hr><pre><code>5.2.5    hibernate.cfg.xml&lt;session-factory&gt;    &lt;!-- 1基本4项 --&gt;    &lt;property name="hibernate.connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt;    &lt;property name="hibernate.connection.url"&gt;jdbc:mysql:///ee19_spring_day03&lt;/property&gt;    &lt;property name="hibernate.connection.username"&gt;root&lt;/property&gt;    &lt;property name="hibernate.connection.password"&gt;1234&lt;/property&gt;    &lt;!-- 2 配置方言 --&gt;    &lt;property name="hibernate.dialect"&gt;org.hibernate.dialect.MySQL5Dialect&lt;/property&gt;    &lt;!-- 3 sql语句 --&gt;    &lt;property name="hibernate.show_sql"&gt;true&lt;/property&gt;    &lt;property name="hibernate.format_sql"&gt;true&lt;/property&gt;    &lt;!-- 4 自动生成表(一般没用) --&gt;    &lt;property name="hibernate.hbm2ddl.auto"&gt;update&lt;/property&gt;    &lt;!-- 5本地线程绑定 --&gt;    &lt;property name="hibernate.current_session_context_class"&gt;thread&lt;/property&gt;    &lt;!-- 导入映射文件 --&gt;    &lt;mapping resource="com/itheima/domain/User.hbm.xml"/&gt;&lt;/session-factory&gt;</code></pre><hr><pre><code>5.2.6    applicationContext.xml    5.2.6.1    添加命名空间    &lt;?xml version="1.0" encoding="UTF-8"?&gt;    &lt;beans xmlns="http://www.springframework.org/schema/beans"           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"       xmlns:aop="http://www.springframework.org/schema/aop"       xmlns:tx="http://www.springframework.org/schema/tx"       xmlns:context="http://www.springframework.org/schema/context"       xsi:schemaLocation="http://www.springframework.org/schema/beans                               http://www.springframework.org/schema/beans/spring-beans.xsd                              http://www.springframework.org/schema/tx                               http://www.springframework.org/schema/tx/spring-tx.xsd                              http://www.springframework.org/schema/aop                               http://www.springframework.org/schema/aop/spring-aop.xsd                              http://www.springframework.org/schema/context                               http://www.springframework.org/schema/context/spring-context.xsd"&gt;</code></pre><hr><pre><code>    5.2.6.2    加载hibernate配置文件    &lt;!-- 1 加载hibenrate.cfg.xml 获得SessionFactory         * configLocation确定配置文件位置    --&gt;    &lt;bean id="sessionFactory" class="org.springframework.orm.hibernate3.LocalSessionFactoryBean"&gt;        &lt;property name="configLocation" value="classpath:hibernate.cfg.xml"&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 2创建模板         * 底层使用session，session 有sessionFactory获得    --&gt;    &lt;bean id="hibernateTemplate" class="org.springframework.orm.hibernate3.HibernateTemplate"&gt;        &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt;    &lt;/bean&gt;</code></pre><hr><pre><code>    5.2.6.3    dao和service    &lt;!-- 3 dao --&gt;    &lt;bean id="userDao" class="com.itheima.dao.impl.UserDaoImpl"&gt;        &lt;property name="hibernateTemplate" ref="hibernateTemplate"&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 4 service --&gt;    &lt;bean id="userService" class="com.itheima.service.impl.UserServiceImpl"&gt;        &lt;property name="userDao" ref="userDao"&gt;&lt;/property&gt;    &lt;/bean&gt;</code></pre><hr><pre><code>    5.2.6.4    事务管理    &lt;!-- 5 事务管理 --&gt;    &lt;!-- 5.1 事务管理器 ：HibernateTransactionManager --&gt;    &lt;bean id="txManager" class="org.springframework.orm.hibernate3.HibernateTransactionManager" &gt;        &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!-- 5.2 事务详情 ，给ABC进行具体事务设置 --&gt;    &lt;tx:advice id="txAdvice" transaction-manager="txManager"&gt;        &lt;tx:attributes&gt;            &lt;tx:method name="register"/&gt;        &lt;/tx:attributes&gt;    &lt;/tx:advice&gt;    &lt;!-- 5.3 AOP编程，ABCD 筛选 ＡＢＣ  --&gt;    &lt;aop:config&gt;        &lt;aop:advisor advice-ref="txAdvice" pointcut="execution(* com.itheima.service..*.*(..))"/&gt;    &lt;/aop:config&gt;</code></pre><hr><pre><code>    5.2.7    测试    @RunWith(SpringJUnit4ClassRunner.class)    @ContextConfiguration(locations="classpath:applicationContext.xml")    public class TestApp {        @Autowired        private UserService userService;        @Test        public void demo01(){            User user = new User();            user.setUsername("jack");            user.setPassword("1234");            user.setAge(18);            userService.register(user);        }    }</code></pre><hr><p>5.3    spring整合hibernate：没有hibernate.cfg.xml 【】</p><pre><code>*    删除hibernate.cfg.xml文件，但需要保存文件内容，将其配置spring中*    修改dao层，继承HibernateDaoSupport</code></pre><hr><pre><code>5.3.1    修改spring，配置SessionFactory&lt;!-- 1.1加载properties文件 --&gt;&lt;!-- 1.2 配置数据源 --&gt;&lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt;    &lt;property name="driverClass" value="com.mysql.jdbc.Driver"&gt;&lt;/property&gt;    &lt;property name="jdbcUrl" value="jdbc:mysql:///ee19_spring_day03"&gt;&lt;/property&gt;    &lt;property name="user" value="root"&gt;&lt;/property&gt;    &lt;property name="password" value="1234"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 1.3配置 LocalSessionFactoryBean，获得SessionFactory     * configLocation确定配置文件位置        &lt;property name="configLocation" value="classpath:hibernate.cfg.xml"&gt;&lt;/property&gt;    1)dataSource 数据源    2)hibernateProperties hibernate其他配置项    3) 导入映射文件        mappingLocations ，确定映射文件位置，需要“classpath:” ,支持通配符 【】            &lt;property name="mappingLocations" value="classpath:com/itheima/domain/User.hbm.xml"&gt;&lt;/property&gt;            &lt;property name="mappingLocations" value="classpath:com/itheima/domain/*.hbm.xml"&gt;&lt;/property&gt;        mappingResources ，加载执行映射文件，从src下开始 。不支持通配符*            &lt;property name="mappingResources" value="com/itheima/domain/User.hbm.xml"&gt;&lt;/property&gt;        mappingDirectoryLocations ，加载指定目录下的，所有配置文件            &lt;property name="mappingDirectoryLocations" value="classpath:com/itheima/domain/"&gt;&lt;/property&gt;        mappingJarLocations ， 从jar包中获得映射文件--&gt;&lt;bean id="sessionFactory" class="org.springframework.orm.hibernate3.LocalSessionFactoryBean"&gt;    &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;    &lt;property name="hibernateProperties"&gt;        &lt;props&gt;            &lt;prop key="hibernate.dialect"&gt;org.hibernate.dialect.MySQL5Dialect&lt;/prop&gt;            &lt;prop key="hibernate.show_sql"&gt;true&lt;/prop&gt;            &lt;prop key="hibernate.format_sql"&gt;true&lt;/prop&gt;            &lt;prop key="hibernate.hbm2ddl.auto"&gt;update&lt;/prop&gt;            &lt;prop key="hibernate.current_session_context_class"&gt;thread&lt;/prop&gt;        &lt;/props&gt;    &lt;/property&gt;    &lt;property name="mappingLocations" value="classpath:com/itheima/domain/*.hbm.xml"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><pre><code>5.3.2    修改dao，使用HibernateDaoSupport*    继承HibernateDaoSupport// 底层需要SessionFactory，自动创建HibernateTemplate模板public class UserDaoImpl extends HibernateDaoSupport implements UserDao {    @Override    public void save(User user) {        this.getHibernateTemplate().save(user);    }}*    spring 删除模板，给dao注入SessionFactory    &lt;!-- 3 dao --&gt;    &lt;bean id="userDao" class="com.itheima.dao.impl.UserDaoImpl"&gt;        &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt;    &lt;/bean&gt;</code></pre><p><img src="/images/20170717/19.png"></p><hr><p>5.4    struts整合spring：spring创建action</p><pre><code>1.编写action类，并将其配置给spring ，spring可以注入service2.编写struts.xml 3.表单jsp页面4.web.xml 配置     1.确定配置文件contextConfigLocation    2.配置监听器 ContextLoaderListener    3.配置前端控制器 StrutsPrepareAndExecuteFitler</code></pre><hr><pre><code>5.4.1    action类*    通用public class UserAction extends ActionSupport implements ModelDriven&lt;User&gt; {    //1 封装数据    private User user = new User();    @Override    public User getModel() {        return user;    }    //2 service    private UserService userService;    public void setUserService(UserService userService) {        this.userService = userService;    }    *    功能    /**         * 注册         * @return         */        public String register(){            userService.register(user);            return "success";        }</code></pre><hr><pre><code>5.4.2    spring配置&lt;!-- 6 配置action --&gt;&lt;bean id="userAction" class="com.itheima.web.action.UserAction" scope="prototype"&gt;    &lt;property name="userService" ref="userService"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><pre><code>5.4.3    struts配置&lt;struts&gt;    &lt;!-- 开发模式 --&gt;    &lt;constant name="struts.devMode" value="true" /&gt;    &lt;package name="default" namespace="/" extends="struts-default"&gt;        &lt;!-- 底层自动从spring容器中通过名称获得内容， getBean("userAction") --&gt;        &lt;action name="userAction_*" class="userAction" method="{1}"&gt;            &lt;result name="success"&gt;/messag.jsp&lt;/result&gt;        &lt;/action&gt;    &lt;/package&gt;&lt;/struts&gt;</code></pre><hr><pre><code>5.4.4    jsp表单&lt;form action="${pageContext.request.contextPath}/userAction_register" method="post"&gt;    用户名：&lt;input type="text" name="username"/&gt; &lt;br/&gt;    密码：&lt;input type="password" name="password"/&gt; &lt;br/&gt;    年龄：&lt;input type="text" name="age"/&gt; &lt;br/&gt;    &lt;input type="submit" /&gt;&lt;/form&gt;</code></pre><hr><pre><code>5.4.5    配置web.xml&lt;!-- 1 确定spring xml位置 --&gt;  &lt;context-param&gt;      &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;      &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;  &lt;/context-param&gt;  &lt;!-- 2 spring监听器 --&gt;  &lt;listener&gt;      &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;  &lt;/listener&gt;  &lt;!-- 3 struts 前端控制器 --&gt;  &lt;filter&gt;      &lt;filter-name&gt;struts2&lt;/filter-name&gt;      &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt;  &lt;/filter&gt;  &lt;filter-mapping&gt;      &lt;filter-name&gt;struts2&lt;/filter-name&gt;      &lt;url-pattern&gt;/*&lt;/url-pattern&gt;  &lt;/filter-mapping&gt;</code></pre><hr><p>5.5    struts整合spring：struts创建action 【】</p><pre><code>*    删除spring action配置*    struts &lt;action class="全限定类名"&gt;&lt;package name="default" namespace="/" extends="struts-default"&gt;    &lt;!-- 底层自动从spring容器中通过名称获得内容， getBean("userAction") --&gt;    &lt;action name="userAction_*" class="com.itheima.web.action.UserAction" method="{1}"&gt;        &lt;result name="success"&gt;/messag.jsp&lt;/result&gt;    &lt;/action&gt;&lt;/package&gt;*    要求：Action类中，必须提供service名称与 spring配置文件一致。（如果名称一样，将自动注入）</code></pre><p><img src="/images/20170717/20.png"></p><pre><code>分析：1. struts 配置文件    default.properties  ,常量配置文件    struts-default.xml ，默认核心配置文件    struts-plugins.xml ，插件配置文件    struts.xml，自定义核心配置文件    常量的使用，后面配置项，将覆盖前面的。2.default.properties  ，此配置文件中确定 按照【名称】自动注入    /org/apache/struts2/default.properties</code></pre><p><img src="/images/20170717/21.png"></p><pre><code>3. struts-plugins.xml ,struts整合spring</code></pre><p><img src="/images/20170717/21.png"></p><pre><code>&lt;constant name="struts.objectFactory" value="spring" /&gt;struts的action将有spring创建总结，之后action有spring创建，并按照名称自动注入</code></pre><hr><p>6    要求</p><p><img src="/images/20170717/22.png">    </p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
            <tag> ssh </tag>
            
            <tag> junit </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 cat mv</title>
      <link href="/2017/07/17/mei-tian-2-ge-linux-ming-ling-cat-mv/"/>
      <url>/2017/07/17/mei-tian-2-ge-linux-ming-ling-cat-mv/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-17-每天2个Linux命令-cat命令"><a href="#2017-07-17-每天2个Linux命令-cat命令" class="headerlink" title="2017-07-17 每天2个Linux命令 cat命令"></a><center>2017-07-17 每天2个Linux命令 cat命令</center></h2><p>cat命令连接文件并打印到标准输出设备上，cat经常用来显示文件的内容，类似于下的type命令。</p><p>注意：当文件较大时，文本在屏幕上迅速闪过（滚屏），用户往往看不清所显示的内容。因此，一般用more等命令分屏显示。为了控制滚屏，可以按Ctrl+S键，停止滚屏；按Ctrl+Q键可以恢复滚屏。按Ctrl+C（中断）键可以终止该命令的执行，并且返回Shell提示符状态。</p><p>(1)用法:</p><pre><code>  用法：cat [选项] [文件]...</code></pre><p> (2)功能:</p><pre><code>  将[文件]或标准输入组合输出到标准输出。</code></pre><p>(3)选项参数:</p><pre><code>  1)-n, --number                                    对输出的所有行编号  2) -s, --squeeze-blank                           不输出多行空行，有连续两行以上的空白行，就代换为一行的空白行  3) -E, --show-ends                                在每行结束处显示 $  4) -b, --number-nonblank                      对非空输出行编号  5) -A, --show-all                                   等价于 -vET，显示不可打印字符，行尾显示“$”  6) -T, --show-tabs                                 将跳格字符显示为 ^I  7) -v, --show-nonprinting                      使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外  8) --help                                              显示此帮助信息并退出  9) --version                                          输出版本信息并退出</code></pre><p> (4)实例:</p><pre><code>由于cat命令是查看文档的,所以首先新建文本文档test1.txt,test2.txt,test3.txt并在文档中写入内容：方法一：(1)首先用touch指令新建三个文档：[sunjimeng@localhost Document]$ touch {text1.txt,text2.txt,text3.txt}[sunjimeng@localhost Document]$ ll总用量 0-rw-rw-r--. 1 sunjimeng sunjimeng 0 5月   4 22:18 text1.txt-rw-rw-r--. 1 sunjimeng sunjimeng 0 5月   4 22:18 text2.txt-rw-rw-r--. 1 sunjimeng sunjimeng 0 5月   4 22:18 text3.txt</code></pre><hr><pre><code>(2)用图形界面，打开文档输入数据：</code></pre><hr><pre><code>(3)由于在CentOs里文档有自动备份的功能，因此这里有6个文档。其中带~符号的需要用查看备份的软件来打开： </code></pre><hr><pre><code>（4）查看shell中的文档信息:复制代码[sunjimeng@localhost Document]$ ll总用量 12-rw-rw-r--. 1 sunjimeng sunjimeng 61 5月   4 22:23 text1.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   4 22:18 text1.txt~-rw-rw-r--. 1 sunjimeng sunjimeng 61 5月   4 22:23 text2.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   4 22:18 text2.txt~-rw-rw-r--. 1 sunjimeng sunjimeng 61 5月   4 22:24 text3.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   4 22:18 text3.txt~</code></pre><hr><pre><code>方法二：在shell中直接修改文档的内容：复制代码[sunjimeng@localhost Document]$ touch text4.txt[sunjimeng@localhost Document]$ cat &gt;text4.txt &lt;&lt;EOF&gt; test4's first line;&gt; test4's second line;&gt; test4's third line;&gt; EOF[sunjimeng@localhost Document]$ ll总用量 16-rw-rw-r--. 1 sunjimeng sunjimeng 61 5月   4 22:23 text1.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   4 22:18 text1.txt~-rw-rw-r--. 1 sunjimeng sunjimeng 61 5月   4 22:23 text2.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   4 22:18 text2.txt~-rw-rw-r--. 1 sunjimeng sunjimeng 61 5月   4 22:24 text3.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   4 22:18 text3.txt~-rw-rw-r--. 1 sunjimeng sunjimeng 61 5月   4 22:31 text4.txt     //这里并没有创建备份文件，是区别所在[sunjimeng@localhost Document]$ </code></pre><hr><pre><code>1)[sunjimeng@localhost Document]$ cat -n text4.txt                 将包括空行在内的各行按编号输出复制代码[sunjimeng@localhost Document]$ cat &gt;text4.txt &lt;&lt;EOF                   //先修改text4.txt的内容&gt; text4's first line&gt; &gt; &gt; text4's second line&gt; &gt; text4's third line&gt; &gt; &gt; EOF[sunjimeng@localhost Document]$ cat -n text4.txt 1    text4's first line 2     3     4    text4's second line 5     6    text4's third line 7     8    </code></pre><hr><pre><code>2)[sunjimeng@localhost Document]$ cat -b text4.txt               将除空行在内的各行按编号输出复制代码[sunjimeng@localhost Document]$ cat -b text4.txt 1    text4's first line 2    text4's second line 3    text4's third line</code></pre><hr><pre><code>3)[sunjimeng@localhost Document]$ cat text1.txt text2.txt text3.txt        用cat命令直接输出各个文件，可以是一个也可以是多个复制代码[sunjimeng@localhost Document]$ cat text1.txt text2.txt text3.txttest1's first line;test1's second line;test1's third line;test2's first line;test2's second line;test2's third line;test3's first line;test3's second line;test3's third line;</code></pre><hr><pre><code>4)[sunjimeng@localhost Document]$ cat text1.txt text2.txt &gt; text5.txt             将讲text1.txt和text2.txt输出到text5.txt里，和输出到标准输出一样，也可以有-n,-b等参数       由于这个特性，cat命令可以将多个压缩包合并成一个，可以用tar命令解压# cat test.tar.gz_?? &gt; test.tar.gz #可以用cat命令将被切割的多个压缩包合并成一个# tar -xvzf test.tar.gz #再用tar命令解压复制代码[sunjimeng@localhost Document]$ cat text1.txt text2.txt &gt; text5.txt[sunjimeng@localhost Document]$ cat text5.txttest1's first line;test1's second line;test1's third line;test2's first line;test2's second line;test2's third line;[sunjimeng@localhost Document]$ 复制代码</code></pre><hr><pre><code>5)[sunjimeng@localhost Document]$ tac text5.txt                  倒序输出文件的各行内容复制代码[sunjimeng@localhost Document]$ tac text5.txttest2's third line;test2's second line;test2's first line;test1's third line;test1's second line;test1's first line;</code></pre><hr><pre><code>6)[sunjimeng@localhost Document]$ cat -s text4.txt                    输出文档中的内容，如果有多个空行则用一个代替复制代码[sunjimeng@localhost Document]$ cat -s text4.txt                最多连续输出一个空行text4's first linetext4's second linetext4's third line[sunjimeng@localhost Document]$ cat text4.txt                   有多少空行，输出多少空行text4's first linetext4's second linetext4's third line</code></pre><hr><pre><code>7)[sunjimeng@localhost Document]$ cat &gt;text6.txt                      从键盘录入内容到文件，回车是保存，退出Ctrl+z复制代码[sunjimeng@localhost Document]$ cat &gt;text6.txtI am MenAngel!                                         //除了最后一个回车之后，其余回车是文档中数据的换行并保存Practice Order!^Z          //回车后是Ctrl+Z命令退出[3]+  已停止               cat &gt; text6.txt[sunjimeng@localhost Document]$ cat text6.txtI am MenAngel!Practice Order!</code></pre><hr><pre><code>8)[sunjimeng@localhost Document]$ cat -E text4.txt                    输出各行文本，并且以$符结尾复制代码[sunjimeng@localhost Document]$ cat -E text4.txttext4's first line$$$text4's second line$$text4's third line$$$</code></pre><hr><pre><code>9)[sunjimeng@localhost Document]$ cat &gt;text6.txt &lt;&lt;EOF              用$取表达式的值小小范例：[sunjimeng@localhost Document]$ cat &gt;text6.txt &lt;&lt;EOF&gt; pwd=$(pwd)&gt; EOF[sunjimeng@localhost Document]$ cat text6.txtpwd=/home/sunjimeng/Document</code></pre><hr><pre><code>10)[sunjimeng@localhost Document]$ cat --help复制代码[sunjimeng@localhost Document]$ cat --help用法：cat [选项]... [文件]...将[文件]或标准输入组合输出到标准输出。  -A, --show-all           等于-vET  -b, --number-nonblank    对非空输出行编号  -e                       等于-vE  -E, --show-ends          在每行结束处显示"$"  -n, --number             对输出的所有行编号  -s, --squeeze-blank      不输出多行空行  -t                       与-vT 等价  -T, --show-tabs          将跳格字符显示为^I  -u                       (被忽略)  -v, --show-nonprinting   使用^ 和M- 引用，除了LFD和 TAB 之外      --help        显示此帮助信息并退出      --version        显示版本信息并退出如果没有指定文件，或者文件为"-"，则从标准输入读取。示例：  cat f - g  先输出f 的内容，然后输出标准输入的内容，最后输出g 的内容。  cat        将标准输入的内容复制到标准输出。GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告cat 的翻译错误要获取完整文档，请运行：info coreutils 'cat invocation'</code></pre><hr><pre><code>11)[sunjimeng@localhost Document]$ cat --version复制代码[sunjimeng@localhost Document]$ cat --versioncat (GNU coreutils) 8.22Copyright (C) 2013 Free Software Foundation, Inc.许可证：GPLv3+：GNU 通用公共许可证第3 版或更新版本&lt;http://gnu.org/licenses/gpl.html&gt;。本软件是自由软件：您可以自由修改和重新发布它。在法律范围内没有其他保证。由Torbjörn Granlund 和Richard M. Stallman 编写。</code></pre><h2 id="2017-07-17-每天2个Linux命令-mv命令"><a href="#2017-07-17-每天2个Linux命令-mv命令" class="headerlink" title="2017-07-17 每天2个Linux命令  mv命令"></a><center>2017-07-17 每天2个Linux命令  mv命令</center></h2><p>mv命令用来对文件或目录重新命名，或者将文件从一个目录移到另一个目录中。</p><p>注意事项：mv与cp的结果不同，mv好像文件“搬家”，文件个数并未增加。而cp对文件进行复制，文件个数增加了。</p><hr><pre><code>(1)用法: 用法:   mv [选项]...   [-T]    源文件    目标文件 或:   mv [选项]...             源文件... 目录 或:   mv [选项]...   -t        目录       源文件...</code></pre><hr><pre><code>(2)功能:   将源文件重命名为目标文件，或将源文件移动至指定目录。</code></pre><hr><pre><code>(3)选项参数:  1) -b：     当文件存在时，覆盖前，为其创建一个备份  2) -f       若目标文件或目录与现有的文件或目录重复，则直接覆盖现有的文件或目录   3)  -i       交互式操作，覆盖前先行询问用户，如果源文件与目标文件或目标目录中的文件同名            ，则询问用户是否覆盖目标文件。这样可以避免误将文件覆盖。  4) -f  -force      强制的意思，如果目标文件已经存在，不会询问而直接覆盖  5) -u    若目标文件已经存在，且 source 比较新，才会更新(update)</code></pre><hr><p>(4)实例:</p><pre><code> 1)[sunjimeng@localhost Document]$ mv text1 mytext  由于此处源文件test1与目标文件是在同一目录下，    可以看作仅仅是改了文件的名字 复制代码[sunjimeng@localhost Document]$ ll                        //目录下为空总用量 0[sunjimeng@localhost Document]$ cat &gt;text1 &lt;&lt;EOF         //新建文件文档并从标准输入中输入数据到文件&gt; I am MenAngel&gt; PWD=$(pwd)&gt; I am testing the order of mv!&gt; EOF[sunjimeng@localhost Document]$ ll总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 text1[sunjimeng@localhost Document]$ mv text1 mytext         //执行mv命令[sunjimeng@localhost Document]$ cat mytextI am MenAngelPWD=/home/sunjimeng/DocumentI am testing the order of mv![sunjimeng@localhost Document]$ ll                     //可见已经改名总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext[sunjimeng@localhost Document]$ 复制代码</code></pre><hr><pre><code>2)[sunjimeng@localhost Document]$ mv mytext{,.txt} 与[sunjimeng@localhost Document]$ mv text text.txt          给文件名增加后缀复制代码[sunjimeng@localhost Document]$ mv mytext{,.txt}                   //增加后缀名的原始方法[sunjimeng@localhost Document]$ ll总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext.txt[sunjimeng@localhost Document]$ touch text[sunjimeng@localhost Document]$ ll总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   5 22:08 text[sunjimeng@localhost Document]$ mv text text.txt                   //利用mv的改名目录增加后缀[sunjimeng@localhost Document]$ ll总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   5 22:08 text.txt</code></pre><hr><pre><code>3)[root@localhost Documents]# mv ../Document/* . 将文件从源目录移动到目标目录，这里源目录和目标目录可以任意指定。.代表当前目录复制代码[sunjimeng@localhost Document]$ ll    //Document下游两个文件总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   5 22:08 text.txt[sunjimeng@localhost Document]$ cd ../Documents  //进入同级兄弟目录Documents，发现其下为空[sunjimeng@localhost Documents]$ ll总用量 0[sunjimeng@localhost Documents]$ mv ../Document/* .  //将Document下的所有文件（*），移动到当前目录（.）。mv: 无法将"../Document/mytext.txt" 移动至"./mytext.txt": 权限不够   //Linux用组名和用户名来管理文件，此时当前用户没有权限移动文件，必须改为root用户mv: 无法将"../Document/text.txt" 移动至"./text.txt": 权限不够    [sunjimeng@localhost Documents]$ su root密码：ABRT 已检测到 '1' 个问题。预了解详细信息请执行：abrt-cli list --since 1462423345[root@localhost Documents]# mv ../Document/* .[root@localhost Documents]# ll                                   //移动完成总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   5 22:08 text.txt[root@localhost Documents]# ls -l ../Document                    //查看Document目录已经没有任何东西总用量 0复制代码</code></pre><hr><pre><code>4)[root@localhost Documents]# mv -t ../Document ./*   功能同（3），但区别是源文件的路径和目标路径的位置发生了变化复制代码[root@localhost Documents]# ll总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   5 22:08 text.txt[root@localhost Documents]# mv -t ./* ../Document   //-t参数的功能就是让他们的位置发生变化，这里第一个参数是目标路径mv: 目标"./mytext.txt" 不是目录[root@localhost Documents]# mv -t ../Document ./*   //位置调换一下就行了[root@localhost Documents]# ll总用量 0[root@localhost Documents]# ll总用量 0[root@localhost Documents]# ls -l ../Document总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   5 22:08 text.txt</code></pre><hr><pre><code>5)[root@localhost Document]# mv mytext.txt mytext  如果第二个参数不是目录名，才将源文件改名，    否则，移动源文件到该目录下（与实例1作比较）复制代码[root@localhost Document]# mkdir mytext         [root@localhost Document]# ll总用量 4drwxr-xr-x. 2 root      root       6 5月   5 22:34 mytext-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext.txt-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   5 22:08 text[root@localhost Document]# mv mytext.txt mytext  /与实例一不同的是，这里mytext是个目录[root@localhost Document]# ll总用量 0drwxr-xr-x. 2 root      root      23 5月   5 22:35 mytext-rw-rw-r--. 1 sunjimeng sunjimeng  0 5月   5 22:08 text[root@localhost Document]# ls -l mytext总用量 4-rw-rw-r--. 1 sunjimeng sunjimeng 73 5月   5 22:02 mytext.txt </code></pre><hr><pre><code>6)[root@localhost Document]# mv -b myword text    源文件和目标文件都是存在的，因此会有覆盖提醒，-b用于在覆盖时备份文件 复制代码[root@localhost Document]# cat &gt;myword &lt;&lt;EOF&gt; this is my word!&gt; EOF[root@localhost Document]# cat &gt;text &lt;&lt;EOF&gt; this is my text!&gt; EOF[root@localhost Document]# mv -b myword text  //在一个文件即将覆盖另一个文件时，默认是提醒的，所以加上-i参数和不加是一样的mv：是否覆盖"text"？ y[root@localhost Document]# cat mywordcat: myword: 没有那个文件或目录[root@localhost Document]# cat textthis is my word![root@localhost Document]# ll总用量 8drwxr-xr-x. 2 root      root      23 5月   5 22:35 mytext  //这里text里存的是前面myword的内容，text的内容备份到text~中，需要特殊软件才能查看-rw-r--r--. 1 root      root      17 5月   5 22:41 text-rw-rw-r--. 1 sunjimeng sunjimeng 17 5月   5 22:41 text~</code></pre><hr><pre><code>7) [root@localhost text]# mv * ../                                将当前目录下的所有内容移动到父级目录（特殊情况）复制代码[root@localhost Document]# mkdir text[root@localhost Document]# touch ./text/{text1,text2,text3}[root@localhost Document]# cd text[root@localhost text]# mv * ../[root@localhost text]# cd ../[root@localhost Document]# ll总用量 0drwxr-xr-x. 2 root root 6 5月   5 22:57 text-rw-r--r--. 1 root root 0 5月   5 22:57 text1-rw-r--r--. 1 root root 0 5月   5 22:57 text2-rw-r--r--. 1 root root 0 5月   5 22:57 text3</code></pre><hr><pre><code>8)[root@localhost Document]# mv -f text2 text3  强制执行操作，并不做任何提醒</code></pre><hr><pre><code>9)[root@localhost Document]# mv -i text2 text3  加不加-i在覆盖时都会提醒复制代码[root@localhost Document]# ll总用量 0drwxr-xr-x. 2 root root 6 5月   5 23:05 text-rw-r--r--. 1 root root 0 5月   5 22:57 text2-rw-r--r--. 1 root root 0 5月   5 22:57 text3-rw-r--r--. 1 root root 0 5月   5 22:57 text4[root@localhost Document]# mv text2 text3mv：是否覆盖"text3"？ n[root@localhost Document]# mv -i text2 text3mv：是否覆盖"text3"？ n[root@localhost Document]# mv -f text2 text3[root@localhost Document]# ll总用量 0drwxr-xr-x. 2 root root 6 5月   5 23:05 text-rw-r--r--. 1 root root 0 5月   5 22:57 text3-rw-r--r--. 1 root root 0 5月   5 22:57 text4</code></pre><hr><pre><code>10)[root@localhost Document]# mv Dir text 将Dir目录移动到text目录下(text存在时)，如果不存在直接将Dir改名为text复制代码[root@localhost Document]# mkdir testDir[root@localhost Document]# ll                       //下面的操作先将文件text3和text4放到textDir目录下总用量 0drwxr-xr-x. 2 root root 6 5月   5 23:09 testDirdrwxr-xr-x. 2 root root 6 5月   5 23:05 text-rw-r--r--. 1 root root 0 5月   5 22:57 text3-rw-r--r--. 1 root root 0 5月   5 22:57 text4[root@localhost Document]# mv {text3,text4} ./testDir[root@localhost Document]# mv testDir Dir          //由于Dir不存在，所以testDir改名为Dir[root@localhost Document]# mv Dir text             //由于text是存在的，所以将Dir移到text目录下[root@localhost Document]# ll总用量 0drwxr-xr-x. 3 root root 16 5月   5 23:10 text      //下面验证了这一点[root@localhost Document]# cd text[root@localhost text]# ll总用量 0drwxr-xr-x. 2 root root 30 5月   5 23:09 Dir[root@localhost text]# cd Dir[root@localhost Dir]# ll总用量 0-rw-r--r--. 1 root root 0 5月   5 22:57 text3-rw-r--r--. 1 root root 0 5月   5 22:57 text4</code></pre><hr><pre><code>11)[root@localhost /]# mv --help复制代码[root@localhost /]# mv --help用法：mv [选项]... [-T] 源文件 目标文件　或：mv [选项]... 源文件... 目录　或：mv [选项]... -t 目录 源文件...Rename SOURCE to DEST, or move SOURCE(s) to DIRECTORY.Mandatory arguments to long options are mandatory for short options too.      --backup[=CONTROL]       为每个已存在的目标文件创建备份  -b                           类似--backup 但不接受参数  -f, --force                  覆盖前不询问  -i, --interactive            覆盖前询问  -n, --no-clobber             不覆盖已存在文件如果您指定了-i、-f、-n 中的多个，仅最后一个生效。      --strip-trailing-slashes    去掉每个源文件参数尾部的斜线  -S, --suffix=SUFFIX        替换常用的备份文件后缀  -t, --target-directory=DIRECTORY  move all SOURCE arguments into DIRECTORY  -T, --no-target-directory    treat DEST as a normal file  -u, --update                 move only when the SOURCE file is newer                                 than the destination file or when the                                 destination file is missing  -v, --verbose                explain what is being done  -Z, --context                set SELinux security context of destination                                 file to default type      --help        显示此帮助信息并退出      --version        显示版本信息并退出The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX.The version control method may be selected via the --backup option or throughthe VERSION_CONTROL environment variable.  Here are the values:  none, off       不进行备份(即使使用了--backup 选项)  numbered, t     备份文件加上数字进行排序  existing, nil   若有数字的备份文件已经存在则使用数字，否则使用普通方式备份  simple, never   永远使用普通方式备份GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告mv 的翻译错误要获取完整文档，请运行：info coreutils 'mv invocation'</code></pre><hr><pre><code>12)[root@localhost /]# mv --version复制代码[root@localhost /]# mv --versionmv (GNU coreutils) 8.22Copyright (C) 2013 Free Software Foundation, Inc.许可证：GPLv3+：GNU 通用公共许可证第3 版或更新版本&lt;http://gnu.org/licenses/gpl.html&gt;。本软件是自由软件：您可以自由修改和重新发布它。在法律范围内没有其他保证。由Mike Parker、David MacKenzie 和Jim Meyering 编写。</code></pre><hr><p>(5)其他:</p><pre><code>  用-b做备份时:        -b 不接受参数，mv会去读取环境变量VERSION_CONTROL来作为备份策略。  --backup该选项指定如果目标文件存在时的动作，共有四种备份策略：    1.CONTROL=none或off : 不备份。    2.CONTROL=numbered或t：数字编号的备份    3.CONTROL=existing或nil：如果存在以数字编号的备份，则继续编号备份m+1...n：    执行mv操作前已存在以数字编号的文件log2.txt.~1~，那么再次执行将产生log2.txt~2~，以次类推。    如果之前没有以数字编号的文件，则使用下面讲到的简单备份。    4.CONTROL=simple或never：使用简单备份：在被覆盖前进行了简单备份，简单备份只能有一份，再次被覆盖时，简单备份也会被覆盖。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring AOP、AspectJ、JdbcTemplate</title>
      <link href="/2017/07/16/spring-aop-aspectj-jdbctemplate/"/>
      <url>/2017/07/16/spring-aop-aspectj-jdbctemplate/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-16-springAOP、AspectJ、JdbcTemplate"><a href="#2017-07-16-springAOP、AspectJ、JdbcTemplate" class="headerlink" title="2017-07-16 springAOP、AspectJ、JdbcTemplate"></a><center>2017-07-16 springAOP、AspectJ、JdbcTemplate</center></h2><p>1    <strong>AOP</strong></p><p>1.1    AOP介绍</p><pre><code>1.1.1    什么是AOP*    在软件业，AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。*    AOP是OOP（面向对象编程）的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。*    利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。*    AOP采取横向抽取机制，取代了传统纵向继承体系重复性代码*    经典应用：事务管理、性能监视、安全检查、缓存 、日志等*    Spring AOP使用纯Java实现，不需要专门的编译过程和类加载器，在运行期通过代理方式向目标类织入增强代码*    AspectJ是一个基于Java语言的AOP框架，Spring2.0开始，Spring AOP引入对Aspect的支持，AspectJ扩展了Java语言，*    提供了一个专门的编译器，在编译时提供横向代码的织入</code></pre><hr><pre><code>1.1.2    AOP实现原理*    aop底层将采用代理机制进行实现。*    接口 + 实现类 ：spring采用 jdk 的动态代理Proxy。*    实现类：spring 采用 cglib字节码增强。</code></pre><hr><pre><code>1.1.3    AOP术语【掌握】1.target：目标类，需要被代理的类。例如：UserService2.Joinpoint(连接点):所谓连接点是指那些可能被拦截到的方法。例如：所有的方法3.PointCut 切入点：已经被增强的连接点。例如：addUser()4.advice 通知/增强，增强代码。例如：after、before5.Weaving(织入):是指把增强advice应用到目标对象target来创建新的代理对象proxy的过程.6.proxy 代理类7.Aspect(切面): 是切入点pointcut和通知advice的结合    一个线是一个特殊的面。    一个切入点和一个通知，组成成一个特殊的面。</code></pre><p>！<a href="/images/20170716/1.png"></a></p><hr><p>1.2    手动方式</p><pre><code>1.2.1    JDK动态代理    JDK动态代理 对“装饰者”设计模式 简化。使用前提：必须有接口    1.目标类：接口 + 实现类    2.切面类：用于存通知 MyAspect    3.工厂类：编写工厂生成代理    4.测试</code></pre><hr><pre><code>1.2.2    目标类public interface UserService {    public void addUser();    public void updateUser();    public void deleteUser();}</code></pre><hr><pre><code>1.2.3    切面类public class MyAspect {    public void before(){        System.out.println("鸡首");    }    public void after(){        System.out.println("牛后");    }}</code></pre><hr><pre><code>1.2.4    工厂public class MyBeanFactory {public static UserService createService(){    //1 目标类    final UserService userService = new UserServiceImpl();    //2切面类    final MyAspect myAspect = new MyAspect();    /* 3 代理类：将目标类（切入点）和 切面类（通知） 结合 --&gt; 切面     *     Proxy.newProxyInstance     *         参数1：loader ，类加载器，动态代理类 运行时创建，任何类都需要类加载器将其加载到内存。     *             一般情况：当前类.class.getClassLoader();     *                     目标类实例.getClass().get...     *         参数2：Class[] interfaces 代理类需要实现的所有接口     *             方式1：目标类实例.getClass().getInterfaces()  ;注意：只能获得自己接口，不能获得父元素接口     *             方式2：new Class[]{UserService.class}        *             例如：jdbc 驱动  --&gt; DriverManager  获得接口 Connection     *         参数3：InvocationHandler  处理类，接口，必须进行实现类，一般采用匿名内部     *             提供 invoke 方法，代理类的每一个方法执行时，都将调用一次invoke     *                 参数31：Object proxy ：代理对象     *                 参数32：Method method : 代理对象当前执行的方法的描述对象（反射）     *                     执行方法名：method.getName()     *                     执行方法：method.invoke(对象，实际参数)     *                 参数33：Object[] args :方法实际参数     *      */    UserService proxService = (UserService)Proxy.newProxyInstance(                            MyBeanFactory.class.getClassLoader(),                             userService.getClass().getInterfaces(),                             new InvocationHandler() {                                @Override                                public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {                                    //前执行                                    myAspect.before();                                    //执行目标类的方法                                    Object obj = method.invoke(userService, args);                                    //后执行                                    myAspect.after();                                    return obj;                                }                            });    return proxService;}}</code></pre><hr><pre><code>1.2.5    测试@Test    public void demo01(){        UserService userService = MyBeanFactory.createService();        userService.addUser();        userService.updateUser();        userService.deleteUser();    }</code></pre><p>！<a href="/images/20170716/7.png"></a></p><hr><p>1.3    CGLIB字节码增强</p><pre><code>    没有接口，只有实现类。    采用字节码增强框架 cglib，在运行时 创建目标类的子类，从而对目标类进行增强。    导入jar包：    自己导包（了解）：        核心：hibernate-distribution-3.6.10.Final\lib\bytecode\cglib\cglib-2.2.jar        依赖：struts-2.3.15.3\apps\struts2-blank\WEB-INF\lib\asm-3.3.jar    spring-core..jar 已经整合以上两个内容</code></pre><p>！<a href="/images/20170716/2.png"></a></p><p>！<a href="/images/20170716/3.png"></a></p><p>！<a href="/images/20170716/4.png"></a></p><hr><pre><code>1.3.1    工厂类public class MyBeanFactory {    public static UserServiceImpl createService(){        //1 目标类        final UserServiceImpl userService = new UserServiceImpl();        //2切面类        final MyAspect myAspect = new MyAspect();        // 3.代理类 ，采用cglib，底层创建目标类的子类        //3.1 核心类        Enhancer enhancer = new Enhancer();        //3.2 确定父类        enhancer.setSuperclass(userService.getClass());        /* 3.3 设置回调函数 , MethodInterceptor接口 等效 jdk InvocationHandler接口         *     intercept() 等效 jdk  invoke()         *         参数1、参数2、参数3：以invoke一样         *         参数4：methodProxy 方法的代理         *                  *          */        enhancer.setCallback(new MethodInterceptor(){            @Override            public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {                //前                myAspect.before();                //执行目标类的方法                Object obj = method.invoke(userService, args);                // * 执行代理类的父类 ，执行目标类 （目标类和代理类 父子关系）                methodProxy.invokeSuper(proxy, args);                //后                myAspect.after();                return obj;            }        });        //3.4 创建代理        UserServiceImpl proxService = (UserServiceImpl) enhancer.create();        return proxService;    }}</code></pre><hr><pre><code>1.3.2    AOP联盟通知类型    •    AOP联盟为通知Advice定义了org.aopalliance.aop.Advice    •    Spring按照通知Advice在目标类方法的连接点位置，可以分为5类    •    前置通知 org.springframework.aop.MethodBeforeAdvice    •    在目标方法执行前实施增强    •    后置通知 org.springframework.aop.AfterReturningAdvice    •    在目标方法执行后实施增强    •    环绕通知 org.aopalliance.intercept.MethodInterceptor    •    在目标方法执行前后实施增强    •    异常抛出通知 org.springframework.aop.ThrowsAdvice    •    在方法抛出异常后实施增强    •    引介通知 org.springframework.aop.IntroductionInterceptor    •    在目标类中添加一些新的方法和属性    环绕通知，必须手动执行目标方法    try{       //前置通知       //执行目标方法       //后置通知    } catch(){       //抛出异常通知    }</code></pre><p>！<a href="/images/20170716/8.png"></a></p><hr><p>1.4    spring编写代理:半自动</p><pre><code>*    让spring 创建代理对象，从spring容器中手动的获取代理对象。*    导入jar包：核心：4+1AOP：AOP联盟（规范）、spring-aop （实现）</code></pre><p>！<a href="/images/20170716/5.png"></a></p><hr><pre><code>1.4.1    目标类public interface UserService {    public void addUser();    public void updateUser();    public void deleteUser();}</code></pre><hr><pre><code>1.4.2    切面类/** * 切面类中确定通知，需要实现不同接口，接口就是规范，从而就确定方法名称。 * * 采用“环绕通知” MethodInterceptor * */public class MyAspect implements MethodInterceptor {    @Override    public Object invoke(MethodInvocation mi) throws Throwable {        System.out.println("前3");        //手动执行目标方法        Object obj = mi.proceed();        System.out.println("后3");        return obj;    }}</code></pre><hr><pre><code>1.4.3    spring配置&lt;!-- 1 创建目标类 --&gt;&lt;bean id="userServiceId" class="com.itheima.b_factory_bean.UserServiceImpl"&gt;&lt;/bean&gt;&lt;!-- 2 创建切面类 --&gt;&lt;bean id="myAspectId" class="com.itheima.b_factory_bean.MyAspect"&gt;&lt;/bean&gt;&lt;!-- 3 创建代理类     * 使用工厂bean FactoryBean ，底层调用 getObject() 返回特殊bean    * ProxyFactoryBean 用于创建代理工厂bean，生成特殊代理对象        interfaces : 确定接口们            通过&lt;array&gt;可以设置多个值            只有一个值时，value=""        target : 确定目标类        interceptorNames : 通知 切面类的名称，类型String[]，如果设置一个值 value=""        optimize :强制使用cglib            &lt;property name="optimize" value="true"&gt;&lt;/property&gt;    底层机制        如果目标类有接口，采用jdk动态代理        如果没有接口，采用cglib 字节码增强        如果声明 optimize = true ，无论是否有接口，都采用cglib--&gt;&lt;bean id="proxyServiceId" class="org.springframework.aop.framework.ProxyFactoryBean"&gt;    &lt;property name="interfaces" value="com.itheima.b_factory_bean.UserService"&gt;&lt;/property&gt;    &lt;property name="target" ref="userServiceId"&gt;&lt;/property&gt;    &lt;property name="interceptorNames" value="myAspectId"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><pre><code>1.4.4    测试@Testpublic void demo01(){    String xmlPath = "com/itheima/b_factory_bean/beans.xml";    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(xmlPath);    //获得代理类    UserService userService = (UserService) applicationContext.getBean("proxyServiceId");    userService.addUser();    userService.updateUser();    userService.deleteUser();}</code></pre><hr><p>1.5    spring aop编程：全自动【掌握】</p><pre><code>*    从spring容器获得目标类，如果配置aop，spring将自动生成代理。*    要确定目标类，aspectj 切入点表达式，导入jar包spring-framework-3.0.2.RELEASE-dependencies\org.aspectj\com.springsource.org.aspectj.weaver\1.6.8.RELEASE</code></pre><p>！<a href="/images/20170716/6.png"></a></p><hr><pre><code>1.5.1    spring配置&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans"       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"       xmlns:aop="http://www.springframework.org/schema/aop"       xsi:schemaLocation="http://www.springframework.org/schema/beans                               http://www.springframework.org/schema/beans/spring-beans.xsd                              http://www.springframework.org/schema/aop                               http://www.springframework.org/schema/aop/spring-aop.xsd"&gt;    &lt;!-- 1 创建目标类 --&gt;    &lt;bean id="userServiceId" class="com.itheima.c_spring_aop.UserServiceImpl"&gt;&lt;/bean&gt;    &lt;!-- 2 创建切面类（通知） --&gt;    &lt;bean id="myAspectId" class="com.itheima.c_spring_aop.MyAspect"&gt;&lt;/bean&gt;    &lt;!-- 3 aop编程         3.1 导入命名空间        3.2 使用 &lt;aop:config&gt;进行配置                proxy-target-class="true" 声明时使用cglib代理            &lt;aop:pointcut&gt; 切入点 ，从目标对象获得具体方法            &lt;aop:advisor&gt; 特殊的切面，只有一个通知 和 一个切入点                advice-ref 通知引用                pointcut-ref 切入点引用        3.3 切入点表达式            execution(* com.itheima.c_spring_aop.*.*(..))            选择方法         返回值任意   包             类名任意   方法名任意   参数任意    --&gt;    &lt;aop:config proxy-target-class="true"&gt;        &lt;aop:pointcut expression="execution(* com.itheima.c_spring_aop.*.*(..))" id="myPointCut"/&gt;        &lt;aop:advisor advice-ref="myAspectId" pointcut-ref="myPointCut"/&gt;    &lt;/aop:config&gt;&lt;/beans&gt;</code></pre><hr><pre><code>1.5.2    测试@Testpublic void demo01(){    String xmlPath = "com/itheima/c_spring_aop/beans.xml";    ApplicationContext applicationContext = new ClassPathXmlApplicationContext(xmlPath);    //获得目标类    UserService userService = (UserService) applicationContext.getBean("userServiceId");    userService.addUser();    userService.updateUser();    userService.deleteUser();}</code></pre><hr><p>2 <strong>AspectJ</strong></p><p>2.1    介绍</p><pre><code>    *    AspectJ是一个基于Java语言的AOP框架    *    Spring2.0以后新增了对AspectJ切点表达式支持    *    @AspectJ 是AspectJ1.5新增功能，通过JDK5注解技术，允许直接在Bean类中定义切面    新版本Spring框架，建议使用AspectJ方式来开发AOP    *    主要用途：自定义开发</code></pre><hr><p>2.2    切入点表达式【掌握】</p><pre><code>1.execution()  用于描述方法 【掌握】    语法：execution(修饰符  返回值  包.类.方法名(参数) throws异常)        修饰符，一般省略            public        公共方法            *            任意        返回值，不能省略            void            返回没有值            String        返回值字符串            *             任意        包，[省略]            com.itheima.crm            固定包            com.itheima.crm.*.service    crm包下面子包任意 （例如：com.itheima.crm.staff.service）            com.itheima.crm..            crm包下面的所有子包（含自己）            com.itheima.crm.*.service..    crm包下面任意子包，固定目录service，service目录任意包        类，[省略]            UserServiceImpl            指定类            *Impl                    以Impl结尾            User*                    以User开头            *                        任意        方法名，不能省略            addUser                    固定方法            add*                        以add开头            *Do                        以Do结尾            *                        任意        (参数)            ()                        无参            (int)                        一个整型            (int ,int)                    两个            (..)                        参数任意        throws ,可省略，一般不写。综合1    execution(* com.itheima.crm.*.service..*.*(..))综合2    &lt;aop:pointcut expression="execution(* com.itheima.*WithCommit.*(..)) ||                           execution(* com.itheima.*Service.*(..))" id="myPointCut"/&gt;2.within:匹配包或子包中的方法(了解)    within(com.itheima.aop..*)3.this:匹配实现接口的代理对象中的方法(了解)    this(com.itheima.aop.user.UserDAO)4.target:匹配实现接口的目标对象中的方法(了解)    target(com.itheima.aop.user.UserDAO)5.args:匹配参数格式符合标准的方法(了解)    args(int,int)6.bean(id)  对指定的bean所有的方法(了解)    bean('userServiceId')</code></pre><hr><p>2.3    AspectJ 通知类型</p><pre><code>*    aop联盟定义通知类型，具有特性接口，必须实现，从而确定方法名称。*    aspectj 通知类型，只定义类型名称。已经方法格式。*    个数：6种，知道5种，掌握1中。    before:前置通知(应用：各种校验)        在方法执行前执行，如果通知抛出异常，阻止方法运行    afterReturning:后置通知(应用：常规数据处理)        方法正常返回后执行，如果方法中抛出异常，通知无法执行        必须在方法执行后才执行，所以可以获得方法的返回值。    around:环绕通知(应用：十分强大，可以做任何事情)        方法执行前后分别执行，可以阻止方法的执行        必须手动执行目标方法    afterThrowing:抛出异常通知(应用：包装异常信息)        方法抛出异常后执行，如果方法没有抛出异常，无法执行    after:最终通知(应用：清理现场)        方法执行完毕后执行，无论方法中是否出现异常环绕try{     //前置：before    //手动执行目标方法    //后置：afterRetruning} catch(){    //抛出异常 afterThrowing} finally{    //最终 after}</code></pre><p>！<a href="/images/20170716/9.png"></a></p><p>！<a href="/images/20170716/10.png"></a></p><p>！<a href="/images/20170716/11.png"></a></p><p>！<a href="/images/20170716/12.png"></a></p><hr><p>2.4    导入jar包 </p><pre><code>    4个：    aop联盟规范    spring aop 实现    aspect 规范    spring aspect 实现</code></pre><p>！<a href="/images/20170716/13.png"></a></p><hr><p>2.5    基于xml</p><pre><code>1.目标类：接口 + 实现2.切面类：编写多个通知，采用aspectj 通知名称任意（方法名任意）3.aop编程，将通知应用到目标类4.测试</code></pre><hr><pre><code>2.5.1    切面类/** * 切面类，含有多个通知 */public class MyAspect {    public void myBefore(JoinPoint joinPoint){        System.out.println("前置通知 ： " + joinPoint.getSignature().getName());    }    public void myAfterReturning(JoinPoint joinPoint,Object ret){        System.out.println("后置通知 ： " + joinPoint.getSignature().getName() + " , --&gt;" + ret);    }    public Object myAround(ProceedingJoinPoint joinPoint) throws Throwable{        System.out.println("前");        //手动执行目标方法        Object obj = joinPoint.proceed();        System.out.println("后");        return obj;    }    public void myAfterThrowing(JoinPoint joinPoint,Throwable e){        System.out.println("抛出异常通知 ： " + e.getMessage());    }    public void myAfter(JoinPoint joinPoint){        System.out.println("最终通知");    }}</code></pre><hr><pre><code>2.5.2    spring配置&lt;!-- 1 创建目标类 --&gt;&lt;bean id="userServiceId" class="com.itheima.d_aspect.a_xml.UserServiceImpl"&gt;&lt;/bean&gt;&lt;!-- 2 创建切面类（通知） --&gt;&lt;bean id="myAspectId" class="com.itheima.d_aspect.a_xml.MyAspect"&gt;&lt;/bean&gt;&lt;!-- 3 aop编程     &lt;aop:aspect&gt; 将切面类 声明“切面”，从而获得通知（方法）        ref 切面类引用    &lt;aop:pointcut&gt; 声明一个切入点，所有的通知都可以使用。        expression 切入点表达式        id 名称，用于其它通知引用--&gt;&lt;aop:config&gt;    &lt;aop:aspect ref="myAspectId"&gt;        &lt;aop:pointcut expression="execution(* com.itheima.d_aspect.a_xml.UserServiceImpl.*(..))" id="myPointCut"/&gt;        &lt;!-- 3.1 前置通知             &lt;aop:before method="" pointcut="" pointcut-ref=""/&gt;                method : 通知，及方法名                pointcut :切入点表达式，此表达式只能当前通知使用。                pointcut-ref ： 切入点引用，可以与其他通知共享切入点。            通知方法格式：public void myBefore(JoinPoint joinPoint){                参数1：org.aspectj.lang.JoinPoint  用于描述连接点（目标方法），获得目标方法名等            例如：        &lt;aop:before method="myBefore" pointcut-ref="myPointCut"/&gt;        --&gt;        &lt;!-- 3.2后置通知  ,目标方法后执行，获得返回值            &lt;aop:after-returning method="" pointcut-ref="" returning=""/&gt;                returning 通知方法第二个参数的名称            通知方法格式：public void myAfterReturning(JoinPoint joinPoint,Object ret){                参数1：连接点描述                参数2：类型Object，参数名 returning="ret" 配置的            例如：        &lt;aop:after-returning method="myAfterReturning" pointcut-ref="myPointCut" returning="ret" /&gt;        --&gt;        &lt;!-- 3.3 环绕通知             &lt;aop:around method="" pointcut-ref=""/&gt;            通知方法格式：public Object myAround(ProceedingJoinPoint joinPoint) throws Throwable{                返回值类型：Object                方法名：任意                参数：org.aspectj.lang.ProceedingJoinPoint                抛出异常            执行目标方法：Object obj = joinPoint.proceed();            例如：        &lt;aop:around method="myAround" pointcut-ref="myPointCut"/&gt;        --&gt;        &lt;!-- 3.4 抛出异常            &lt;aop:after-throwing method="" pointcut-ref="" throwing=""/&gt;                throwing ：通知方法的第二个参数名称            通知方法格式：public void myAfterThrowing(JoinPoint joinPoint,Throwable e){                参数1：连接点描述对象                参数2：获得异常信息，类型Throwable ，参数名由throwing="e" 配置            例如：        &lt;aop:after-throwing method="myAfterThrowing" pointcut-ref="myPointCut" throwing="e"/&gt;        --&gt;        &lt;!-- 3.5 最终通知 --&gt;                    &lt;aop:after method="myAfter" pointcut-ref="myPointCut"/&gt;    &lt;/aop:aspect&gt;&lt;/aop:config&gt;</code></pre><hr><p>2.6    基于注解</p><pre><code>2.6.1    替换bean    &lt;!-- 1 创建目标类 --&gt;    &lt;bean id="userServiceId" class="com.itheima.d_aspect.b_anno.UserServiceImpl"&gt;&lt;/bean&gt;    &lt;!-- 2 创建切面类（通知） --&gt;    &lt;bean id="myAspectId" class="com.itheima.d_aspect.b_anno.MyAspect"&gt;&lt;/bean&gt;</code></pre><p>！<a href="/images/20170716/14.png"></a></p><p>！<a href="/images/20170716/15.png"></a></p><pre><code>*    注意：扫描&lt;beans xmlns="http://www.springframework.org/schema/beans"   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"   xmlns:context="http://www.springframework.org/schema/context"   xmlns:aop="http://www.springframework.org/schema/aop"   xsi:schemaLocation="http://www.springframework.org/schema/beans                           http://www.springframework.org/schema/beans/spring-beans.xsd                          http://www.springframework.org/schema/aop                           http://www.springframework.org/schema/aop/spring-aop.xsd                          http://www.springframework.org/schema/context                           http://www.springframework.org/schema/context/spring-context.xsd"&gt;&lt;!-- 1.扫描 注解类 --&gt;&lt;context:component-scan base-package="com.itheima.d_aspect.b_anno"&gt;&lt;/context:component-scan&gt;</code></pre><hr><pre><code>2.6.2    替换aop*    必须进行aspectj 自动代理&lt;!-- 2.确定 aop注解生效 --&gt;&lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;*    声明切面 &lt;aop:aspect ref="myAspectId"&gt;</code></pre><p>！<a href="/images/20170716/16.png"></a></p><pre><code>*    替换前置通知&lt;aop:before method="myBefore" pointcut="execution(* com.itheima.d_aspect.b_anno.UserServiceImpl.*(..))"/&gt;//切入点当前有效@Before("execution(* com.itheima.d_aspect.b_anno.UserServiceImpl.*(..))")public void myBefore(JoinPoint joinPoint){    System.out.println("前置通知 ： " + joinPoint.getSignature().getName());}*    替换 公共切入点&lt;aop:pointcut expression="execution(* com.itheima.d_aspect.b_anno.UserServiceImpl.*(..))" id="myPointCut"/&gt;  //声明公共切入点@Pointcut("execution(* com.itheima.d_aspect.b_anno.UserServiceImpl.*(..))")private void myPointCut(){}*    替换后置&lt;aop:after-returning method="myAfterReturning" pointcut-ref="myPointCut" returning="ret" /&gt;@AfterReturning(value="myPointCut()" ,returning="ret")public void myAfterReturning(JoinPoint joinPoint,Object ret){    System.out.println("后置通知 ： " + joinPoint.getSignature().getName() + " , --&gt;" + ret);}</code></pre><p>！<a href="/images/20170716/17.png"></a></p><pre><code>*    替换环绕&lt;aop:around method="myAround" pointcut-ref="myPointCut"/&gt;@Around(value = "myPointCut()")public Object myAround(ProceedingJoinPoint joinPoint) throws Throwable{    System.out.println("前");    //手动执行目标方法    Object obj = joinPoint.proceed();    System.out.println("后");    return obj;}*    替换抛出异常&lt;aop:after-throwing method="myAfterThrowing" pointcut="execution(* com.itheima.d_aspect.b_anno.UserServiceImpl.*(..))" throwing="e"/&gt;@AfterThrowing(value="execution(* com.itheima.d_aspect.b_anno.UserServiceImpl.*(..))" ,throwing="e")public void myAfterThrowing(JoinPoint joinPoint,Throwable e){    System.out.println("抛出异常通知 ： " + e.getMessage());}</code></pre><hr><pre><code>2.6.3    切面类/** * 切面类，含有多个通知 */@Component@Aspectpublic class MyAspect {    //切入点当前有效//    @Before("execution(* com.itheima.d_aspect.b_anno.UserServiceImpl.*(..))")    public void myBefore(JoinPoint joinPoint){        System.out.println("前置通知 ： " + joinPoint.getSignature().getName());    }    //声明公共切入点    @Pointcut("execution(* com.itheima.d_aspect.b_anno.UserServiceImpl.*(..))")    private void myPointCut(){    }//    @AfterReturning(value="myPointCut()" ,returning="ret")    public void myAfterReturning(JoinPoint joinPoint,Object ret){        System.out.println("后置通知 ： " + joinPoint.getSignature().getName() + " , --&gt;" + ret);    }//    @Around(value = "myPointCut()")    public Object myAround(ProceedingJoinPoint joinPoint) throws Throwable{        System.out.println("前");        //手动执行目标方法        Object obj = joinPoint.proceed();        System.out.println("后");        return obj;    }//    @AfterThrowing(value="execution(* com.itheima.d_aspect.b_anno.UserServiceImpl.*(..))" ,throwing="e")    public void myAfterThrowing(JoinPoint joinPoint,Throwable e){        System.out.println("抛出异常通知 ： " + e.getMessage());    }    @After("myPointCut()")    public void myAfter(JoinPoint joinPoint){        System.out.println("最终通知");    }}</code></pre><hr><pre><code>2.6.4    spring配置&lt;!-- 1.扫描 注解类 --&gt;&lt;context:component-scan base-package="com.itheima.d_aspect.b_anno"&gt;&lt;/context:component-scan&gt;&lt;!-- 2.确定 aop注解生效 --&gt;&lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;</code></pre><hr><pre><code>2.6.5    aop注解总结@Aspect  声明切面，修饰切面类，从而获得 通知。通知    @Before 前置    @AfterReturning 后置    @Around 环绕    @AfterThrowing 抛出异常    @After 最终切入点    @PointCut ，修饰方法 private void xxx(){}  之后通过“方法名”获得切入点引用</code></pre><hr><p>3    JdbcTemplate</p><pre><code>spring 提供用于操作JDBC工具类，类似：DBUtils。依赖 连接池DataSource （数据源）</code></pre><hr><p>3.1    环境搭建</p><pre><code>3.1.1    创建表create database ee19_spring_day02;use ee19_spring_day02;create table t_user(  id int primary key auto_increment,  username varchar(50),  password varchar(32));insert into t_user(username,password) values('jack','1234');insert into t_user(username,password) values('rose','5678');</code></pre><hr><pre><code>3.1.2    导入jar包</code></pre><p>！<a href="/images/20170716/18.png"></a></p><hr><pre><code>3.1.3    javabeanpackage com.itheima.domain;public class User {    private Integer id;    private String username;    private String password;</code></pre><p>3.2    使用api（了解）</p><pre><code>public static void main(String[] args) {        //1 创建数据源（连接池） dbcp        BasicDataSource dataSource = new BasicDataSource();        // * 基本4项        dataSource.setDriverClassName("com.mysql.jdbc.Driver");        dataSource.setUrl("jdbc:mysql://localhost:3306/ee19_spring_day02");        dataSource.setUsername("root");        dataSource.setPassword("1234");        //2  创建模板        JdbcTemplate jdbcTemplate = new JdbcTemplate();        jdbcTemplate.setDataSource(dataSource);        //3 通过api操作        jdbcTemplate.update("insert into t_user(username,password) values(?,?);", "tom","998");    }</code></pre><hr><p>3.3    配置DBCP</p><pre><code>&lt;!-- 创建数据源 --&gt;&lt;bean id="dataSourceId" class="org.apache.commons.dbcp.BasicDataSource"&gt;    &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"&gt;&lt;/property&gt;    &lt;property name="url" value="jdbc:mysql://localhost:3306/ee19_spring_day02"&gt;&lt;/property&gt;    &lt;property name="username" value="root"&gt;&lt;/property&gt;    &lt;property name="password" value="1234"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 创建模板 ,需要注入数据源--&gt;&lt;bean id="jdbcTemplateId" class="org.springframework.jdbc.core.JdbcTemplate"&gt;    &lt;property name="dataSource" ref="dataSourceId"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置dao --&gt;&lt;bean id="userDaoId" class="com.itheima.c_dbcp.UserDao"&gt;    &lt;property name="jdbcTemplate" ref="jdbcTemplateId"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><p>3.4    配置C3P0</p><pre><code>&lt;!-- 创建数据源 c3p0--&gt;&lt;bean id="dataSourceId" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt;    &lt;property name="driverClass" value="com.mysql.jdbc.Driver"&gt;&lt;/property&gt;    &lt;property name="jdbcUrl" value="jdbc:mysql://localhost:3306/ee19_spring_day02"&gt;&lt;/property&gt;    &lt;property name="user" value="root"&gt;&lt;/property&gt;    &lt;property name="password" value="1234"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><p>3.5    使用JdbcDaoSupport</p><hr><pre><code>3.5.1    dao层</code></pre><p>！<a href="/images/20170716/19.png"></a></p><pre><code>3.5.2    spring配置文件&lt;!-- 配置dao     * dao 继承 JdbcDaoSupport，之后只需要注入数据源，底层将自动创建模板--&gt;&lt;bean id="userDaoId" class="com.itheima.e_jdbcdaosupport.UserDao"&gt;    &lt;property name="dataSource" ref="dataSourceId"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><pre><code>3.5.3    源码分析</code></pre><p>！<a href="/images/20170716/20.png"></a></p><hr><p>4.6    配置properties</p><hr><p>4.6.1    properties文件</p><pre><code>jdbc.driverClass=com.mysql.jdbc.Driverjdbc.jdbcUrl=jdbc:mysql://localhost:3306/ee19_spring_day02jdbc.user=rootjdbc.password=1234</code></pre><p>4.6.2    spring配置</p><pre><code>&lt;!-- 加载配置文件     "classpath:"前缀表示 src下    在配置文件之后通过  ${key} 获得内容--&gt;&lt;context:property-placeholder location="classpath:com/itheima/f_properties/jdbcInfo.properties"/&gt;&lt;!-- 创建数据源 c3p0--&gt;&lt;bean id="dataSourceId" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt;    &lt;property name="driverClass" value="${jdbc.driverClass}"&gt;&lt;/property&gt;    &lt;property name="jdbcUrl" value="${jdbc.jdbcUrl}"&gt;&lt;/property&gt;    &lt;property name="user" value="${jdbc.user}"&gt;&lt;/property&gt;    &lt;property name="password"  value="${jdbc.password}"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><p>4    要求</p><p>！<a href="/images/20170716/21.png"></a></p><p>！<a href="/images/20170716/22.png"></a></p><pre><code>properties +  JdbcDaoSupport  + c3p0UserDao  --&gt; api ( update / query  / queryForObject)</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
            <tag> AOP </tag>
            
            <tag> AspectJ </tag>
            
            <tag> JdbcTemplate </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring生命周期（后处理Bean）、属性注入</title>
      <link href="/2017/07/16/spring-sheng-ming-zhou-qi-hou-chu-li-bean-shu-xing-zhu-ru/"/>
      <url>/2017/07/16/spring-sheng-ming-zhou-qi-hou-chu-li-bean-shu-xing-zhu-ru/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-15-生命周期（后处理Bean）、属性注入"><a href="#2017-07-15-生命周期（后处理Bean）、属性注入" class="headerlink" title="2017-07-15 生命周期（后处理Bean）、属性注入"></a><center>2017-07-15 生命周期（后处理Bean）、属性注入</center></h2><p>spring的生命周期总共11个步骤</p><p>！<a href="/images/20170715/1.png"></a></p><p>！<a href="/images/20170715/2.png"></a></p><p>！<a href="/images/20170715/3.png"></a></p><hr><ol><li><p>生命周期</p><pre><code> 1.1    初始化和销毁 目标方法执行前后执行后，将进行初始化或销毁。 &lt;bean id="" class="" init-method="初始化方法名称"  destroy-method="销毁的方法名称"&gt; 1.1.1    目标类 public class UserServiceImpl implements UserService {     @Override     public void addUser() {         System.out.println("e_lifecycle add user");     }     public void myInit(){         System.out.println("初始化");     }     public void myDestroy(){         System.out.println("销毁");     } } 1.1.2    spring配置 &lt;!--           init-method 用于配置初始化方法,准备数据等         destroy-method 用于配置销毁方法,清理资源等     --&gt;     &lt;bean id="userServiceId" class="com.itheima.e_lifecycle.UserServiceImpl"          init-method="myInit" destroy-method="myDestroy" &gt;&lt;/bean&gt;</code></pre></li></ol><pre><code>    1.1.3    测试    @Test        public void demo02() throws Exception{            //spring 工厂            String xmlPath = "com/itheima/e_lifecycle/beans.xml";            ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(xmlPath);            UserService userService = (UserService) applicationContext.getBean("userServiceId");            userService.addUser();            //要求：1.容器必须close，销毁方法执行; 2.必须是单例的    //        applicationContext.getClass().getMethod("close").invoke(applicationContext);            // * 此方法接口中没有定义，实现类提供            applicationContext.close();        }</code></pre><hr><pre><code>    1.2     BeanPostProcessor 后处理Bean    spring 提供一种机制，只要实现此接口BeanPostProcessor，并将实现类提供给spring容器，    spring容器将自动执行，在初始化方法前执行before()，在初始化方法后执行after() 。 配置&lt;bean class=""&gt;    Factory hook(勾子) that allows for custom modification of new bean instances, e.g.     checking for marker interfaces or wrapping them with proxies.     spring提供工厂勾子，用于修改实例对象，可以生成代理对象，是AOP底层。    模拟    A a =new A();    a = B.before(a)            --&gt; 将a的实例对象传递给后处理bean，可以生成代理对象并返回。    a.init();    a = B.after(a);    a.addUser();        //生成代理对象，目的在目标方法前后执行（例如：开启事务、提交事务）    a.destroy()    1.2.1    编写实现类    public class MyBeanPostProcessor implements BeanPostProcessor {        @Override        public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {            System.out.println("前方法 ： " + beanName);            return bean;        }        @Override        public Object postProcessAfterInitialization(final Object bean, String beanName) throws BeansException {            System.out.println("后方法 ： " + beanName);            // bean 目标对象            // 生成 jdk 代理            return Proxy.newProxyInstance(                        MyBeanPostProcessor.class.getClassLoader(),                         bean.getClass().getInterfaces(),                         new InvocationHandler(){                            @Override                            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {                                System.out.println("------开启事务");                                //执行目标方法                                Object obj = method.invoke(bean, args);                                System.out.println("------提交事务");                                return obj;                            }});        }    }    1.2.2    配置    &lt;!-- 将后处理的实现类注册给spring --&gt;        &lt;bean class="com.itheima.e_lifecycle.MyBeanPostProcessor"&gt;&lt;/bean&gt;    问题1：后处理bean作用某一个目标类，还是所有目标类？        所有    问题2：如何只作用一个？        通过“参数2”beanName进行控制</code></pre><p><img src="/images/20170715/4.png"></p><hr><p>2  属性依赖注入</p><pre><code>*    依赖注入方式：手动装配 和 自动装配*    手动装配：一般进行配置信息都采用手动 重要&lt;br/&gt;    基于xml装配：构造方法、setter方法&lt;br/&gt;    基于注解装配：&lt;br/&gt;*    自动装配：struts和spring 整合可以自动装配  一般&lt;br/&gt;    byType：按类型装配 &lt;br/&gt;    byName：按名称装配&lt;br/&gt;    constructor构造装配，&lt;br/&gt;    auto： 不确定装配。&lt;br/&gt;</code></pre><p>2.1     构造方法</p><pre><code>    2.1.1    目标类    public class User {        private Integer uid;        private String username;        private Integer age;        public User(Integer uid, String username) {            super();            this.uid = uid;            this.username = username;        }        public User(String username, Integer age) {            super();            this.username = username;            this.age = age;        }    2.1.2    spring配置    &lt;!-- 构造方法注入         * &lt;constructor-arg&gt; 用于配置构造方法一个参数argument            name ：参数的名称            value：设置普通数据            ref：引用数据，一般是另一个bean id值            index ：参数的索引号，从0开始 。如果只有索引，匹配到了多个构造方法时，默认使用第一个。            type ：确定参数类型        例如：使用名称name            &lt;constructor-arg name="username" value="jack"&gt;&lt;/constructor-arg&gt;            &lt;constructor-arg name="age" value="18"&gt;&lt;/constructor-arg&gt;        例如2：【类型type 和  索引 index】            &lt;constructor-arg index="0" type="java.lang.String" value="1"&gt;&lt;/constructor-arg&gt;            &lt;constructor-arg index="1" type="java.lang.Integer" value="2"&gt;&lt;/constructor-arg&gt;    --&gt;    &lt;bean id="userId" class="com.itheima.f_xml.a_constructor.User" &gt;        &lt;constructor-arg index="0" type="java.lang.String" value="1"&gt;&lt;/constructor-arg&gt;        &lt;constructor-arg index="1" type="java.lang.Integer" value="2"&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;</code></pre><hr><p>2.2    setter方法</p><pre><code>&lt;!-- setter方法注入     * 普通数据         &lt;property name="" value="值"&gt;        等效        &lt;property name=""&gt;            &lt;value&gt;值    * 引用数据        &lt;property name="" ref="另一个bean"&gt;        等效        &lt;property name=""&gt;            &lt;ref bean="另一个bean"/&gt;--&gt;&lt;bean id="personId" class="com.itheima.f_xml.b_setter.Person"&gt;    &lt;property name="pname" value="张三"&gt;&lt;/property&gt;    &lt;property name="age"&gt;        &lt;value&gt;1234&lt;/value&gt;    &lt;/property&gt;    &lt;property name="homeAddr" ref="homeAddrId"&gt;&lt;/property&gt;    &lt;property name="companyAddr"&gt;        &lt;ref bean="companyAddrId"/&gt;    &lt;/property&gt;&lt;/bean&gt;&lt;bean id="homeAddrId" class="com.itheima.f_xml.b_setter.Address"&gt;    &lt;property name="addr" value="阜南"&gt;&lt;/property&gt;    &lt;property name="tel" value="911"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id="companyAddrId" class="com.itheima.f_xml.b_setter.Address"&gt;    &lt;property name="addr" value="北京八宝山"&gt;&lt;/property&gt;    &lt;property name="tel" value="120"&gt;&lt;/property&gt;&lt;/bean&gt;</code></pre><hr><p>2.3    P命令空间[了解]</p><pre><code>对“setter方法注入”进行简化，替换&lt;property name="属性名"&gt;，而是在&lt;bean p:属性名="普通值"  p:属性名-ref="引用值"&gt;p命名空间使用前提，必须添加命名空间&lt;bean id="personId" class="com.itheima.f_xml.c_p.Person"     p:pname="禹太璞" p:age="22"     p:homeAddr-ref="homeAddrId" p:companyAddr-ref="companyAddrId"&gt;&lt;/bean&gt;&lt;bean id="homeAddrId" class="com.itheima.f_xml.c_p.Address"    p:addr="DG" p:tel="东莞"&gt;&lt;/bean&gt;&lt;bean id="companyAddrId" class="com.itheima.f_xml.c_p.Address"    p:addr="DG" p:tel="岛国"&gt;&lt;/bean&gt;</code></pre><hr><p>2.4    SpEL[了解]</p><pre><code>对&lt;property&gt;进行统一编程，所有的内容都使用value&lt;property name="" value="#{表达式}"&gt;#{123}、#{'jack'} ： 数字、字符串#{beanId}    ：另一个bean引用#{beanId.propName}    ：操作数据#{beanId.toString()}    ：执行方法#{T(类).字段|方法}    ：静态方法或字段&lt;!--     &lt;property name="cname" value="#{'jack'}"&gt;&lt;/property&gt;    &lt;property name="cname" value="#{customerId.cname.toUpperCase()}"&gt;&lt;/property&gt;        通过另一个bean，获得属性，调用的方法    &lt;property name="cname" value="#{customerId.cname?.toUpperCase()}"&gt;&lt;/property&gt;        ?.  如果对象不为null，将调用方法--&gt;&lt;bean id="customerId" class="com.itheima.f_xml.d_spel.Customer" &gt;    &lt;property name="cname" value="#{customerId.cname?.toUpperCase()}"&gt;&lt;/property&gt;    &lt;property name="pi" value="#{T(java.lang.Math).PI}"&gt;&lt;/property&gt;&lt;/bean&gt;阅读：</code></pre><p><img src="/images/20170715/5.png"></p><p><img src="/images/20170715/4.png"></p><hr><p>2.5    集合注入</p><pre><code>&lt;!--         集合的注入都是给&lt;property&gt;添加子标签            数组：&lt;array&gt;            List：&lt;list&gt;            Set：&lt;set&gt;            Map：&lt;map&gt; ，map存放k/v 键值对，使用&lt;entry&gt;描述            Properties：&lt;props&gt;  &lt;prop key=""&gt;&lt;/prop&gt;  【】        普通数据：&lt;value&gt;        引用数据：&lt;ref&gt;    --&gt;    &lt;bean id="collDataId" class="com.itheima.f_xml.e_coll.CollData" &gt;        &lt;property name="arrayData"&gt;            &lt;array&gt;                &lt;value&gt;DS&lt;/value&gt;                &lt;value&gt;DZD&lt;/value&gt;                &lt;value&gt;屌丝&lt;/value&gt;                &lt;value&gt;屌中屌&lt;/value&gt;            &lt;/array&gt;        &lt;/property&gt;        &lt;property name="listData"&gt;            &lt;list&gt;                &lt;value&gt;张三&lt;/value&gt;                &lt;value&gt;李四&lt;/value&gt;                &lt;value&gt;王五&lt;/value&gt;                &lt;value&gt;赵六&lt;/value&gt;            &lt;/list&gt;        &lt;/property&gt;        &lt;property name="setData"&gt;            &lt;set&gt;                &lt;value&gt;张三&lt;/value&gt;                &lt;value&gt;李四&lt;/value&gt;                &lt;value&gt;王五&lt;/value&gt;            &lt;/set&gt;        &lt;/property&gt;        &lt;property name="mapData"&gt;            &lt;map&gt;                &lt;entry key="jack" value="杰克"&gt;&lt;/entry&gt;                &lt;entry&gt;                    &lt;key&gt;&lt;value&gt;rose&lt;/value&gt;&lt;/key&gt;                    &lt;value&gt;肉丝&lt;/value&gt;                &lt;/entry&gt;            &lt;/map&gt;        &lt;/property&gt;        &lt;property name="propsData"&gt;            &lt;props&gt;                &lt;prop key="高富帅"&gt;嫐&lt;/prop&gt;                &lt;prop key="白富美"&gt;嬲&lt;/prop&gt;                &lt;prop key="男屌丝"&gt;挊&lt;/prop&gt;            &lt;/props&gt;        &lt;/property&gt;    &lt;/bean&gt;</code></pre><p><img src="/images/20170715/7.png"></p><hr><p>3  装配Bean 基于注解</p><pre><code>    注解：就是一个类，使用@注解名称    开发中：使用注解 取代 xml配置文件。1. @Component取代&lt;bean class=""&gt;    @Component("id") 取代 &lt;bean id="" class=""&gt;2.web开发，提供3个@Component注解衍生注解（功能一样）取代&lt;bean class=""&gt;    @Repository ：dao层    @Service：service层    @Controller：web层3.依赖注入，给私有字段设置，也可以给setter方法设置    普通值：@Value("")    引用值：        方式1：按照【类型】注入            @Autowired        方式2：按照【名称】注入1            @Autowired            @Qualifier("名称")        方式3：按照【名称】注入2            @Resource("名称")4.生命周期    初始化：@PostConstruct    销毁：@PreDestroy5.作用域    @Scope("prototype") 多例&lt;beans xmlns="http://www.springframework.org/schema/beans"   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"   xmlns:context="http://www.springframework.org/schema/context"   xsi:schemaLocation="http://www.springframework.org/schema/beans                           http://www.springframework.org/schema/beans/spring-beans.xsd                          http://www.springframework.org/schema/context                           http://www.springframework.org/schema/context/spring-context.xsd"&gt;&lt;!-- 组件扫描，扫描含有注解的类 --&gt;&lt;context:component-scan base-package="com.itheima.g_annotation.a_ioc"&gt;&lt;/context:component-scan&gt;&lt;/beans&gt;    注解使用前提，添加命名空间，让spring扫描含有注解类</code></pre><p><img src="/images/20170715/6.png"></p><p><img src="/images/20170715/8.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 rmdir pwd</title>
      <link href="/2017/07/16/mei-tian-2-ge-linux-ming-ling-rmdir-pwd/"/>
      <url>/2017/07/16/mei-tian-2-ge-linux-ming-ling-rmdir-pwd/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-15-每天2个Linux命令-rmdir命令"><a href="#2017-07-15-每天2个Linux命令-rmdir命令" class="headerlink" title=" 2017-07-15 每天2个Linux命令 rmdir命令"></a><center> 2017-07-15 每天2个Linux命令 rmdir命令</center></h2><p>rmdir命令用来删除空目录。</p><p>利用rmdir命令可以从一个目录中删除一个或多个空的子目录。该命令从一个目录中删除一个或多个子目录，其中dirname表示目录名。如果dirname中没有指定路径，则删除当前目录下由dirname指定的目录；如dirname中包含路径，则删除指定位置的目录。删除目录时，必须具有对其父目录的写权限。</p><p>注意：子目录被删除之前应该是空目录。就是说，该目录中的所有文件必须用rm命令全部删除，另外，当前工作目录必须在被删除目录之上，不能是被删除目录本身，也不能是被删除目录的子目录。 虽然还可以用带有-r选项的rm命令递归删除一个目录中的所有文件和该目录本身，但是这样做存在很大的危险性。</p><hr><p>(1)用法：</p><pre><code>用法：rmdir [选项]... 目录...</code></pre><p>(2)功能：</p><pre><code>功能:删除指定的空目录</code></pre><p>(3)选项参数：</p><pre><code>  1) -p或--parents                                                     删除指定目录后，若该目录的上层目录已变成空目录，则将其一并删除  2) --ignore-fail-on-non-empty                                 此选项使rmdir命令忽略由于删除非空目录时导致的错误信息    3) -v或-verboes                                                      显示命令的详细执行过程  4) --help                                                                显示命令的帮助信息  5) --version                                                            显示命令的版本信息。</code></pre><p>(4)实例：</p><p>1)[root@localhost sunjimeng]# rmdir –ignore-fail-on-non-empty Documents<br>        与[root@localhost sunjimeng]# rmdir –ignore有一样的功能，  目录不为空时，既不提醒也不删除</p><pre><code>复制代码[root@localhost sunjimeng]# ls -l /home/sunjimeng/Documents总用量 0drwxrwxr-x. 2 sunjimeng sunjimeng  6 5月   1 02:49 mainDirdrwxrwxr-x. 2 sunjimeng sunjimeng  6 5月   1 02:52 secondDirdrwxrwxr-x. 8 sunjimeng sunjimeng 78 5月   1 03:01 thirdDir[root@localhost sunjimeng]# rmdir Documentsrmdir: 删除 "Documents" 失败: 目录非空[root@localhost sunjimeng]# rmdir --ignore-fail-on-non-empty Documents[root@localhost sunjimeng]# </code></pre><hr><p>2)[root@localhost sunjimeng]# rmdir ./Documents/thirdDir/te*   用rmdir删除指定路径的目录</p><pre><code>复制代码[root@localhost sunjimeng]# ls -l ./Documents/thirdDir总用量 0drwxrwxr-x. 2 sunjimeng sunjimeng 6 5月   1 02:57 test1drwxrwxr-x. 2 sunjimeng sunjimeng 6 5月   1 02:57 test2drwxrwxr-x. 2 sunjimeng sunjimeng 6 5月   1 02:57 test3drwxrwxr-x. 2 sunjimeng sunjimeng 6 5月   1 03:01 test4drwxrwxr-x. 2 sunjimeng sunjimeng 6 5月   1 03:01 test5drwxrwxr-x. 2 sunjimeng sunjimeng 6 5月   1 03:01 test6[root@localhost sunjimeng]# rmdir ./Documents/thirdDir/te*   //用通配符将所有te开头的全部删除[root@localhost sunjimeng]# ls -l ./Documents/thirdDir总用量 0</code></pre><hr><p>3)[root@localhost sunjimeng]# rmdir -p ./Documents/{mainDir,secondDir,thirdDir}  删除全部的3个子目录，若删除后父目录也为空则一并删除</p><pre><code>复制代码[root@localhost sunjimeng]# rmdir -p ./Documents/{mainDir,secondDir,thirdDir}rmdir: 删除目录 "./Documents" 失败: 目录非空                                //这里虽然出现提醒但依然被删除了rmdir: 删除目录 "./Documents" 失败: 目录非空rmdir: 删除目录 "." 失败: 无效的参数[root@localhost sunjimeng]# ll总用量 0drwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Desktopdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Downloadsdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Musicdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Picturesdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Publicdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Templatesdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Videos[root@localhost sunjimeng]# cd Documents                                 //这里可以验证bash: cd: Documents: 没有那个文件或目录</code></pre><hr><p>4)[root@localhost sunjimeng]# rmdir –verbose -p ./Documents/firstDir/test1   递归的删除目录，并输出过程信息(–verbose这里注意是两个-)</p><pre><code>复制代码[root@localhost sunjimeng]# ls -l ./Documents总用量 0drwxr-xr-x. 3 root root 18 5月   2 22:26 firstDir[root@localhost sunjimeng]# ls -l ./Documents/firstDir总用量 0drwxr-xr-x. 2 root root 6 5月   2 22:26 test1[root@localhost sunjimeng]# rmdir --verbose -p ./Documents/firstDir/test1rmdir: 正在删除目录 "./Documents/firstDir/test1"rmdir: 正在删除目录 "./Documents/firstDir"rmdir: 正在删除目录 "./Documents"rmdir: 正在删除目录 "."rmdir: 删除目录 "." 失败: 无效的参数[root@localhost sunjimeng]# ll总用量 0drwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Desktopdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Downloadsdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Musicdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Picturesdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Publicdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Templatesdrwxr-xr-x. 2 sunjimeng sunjimeng 6 5月   1 01:23 Videos[root@localhost sunjimeng]# </code></pre><hr><p> 5)[root@localhost sunjimeng]# rmdir –help</p><pre><code>复制代码[root@localhost sunjimeng]# rmdir --help用法：rmdir [选项]... 目录...删除指定的空目录。      --ignore-fail-on-non-empty            忽略仅由目录非空产生的所有错误  -p, --parents   remove DIRECTORY and its ancestors; e.g., 'rmdir -p a/b/c' is                    similar to 'rmdir a/b/c a/b a'  -v, --verbose   output a diagnostic for every directory processed      --help        显示此帮助信息并退出      --version        显示版本信息并退出GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告rmdir 的翻译错误要获取完整文档，请运行：info coreutils 'rmdir invocation'</code></pre><p>6)[root@localhost sunjimeng]# rmdir –version</p><pre><code>复制代码[root@localhost sunjimeng]# rmdir --versionrmdir (GNU coreutils) 8.22Copyright (C) 2013 Free Software Foundation, Inc.许可证：GPLv3+：GNU 通用公共许可证第3 版或更新版本&lt;http://gnu.org/licenses/gpl.html&gt;。本软件是自由软件：您可以自由修改和重新发布它。在法律范围内没有其他保证。由David MacKenzie 编写。</code></pre><h2 id="2017-07-15-每天2个Linux命令-pwd命令"><a href="#2017-07-15-每天2个Linux命令-pwd命令" class="headerlink" title=" 2017-07-15 每天2个Linux命令 pwd命令"></a><center> 2017-07-15 每天2个Linux命令 pwd命令</center></h2><p>pwd命令以绝对路径的方式显示用户当前工作目录。命令将当前目录的全路径名称（从根目录）写入标准输出。全部目录使用/分隔。第一个/表示根目录，最后一个目录是当前目录。</p><hr><p>(1)用法介绍：</p><pre><code>pwd[选项] </code></pre><p>(2)选项参数：</p><pre><code>  一般情况下不带任何参数  1) -L, --logical                                                显示当前目录  2) -P, --physical                                             显示当前目录的实际物理地址  3) --help                                                        帮助  4) --version                                                    版本</code></pre><hr><p>(3)功能:</p><pre><code>执行pwd命令可立刻得知您目前所在的工作目录的绝对路径名称。</code></pre><p>(4)运行实例:</p><p>1)[root@localhost Documents]# pwd             查看默认工作目录的完整路径，查看是否成功到达指定文件夹</p><pre><code>[root@localhost sunjimeng]# mkdir Documents[root@localhost sunjimeng]# cd ../../[root@localhost /]# cd /home/sunjimeng/Documents[root@localhost Documents]# pwd/home/sunjimeng/Documents[root@localhost Documents]# </code></pre><hr><p>2)[sunjimeng@localhost init.d]$ pwd -P        目录连接链接时，pwd -P  显示出实际物理路径，pwd显示连接路径</p><pre><code>复制代码[sunjimeng@localhost mail]$ cd /[sunjimeng@localhost /]$ cd etc[sunjimeng@localhost etc]$ cd init.d[sunjimeng@localhost init.d]$ pwd/etc/init.d[sunjimeng@localhost init.d]$ pwd -P/etc/rc.d/init.d[sunjimeng@localhost init.d]$ </code></pre><hr><p>3)[sunjimeng@localhost init.d]$ pwd -L 与pwd命令具有一样的功能               显示当前目录的连接路径</p><pre><code>[sunjimeng@localhost /]$ cd etc/init.d[sunjimeng@localhost init.d]$ pwd/etc/init.d[sunjimeng@localhost init.d]$ pwd -L/etc/init.d[sunjimeng@localhost init.d]$</code></pre><hr><p>4)[sunjimeng@localhost /]$ man pwd</p><pre><code>复制代码PWD(1)                           User Commands                          PWD(1)NAME       pwd - print name of current/working directorySYNOPSIS       pwd [OPTION]...DESCRIPTION       Print the full filename of the current working directory.       -L, --logical              use PWD from environment, even if it contains symlinks       -P, --physical              avoid all symlinks       --help display this help and exit       --version              output version information and exit复制代码</code></pre><hr><p>5)/bin/pwd同pwd的用法一样：</p><pre><code>  /bin/pwd [选项] 选项： -L 目录连接链接时，输出连接路径 -P 输出物理路径复制代码[root@localhost init.d]# cd /[root@localhost /]# cd etc/init.d[root@localhost init.d]# pwd/etc/init.d[root@localhost init.d]# pwd -P/etc/rc.d/init.d[root@localhost init.d]# pwd -L/etc/init.d[root@localhost init.d]# /bin/pwd/etc/rc.d/init.d[root@localhost init.d]# /bin/pwd -L/etc/init.d[root@localhost init.d]# /bin/pwd -P/etc/rc.d/init.d如果cd命令是逐级进入的化，区分连接路径和实际路径就没有意义了：复制代码[root@localhost init.d]# cd /                      //无论什么命令，输出的工作路径都是/etc/rc.d/unit.d[root@localhost /]# cd etc/rc.d/init.d[root@localhost init.d]# pwd/etc/rc.d/init.d[root@localhost init.d]# /bin/pwd/etc/rc.d/init.d[root@localhost init.d]# pwd -L/etc/rc.d/init.d[root@localhost init.d]# pwd -P/etc/rc.d/init.d[root@localhost init.d]# /bin/pwd -L/etc/rc.d/init.d[root@localhost init.d]# /bin/pwd -P/etc/rc.d/init.d</code></pre><hr><p>6)/bin/pwd与pwd命令的区别:(当前目录被删除了，而pwd命令仍然显示那个目录，而/bin/pwd则不会)</p><pre><code>复制代码[root@localhost init.d]# cd /[root@localhost /]# cd /home/sunjimeng/Documents[root@localhost Documents]# mkdir removed[root@localhost Documents]# ls -l总用量 0drwxr-xr-x. 2 root root 6 5月   4 07:29 removed[root@localhost Documents]# cd removed[root@localhost removed]# rmdir ../removed -rf  //这里犯了一个错误，rmdir没有rf选项参数，rm ../removed -rf等价于 rmdir ../removedrmdir：无效选项 -- rTry 'rmdir --help' for more information.[root@localhost removed]# rmdir ../removed[root@localhost removed]# pwd/home/sunjimeng/Documents/removed[root@localhost removed]# /bin/pwd/bin/pwd: 在匹配的inode ".." 上找不到目录入口      //这里的结果表明了他们的区别[root@localhost removed]# cd ../[root@localhost Documents]# ll总用量 0</code></pre><p>(5)其它</p><pre><code>软链接与硬链接的区别（讲解）:Linux 软连接与硬连接对于一个文件来说，有唯一的索引接点与之对应，而对于一个索引接点号，却可以有多个文件名与之对应。因此，在磁盘上的同一个文件可以通过不同的路径去访问该文件。注意在Linux下是一切皆文件的啊，文件夹、新加的硬盘 ...都可以看着文件来处理的啊。连接有软连接和硬连接(hard link)之分的，软连接(symbolic link)又叫符号连接。符号连接相当于Windows下的快捷方式</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 touch rm</title>
      <link href="/2017/07/16/mei-tian-2-ge-linux-ming-ling-touch-rm/"/>
      <url>/2017/07/16/mei-tian-2-ge-linux-ming-ling-touch-rm/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-15-每天2个Linux命令-touch命令"><a href="#2017-07-15-每天2个Linux命令-touch命令" class="headerlink" title=" 2017-07-15 每天2个Linux命令 touch命令"></a><center> 2017-07-15 每天2个Linux命令 touch命令</center></h2><p>touch命令有两个功能：一是用于把已存在文件的时间标签更新为系统当前的时间（默认方式），它们的数据将原封不动地保留下来；二是用来创建新的空文件。</p><p>(1)用法</p><pre><code>  用法：touch [选项]... 文件...</code></pre><p>(2)功能</p><pre><code>  1）将每个文件的访问时间和修改时间改为当前时间；  2）不存在的文件将会被创建为空文件，除非使用-c 或-h 选项；</code></pre><p>(3)选项参数</p><pre><code>  1) -f, --force 忽略不存在的文件，从不给出提示   2) -i, --interactive 进行交互式删除   3) -r, -R, --recursive 指示rm将参数中列出的全部目录和子目录均递归地删除  4) -v, --verbose 详细显示进行的步骤   5) --help 显示此帮助信息并退出   6) --version 输出版本信息并退出  7) -a 只更改访问时间  8) -d, --date=字符串 使用指定字符串表示时间替代当前时间  9) -t STAMP 使用[[CC]YY]MMDDhhmm[.ss] 格式的时间替代当前时间</code></pre><p>(4)实例： </p><pre><code>  1)[root@localhost /]# touch /home/sunjimeng/Document/touch_test_file         在指定目下创建文件，如果没有指定，则默认在当前文件夹下（若文件已经存在，则可以看作重新更改文件档案时间）        复制代码[root@localhost /]# ls -l /home/sunjimeng/Document总用量 0drwxrwxr-x. 3 sunjimeng sunjimeng 17 5月   1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 5月   1 03:21 Father[root@localhost /]# touch /home/sunjimeng/Document/touch_test_file[root@localhost /]# cd home/sunjimeng/Document[root@localhost Document]# ll总用量 0drwxrwxr-x. 3 sunjimeng sunjimeng 17 5月   1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 5月   1 03:21 Father-rw-r--r--. 1 root      root       0 5月   1 18:30 touch_test_file    //第一次创建的时间[root@localhost Document]# [root@localhost Document]# touch touch_test_file [root@localhost Document]# ll 总用量 0 drwxrwxr-x. 3 sunjimeng sunjimeng 17 5月 1 03:13 bin drwxrwxr-x. 3 sunjimeng sunjimeng 18 5月 1 03:21 Father -rw-r--r--. 1 root root 0 5月 1 18:35 touch_test_file                 //第二次更改文件的时间为当前时间，若文件中存有内容，则内容不变</code></pre><hr><pre><code>2)[root@localhost Document]# touch -t 06061806 touch_test_file    不创建文件，只是更改文档时间（这里加不加-c操作是一样的）[root@localhost Document]# touch -t 06061806 touch_test_file[root@localhost Document]# ll总用量 0drwxrwxr-x. 3 sunjimeng sunjimeng 17 5月   1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 5月   1 03:21 Father-rw-r--r--. 1 root      root       0 6月   6 2016 touch_test_file</code></pre><hr><pre><code>3)[root@localhost Document]# touch touch_test_file1 touch_test_file2    将touch_test_file2的时间更改为与touch_test_file1的时间相同复制代码[root@localhost Document]# touch touch_test_file2[root@localhost Document]# ll总用量 0drwxrwxr-x. 3 sunjimeng sunjimeng 17 5月   1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 5月   1 03:21 Father-rw-r--r--. 1 root      root       0 6月   6 2016 touch_test_file      //两个文件时间不相同-rw-r--r--. 1 root      root       0 5月   1 18:42 touch_test_file2    [root@localhost Document]# touch -r touch_test_file touch_test_file2[root@localhost Document]# ll总用量 0drwxrwxr-x. 3 sunjimeng sunjimeng 17 5月   1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 5月   1 03:21 Father-rw-r--r--. 1 root      root       0 6月   6 2016 touch_test_file     //两个文件时间相同-rw-r--r--. 1 root      root       0 6月   6 2016 touch_test_file2</code></pre><hr><pre><code>4)[root@localhost Document]# touch -d "10 days ago" touch_test_file2 将当前指定文件时间更改为相对现在的过去或未来时间复制代码[root@localhost Document]# touch -d "10 days ago" touch_test_file2[root@localhost Document]# ll总用量 0drwxrwxr-x. 3 sunjimeng sunjimeng 17 5月   1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 5月   1 03:21 Father-rw-r--r--. 1 root      root       0 6月   6 2016 touch_test_file-rw-r--r--. 1 root      root       0 4月  21 18:48 touch_test_file2           //不是6月6号的10天前，而是当前时间的10天前</code></pre><hr><pre><code> 5)[root@localhost Document]# touch --help 与touch --version复制代码[root@localhost Document]# touch --help用法：touch [选项]... 文件...Update the access and modification times of each FILE to the current time.A FILE argument that does not exist is created empty, unless -c or -his supplied.A FILE argument string of - is handled specially and causes touch tochange the times of the file associated with standard output.Mandatory arguments to long options are mandatory for short options too.  -a            只更改访问时间  -c, --no-create    不创建任何文件  -d, --date=字符串    使用指定字符串表示时间而非当前时间  -f            (忽略)  -h, --no-dereference        会影响符号链接本身，而非符号链接所指示的目的地                (当系统支持更改符号链接的所有者时，此选项才有用)  -m            只更改修改时间  -r, --reference=FILE   use this file's times instead of current time  -t STAMP               use [[CC]YY]MMDDhhmm[.ss] instead of current time      --time=WORD        change the specified time:                           WORD is access, atime, or use: equivalent to -a                           WORD is modify or mtime: equivalent to -m      --help        显示此帮助信息并退出      --version        显示版本信息并退出请注意，-d 和-t 选项可接受不同的时间/日期格式。GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告touch 的翻译错误要获取完整文档，请运行：info coreutils 'touch invocation'[root@localhost Document]# touch --versiontouch (GNU coreutils) 8.22Copyright (C) 2013 Free Software Foundation, Inc.许可证：GPLv3+：GNU 通用公共许可证第3 版或更新版本&lt;http://gnu.org/licenses/gpl.html&gt;。本软件是自由软件：您可以自由修改和重新发布它。在法律范围内没有其他保证。由Paul Rubin、Arnold Robbins、Jim Kingdon、David MacKenzie 和 Randy Smith 编写。复制代码</code></pre><hr><pre><code>(5)其他说明：-t  time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time规定为如下形式的十进制数:         [[CC]YY]MMDDhhmm[.SS]        这里，CC为年数中的前两位，即”世纪数”；YY为年数的后两位，即某世纪中的年数．如果不给出CC的值，则touch     将把年数CCYY限定在1969--2068之内．MM为月数，DD为天将把年数CCYY限定在1969--2068之内．MM为月数，D   D为天数，hh 为小时数(几点)，mm为分钟数，SS为秒数．此处秒的设定范围是0--61，这样可以处理闰秒．   这些数字组成的时间是环境变量TZ指定的时区中的一个时 间．由于系统的限制，早于1970年1月1日的时间是错误的。</code></pre><hr><h2 id="2017-07-15-每天2个Linux命令-rm命令"><a href="#2017-07-15-每天2个Linux命令-rm命令" class="headerlink" title=" 2017-07-15 每天2个Linux命令 rm命令"></a><center> 2017-07-15 每天2个Linux命令 rm命令</center></h2><p>rm命令可以删除一个目录中的一个或多个文件或目录，也可以将某个目录及其下属的所有文件及其子目录均删除掉。对于链接文件，只是删除整个链接文件，而原有文件保持不变。</p><p>注意：使用rm命令要格外小心。因为一旦删除了一个文件，就无法再恢复它。所以，在删除文件之前，最好再看一下文件的内容，确定是否真要删除。rm命令可以用-i选项，这个选项在使用文件扩展名字符删除多个文件时特别有用。使用这个选项，系统会要求你逐一确定是否要删除。这时，必须输入y并按Enter键，才能删除文件。如果仅按Enter键或其他字符，文件不会被删除。 </p><hr><p>(1)用法：</p><pre><code>   用法：rm [选项]... 文件...</code></pre><hr><p>(2)功能：</p><pre><code>   删除 (unlink) 文件。</code></pre><hr><p>(3)选项参数：</p><pre><code>   1) -f, --force           强制删除。忽略不存在的文件，不提示确认  2) -i                      在删除前需要确认  3) -I                   在删除超过三个文件或者递归删除前要求确认。此选项比-i 提示内容更少，但同样可以阻止大多数错误发生  4) --interactive[=WHEN]  根据指定的WHEN 进行确认提示：never，once (-I)， 或者always (-i)。如果此参数不加WHEN 则总是提示  5) --one-file-system      递归删除一个层级时，跳过所有不符合命令行参 数的文件系统上的文件  6) --no-preserve-roo         不特殊对待"/" --preserve-root 不允许删除"/"(默认)  7) -r, -R, --recursive      递归删除目录及其内容  8) -v, --verbose    详细显示进行的步骤 --help 显示此帮助信息并退出 --version 显示版本信息并退出  9) -d           直接把欲删除的目录的硬连接数据删除成0，删除该目录</code></pre><hr><p>(4)实例：</p><p>1)[root@localhost Document]# rm -i touch_test_file               等同于rm touch_test_file，交互式删除，y键确认删除，n键不删除</p><pre><code>[root@localhost Document]# rm -i touch_test_filerm：是否删除普通空文件 "touch_test_file"？n[root@localhost Document]# rm -i {touch_test_file,touch_test_file2}rm：是否删除普通空文件 "touch_test_file"？yrm：是否删除普通空文件 "touch_test_file2"？y</code></pre><hr><p>2)[root@localhost Document]# rm -f test   强制删除文件不做交互提醒</p><pre><code>复制代码[root@localhost Document]# ll总用量 0-rw-r--r--. 1 root      root       0 5月   1 18:49 10 days agodrwxrwxr-x. 3 sunjimeng sunjimeng 17 5月   1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 5月   1 03:21 Father-rw-r--r--. 1 root      root       0 5月   1 18:58 test[root@localhost Document]# rm -f test[root@localhost Document]# ll总用量 0-rw-r--r--. 1 root      root       0 5月   1 18:49 10 days agodrwxrwxr-x. 3 sunjimeng sunjimeng 17 5月   1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 5月   1 03:21 Father</code></pre><hr><p>3)[root@localhost Document]# rm -r *                  删除当前目录下除隐含文件外的所有文件和子目录</p><pre><code>复制代码[root@localhost Document]# ll总用量 0-rw-r--r--. 1 root      root       0 5月   1 18:49 10 days agodrwxrwxr-x. 3 sunjimeng sunjimeng 17 5月   1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 5月   1 03:21 Father[root@localhost Document]# rm -r *rm：是否删除普通空文件 "10 days ago"？yrm：是否进入目录"bin"? yrm：是否删除目录 "bin/os_1"？yrm：是否删除目录 "bin"？yrm：是否进入目录"Father"? yrm：是否删除目录 "Father/Child"？yrm：是否删除目录 "Father"？y[root@localhost Document]# ll总用量 0</code></pre><hr><p>4)[root@localhost Document]# rm -v test1    显示删除的详细步骤</p><pre><code>复制代码[root@localhost Document]# touch {test1,test2}[root@localhost Document]# rm -v test1rm：是否删除普通空文件 "test1"？y已删除"test1"[root@localhost Document]# ll总用量 0-rw-r--r--. 1 root root 0 5月   1 19:24 test2[root@localhost Document]# </code></pre><hr><p>5)[root@localhost Document]# rm f* 与[root@localhost Document]# rm ./t*  删除以某个或某些字符结尾或开头的文件</p><pre><code>复制代码[root@localhost Document]# touch {file1,file2,test1,test2}[root@localhost Document]# ll总用量 0-rw-r--r--. 1 root root 0 5月   1 19:28 file1-rw-r--r--. 1 root root 0 5月   1 19:28 file2-rw-r--r--. 1 root root 0 5月   1 19:28 test1-rw-r--r--. 1 root root 0 5月   1 19:28 test2[root@localhost Document]# rm  f*rm：是否删除普通空文件 "file1"？yrm：是否删除普通空文件 "file2"？y[root@localhost Document]# rm ./t*rm：是否删除普通空文件 "./test1"？yrm：是否删除普通空文件 "./test2"？y[root@localhost Document]# ll总用量 0</code></pre><hr><p>6)[root@localhost Document]# touch – -test与[root@localhost Document]# rm – -test      删除以-字符开头的文件，另外ls – -test可以列出此-开头的文件</p><pre><code>复制代码[root@localhost Document]# touch -testtouch: 日期格式"est" 无效[root@localhost Document]# touch -- -test[root@localhost Document]# ll总用量 0-rw-r--r--. 1 root root 0 5月   1 19:37 -test[root@localhost Document]# rm -testrm：无效选项 -- tTry 'rm ./-test' to remove the file "-test".Try 'rm --help' for more information.[root@localhost Document]# rm -- -testrm：是否删除普通空文件 "-test"？y</code></pre><hr><p>7)myrm(){ D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv “$@” $D &amp;&amp; echo “moved to $D ok”; }  自定义回收站功能</p><pre><code>复制代码[root@localhost test]# myrm(){ D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D;     mv "$@" $D &amp;&amp; echo "moved to $D ok"; }[root@localhost test]# alias rm='myrm'[root@localhost test]# touch 1.log 2.log 3.log[root@localhost test]# ll总计 16-rw-r--r-- 1 root root    0 10-26 15:08 1.log-rw-r--r-- 1 root root    0 10-26 15:08 2.log-rw-r--r-- 1 root root    0 10-26 15:08 3.logdrwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# rm [123].logmoved to /tmp/20121026150901 ok[root@localhost test]# ll总计 16drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# ls /tmp/20121026150901/1.log  2.log  3.log[root@localhost test]#  复制代码 说明：   上面的操作过程模拟了回收站的效果，即删除文件的时候只是把文件放到一个临时目录中，这样在需要的时候还可以恢复过来。</code></pre><hr><p>8)</p><pre><code>复制代码[root@localhost Document]# rm --help用法：rm [选项]... 文件...Remove (unlink) the FILE(s).  -f, --force           ignore nonexistent files and arguments, never prompt  -i                    prompt before every removal  -I                    prompt once before removing more than three files, or                          when removing recursively; less intrusive than -i,                          while still giving protection against most mistakes      --interactive[=WHEN]  prompt according to WHEN: never, once (-I), or                          always (-i); without WHEN, prompt always      --one-file-system        递归删除一个层级时，跳过所有不符合命令行参                数的文件系统上的文件      --no-preserve-root  do not treat '/' specially      --preserve-root   do not remove '/' (default)  -r, -R, --recursive   remove directories and their contents recursively  -d, --dir             remove empty directories  -v, --verbose         explain what is being done      --help        显示此帮助信息并退出      --version        显示版本信息并退出默认时，rm 不会删除目录。使用--recursive(-r 或-R)选项可删除每个给定的目录，以及其下所有的内容。To remove a file whose name starts with a '-', for example '-foo',use one of these commands:  rm -- -foo  rm ./-foo请注意，如果使用rm 来删除文件，通常仍可以将该文件恢复原状。如果想保证该文件的内容无法还原，请考虑使用shred。GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;请向&lt;http://translationproject.org/team/zh_CN.html&gt; 报告rm 的翻译错误要获取完整文档，请运行：info coreutils 'rm invocation'</code></pre><hr><p>9）[root@localhost Document]# rm –version 版本信息</p><pre><code>复制代码[root@localhost Document]# rm --versionrm (GNU coreutils) 8.22Copyright (C) 2013 Free Software Foundation, Inc.许可证：GPLv3+：GNU 通用公共许可证第3 版或更新版本&lt;http://gnu.org/licenses/gpl.html&gt;。本软件是自由软件：您可以自由修改和重新发布它。在法律范围内没有其他保证。由Paul Rubin、David MacKenzie、Richard M. Stallman 和Jim Meyering 编写。</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring核心API、装配Bean 基于XML、Bean种类</title>
      <link href="/2017/07/14/spring-he-xin-api-zhuang-pei-bean-ji-yu-xml-bean-chong-lei/"/>
      <url>/2017/07/14/spring-he-xin-api-zhuang-pei-bean-ji-yu-xml-bean-chong-lei/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-0714-核心API、装配Bean-基于XML、Bean种类"><a href="#2017-0714-核心API、装配Bean-基于XML、Bean种类" class="headerlink" title="2017.0714 核心API、装配Bean 基于XML、Bean种类"></a><center>2017.0714 核心API、装配Bean 基于XML、Bean种类</center></h2><p><img src="/images/20170714/4.png"></p><ul><li><p>BeanFactory ：这是一个工厂，用于生成任意bean。<br>采取延迟加载，第一次getBean时才会初始化Bean</p></li><li><p>ApplicationContext：是BeanFactory的子接口，功能更强大。（国际化处理、事件传递、Bean自动装配、各种不同应用层的Context实    现）。当配置文件被加载，就进行对象实例化。</p><p>ClassPathXmlApplicationContext 用于加载classpath（类路径、src）下的xml<br><br>   加载xml运行时位置 –&gt; /WEB-INF/classes/…xml<br><br>FileSystemXmlApplicationContext 用于加载指定盘符下的xml<br><br>   加载xml运行时位置 –&gt; /WEB-INF/…xml<br></p><pre><code>   通过java web ServletContext.getRealPath() 获得具体盘符</code></pre></li></ul><pre><code>    @Test    public void demo02(){        //使用BeanFactory  --第一次条用getBean实例化        String xmlPath = "com/itheima/b_di/beans.xml";        BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(xmlPath));        BookService bookService = (BookService) beanFactory.getBean("bookServiceId");        bookService.addBook();    }</code></pre><p>applicationContex一加载、配置文件就实例化</p><hr><ol><li>实例化方式</li></ol><pre><code>**3种bean实例化方式：默认构造、静态工厂、实例工厂**</code></pre><hr><pre><code>1.1    默认构造&lt;bean id="" class=""&gt;  必须提供默认构造</code></pre><hr><pre><code>1.2    静态工厂    常用与spring整合其他框架（工具）    静态工厂：用于生成实例对象，所有的方法必须是static    &lt;bean id=""  class="工厂全限定类名 也是包名+类名"  factory-method="静态方法"&gt;</code></pre><hr><pre><code>1.2.1    工厂public class MyBeanFactory {    /**     * 创建实例     * @return     */    public static UserService createService(){        return new UserServiceImpl();    }}</code></pre><hr><pre><code>1.2.2    spring配置&lt;!-- 将静态工厂创建的实例交予spring     class 确定静态工厂全限定类名    factory-method 确定静态方法名--&gt;&lt;bean id="userServiceId" class="com.itheima.c_inject.b_static_factory.MyBeanFactory" factory-method="createService"&gt;&lt;/bean&gt;</code></pre><p><img src="/images/20170714/5.png"></p><hr><pre><code>1.3    实例工厂    实例工厂：必须先有工厂实例对象，通过实例对象创建对象。提供所有的方法都是“非静态”的</code></pre><hr><pre><code>1.3.1    工厂    /**     * 实例工厂,所有方法非静态     *     */    public class MyBeanFactory {        /**         * 创建实例         * @return         */        public UserService createService(){            return new UserServiceImpl();        }    }</code></pre><hr><pre><code>1.3.2    spring配置&lt;!-- 创建工厂实例 --&gt;&lt;bean id="myBeanFactoryId" class="com.itheima.c_inject.c_factory.MyBeanFactory"&gt;&lt;/bean&gt;&lt;!-- 获得userservice     * factory-bean 确定工厂实例    * factory-method 确定普通方法--&gt;&lt;bean id="userServiceId" factory-bean="myBeanFactoryId" factory-method="createService"&gt;&lt;/bean&gt;</code></pre><p><img src="/images/20170714/6.png"></p><ol start="2"><li><p>Bean种类</p><ul><li><p>普通bean：之前操作的都是普通bean。<bean id="" class="A"> ，spring直接创建A实例，并返回</bean></p></li><li><p>FactoryBean：是一个特殊的bean，具有工厂生成对象能力，只能生成特定的对象。<br><br>  bean必须使用 FactoryBean接口，此接口提供方法 getObject() 用于获得特定bean。<br><br>  <bean id="" class="FB"> 先创建FB实例，使用调用getObject()方法，并返回方法的返回值<br></bean></p><pre><code>  FB fb = new FB();&lt;br/&gt;  return fb.getObject();&lt;br/&gt;</code></pre></li><li><p>BeanFactory 和 FactoryBean 对比？<br><br>  BeanFactory：工厂，用于生成任意bean。<br><br>  FactoryBean：特殊bean，用于生成另一个特定的bean。例如：ProxyFactoryBean ，此工厂bean用于生产代理。<br><br>  <bean id="" class="....ProxyFactoryBean"> 获得代理对象实例。AOP使用<br></bean></p></li></ul></li><li><p>作用域<br><br> 作用域：用于确定spring创建bean实例个数</p></li></ol><p><img src="/images/20170714/7.png"></p><pre><code>    取值：    singleton 单例，默认值。    prototype 多例，每执行一次getBean将获得一个实例。例如：struts整合spring，配置action多例。    配置信息    &lt;bean id="" class=""  scope=""&gt;    &lt;bean id="userServiceId" class="com.itheima.d_scope.UserServiceImpl"  scope="prototype" &gt;&lt;/bean&gt;</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
            <tag> bean </tag>
            
            <tag> xml </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安装Python、Python解释器</title>
      <link href="/2017/07/14/an-zhuang-python-python-jie-shi-qi/"/>
      <url>/2017/07/14/an-zhuang-python-python-jie-shi-qi/</url>
      
        <content type="html"><![CDATA[<h2 id="20170714-安装Python、Python解释器"><a href="#20170714-安装Python、Python解释器" class="headerlink" title="20170714 安装Python、Python解释器"></a><center>20170714 安装Python、Python解释器</center></h2><p>因为Python是跨平台的，它可以运行在Windows、Mac和各种Linux/Unix系统上。在Windows上写Python程序，放到Linux上也是能够运行的。</p><p>要开始学习Python编程，首先就得把Python安装到你的电脑里。安装后，你会得到Python解释器（就是负责运行Python程序的），一个命令行交互环境，还有一个简单的集成开发环境。</p><p>安装Python 3.5</p><p>目前，Python有两个版本，一个是2.x版，一个是3.x版，这两个版本是不兼容的。由于3.x版越来越普及，我们的教程将以最新的Python 3.5版本为基础。请确保你的电脑上安装的Python版本是最新的3.5.x，这样，你才能无痛学习这个教程。</p><hr><ul><li><p>在Mac上安装Python</p><pre><code>  如果你正在使用Mac，系统是OS X 10.8~10.10，那么系统自带的Python版本是2.7。要安装最新的Python 3.5，有两个方法：  方法一：从Python官网下载Python 3.5的安装程序（网速慢的同学请移步国内镜像），双击运行并安装；  方法二：如果安装了Homebrew，直接通过命令brew install python3安装即可。</code></pre></li><li><p>在Linux上安装Python</p><pre><code>  如果你正在使用Linux，那我可以假定你有Linux系统管理经验，自行安装Python 3应该没有问题，否则，请换回Windows系统。  对于大量的目前仍在使用Windows的同学，如果短期内没有打算换Mac，就可以继续阅读以下内容。</code></pre></li><li><p>在Windows上安装Python</p><pre><code>  首先，根据你的Windows版本（64位还是32位）从Python的官方网站下载Python 3.5  对应的64位安装程序或32位安装程序（网速慢的同学请移步国内镜像），然后，运行下载的EXE安装包：</code></pre><p>  <img src="/images/20170714/2.png"></p><pre><code>  特别要注意勾上Add Python 3.5 to PATH，然后点“Install Now”即可完成安装。</code></pre></li><li><p>运行Python</p><pre><code>  安装成功后，打开命令提示符窗口，敲入python后，会出现两种情况：  情况一：</code></pre><p><img src="/images/20170714/1.png"></p><pre><code>  看到上面的画面，就说明Python安装成功！  你看到提示符&gt;&gt;&gt;就表示我们已经在Python交互式环境中了，可以输入任何Python代码，  回车后会立刻得到执行结果。现在，输入exit()并回车，就可以退出Python交互式环境（直接关掉命令行窗口也可以）。  情况二：得到一个错误：  ‘python’ 不是内部或外部命令，也不是可运行的程序或批处理文件。</code></pre><p>  <img src="/images/20170714/3.png"></p><pre><code>  这是因为Windows会根据一个Path的环境变量设定的路径去查找python.exe，如果没找到，就会报错  。如果在安装时漏掉了勾选Add Python 3.5 to PATH，那就要手动把python.exe所在的路径添加到Path中。  如果你不知道怎么修改环境变量，建议把Python安装程序重新运行一遍，务必记得勾上Add Python 3.5 to PATH。</code></pre></li><li><p>小结</p><pre><code>  学会如何把Python安装到计算机中，并且熟练打开和退出Python交互式环境。  在Windows上运行Python时，请先启动命令行，然后运行python。  在Mac和Linux上运行Python时，请打开终端，然后运行python3。</code></pre></li></ul><hr><p>python解释器</p><pre><code>当我们编写Python代码时，我们得到的是一个包含Python代码的以.py为扩展名的文本文件。要运行代码，就需要Python解释器去执行.py文件。由于整个Python语言从规范到解释器都是开源的，所以理论上，只要水平够高，任何人都可以编写Python解释器来执行Python代码（当然难度很大）。事实上，确实存在多种Python解释器。</code></pre><ul><li><p>CPython</p><pre><code>  当我们从Python官方网站下载并安装好Python 3.5后，我们就直接获得了一个官方版本的解释器：CPython。  这个解释器是用C语言开发的，所以叫CPython。在命令行下运行python就是启动CPython解释器。  CPython是使用最广的Python解释器。教程的所有代码也都在CPython下执行。</code></pre></li><li><p>IPython</p><pre><code>  IPython是基于CPython之上的一个交互式解释器，也就是说，IPython只是在交互方式上有所增强，  但是执行Python代码的功能和CPython是完全一样的。好比很多国产浏览器虽然外观不同，但内核其实都是调用了IE。  CPython用&gt;&gt;&gt;作为提示符，而IPython用In [序号]:作为提示符。</code></pre></li><li><p>PyPy</p><pre><code>  PyPy是另一个Python解释器，它的目标是执行速度。PyPy采用JIT技术，对Python代码进行动态编译（注意不是解释），  所以可以显著提高Python代码的执行速度。  绝大部分Python代码都可以在PyPy下运行，但是PyPy和CPython有一些是不同的，  这就导致相同的Python代码在两种解释器下执行可能会有不同的结果。如果你的代码要放到PyPy下执行，  就需要了解PyPy和CPython的不同点。</code></pre></li><li><p>Jython</p><pre><code>  Jython是运行在Java平台上的Python解释器，可以直接把Python代码编译成Java字节码执行。</code></pre></li><li><p>IronPython</p><pre><code>  IronPython和Jython类似，只不过IronPython是运行在微软.Net平台上的Python解释器，可以直接把Python代码编译成.Net的字节码。</code></pre></li><li><p>小结</p><pre><code>  Python的解释器很多，但使用最广泛的还是CPython。如果要和Java或.Net平台交互，  最好的办法不是用Jython或IronPython，而是通过网络调用来交互，确保各程序之间的独立性。  本教程的所有代码只确保在CPython 3.5版本下运行。请务必在本地安装CPython（也就是从Python官方网站下载的安装程序）。</code></pre></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 cd mkdir</title>
      <link href="/2017/07/14/mei-tian-2-ge-linux-ming-ling-cd-mkdir/"/>
      <url>/2017/07/14/mei-tian-2-ge-linux-ming-ling-cd-mkdir/</url>
      
        <content type="html"><![CDATA[<h2 id="20170714-每天2个Linux命令-cd命令"><a href="#20170714-每天2个Linux命令-cd命令" class="headerlink" title="20170714 每天2个Linux命令  cd命令"></a><center>20170714 每天2个Linux命令  cd命令</center></h2><p>cd命令用来切换工作目录至dirname。 其中dirName表示法可为绝对路径或相对路径。若目录名称省略，则变换至使用者的home directory(也就是刚login时所在的目录)。另外，~也表示为home directory的意思，.则是表示目前所在的目录，..则表示目前目录位置的上一层目录。</p><hr><p>1.用法：</p><pre><code>cd (选项) [目录]</code></pre><p>2.功能：</p><pre><code>切换当前目录至dirName</code></pre><p>3.选项：</p><pre><code>(1) -p    如果要切换到的目标目录是一个符号连接，直接切换到符号连接指向的目标目录(2) -L    如果要切换的目标目录是一个符号的连接，直接切换到字符连接名代表的目录，而非符号连接所指向的目标目录。(3) -     当仅实用"-"一个选项时，当前工作目录将被切换到环境变量"OLDPWD"所表示的目录。</code></pre><p>4.实例：</p><p>(1)  cd 进入用户主目录；cd ~ 进入用户主目录；</p><pre><code>[sunjimeng@localhost ~]$ cd /        /*刚开启terminal终端，是用户的主目录*/   /* “cd /” 进入根目录*/[sunjimeng@localhost /]$ cd          /*cd命令默认进入用户的主目录*/[sunjimeng@localhost ~]$             /*默认的主目录是这样的“~”*/[sunjimeng@localhost ~]$ cd /        /*"cd"命令和"cd ~"可以达到一样的功能*/[sunjimeng@localhost /]$ cd ~[sunjimeng@localhost ~]$ </code></pre><p>(2) cd - 返回进入此目录之前所在的目录；</p><pre><code>复制代码[sunjimeng@localhost /]$ cd /home/sunjimeng                  /*由根目录进入用户目录*/[sunjimeng@localhost ~]$ ll                                  //列出用户目录下的目录及文件total 0drwxr-xr-x. 2 sunjimeng sunjimeng 6 May  1 01:23 Desktopdrwxr-xr-x. 2 sunjimeng sunjimeng 6 May  1 01:23 Documentsdrwxr-xr-x. 2 sunjimeng sunjimeng 6 May  1 01:23 Downloadsdrwxr-xr-x. 2 sunjimeng sunjimeng 6 May  1 01:23 Musicdrwxr-xr-x. 2 sunjimeng sunjimeng 6 May  1 01:23 Picturesdrwxr-xr-x. 2 sunjimeng sunjimeng 6 May  1 01:23 Publicdrwxr-xr-x. 2 sunjimeng sunjimeng 6 May  1 01:23 Templatesdrwxr-xr-x. 2 sunjimeng sunjimeng 6 May  1 01:23 Videos[sunjimeng@localhost ~]$ cd Desktop       //选择进入Desktop文件夹[sunjimeng@localhost Desktop]$ cd -      //"cd -"命令功能：（1）输出之前的目录名称；（2）返回之前的目录。/home/sunjimeng </code></pre><p>(3) cd .. 返回上级目录（若当前目录为“/“，则执行完后还在“/“；”..”为上级目录的意思）；cd ../.. 返回上两级目录；</p><pre><code>[sunjimeng@localhost /]$ cd ..                       //在根目录下返回上一级目录，依然是根目录[sunjimeng@localhost /]$ cd /home/sunjimeng/Desktop  //进入自定义文件夹[sunjimeng@localhost Desktop]$ cd ..                 //返回上一级 /home/sunjimeng，即用户主目录[sunjimeng@localhost ~]$ cd ../..                    //返回上两级目录[sunjimeng@localhost /]$</code></pre><p> (4) cd !$ 把上个命令的参数作为cd参数使用。</p><pre><code>[sunjimeng@localhost ~]$ cd /home/sunjimeng/Desktop  //进入用户主目录的桌面文件夹[sunjimeng@localhost Desktop]$ cd !$     //cd !$功能：（1）打印这个命令的解释；（2）执行这个命令cd /home/sunjimeng/Desktop[sunjimeng@localhost Desktop]$ [sunjimeng@localhost Desktop]$ cd ..[sunjimeng@localhost ~]$ cd !$cd ..[sunjimeng@localhost home]$</code></pre><h2 id="20170714-每天2个Linux命令-mkdir命令命令"><a href="#20170714-每天2个Linux命令-mkdir命令命令" class="headerlink" title=" 20170714 每天2个Linux命令  mkdir命令命令"></a><center> 20170714 每天2个Linux命令  mkdir命令命令</center></h2><p>mkdir命令用来创建目录。</p><hr><p>(1)用法:   </p><pre><code>用法: mkdir [选项]... 目录...</code></pre><p>(2)功能：</p><pre><code>功能: 若指定目录不存在则创建目录该命令创建由dirname命名的目录。如果在目录名的前面没有加任何路径名，则在当前目录下创建由dirname指定的目录；&lt;br/&gt;如果给出了一个已经存在的路径，将会在该目录下创建一个指定的目录。在创建目录时，应保证新建的目录与它所在目录下的文件没有重名。</code></pre><p>(3)选项参数</p><pre><code>   1）-Z:      设置安全上下文，当使用SELinux时有效   2) -m:&lt;目标属性&gt;或-mode&lt;目标属性&gt;    建立目录的同时设置目录的权限   3) -p或--parents   若所要建立目录的上层目录目前尚未建立，则会一并建立上层目录   4) -version       显示版本信息</code></pre><p> (4)实例</p><p>1)[sunjimeng@localhost Documents]$ mkdir mainDir   在当前文件夹下创建一个新文件</p><pre><code>[sunjimeng@localhost Documents]$ ll            //列出当前目录下的文件及文件夹total 0[sunjimeng@localhost Documents]$ mkdir mainDir //新建一个文件[sunjimeng@localhost Documents]$ ll            //查看total 0drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 02:49 mainDir</code></pre><p>2)[sunjimeng@localhost Documents]$ mkdir -v secondDir  在当期那文件夹下下创建一个新文件，并输出提示信息</p><pre><code>[sunjimeng@localhost Documents]$ mkdir -v secondDirmkdir: created directory ‘secondDir’[sunjimeng@localhost Documents]$ </code></pre><p>3)[sunjimeng@localhost Documents]$ mkdir -p thirdDir/{test1,test2,test3}   <br>在当前文件夹下创建一个新文夹，而且包含多个子文件夹复制代码</p><pre><code>[sunjimeng@localhost Documents]$ mkdir -p thirdDir/{test1,test2,test3}  //新建包含多个子文件夹的文件夹[sunjimeng@localhost Documents]$ ll   //查看当前工作目录下有的文件及文件夹，以详细信息输出total 0drwxrwxr-x. 2 sunjimeng sunjimeng  6 May  1 02:49 mainDirdrwxrwxr-x. 2 sunjimeng sunjimeng  6 May  1 02:52 secondDirdrwxrwxr-x. 5 sunjimeng sunjimeng 42 May  1 02:57 thirdDir[sunjimeng@localhost Documents]$ cd thirdDir  //进入目录[sunjimeng@localhost thirdDir]$ ll    //查看目录下的子目录total 0drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 02:57 test1drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 02:57 test2drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 02:57 test3[sunjimeng@localhost thirdDir]$ [sunjimeng@localhost Documents]$ ll                                 //查看Document文件夹下的文件及文件夹total 0drwxrwxr-x. 2 sunjimeng sunjimeng  6 May  1 02:49 mainDirdrwxrwxr-x. 2 sunjimeng sunjimeng  6 May  1 02:52 secondDirdrwxrwxr-x. 5 sunjimeng sunjimeng 42 May  1 03:01 thirdDir[sunjimeng@localhost Documents]$ mkdir thirdDir/{test4,test5,test6}//虽然已经存在了thirdDir文件夹，但丝毫不影响这个操作[sunjimeng@localhost Documents]$ ll                      total 0drwxrwxr-x. 2 sunjimeng sunjimeng  6 May  1 02:49 mainDirdrwxrwxr-x. 2 sunjimeng sunjimeng  6 May  1 02:52 secondDirdrwxrwxr-x. 8 sunjimeng sunjimeng 78 May  1 03:01 thirdDir[sunjimeng@localhost Documents]$ cd thirdDir[sunjimeng@localhost thirdDir]$ ll                                //因为新建的重名文件夹下的子文件夹集将可以添加到已有重名文件夹下total 0drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 02:57 test1drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 02:57 test2drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 02:57 test3drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 03:01 test4drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 03:01 test5drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 03:01 test6</code></pre><p>4)[sunjimeng@localhost Documents]$ mkdir -m 700 /home/sunjimeng/Document 在指定路径下创建文件夹，并且只有文件主有读、写和执行权限，其他人无权问。</p><pre><code>复制代码[sunjimeng@localhost Documents]$ mkdir -m 700 /home/sunjimeng/Document[sunjimeng@localhost Documents]$ cd /home/sunjimeng[sunjimeng@localhost ~]$ lltotal 0drwxr-xr-x. 2 sunjimeng sunjimeng  6 May  1 01:23 Desktopdrwx------. 2 sunjimeng sunjimeng  6 May  1 03:07 Document     //这一项即为所新建的文件夹drwxr-xr-x. 5 sunjimeng sunjimeng 51 May  1 02:57 Documentsdrwxr-xr-x. 2 sunjimeng sunjimeng  6 May  1 01:23 Downloadsdrwxr-xr-x. 2 sunjimeng sunjimeng  6 May  1 01:23 Musicdrwxr-xr-x. 2 sunjimeng sunjimeng  6 May  1 01:23 Picturesdrwxr-xr-x. 2 sunjimeng sunjimeng  6 May  1 01:23 Publicdrwxr-xr-x. 2 sunjimeng sunjimeng  6 May  1 01:23 Templatesdrwxr-xr-x. 2 sunjimeng sunjimeng  6 May  1 01:23 Videos复制代码</code></pre><p> 5)[sunjimeng@localhost Document]$ mkdir -pm 750 bin/os_1 在当前目录中建立bin和bin下的os_1目录，权限设置为文件主可读、写、执行，同组用户可读和执行，其他用户无权访问</p><pre><code>复制代码[sunjimeng@localhost Document]$ mkdir -pm 750 bin/os_1[sunjimeng@localhost Document]$ lltotal 0drwxrwxr-x. 3 sunjimeng sunjimeng 17 May  1 03:13 bin[sunjimeng@localhost Document]$ cd bin[sunjimeng@localhost bin]$ lltotal 0drwxr-x---. 2 sunjimeng sunjimeng 6 May  1 03:13 os_1[sunjimeng@localhost bin]$  </code></pre><p>6)[sunjimeng@localhost Document]$ mkdir –version    显示mkdir的版本信息</p><pre><code>复制代码[sunjimeng@localhost Document]$ mkdir --versionmkdir (GNU coreutils) 8.22Copyright (C) 2013 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;.This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Written by David MacKenzie.</code></pre><p> 7)[sunjimeng@localhost Document]$ mkdir –parents Father/Child  与  mkdir -p Father/Child的效果是一样的   同理 -m等同于–mood</p><pre><code>复制代码[sunjimeng@localhost Document]$ mkdir --parents Father/Child[sunjimeng@localhost Document]$ lltotal 0drwxrwxr-x. 3 sunjimeng sunjimeng 17 May  1 03:13 bindrwxrwxr-x. 3 sunjimeng sunjimeng 18 May  1 03:21 Father[sunjimeng@localhost Document]$ cd Father[sunjimeng@localhost Father]$ lltotal 0drwxrwxr-x. 2 sunjimeng sunjimeng 6 May  1 03:21 Child[sunjimeng@localhost Father]$ </code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring概述、IOC、DI</title>
      <link href="/2017/07/13/spring-gai-shu-ioc-di/"/>
      <url>/2017/07/13/spring-gai-shu-ioc-di/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-13-spring基础day01-1"><a href="#2017-07-13-spring基础day01-1" class="headerlink" title="2017.07.13 spring基础day01_1"></a><center>2017.07.13 spring基础day01_1</center></h2><p>struts：web层，比较简单（ValueStack值栈，拦截器） <br><br>hibernate：dao层，知识点杂 <br><br>spring：service层，重要，讲多少用多少  –&gt; 【了解】  <br></p><p><img src="/images/20170713/1.png"></p><p>spring day01：基础（IoC控制反转、DI依赖注入）、整合Junit、整合web <br><br>spring day02：AOP切面编程、JdbcTemplate <br><br>spring day03：事务管理、SSH整合 <br></p><hr><ol><li><p><strong>spring框架概述</strong> <br><br> 1.1 <strong>什么是spring</strong><br></p><pre><code>     * Spring是一个开源框架，Spring是于2003 年兴起的一个轻量级的Java 开发框架，由Rod Johnson 在其著作Expert One-On-    One     J2EE Development and Design中阐述的部分理念和原型衍生而来。它是为了解决企业应用开发的复杂性而创建    的。框架的主要优    势之一就是其分层架构，分层架构允许使用者选择使用哪一个组件，同时为 J2EE 应用程序开发提供集成的    框架。Spring使用基本的    JavaBean来完成以前只可能由EJB完成的事情。然而，Spring的用途不仅限于服务器端的开发。    从简单性、可测试性和松耦合的角度    而言，任何Java应用都可以从Spring中受益。Spring的核心是控制反转（IoC）和面    向切面（AOP）。简单来说，Spring是一个分层    的JavaSE/EE full-stack(一站式) 轻量级开源框架&lt;br/&gt;     *     轻量级：与EJB对比，依赖资源少，销毁的资源少。&lt;br/&gt;     *     分层： 一站式，每一个层都提供的解决方案&lt;br/&gt;         web层：struts，spring-MVC&lt;br/&gt;         service层：spring&lt;br/&gt;         dao层：hibernate，mybatis ， jdbcTemplate  --&gt; spring-data&lt;br/&gt;</code></pre><p> 1.2 <strong>spring由来</strong><br></p><pre><code>     *    Expert One-to-One J2EE Design and Development &lt;br/&gt;     *    Expert One-to-One J2EE Development without EJB</code></pre><p> 1.3 <strong>spring核心</strong><br></p><pre><code>     *  Spring的核心是控制反转（IoC）和面向切面（AOP）</code></pre><p> 1.4 <strong>spring优点</strong><br></p><pre><code>     *    方便解耦，简化开发  （高内聚低耦合）&lt;br/&gt;         *    Spring就是一个大工厂（容器），可以将所有对象创建和依赖关系维护，交给Spring管理&lt;br/&gt;         *    spring工厂是用于生成bean&lt;br/&gt;     *   AOP编程的支持&lt;br/&gt;         *    Spring提供面向切面编程，可以方便的实现对程序进行权限拦截、运行监控等功能&lt;br/&gt;     *    声明式事务的支持&lt;br/&gt;         *    只需要通过配置就可以完成对事务的管理，而无需手动编程&lt;br/&gt;     *    方便程序的测试&lt;br/&gt;         *    Spring对Junit4支持，可以通过注解方便的测试Spring程序&lt;br/&gt;     *    方便集成各种优秀框架&lt;br/&gt;         *    Spring不排斥各种优秀的开源框架，其内部提供了对各种优秀框架（如：Struts、Hibernate、MyBatis、Quartz等）的直接支持&lt;br/&gt;     *    降低JavaEE API的使用难度&lt;br/&gt;     *    Spring 对JavaEE开发中非常难用的一些API（JDBC、JavaMail、远程调用等），都提供了封装，使这些API应用难度大大降低</code></pre><p> 1.5 <strong>spring体系结构</strong><br> <img src="/images/20170713/1.png"></p><pre><code>     核心容器：beans、core、context、expression</code></pre></li><li><p><strong>入门案例：IoC【掌握】</strong><br><br> 2.1 <strong>导入jar包</strong><br></p><pre><code>     4 + 1  ： 4个核心（beans、core、context、expression） + 1个依赖（commons-loggins...jar）</code></pre><p> <img src="/images/20170713/3.png"><br> <img src="/images/20170713/4.png"></p><p> 2.2 <strong>目标类</strong><br></p><pre><code>     *    提供UserService接口和实现类&lt;br/&gt;     *      获得UserService实现类的实例     *      之前开发中，直接new一个对象即可。         学习spring之后，将由Spring创建对象实例--&gt; IoC 控制反转（Inverse of  Control）         之后需要实例对象时，从spring工厂（容器）中获得，需要将实现类的全限定名称配置到xml文件中&lt;br/&gt;     &lt;font color=red&gt;控制反转：就是创建对象的事情由自己反转给了sprig容器&lt;/font&gt;     public interface UserService {         public void addUser();     }     public class UserServiceImpl implements UserService {         @Override         public void addUser() {         System.out.println("a_ico add user");         }     }</code></pre><p> 2.3 <strong>配置文件</strong><br></p><pre><code>     *     位置：任意，开发中一般在classpath下（src）&lt;br/&gt;     *   名称：任意，开发中常用applicationContext.xml&lt;br/&gt;     *   内容：添加schema约束         约束文件位置：spring-framework-3.2.0.RELEASE\docs\spring-framework-reference\html\ xsd-config.html     &lt;?xml version="1.0" encoding="UTF-8"?&gt;     &lt;beans xmlns="http://www.springframework.org/schema/beans"            xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"            xsi:schemaLocation="http://www.springframework.org/schema/beans                        http://www.springframework.org/schema/beans/spring-beans.xsd"&gt;     &lt;!-- 配置service          &lt;bean&gt; 配置需要创建的对象         id ：用于之后从spring容器获得实例时使用的         class ：需要创建实例的全限定类名     --&gt;         &lt;bean id="userServiceId" class="com.itheima.a_ioc.UserServiceImpl"&gt;&lt;/bean&gt;     &lt;/beans&gt;</code></pre><p> 2.4 <strong>测试</strong><br></p><pre><code> @Test public void demo02(){     //从spring容器获得     //1 获得容器     String xmlPath = "com/itheima/a_ioc/beans.xml";     ApplicationContext applicationContext = new ClassPathXmlApplicationContext(xmlPath);     //2获得内容 --不需要自己new，都是从spring容器获得     UserService userService = (UserService) applicationContext.getBean("userServiceId");     userService.addUser(); }</code></pre><p> 2.5 <strong>最终如下图所市</strong><br> <img src="/images/20170713/5.png"></p></li></ol><ol start="3"><li><p><strong>入门案例：DI【掌握】</strong></p><ul><li><p>DI Dependency Injection ,依赖注入 <br><br>  is a ：是一个，继承。<br><br>  has a：有一个，成员变量，依赖。<br></p><pre><code>  class B {&lt;br/&gt;         private A a;   //B类依赖A类&lt;br/&gt;  }&lt;br/&gt;</code></pre><p>  依赖：一个对象需要使用另一个对象<br><br>  注入：通过setter方法进行另一个对象实例设置。<br></p></li><li><p>例如：<br><br>  class BookServiceImpl{<br></p><pre><code>  //之前开发：接口 = 实现类  （service和dao耦合）&lt;br/&gt;  //private BookDao bookDao = new BookDaoImpl();&lt;br/&gt;   //spring之后 （解耦：service实现类使用dao接口，不知道具体的实现类）&lt;br/&gt;  private BookDao bookDao;&lt;br/&gt;  setter方法&lt;br/&gt;</code></pre><p> }<br></p><p>  模拟spring执行过程<br><br>  创建service实例：BookService bookService = new BookServiceImpl()        –&gt;IoC  <bean><br><br>  创建dao实例：BookDao bookDao = new BookDaoImple()                –&gt;IoC<br><br>  将dao设置给service：bookService.setBookDao(bookDao);                –&gt;DI   <property><br></property></bean></p></li></ul><p> 3.1    <strong>目标类</strong><br></p><pre><code> *    创建BookService接口和实现类&lt;br/&gt; *    创建BookDao接口和实现类&lt;br/&gt; *    将dao和service配置 xml文件&lt;br/&gt; *    使用api测试&lt;br/&gt; 3.1.1    dao&lt;br/&gt;         public interface BookDao {             public void addBook();         }         public class BookDaoImpl implements BookDao {             @Override             public void addBook() {             System.out.println("di  add book");             }         } 3.1.2    service</code></pre><p> <img src="/images/20170713/6.png"></p><pre><code>         public interface BookService {             public abstract void addBook();         }         public class BookServiceImpl implements BookService {             // 方式1：之前，接口=实现类         //    private BookDao bookDao = new BookDaoImpl();             // 方式2：接口 + setter             private BookDao bookDao;             public void setBookDao(BookDao bookDao) {                 this.bookDao = bookDao;             }             @Override             public void addBook(){                 this.bookDao.addBook();             }         }</code></pre><p> 3.2    <strong>配置文件</strong><br> <img src="/images/20170713/7.png"></p><pre><code>     &lt;beans xmlns="http://www.springframework.org/schema/beans"            xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"                xsi:schemaLocation="http://www.springframework.org/schema/beans                        http://www.springframework.org/schema/beans/spring-beans.xsd"&gt;             &lt;!--          模拟spring执行过程             创建service实例：BookService bookService = new BookServiceImpl()    IoC  &lt;bean&gt;             创建dao实例：BookDao bookDao = new BookDaoImpl()            IoC             将dao设置给service：bookService.setBookDao(bookDao);        DI   &lt;property&gt;             &lt;property&gt; 用于进行属性注入                 name： bean的属性名，通过setter方法获得                     setBookDao ##&gt; BookDao  ##&gt; bookDao                 ref ：另一个bean的id值的引用          --&gt;         &lt;!-- 创建service --&gt;         &lt;bean id="bookServiceId" class="com.itheima.b_di.BookServiceImpl"&gt;             &lt;property name="bookDao" ref="bookDaoId"&gt;&lt;/property&gt;         &lt;/bean&gt;         &lt;!-- 创建dao实例 --&gt;         &lt;bean id="bookDaoId" class="com.itheima.b_di.BookDaoImpl"&gt;&lt;/bean&gt;</code></pre></li></ol><pre><code>        &lt;/beans&gt;3.3    **测试**        @Test        public void demo01(){            //从spring容器获得            String xmlPath = "com/itheima/b_di/beans.xml";            ApplicationContext applicationContext = new ClassPathXmlApplicationContext(xmlPath);            BookService bookService = (BookService) applicationContext.getBean("bookServiceId");            bookService.addBook();        }3.4 **最终目录结构**</code></pre><p><img src="/images/20170713/8.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
            <tag> IOC </tag>
            
            <tag> DI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>每天2个Linux命令 ls su</title>
      <link href="/2017/07/13/mei-tian-2-ge-linux-ming-ling-ls-su/"/>
      <url>/2017/07/13/mei-tian-2-ge-linux-ming-ling-ls-su/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-13-每天2个Linux命令（1）-ls命令"><a href="#2017-07-13-每天2个Linux命令（1）-ls命令" class="headerlink" title="2017.07.13  每天2个Linux命令（1）  ls命令"></a><center>2017.07.13  每天2个Linux命令（1）  ls命令</center></h2><ul><li>ls是list的缩写，ls命令是Linux系统下最常用的命令之一</li><li>ls命令用于打印当前目录的清单，如果指定其它目录，那么就会显示其他目录的文件及文件夹的清单。 通过ls 命令还可以查看文件其它的详细信息</li><li>ls命令的输出信息可以进行彩色加亮显示，以分区不同类型的文件</li></ul><hr><ol><li><strong>用法：</strong><br><br> ls  [选项]   [目录名]</li><li><strong>功能：</strong><br><br> ls - list directory contents<br> 列出目标目录中所有的子目录和文件。</li><li><strong>常用选项参数：<br></strong><pre><code> 1) -a  列出目录下的所有文件，包括以 . 开头的隐含文件。&lt;br/&gt; 2) -A  列出除. (当前目录)及..（当前目录的父目录）以外的任何项目。&lt;br/&gt; 3) -l  所有输出信息用单列格式输出，每行只列出一个文件，不输出为多列。-l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。&lt;br/&gt; 4) -R(–recursive) 递归列出所有子目录层。&lt;br/&gt;  5) -i  显示文件索引节点号（inode），一个索引节点代表一个文件。&lt;br/&gt; 6) -d(–directory) 将目录像文件一样显示，而不是显示其下的文件。&lt;br/&gt; 7) -h  以可以理解的方式显示出文件的大小&lt;br/&gt;</code></pre></li><li><strong>常用实例:  <br></strong></li></ol><hr><pre><code>    1)    ls -l  等价于 ll 以单行单个的形式列出/root目录下的文件的所有信息        drwx------  18 root root  4096 Jul 13 10:31 ./&lt;br/&gt;        drwxr-xr-x  24 root root  4096 May 24 23:00 ../&lt;br/&gt;        -rw-------   1 root root  3093 Jul 13 18:44 .bash_history&lt;br/&gt;        -rw-r--r--   1 root root  3106 Oct 23  2015 .bashrc&lt;br/&gt;        ....等等        上面显示的意思的格式是：        文件类型 文件权限 文件硬链接的次数 文件的属主(owner)  文件的属组(group) 文件大小(size)，单位是字节 时间戳()：最近一次被修改的时间        文件类型的分类：            -：普通文件 (f)                d: 目录文件                                             b: 块设备文件 (block)                               c: 字符设备文件 (character)            l: 符号链接文件(symbolic link file)            p: 命令管道文件(pipe)            s: 套接字文件(socket)        文件权限的划分：9位，每3位一组，每一组：rwx(读，写，执行), r--        时间戳(timestamp)：                访问时间:access            修改时间:modify，文件内容发生了改变                改变时间:change，metadata，元数据</code></pre><hr><pre><code>    2)    ls -R  递归地显示出当前工作目录下所有的文件信息        config-3.10.0-229.el7.x86_64                             initrd-plymouth.img        grub                                                     symvers-3.10.0-229.el7.x86_64.gz        grub2                                                    System.map-3.10.0-229.el7.x86_64        initramfs-0-rescue-35667f30fcac420f933d23d8835c4cf3.img  vmlinuz-0-rescue-35667f30fcac420f933d23d8835c4cf3        initramfs-3.10.0-229.el7.x86_64.img                      vmlinuz-3.10.0-229.el7.x86_64        ...等等</code></pre><hr><pre><code>    3）ls -R boot/grub2    递归的显示出指定文件目录的下的所有文件        boot/grub2:        device.map  fonts  grub.cfg  grubenv  i386-pc  locale  themes        boot/grub2/fonts:        unicode.pf2        boot/grub2/i386-pc:        acpi.mod              date.mod             gcry_twofish.mod          mdraid09_be.mod  password.mod         test_blockarg.mod        adler32.mod           datetime.mod         gcry_whirlpool.mod        mdraid09.mod     password_pbkdf2.mod  testload.mod        ...等等</code></pre><hr><pre><code>    4） ls -tl    按修改时间排序输出文件的详细信息        总用量 4588        drwxr-xr-x. 2 root      root         4096 4月  26 03:38 empty        drwxr-xr-x. 2 root      root           32 4月  22 22:29 text        drwxr-xr-x. 2 sunjimeng sunjimeng       6 4月  19 03:30 公共        drwxr-xr-x. 2 sunjimeng sunjimeng       6 4月  19 03:30 模板        drwxr-xr-x. 2 sunjimeng sunjimeng       6 4月  19 03:30 视频        drwxr-xr-x. 2 sunjimeng sunjimeng       6 4月  19 03:30 图片        drwxr-xr-x. 2 sunjimeng sunjimeng       6 4月  19 03:30 文档        drwxr-xr-x. 2 sunjimeng sunjimeng       6 4月  19 03:30 下载        drwxr-xr-x. 2 sunjimeng sunjimeng       6 4月  19 03:30 音乐        drwxr-xr-x. 2 sunjimeng sunjimeng       6 4月  19 03:30 桌面</code></pre><hr><pre><code>    5) ls -ihl     详细地输出文件的索引号(-i)和文件的大小(-h)，索引号即每个文件的inode号        总用量 4.5M          2843373 -rw-------. 1 sunjimeng sunjimeng 4.5M 4月  14 21:54 core.3246        272893290 drwxr-xr-x. 2 root      root      4.0K 4月  26 03:38 empty        406101499 drwxr-xr-x. 2 root      root        32 4月  22 22:29 text          2504431 drwxr-xr-x. 2 sunjimeng sunjimeng    6 4月  19 03:30 公共        406095911 drwxr-xr-x. 2 sunjimeng sunjimeng    6 4月  19 03:30 模板          2504433 drwxr-xr-x. 2 sunjimeng sunjimeng    6 4月  19 03:30 视频        406095912 drwxr-xr-x. 2 sunjimeng sunjimeng    6 4月  19 03:30 图片        136673997 drwxr-xr-x. 2 sunjimeng sunjimeng    6 4月  19 03:30 文档        270959540 drwxr-xr-x. 2 sunjimeng sunjimeng    6 4月  19 03:30 下载        270959541 drwxr-xr-x. 2 sunjimeng sunjimeng    6 4月  19 03:30 音乐        136673996 drwxr-xr-x. 2 sunjimeng sunjimeng    6 4月  19 03:30 桌面</code></pre><hr><pre><code>    6)  ls -dl     只显示当前目录，而不显示当前目录下的文件，把当前目录当作文件一样显示        drwx------. 16 sunjimeng sunjimeng 4096 4月  29 00:36 .</code></pre><hr><pre><code>    7) ls -a与  ls -A的比较        [root@localhost sunjimeng]# ls -a        .              .bash_profile  .core.3246.swp    .local            公共  下载        ..             .bashrc        empty             .mozilla          模板  音乐        .1.log.swp     .cache         .esd_auth         .serverauth.3770  视频  桌面        .bash_history  .config        .hellow.java.swp  text              图片        .bash_logout   core.3246      .ICEauthority     .viminfo          文档        [root@localhost sunjimeng]# ls -A        .1.log.swp     .cache          .esd_auth         .serverauth.3770  视频  桌面        .bash_history  .config         .hellow.java.swp  text              图片        .bash_logout   core.3246       .ICEauthority     .viminfo          文档        .bash_profile  .core.3246.swp  .local            公共              下载        .bashrc        empty           .mozilla          模板              音乐        可以很清晰的看到ls -A 比 ls -a 少了 . 和 ..</code></pre><ol start="5"><li><p><strong>其他</strong><br><br> 显示彩色目录列表</p><p> 打开/etc/bashrc, 加入如下一行:</p><p> alias ls=”ls –color”</p><p> 下次启动bash时就可以像在Slackware里那样显示彩色的目录列表了, 其中颜色的含义如下:</p><ol><li><p>蓝色–&gt;目录</p></li><li><p>绿色–&gt;可执行文件</p></li><li><p>红色–&gt;压缩文件</p></li><li><p>浅蓝色–&gt;链接文件</p></li><li><p>灰色–&gt;其他文件</p></li></ol></li><li><p><strong>常用的命令：</strong></p><ul><li>-l：长格式显示   ls  -l</li><li>-h：做单位转换   ls  -h</li><li>-a: 显示以.开头的隐藏文件  ls -a</li><li>-A 不包含.和..  ls -A</li><li>-d: 显示目录自身属性</li><li>-i: index node, inode  (ls -i )</li><li>-r: 逆序显示  (ls -r /root)</li><li>-R: 递归(recursive)显示 (ls -R /root) </li></ul></li></ol><h2 id="2017-07-13-每天2个Linux命令（2）-su命令"><a href="#2017-07-13-每天2个Linux命令（2）-su命令" class="headerlink" title="2017.07.13  每天2个Linux命令（2）  su命令"></a><center>2017.07.13  每天2个Linux命令（2）  su命令</center></h2><ol><li><strong>命令用法</strong><br><pre><code>     su [-fmp] [-c command] [-s shell] [--help] [--version] [-] [USER [ARG]]</code></pre></li><li><strong>功能:</strong><br><pre><code>     su的作用是变更为其它使用者的身份，超级用户除外，需要键入该使用者的密码。</code></pre></li><li><strong>参数说明</strong><br><pre><code>     1) -f ， –fast：不必读启动文件（如 csh.cshrc 等），仅用于csh或tcsh两种Shell。&lt;br/&gt;     2) -l ， –login：加了这个参数之后，就好像是重新登陆一样，大部分环境变量(例如HOME、SHELL和USER等)都是以该使用者(USER)为主，并             且工作目录也会改变。如果没有指定USER，缺省情况是root。&lt;br/&gt;     3) -m， -p ，–preserve-environment：执行su时不改变环境变数&lt;br/&gt;     4) -c command：变更账号为USER的使用者，并执行指令（command）后再变回原来使用者&lt;br/&gt;     5) –help 显示说明文件&lt;br/&gt;     6) –version 显示版本资讯&lt;br/&gt;     7) USER：欲变更的使用者账号， ARG:  传入新的Shell参数。&lt;br/&gt;</code></pre></li><li><strong>常用实例:</strong><br></li></ol><hr><pre><code>    su -c ls root 变更帐号为 root 并在执行 ls 指令后退出变回原使用者。    su [用户名]    a&gt;在root用户下, 输入 su 普通用户. 则切换至普通用户, 从root切换到变通用户不需要密码    b&gt;在普通用户下, 输入 su [用户名]    提示 password:    输入用户的PASSWORD, 则切换至该用户</code></pre><ol start="5"><li><strong>扩展阅读一:</strong>:Linux下 su命令与su - 命令有什么区别？<br></li></ol><hr><pre><code>    su 是切换到其他用户，但是不切换环境变量（比如说那些export命令查看一下，就知道两个命令的区别了）    su - 是完整的切换到一个用户环境    所以建议大家切换用户的时候,尽量使用 su -  linuxso 这样 否则可能发现某些命令执行不了</code></pre><ol start="6"><li>**扩展阅读二:**su和sudo的区别?<br></li></ol><hr><pre><code>    由于su 对切换到超级权限用户root后，权限的无限制性，所以su并不能担任多个管理员所管理的系统。如果用su 来切换到超级用户来管理系统，也不能明确哪些工作是由哪个管理员进行的操作。特别是对于服务器的管理有多人参与管理时，最好是针对每个管理员的技术特长和 管理范围，并且有针对性的下放给权限，并且约定其使用哪些工具来完成与其相关的工作，这时我们就有必要用到 sudo。    通过sudo，我们能把某些超级权限有针对性的下放，并且不需要普通用户知道root密码，所以sudo 相对于权限无限制性的su来说，还是比较安全的，所以sudo 也能被称为受限制的su ；另外sudo 是需要授权许可的，所以也被称为授权许可的su；    sudo 执行命令的流程是当前用户切换到root（或其它指定切换到的用户），然后以root（或其它指定的切换到的用户）身份执行命令，执行完成后，直接退回到当前用户；而这些的前提是要通过sudo的配置文件/etc/sudoers来进行授权；</code></pre><ol start="7"><li><strong>常用的命令：</strong> <br></li></ol><hr><pre><code>    * （su -l  dengtao） (exit）  exit  退出</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> linux每天2个命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python简介</title>
      <link href="/2017/07/13/python-jian-jie/"/>
      <url>/2017/07/13/python-jian-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="2017-07-13-python简介"><a href="#2017-07-13-python简介" class="headerlink" title="2017.07.13  python简介"></a><center>2017.07.13  python简介</center></h2><ol start="0"><li><p>Python是一种计算机程序设计语言。你可能已经听说过很多种流行的编程语言，比如非常难学的C语言，非常流行的Java语言，适合初学者的Basic语言，适合网页编程的JavaScript语言等等</p></li><li><p>那Python是一种什么语言？</p><ol><li>我们普及一下编程语言的基础知识。用任何编程语言来开发程序，都是为了让计算机干活，比如下载一个MP3，编写一个文档等等，而计算机干活的CPU只认识机器指令，所以，尽管不同的编程语言差异极大，最后都得“翻译”成CPU可以执行的机器指令。而不同的编程语言，干同一个活，编写的代码量，差距也很大</li><li>比如，完成同一个任务，C语言要写1000行代码，Java只需要写100行，而Python可能只要20行</li><li>所以Python是一种相当高级的语言</li></ol></li><li><p>用Python可以做什么？</p><p> 可以做日常任务，比如自动备份你的MP3；可以做网站，很多著名的网站包括YouTube就是Python写的；可以做网络游戏的后台，很多在线游戏的后台都是Python开发的。总之就是能干很多很多事啦。</p></li><li><p>Python不能做什么？</p><p> 比如写操作系统，这个只能用C语言写；写手机应用，只能用Swift/Objective-C（针对iPhone）和Java（针对Android）；写3D游戏，最好用C或C++。     </p></li><li><p>Python是著名的“龟叔”Guido van Rossum在1989年圣诞节期间，为了打发无聊的圣诞节而编写的一个编程语言</p></li></ol><ol start="5"><li><p>现在，全世界差不多有600多种编程语言，但流行的编程语言也就那么20来种。<br><br> 如果你听说过TIOBE排行榜，你就能知道编程语言的大致流行程度<br><br> 总的来说，这几种编程语言各有千秋。C语言是可以用来编写操作系统的贴近硬件的语言，<br><br> 所以，C语言适合开发那些追求运行速度、充分发挥硬件性能的程序。而Python是用来编写应用程序的高级编程语言。</p></li><li><p>当你用一种语言开始作真正的软件开发时，你除了编写代码外，还需要很多基本的已经写好的现成的东西，来帮助你加快开发进度。比如说，要编    写一个电子邮件客户端，如果先从最底层开始编写网络协议相关的代码，那估计一年半载也开发不出来。高级编程语言通常都会提供一个比较完    善的基础代码库，让你能直接调用，比如，针对电子邮件协议的SMTP库，针对桌面环境的GUI库，在这些已有的代码库的基础上开发，一个电子    邮件客户端几天就能开发出来。</p><p> Python就为我们提供了非常完善的基础代码库，覆盖了网络、文件、GUI、数据库、文本等大量内容，被形象地称作“内置电池（batteries included）”。用Python开发，许多功能不必从零编写，直接使用现成的即可。</p><p> 除了内置的库外，Python还有大量的第三方库，也就是别人开发的，供你直接使用的东西。当然，如果你开发的代码通过很好的封装，也可以作为第三方库给别人使用。</p><p> 许多大型网站就是用Python开发的，例如YouTube、Instagram，还有国内的豆瓣。很多大公司，包括Google、Yahoo等，甚至NASA（美国航空航天局）都大量地使用Python。</p><p> 龟叔给Python的定位是“优雅”、“明确”、“简单”，所以Python程序看上去总是简单易懂，初学者学Python，不但入门容易，而且将来深入下去，可以编写那些非常非常复杂的程序。</p><p> 总的来说，Python的哲学就是简单优雅，尽量写容易看明白的代码，尽量写少的代码。如果一个资深程序员向你炫耀他写的晦涩难懂、动不动就几万行的代码，你可以尽情地嘲笑他。</p></li><li><p>那Python适合开发哪些类型的应用呢？<br> 首选是网络应用，包括网站、后台服务等等；</p><p> 其次是许多日常需要的小工具，包括系统管理员需要的脚本任务等等；</p><p> 另外就是把其他语言开发的程序再包装起来，方便使用。</p></li><li><p>最后说说Python的缺点</p><ol><li><p>第一个缺点就是运行速度慢，和C程序相比非常慢，因为Python是解释型语言，你的代码在执行时会一行一行地翻译成CPU能理解的机器码，<br><br> 这个翻译过程非常耗时，所以很慢。而C程序是运行前直接编译成CPU能执行的机器码，所以非常快。</p><p> 但是大量的应用程序不需要这么快的运行速度，因为用户根本感觉不出来。<br>例如开发一个下载MP3的网络应用程序，C程序的运行时间需要0.001秒，而Python程序的运行时间需要0.1秒，慢了100倍，但由于网络更慢，需要等待1秒，你想，用户能感觉到1.001秒和1.1秒的区别吗？<br>这就好比F1赛车和普通的出租车在北京三环路上行驶的道理一样，虽然F1赛车理论时速高达400公里，但由于三环路堵车的时速只有20公里，因此，作为乘客，你感觉的时速永远是20公里。</p></li><li><p>第二个缺点就是代码不能加密。如果要发布你的Python程序，实际上就是发布源代码，这一点跟C语言不同，C语言不用发布源代码，<br>只需要    把编译后的机器码（也就是你在Windows上常见的xxx.exe文件）发布出去。要从机器码反推出C代码是不可能的，所以，凡是编译型的语言，都没有这个问题，而解释型的语言，则必须把源码发布出去。</p><p> 这个缺点仅限于你要编写的软件需要卖给别人挣钱的时候。<br>好消息是目前的互联网时代，靠卖软件授权的商业模式越来越少了，靠网站和移动应用卖服务的模式越来越多了，后一种模式不需要把源码给别人。</p><p> 再说了，现在如火如荼的开源运动和互联网自由开放的精神是一致的，互联网上有无数非常优秀的像Linux一样的开源代码，我们千万不要高估自己写的代码真的有非常大的“商业价值”。<br>那些大公司的代码不愿意开放的更重要的原因是代码写得太烂了，一旦开源，就没人敢用他们的产品了。</p></li></ol></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
